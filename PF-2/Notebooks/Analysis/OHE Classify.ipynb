{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PF - OHE Classify",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AzfXz1MJvgC"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUy6JNRJp2X"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d jackstapleton/petfinder-pf-nc-ua-all-dataset\n",
        "\n",
        "!mkdir ~/.data\n",
        "!unzip -q petfinder-pf-nc-ua-all-dataset.zip -d /.data\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iArOU6tJyMy"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NEr1Rv-Jytn"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp8ZmyO4J1VR"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import re\n",
        "import pickle\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.nn.utils import weight_norm as WN\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from time import time\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rf1OwHaJ3kF"
      },
      "source": [
        "## Constants and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm8L6g3WJ5Td"
      },
      "source": [
        "SEED = 49\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PATH = \"/.data\"\n",
        "\n",
        "verbose = True\n",
        "DEBUG = False\n",
        "\n",
        "# sc_y = StandardScaler()\n",
        "ohe = OneHotEncoder()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1x_qFtmJ77_"
      },
      "source": [
        "def breaker(num=50, char=\"*\") -> None:\n",
        "    print(\"\\n\" + num*char + \"\\n\")\n",
        "\n",
        "\n",
        "def get_targets() -> np.ndarray:\n",
        "    df = pd.read_csv(\"/content/gdrive/My Drive/train.csv\", engine=\"python\")\n",
        "    targets = df[\"Pawpularity\"].copy().values\n",
        "    oh_targets = targets.copy()\n",
        "    oh_targets = ohe.fit_transform(oh_targets.reshape(-1, 1))\n",
        "    oh_targets = oh_targets.todense()\n",
        "    return targets, oh_targets\n",
        "\n",
        "\n",
        "def show_graphs(L: list, title=None) -> None:\n",
        "    TL, VL = [], []\n",
        "    for i in range(len(L)):\n",
        "        TL.append(L[i][\"train\"])\n",
        "        VL.append(L[i][\"valid\"])\n",
        "    x_Axis = np.arange(1, len(L) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(x_Axis, TL, \"r\", label=\"train\")\n",
        "    plt.plot(x_Axis, VL, \"b\", label=\"valid\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    if title:\n",
        "        plt.title(\"{} Loss\".format(title))\n",
        "    else:\n",
        "        plt.title(\"Loss\")\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHIEDbzxJ9oF"
      },
      "source": [
        "## Dataset Template and BuildDataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqBx-KAYKAWv"
      },
      "source": [
        "class DS(Dataset):\n",
        "    def __init__(self, features=None, targets=None):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.features[idx]), torch.FloatTensor(self.targets[idx])\n",
        "    \n",
        "\n",
        "def build_dataloaders(tr_features: np.ndarray, va_features: np.ndarray,\n",
        "                      tr_targets: np.ndarray, va_targets: np.ndarray,\n",
        "                      batch_size: int, seed: int):\n",
        "\n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Building Train and Validation DataLoaders ...\")\n",
        "    \n",
        "    tr_data_setup = DS(features=tr_features, targets=tr_targets)\n",
        "    va_data_setup = DS(features=va_features, targets=va_targets)\n",
        "    \n",
        "    dataloaders = {\n",
        "        \"train\" : DL(tr_data_setup, batch_size=batch_size, shuffle=True, generator=torch.manual_seed(seed)),\n",
        "        \"valid\" : DL(va_data_setup, batch_size=batch_size, shuffle=False)\n",
        "    }\n",
        "    \n",
        "    return dataloaders"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPI2vrMBLdt2"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUMkH6vTLc7Q"
      },
      "source": [
        "def build_model(IL: int, seed: int):\n",
        "    class ANN(nn.Module):\n",
        "        def __init__(self, IL=None):\n",
        "            super(ANN, self).__init__()\n",
        "\n",
        "            self.classifier = nn.Sequential()\n",
        "            self.classifier.add_module(\"BN\", nn.BatchNorm1d(num_features=IL, eps=1e-5))\n",
        "            self.classifier.add_module(\"FC\", WN(nn.Linear(in_features=IL, out_features=100)))\n",
        "\n",
        "        def get_optimizer(self, lr=1e-3, wd=0):\n",
        "            params = [p for p in self.parameters() if p.requires_grad]\n",
        "            return optim.Adam(params, lr=lr, weight_decay=wd)\n",
        "\n",
        "        def get_plateau_scheduler(self, optimizer=None, patience=5, eps=1e-8):\n",
        "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=patience, eps=eps, verbose=True)\n",
        "\n",
        "        def forward(self, x1, x2=None):\n",
        "            if x2 is not None:\n",
        "                return self.classifier(x1), self.classifier(x2)\n",
        "            else:\n",
        "                return self.classifier(x1)\n",
        "    \n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Building Model ...\")\n",
        "        print(\"\\n{} -> 1\".format(IL))\n",
        "    \n",
        "    torch.manual_seed(seed)\n",
        "    model = ANN(IL=IL)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqIDjeDFMAAU"
      },
      "source": [
        "## Fit and Predict Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOYE-ehwL-xC"
      },
      "source": [
        "def fit(model=None, optimizer=None, scheduler=None, \n",
        "        epochs=None, early_stopping_patience=None,\n",
        "        dataloaders=None, fold=None, verbose=False) -> tuple:\n",
        "    \n",
        "    name = \"./Fold_{}_state.pt\".format(fold)\n",
        "    \n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Training Fold {}...\".format(fold))\n",
        "        breaker()\n",
        "    else:\n",
        "        print(\"Training Fold {}...\".format(fold))\n",
        "\n",
        "    Losses = []\n",
        "    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
        "\n",
        "    start_time = time()\n",
        "    for e in range(epochs):\n",
        "        e_st = time()\n",
        "        epochLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
        "\n",
        "        for phase in [\"train\", \"valid\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            \n",
        "            lossPerPass = []\n",
        "\n",
        "            for X, y in dataloaders[phase]:\n",
        "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    output = model(X)\n",
        "                    loss = torch.nn.BCEWithLogitsLoss()(output, y.squeeze(dim=1))\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                lossPerPass.append(loss.item())\n",
        "            epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
        "        Losses.append(epochLoss)\n",
        "\n",
        "        if early_stopping_patience:\n",
        "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "                bestLoss = epochLoss\n",
        "                BLE = e + 1\n",
        "                torch.save({\"model_state_dict\": model.state_dict(),\n",
        "                            \"optim_state_dict\": optimizer.state_dict()},\n",
        "                           name)\n",
        "                early_stopping_step = 0\n",
        "            else:\n",
        "                early_stopping_step += 1\n",
        "                if early_stopping_step > early_stopping_patience:\n",
        "                    if verbose:\n",
        "                        print(\"\\nEarly Stopping at Epoch {}\".format(e))\n",
        "                    break\n",
        "        \n",
        "        if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "            bestLoss = epochLoss\n",
        "            BLE = e + 1\n",
        "            torch.save({\"model_state_dict\": model.state_dict(),\n",
        "                        \"optim_state_dict\": optimizer.state_dict()},\n",
        "                       name)\n",
        "        \n",
        "        if scheduler:\n",
        "            scheduler.step(epochLoss[\"valid\"])\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Time: {:.2f} seconds\".format(e+1, epochLoss[\"train\"], epochLoss[\"valid\"], time()-e_st))\n",
        "    \n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Best Validation Loss at Epoch {}\".format(BLE))\n",
        "        breaker()\n",
        "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(len(Losses), (time()-start_time)/60))\n",
        "        breaker()\n",
        "        print(\"Training Completed\")\n",
        "        breaker()\n",
        "\n",
        "    return Losses, BLE, name\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "def predict_batch(model=None, dataloader=None, mode=\"test\", path=None) -> np.ndarray:    \n",
        "    model.load_state_dict(torch.load(path, map_location=DEVICE)[\"model_state_dict\"])\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    y_pred = torch.zeros(1, 1).to(DEVICE)\n",
        "\n",
        "    if re.match(r\"valid\", mode, re.IGNORECASE):\n",
        "        for X, _ in dataloader:\n",
        "            X = X.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                output = torch.argmax(model(X), dim=1)\n",
        "            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n",
        "\n",
        "    elif re.match(r\"test\", mode, re.IGNORECASE):\n",
        "        for X in dataloader:\n",
        "            X = X.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "               output = torch.argmax(model(X), dim=1)\n",
        "            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n",
        "    \n",
        "    y_pred = y_pred[1:].detach().cpu().numpy()\n",
        "    y_pred = y_pred + 1\n",
        "    return y_pred"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu2YI71ETi7T"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ga2Gv8wNcep"
      },
      "source": [
        "def train(features: np.ndarray, targets: np.ndarray, oh_targets: np.ndarray,\n",
        "          n_splits: int, batch_size: int, lr: float, wd: float, \n",
        "          epochs: int, early_stopping: int, \n",
        "          patience=None, eps=None) -> list:        \n",
        "    \n",
        "    metrics = []\n",
        "        \n",
        "    KFold_start_time = time()\n",
        "    breaker()\n",
        "    print(\"Performing {} Fold CV ...\".format(n_splits))\n",
        "    if verbose:\n",
        "        pass\n",
        "    else:\n",
        "        breaker()\n",
        "    fold = 1\n",
        "    for tr_idx, va_idx in KFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(features):\n",
        "\n",
        "        tr_features, va_features = features[tr_idx], features[va_idx]\n",
        "        tr_targets, va_targets = targets[tr_idx], targets[va_idx]\n",
        "        oh_tr_targets, oh_va_targets = oh_targets[tr_idx], oh_targets[va_idx]\n",
        "\n",
        "\n",
        "        dataloaders = build_dataloaders(tr_features, va_features,\n",
        "                                        oh_tr_targets, oh_va_targets, \n",
        "                                        batch_size, SEED)\n",
        "        model = build_model(IL=tr_features.shape[1], seed=SEED).to(DEVICE)\n",
        "        optimizer = model.get_optimizer(lr=lr, wd=wd)\n",
        "        scheduler = None\n",
        "        if isinstance(patience, int) and isinstance(eps, float):\n",
        "            scheduler = model.get_plateau_scheduler(optimizer, patience, eps)\n",
        "\n",
        "        L, _, name = fit(model=model, optimizer=optimizer, scheduler=scheduler, \n",
        "                         epochs=epochs, early_stopping_patience=early_stopping,\n",
        "                         dataloaders=dataloaders, fold=fold, verbose=verbose)\n",
        "        y_pred = predict_batch(model=model, dataloader=dataloaders[\"valid\"], mode=\"valid\", path=name)\n",
        "        RMSE = np.sqrt(mean_squared_error(y_pred, va_targets))\n",
        "        if verbose:\n",
        "            print(\"Validation RMSE [Fold {}]: {:.5f}\".format(fold, RMSE))\n",
        "            breaker()\n",
        "            show_graphs(L)\n",
        "        \n",
        "        metrics_dict = {\"Fold\" : fold, \"RMSE\" : RMSE}\n",
        "        metrics.append(metrics_dict)\n",
        "        \n",
        "        fold += 1\n",
        "\n",
        "    breaker()\n",
        "    print(\"Total Time to {} Fold CV : {:.2f} minutes\".format(n_splits, (time() - KFold_start_time)/60))\n",
        "    breaker()\n",
        "\n",
        "    return metrics, (time() - KFold_start_time)/60"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN_yv1_qThOi"
      },
      "source": [
        "## Main\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAuRhtjZTgyr"
      },
      "source": [
        "def main():\n",
        "    breaker()\n",
        "    print(\"Clean Memory , {} Objects Collected ...\".format(gc.collect()))\n",
        "\n",
        "    ########### Params ###########\n",
        "    \n",
        "    if DEBUG:\n",
        "        n_splits = 3\n",
        "        patience, eps = 5, 1e-8\n",
        "        epochs, early_stopping = 5, 5\n",
        "\n",
        "        batch_size = 128\n",
        "        lr = 1e-3\n",
        "        wd = 1e-1\n",
        "    else:\n",
        "        n_splits = 10\n",
        "        patience, eps = 5, 1e-8\n",
        "        epochs, early_stopping = 1000, 50\n",
        "\n",
        "        batch_size = 128\n",
        "        lr = 1e-6\n",
        "        wd = 1e-5\n",
        "    \n",
        "    ##############################\n",
        "\n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Loading Data ...\")\n",
        "    \n",
        "    features = np.load(os.path.join(PATH, \"densenet169_features.npy\"))\n",
        "    targets, oh_targets = get_targets()\n",
        "\n",
        "    # Without Scheduler\n",
        "    metrics, _ = train(features, targets, oh_targets, n_splits, batch_size, lr, wd, epochs, early_stopping, patience=None, eps=None)\n",
        "\n",
        "    # With Scheduler\n",
        "    # train(images, targets, n_splits, batch_size, lr, wd, epochs, early_stopping, pretrained_ann_path, patience=patience, eps=eps)\n",
        "\n",
        "    if verbose:\n",
        "        pass\n",
        "    else:\n",
        "        breaker()\n",
        "    rmse = []\n",
        "    for i in range(len(metrics)):\n",
        "        print(\"Fold {}, RMSE {:.5f}\".format(metrics[i][\"Fold\"], metrics[i][\"RMSE\"]))\n",
        "        rmse.append(metrics[i][\"RMSE\"])\n",
        "    breaker()\n",
        "\n",
        "    best_index = rmse.index(min(rmse))\n",
        "\n",
        "    print(\"Best RMSE : {:.5f}\".format(metrics[best_index][\"RMSE\"]))\n",
        "    print(\"Avg RMSE  : {:.5f}\".format(sum(rmse) / len(rmse)))\n",
        "\n",
        "    with open(\"metrics.pkl\", \"wb\") as fp:\n",
        "        pickle.dump(metrics, fp)\n",
        "\n",
        "    breaker()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DHU3rBEBT7yQ",
        "outputId": "a626b22e-9e8b-422a-f28b-34bc588e5694"
      },
      "source": [
        "main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Clean Memory , 152 Objects Collected ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Loading Data ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Performing 10 Fold CV ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 1...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71488 | Valid Loss: 0.71176 | Time: 0.72 seconds\n",
            "Epoch: 2 | Train Loss: 0.71435 | Valid Loss: 0.71386 | Time: 0.45 seconds\n",
            "Epoch: 3 | Train Loss: 0.71381 | Valid Loss: 0.71406 | Time: 0.44 seconds\n",
            "Epoch: 4 | Train Loss: 0.71332 | Valid Loss: 0.71255 | Time: 0.44 seconds\n",
            "Epoch: 5 | Train Loss: 0.71283 | Valid Loss: 0.71209 | Time: 0.45 seconds\n",
            "Epoch: 6 | Train Loss: 0.71236 | Valid Loss: 0.71172 | Time: 0.45 seconds\n",
            "Epoch: 7 | Train Loss: 0.71191 | Valid Loss: 0.71152 | Time: 0.45 seconds\n",
            "Epoch: 8 | Train Loss: 0.71148 | Valid Loss: 0.71140 | Time: 0.46 seconds\n",
            "Epoch: 9 | Train Loss: 0.71108 | Valid Loss: 0.71130 | Time: 0.46 seconds\n",
            "Epoch: 10 | Train Loss: 0.71067 | Valid Loss: 0.70984 | Time: 0.45 seconds\n",
            "Epoch: 11 | Train Loss: 0.71027 | Valid Loss: 0.70971 | Time: 0.45 seconds\n",
            "Epoch: 12 | Train Loss: 0.70989 | Valid Loss: 0.70937 | Time: 0.45 seconds\n",
            "Epoch: 13 | Train Loss: 0.70952 | Valid Loss: 0.70897 | Time: 0.47 seconds\n",
            "Epoch: 14 | Train Loss: 0.70915 | Valid Loss: 0.70902 | Time: 0.47 seconds\n",
            "Epoch: 15 | Train Loss: 0.70878 | Valid Loss: 0.70850 | Time: 0.47 seconds\n",
            "Epoch: 16 | Train Loss: 0.70844 | Valid Loss: 0.70809 | Time: 0.47 seconds\n",
            "Epoch: 17 | Train Loss: 0.70810 | Valid Loss: 0.70769 | Time: 0.45 seconds\n",
            "Epoch: 18 | Train Loss: 0.70776 | Valid Loss: 0.70725 | Time: 0.46 seconds\n",
            "Epoch: 19 | Train Loss: 0.70742 | Valid Loss: 0.70745 | Time: 0.45 seconds\n",
            "Epoch: 20 | Train Loss: 0.70709 | Valid Loss: 0.70679 | Time: 0.46 seconds\n",
            "Epoch: 21 | Train Loss: 0.70675 | Valid Loss: 0.70659 | Time: 0.47 seconds\n",
            "Epoch: 22 | Train Loss: 0.70643 | Valid Loss: 0.70568 | Time: 0.46 seconds\n",
            "Epoch: 23 | Train Loss: 0.70612 | Valid Loss: 0.70653 | Time: 0.45 seconds\n",
            "Epoch: 24 | Train Loss: 0.70580 | Valid Loss: 0.70528 | Time: 0.45 seconds\n",
            "Epoch: 25 | Train Loss: 0.70547 | Valid Loss: 0.70547 | Time: 0.47 seconds\n",
            "Epoch: 26 | Train Loss: 0.70516 | Valid Loss: 0.70485 | Time: 0.45 seconds\n",
            "Epoch: 27 | Train Loss: 0.70484 | Valid Loss: 0.70447 | Time: 0.48 seconds\n",
            "Epoch: 28 | Train Loss: 0.70453 | Valid Loss: 0.70392 | Time: 0.46 seconds\n",
            "Epoch: 29 | Train Loss: 0.70421 | Valid Loss: 0.70406 | Time: 0.46 seconds\n",
            "Epoch: 30 | Train Loss: 0.70391 | Valid Loss: 0.70360 | Time: 0.47 seconds\n",
            "Epoch: 31 | Train Loss: 0.70358 | Valid Loss: 0.70315 | Time: 0.47 seconds\n",
            "Epoch: 32 | Train Loss: 0.70326 | Valid Loss: 0.70294 | Time: 0.47 seconds\n",
            "Epoch: 33 | Train Loss: 0.70297 | Valid Loss: 0.70315 | Time: 0.48 seconds\n",
            "Epoch: 34 | Train Loss: 0.70264 | Valid Loss: 0.70208 | Time: 0.45 seconds\n",
            "Epoch: 35 | Train Loss: 0.70231 | Valid Loss: 0.70170 | Time: 0.45 seconds\n",
            "Epoch: 36 | Train Loss: 0.70199 | Valid Loss: 0.70241 | Time: 0.48 seconds\n",
            "Epoch: 37 | Train Loss: 0.70167 | Valid Loss: 0.70166 | Time: 0.45 seconds\n",
            "Epoch: 38 | Train Loss: 0.70135 | Valid Loss: 0.70140 | Time: 0.49 seconds\n",
            "Epoch: 39 | Train Loss: 0.70100 | Valid Loss: 0.70088 | Time: 0.45 seconds\n",
            "Epoch: 40 | Train Loss: 0.70070 | Valid Loss: 0.70021 | Time: 0.47 seconds\n",
            "Epoch: 41 | Train Loss: 0.70036 | Valid Loss: 0.70027 | Time: 0.46 seconds\n",
            "Epoch: 42 | Train Loss: 0.70003 | Valid Loss: 0.69903 | Time: 0.46 seconds\n",
            "Epoch: 43 | Train Loss: 0.69971 | Valid Loss: 0.69917 | Time: 0.46 seconds\n",
            "Epoch: 44 | Train Loss: 0.69936 | Valid Loss: 0.69895 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69900 | Valid Loss: 0.69907 | Time: 0.45 seconds\n",
            "Epoch: 46 | Train Loss: 0.69867 | Valid Loss: 0.69802 | Time: 0.45 seconds\n",
            "Epoch: 47 | Train Loss: 0.69832 | Valid Loss: 0.69814 | Time: 0.47 seconds\n",
            "Epoch: 48 | Train Loss: 0.69797 | Valid Loss: 0.69783 | Time: 0.45 seconds\n",
            "Epoch: 49 | Train Loss: 0.69761 | Valid Loss: 0.69724 | Time: 0.46 seconds\n",
            "Epoch: 50 | Train Loss: 0.69725 | Valid Loss: 0.69726 | Time: 0.44 seconds\n",
            "Epoch: 51 | Train Loss: 0.69688 | Valid Loss: 0.69640 | Time: 0.46 seconds\n",
            "Epoch: 52 | Train Loss: 0.69652 | Valid Loss: 0.69620 | Time: 0.45 seconds\n",
            "Epoch: 53 | Train Loss: 0.69614 | Valid Loss: 0.69657 | Time: 0.45 seconds\n",
            "Epoch: 54 | Train Loss: 0.69576 | Valid Loss: 0.69593 | Time: 0.47 seconds\n",
            "Epoch: 55 | Train Loss: 0.69538 | Valid Loss: 0.69530 | Time: 0.45 seconds\n",
            "Epoch: 56 | Train Loss: 0.69499 | Valid Loss: 0.69486 | Time: 0.46 seconds\n",
            "Epoch: 57 | Train Loss: 0.69461 | Valid Loss: 0.69394 | Time: 0.46 seconds\n",
            "Epoch: 58 | Train Loss: 0.69422 | Valid Loss: 0.69407 | Time: 0.47 seconds\n",
            "Epoch: 59 | Train Loss: 0.69384 | Valid Loss: 0.69363 | Time: 0.46 seconds\n",
            "Epoch: 60 | Train Loss: 0.69342 | Valid Loss: 0.69342 | Time: 0.48 seconds\n",
            "Epoch: 61 | Train Loss: 0.69302 | Valid Loss: 0.69231 | Time: 0.46 seconds\n",
            "Epoch: 62 | Train Loss: 0.69262 | Valid Loss: 0.69158 | Time: 0.46 seconds\n",
            "Epoch: 63 | Train Loss: 0.69220 | Valid Loss: 0.69235 | Time: 0.45 seconds\n",
            "Epoch: 64 | Train Loss: 0.69178 | Valid Loss: 0.69154 | Time: 0.47 seconds\n",
            "Epoch: 65 | Train Loss: 0.69136 | Valid Loss: 0.69149 | Time: 0.45 seconds\n",
            "Epoch: 66 | Train Loss: 0.69093 | Valid Loss: 0.69087 | Time: 0.45 seconds\n",
            "Epoch: 67 | Train Loss: 0.69050 | Valid Loss: 0.69053 | Time: 0.46 seconds\n",
            "Epoch: 68 | Train Loss: 0.69005 | Valid Loss: 0.69050 | Time: 0.46 seconds\n",
            "Epoch: 69 | Train Loss: 0.68962 | Valid Loss: 0.68907 | Time: 0.47 seconds\n",
            "Epoch: 70 | Train Loss: 0.68919 | Valid Loss: 0.68892 | Time: 0.46 seconds\n",
            "Epoch: 71 | Train Loss: 0.68874 | Valid Loss: 0.68899 | Time: 0.46 seconds\n",
            "Epoch: 72 | Train Loss: 0.68828 | Valid Loss: 0.68863 | Time: 0.45 seconds\n",
            "Epoch: 73 | Train Loss: 0.68784 | Valid Loss: 0.68795 | Time: 0.47 seconds\n",
            "Epoch: 74 | Train Loss: 0.68738 | Valid Loss: 0.68702 | Time: 0.45 seconds\n",
            "Epoch: 75 | Train Loss: 0.68692 | Valid Loss: 0.68661 | Time: 0.47 seconds\n",
            "Epoch: 76 | Train Loss: 0.68645 | Valid Loss: 0.68724 | Time: 0.44 seconds\n",
            "Epoch: 77 | Train Loss: 0.68597 | Valid Loss: 0.68583 | Time: 0.46 seconds\n",
            "Epoch: 78 | Train Loss: 0.68550 | Valid Loss: 0.68476 | Time: 0.46 seconds\n",
            "Epoch: 79 | Train Loss: 0.68503 | Valid Loss: 0.68508 | Time: 0.44 seconds\n",
            "Epoch: 80 | Train Loss: 0.68454 | Valid Loss: 0.68420 | Time: 0.47 seconds\n",
            "Epoch: 81 | Train Loss: 0.68405 | Valid Loss: 0.68373 | Time: 0.47 seconds\n",
            "Epoch: 82 | Train Loss: 0.68355 | Valid Loss: 0.68383 | Time: 0.46 seconds\n",
            "Epoch: 83 | Train Loss: 0.68306 | Valid Loss: 0.68332 | Time: 0.45 seconds\n",
            "Epoch: 84 | Train Loss: 0.68256 | Valid Loss: 0.68276 | Time: 0.49 seconds\n",
            "Epoch: 85 | Train Loss: 0.68206 | Valid Loss: 0.68200 | Time: 0.45 seconds\n",
            "Epoch: 86 | Train Loss: 0.68156 | Valid Loss: 0.68116 | Time: 0.49 seconds\n",
            "Epoch: 87 | Train Loss: 0.68104 | Valid Loss: 0.68024 | Time: 0.46 seconds\n",
            "Epoch: 88 | Train Loss: 0.68053 | Valid Loss: 0.68035 | Time: 0.45 seconds\n",
            "Epoch: 89 | Train Loss: 0.68001 | Valid Loss: 0.67933 | Time: 0.47 seconds\n",
            "Epoch: 90 | Train Loss: 0.67948 | Valid Loss: 0.67911 | Time: 0.47 seconds\n",
            "Epoch: 91 | Train Loss: 0.67895 | Valid Loss: 0.67882 | Time: 0.47 seconds\n",
            "Epoch: 92 | Train Loss: 0.67841 | Valid Loss: 0.67813 | Time: 0.47 seconds\n",
            "Epoch: 93 | Train Loss: 0.67789 | Valid Loss: 0.67791 | Time: 0.47 seconds\n",
            "Epoch: 94 | Train Loss: 0.67734 | Valid Loss: 0.67697 | Time: 0.45 seconds\n",
            "Epoch: 95 | Train Loss: 0.67681 | Valid Loss: 0.67619 | Time: 0.48 seconds\n",
            "Epoch: 96 | Train Loss: 0.67626 | Valid Loss: 0.67549 | Time: 0.47 seconds\n",
            "Epoch: 97 | Train Loss: 0.67571 | Valid Loss: 0.67584 | Time: 0.46 seconds\n",
            "Epoch: 98 | Train Loss: 0.67515 | Valid Loss: 0.67594 | Time: 0.46 seconds\n",
            "Epoch: 99 | Train Loss: 0.67459 | Valid Loss: 0.67426 | Time: 0.48 seconds\n",
            "Epoch: 100 | Train Loss: 0.67403 | Valid Loss: 0.67310 | Time: 0.47 seconds\n",
            "Epoch: 101 | Train Loss: 0.67345 | Valid Loss: 0.67276 | Time: 0.47 seconds\n",
            "Epoch: 102 | Train Loss: 0.67289 | Valid Loss: 0.67186 | Time: 0.47 seconds\n",
            "Epoch: 103 | Train Loss: 0.67231 | Valid Loss: 0.67206 | Time: 0.46 seconds\n",
            "Epoch: 104 | Train Loss: 0.67174 | Valid Loss: 0.67089 | Time: 0.48 seconds\n",
            "Epoch: 105 | Train Loss: 0.67115 | Valid Loss: 0.67043 | Time: 0.46 seconds\n",
            "Epoch: 106 | Train Loss: 0.67057 | Valid Loss: 0.67007 | Time: 0.48 seconds\n",
            "Epoch: 107 | Train Loss: 0.66998 | Valid Loss: 0.66955 | Time: 0.46 seconds\n",
            "Epoch: 108 | Train Loss: 0.66938 | Valid Loss: 0.66972 | Time: 0.45 seconds\n",
            "Epoch: 109 | Train Loss: 0.66878 | Valid Loss: 0.66848 | Time: 0.46 seconds\n",
            "Epoch: 110 | Train Loss: 0.66819 | Valid Loss: 0.66779 | Time: 0.47 seconds\n",
            "Epoch: 111 | Train Loss: 0.66758 | Valid Loss: 0.66707 | Time: 0.45 seconds\n",
            "Epoch: 112 | Train Loss: 0.66696 | Valid Loss: 0.66635 | Time: 0.45 seconds\n",
            "Epoch: 113 | Train Loss: 0.66634 | Valid Loss: 0.66551 | Time: 0.46 seconds\n",
            "Epoch: 114 | Train Loss: 0.66573 | Valid Loss: 0.66510 | Time: 0.46 seconds\n",
            "Epoch: 115 | Train Loss: 0.66513 | Valid Loss: 0.66449 | Time: 0.48 seconds\n",
            "Epoch: 116 | Train Loss: 0.66449 | Valid Loss: 0.66457 | Time: 0.45 seconds\n",
            "Epoch: 117 | Train Loss: 0.66386 | Valid Loss: 0.66257 | Time: 0.46 seconds\n",
            "Epoch: 118 | Train Loss: 0.66323 | Valid Loss: 0.66223 | Time: 0.45 seconds\n",
            "Epoch: 119 | Train Loss: 0.66259 | Valid Loss: 0.66218 | Time: 0.46 seconds\n",
            "Epoch: 120 | Train Loss: 0.66196 | Valid Loss: 0.66134 | Time: 0.45 seconds\n",
            "Epoch: 121 | Train Loss: 0.66131 | Valid Loss: 0.66150 | Time: 0.46 seconds\n",
            "Epoch: 122 | Train Loss: 0.66067 | Valid Loss: 0.66052 | Time: 0.46 seconds\n",
            "Epoch: 123 | Train Loss: 0.66002 | Valid Loss: 0.66030 | Time: 0.46 seconds\n",
            "Epoch: 124 | Train Loss: 0.65937 | Valid Loss: 0.65907 | Time: 0.47 seconds\n",
            "Epoch: 125 | Train Loss: 0.65870 | Valid Loss: 0.65815 | Time: 0.46 seconds\n",
            "Epoch: 126 | Train Loss: 0.65805 | Valid Loss: 0.65752 | Time: 0.46 seconds\n",
            "Epoch: 127 | Train Loss: 0.65739 | Valid Loss: 0.65656 | Time: 0.45 seconds\n",
            "Epoch: 128 | Train Loss: 0.65671 | Valid Loss: 0.65616 | Time: 0.49 seconds\n",
            "Epoch: 129 | Train Loss: 0.65604 | Valid Loss: 0.65471 | Time: 0.45 seconds\n",
            "Epoch: 130 | Train Loss: 0.65538 | Valid Loss: 0.65481 | Time: 0.45 seconds\n",
            "Epoch: 131 | Train Loss: 0.65469 | Valid Loss: 0.65359 | Time: 0.45 seconds\n",
            "Epoch: 132 | Train Loss: 0.65402 | Valid Loss: 0.65309 | Time: 0.46 seconds\n",
            "Epoch: 133 | Train Loss: 0.65334 | Valid Loss: 0.65351 | Time: 0.45 seconds\n",
            "Epoch: 134 | Train Loss: 0.65265 | Valid Loss: 0.65202 | Time: 0.45 seconds\n",
            "Epoch: 135 | Train Loss: 0.65195 | Valid Loss: 0.65217 | Time: 0.45 seconds\n",
            "Epoch: 136 | Train Loss: 0.65126 | Valid Loss: 0.65096 | Time: 0.46 seconds\n",
            "Epoch: 137 | Train Loss: 0.65057 | Valid Loss: 0.64883 | Time: 0.47 seconds\n",
            "Epoch: 138 | Train Loss: 0.64989 | Valid Loss: 0.64899 | Time: 0.45 seconds\n",
            "Epoch: 139 | Train Loss: 0.64917 | Valid Loss: 0.64813 | Time: 0.45 seconds\n",
            "Epoch: 140 | Train Loss: 0.64848 | Valid Loss: 0.64774 | Time: 0.45 seconds\n",
            "Epoch: 141 | Train Loss: 0.64778 | Valid Loss: 0.64722 | Time: 0.45 seconds\n",
            "Epoch: 142 | Train Loss: 0.64704 | Valid Loss: 0.64592 | Time: 0.45 seconds\n",
            "Epoch: 143 | Train Loss: 0.64635 | Valid Loss: 0.64574 | Time: 0.44 seconds\n",
            "Epoch: 144 | Train Loss: 0.64564 | Valid Loss: 0.64601 | Time: 0.46 seconds\n",
            "Epoch: 145 | Train Loss: 0.64491 | Valid Loss: 0.64250 | Time: 0.47 seconds\n",
            "Epoch: 146 | Train Loss: 0.64420 | Valid Loss: 0.64427 | Time: 0.47 seconds\n",
            "Epoch: 147 | Train Loss: 0.64347 | Valid Loss: 0.64327 | Time: 0.45 seconds\n",
            "Epoch: 148 | Train Loss: 0.64274 | Valid Loss: 0.64263 | Time: 0.46 seconds\n",
            "Epoch: 149 | Train Loss: 0.64202 | Valid Loss: 0.64107 | Time: 0.46 seconds\n",
            "Epoch: 150 | Train Loss: 0.64128 | Valid Loss: 0.64063 | Time: 0.46 seconds\n",
            "Epoch: 151 | Train Loss: 0.64054 | Valid Loss: 0.64004 | Time: 0.49 seconds\n",
            "Epoch: 152 | Train Loss: 0.63982 | Valid Loss: 0.63969 | Time: 0.48 seconds\n",
            "Epoch: 153 | Train Loss: 0.63907 | Valid Loss: 0.63901 | Time: 0.46 seconds\n",
            "Epoch: 154 | Train Loss: 0.63833 | Valid Loss: 0.63757 | Time: 0.45 seconds\n",
            "Epoch: 155 | Train Loss: 0.63759 | Valid Loss: 0.63504 | Time: 0.49 seconds\n",
            "Epoch: 156 | Train Loss: 0.63684 | Valid Loss: 0.63661 | Time: 0.46 seconds\n",
            "Epoch: 157 | Train Loss: 0.63610 | Valid Loss: 0.63583 | Time: 0.48 seconds\n",
            "Epoch: 158 | Train Loss: 0.63536 | Valid Loss: 0.63507 | Time: 0.47 seconds\n",
            "Epoch: 159 | Train Loss: 0.63460 | Valid Loss: 0.63377 | Time: 0.49 seconds\n",
            "Epoch: 160 | Train Loss: 0.63385 | Valid Loss: 0.63260 | Time: 0.49 seconds\n",
            "Epoch: 161 | Train Loss: 0.63309 | Valid Loss: 0.63230 | Time: 0.49 seconds\n",
            "Epoch: 162 | Train Loss: 0.63233 | Valid Loss: 0.63109 | Time: 0.45 seconds\n",
            "Epoch: 163 | Train Loss: 0.63157 | Valid Loss: 0.63014 | Time: 0.47 seconds\n",
            "Epoch: 164 | Train Loss: 0.63081 | Valid Loss: 0.63095 | Time: 0.45 seconds\n",
            "Epoch: 165 | Train Loss: 0.63004 | Valid Loss: 0.62860 | Time: 0.45 seconds\n",
            "Epoch: 166 | Train Loss: 0.62927 | Valid Loss: 0.62868 | Time: 0.45 seconds\n",
            "Epoch: 167 | Train Loss: 0.62850 | Valid Loss: 0.62822 | Time: 0.45 seconds\n",
            "Epoch: 168 | Train Loss: 0.62774 | Valid Loss: 0.62760 | Time: 0.47 seconds\n",
            "Epoch: 169 | Train Loss: 0.62695 | Valid Loss: 0.62631 | Time: 0.46 seconds\n",
            "Epoch: 170 | Train Loss: 0.62618 | Valid Loss: 0.62577 | Time: 0.47 seconds\n",
            "Epoch: 171 | Train Loss: 0.62541 | Valid Loss: 0.62303 | Time: 0.46 seconds\n",
            "Epoch: 172 | Train Loss: 0.62464 | Valid Loss: 0.62343 | Time: 0.46 seconds\n",
            "Epoch: 173 | Train Loss: 0.62385 | Valid Loss: 0.62338 | Time: 0.47 seconds\n",
            "Epoch: 174 | Train Loss: 0.62308 | Valid Loss: 0.62281 | Time: 0.48 seconds\n",
            "Epoch: 175 | Train Loss: 0.62229 | Valid Loss: 0.62046 | Time: 0.46 seconds\n",
            "Epoch: 176 | Train Loss: 0.62149 | Valid Loss: 0.62149 | Time: 0.47 seconds\n",
            "Epoch: 177 | Train Loss: 0.62071 | Valid Loss: 0.62030 | Time: 0.45 seconds\n",
            "Epoch: 178 | Train Loss: 0.61993 | Valid Loss: 0.61837 | Time: 0.46 seconds\n",
            "Epoch: 179 | Train Loss: 0.61913 | Valid Loss: 0.61783 | Time: 0.46 seconds\n",
            "Epoch: 180 | Train Loss: 0.61834 | Valid Loss: 0.61716 | Time: 0.47 seconds\n",
            "Epoch: 181 | Train Loss: 0.61754 | Valid Loss: 0.61758 | Time: 0.46 seconds\n",
            "Epoch: 182 | Train Loss: 0.61676 | Valid Loss: 0.61478 | Time: 0.46 seconds\n",
            "Epoch: 183 | Train Loss: 0.61595 | Valid Loss: 0.61491 | Time: 0.46 seconds\n",
            "Epoch: 184 | Train Loss: 0.61515 | Valid Loss: 0.61500 | Time: 0.44 seconds\n",
            "Epoch: 185 | Train Loss: 0.61436 | Valid Loss: 0.61336 | Time: 0.48 seconds\n",
            "Epoch: 186 | Train Loss: 0.61354 | Valid Loss: 0.61230 | Time: 0.45 seconds\n",
            "Epoch: 187 | Train Loss: 0.61275 | Valid Loss: 0.61293 | Time: 0.46 seconds\n",
            "Epoch: 188 | Train Loss: 0.61195 | Valid Loss: 0.61074 | Time: 0.46 seconds\n",
            "Epoch: 189 | Train Loss: 0.61114 | Valid Loss: 0.60943 | Time: 0.46 seconds\n",
            "Epoch: 190 | Train Loss: 0.61034 | Valid Loss: 0.60884 | Time: 0.46 seconds\n",
            "Epoch: 191 | Train Loss: 0.60952 | Valid Loss: 0.60873 | Time: 0.47 seconds\n",
            "Epoch: 192 | Train Loss: 0.60871 | Valid Loss: 0.60643 | Time: 0.47 seconds\n",
            "Epoch: 193 | Train Loss: 0.60791 | Valid Loss: 0.60719 | Time: 0.45 seconds\n",
            "Epoch: 194 | Train Loss: 0.60709 | Valid Loss: 0.60488 | Time: 0.47 seconds\n",
            "Epoch: 195 | Train Loss: 0.60628 | Valid Loss: 0.60374 | Time: 0.45 seconds\n",
            "Epoch: 196 | Train Loss: 0.60546 | Valid Loss: 0.60434 | Time: 0.47 seconds\n",
            "Epoch: 197 | Train Loss: 0.60465 | Valid Loss: 0.60397 | Time: 0.47 seconds\n",
            "Epoch: 198 | Train Loss: 0.60384 | Valid Loss: 0.60321 | Time: 0.45 seconds\n",
            "Epoch: 199 | Train Loss: 0.60302 | Valid Loss: 0.60120 | Time: 0.47 seconds\n",
            "Epoch: 200 | Train Loss: 0.60218 | Valid Loss: 0.59953 | Time: 0.46 seconds\n",
            "Epoch: 201 | Train Loss: 0.60137 | Valid Loss: 0.59987 | Time: 0.46 seconds\n",
            "Epoch: 202 | Train Loss: 0.60055 | Valid Loss: 0.60071 | Time: 0.44 seconds\n",
            "Epoch: 203 | Train Loss: 0.59973 | Valid Loss: 0.59787 | Time: 0.46 seconds\n",
            "Epoch: 204 | Train Loss: 0.59891 | Valid Loss: 0.59719 | Time: 0.45 seconds\n",
            "Epoch: 205 | Train Loss: 0.59808 | Valid Loss: 0.59823 | Time: 0.47 seconds\n",
            "Epoch: 206 | Train Loss: 0.59724 | Valid Loss: 0.59569 | Time: 0.46 seconds\n",
            "Epoch: 207 | Train Loss: 0.59643 | Valid Loss: 0.59480 | Time: 0.46 seconds\n",
            "Epoch: 208 | Train Loss: 0.59561 | Valid Loss: 0.59500 | Time: 0.43 seconds\n",
            "Epoch: 209 | Train Loss: 0.59477 | Valid Loss: 0.59315 | Time: 0.45 seconds\n",
            "Epoch: 210 | Train Loss: 0.59392 | Valid Loss: 0.59204 | Time: 0.47 seconds\n",
            "Epoch: 211 | Train Loss: 0.59311 | Valid Loss: 0.59269 | Time: 0.44 seconds\n",
            "Epoch: 212 | Train Loss: 0.59228 | Valid Loss: 0.59089 | Time: 0.46 seconds\n",
            "Epoch: 213 | Train Loss: 0.59144 | Valid Loss: 0.59062 | Time: 0.47 seconds\n",
            "Epoch: 214 | Train Loss: 0.59061 | Valid Loss: 0.58864 | Time: 0.47 seconds\n",
            "Epoch: 215 | Train Loss: 0.58978 | Valid Loss: 0.58701 | Time: 0.45 seconds\n",
            "Epoch: 216 | Train Loss: 0.58893 | Valid Loss: 0.58714 | Time: 0.47 seconds\n",
            "Epoch: 217 | Train Loss: 0.58810 | Valid Loss: 0.58721 | Time: 0.46 seconds\n",
            "Epoch: 218 | Train Loss: 0.58726 | Valid Loss: 0.58634 | Time: 0.45 seconds\n",
            "Epoch: 219 | Train Loss: 0.58641 | Valid Loss: 0.58459 | Time: 0.47 seconds\n",
            "Epoch: 220 | Train Loss: 0.58556 | Valid Loss: 0.58507 | Time: 0.47 seconds\n",
            "Epoch: 221 | Train Loss: 0.58473 | Valid Loss: 0.58391 | Time: 0.47 seconds\n",
            "Epoch: 222 | Train Loss: 0.58390 | Valid Loss: 0.58260 | Time: 0.45 seconds\n",
            "Epoch: 223 | Train Loss: 0.58306 | Valid Loss: 0.58178 | Time: 0.46 seconds\n",
            "Epoch: 224 | Train Loss: 0.58220 | Valid Loss: 0.58019 | Time: 0.47 seconds\n",
            "Epoch: 225 | Train Loss: 0.58137 | Valid Loss: 0.58065 | Time: 0.46 seconds\n",
            "Epoch: 226 | Train Loss: 0.58052 | Valid Loss: 0.57908 | Time: 0.45 seconds\n",
            "Epoch: 227 | Train Loss: 0.57968 | Valid Loss: 0.57745 | Time: 0.47 seconds\n",
            "Epoch: 228 | Train Loss: 0.57883 | Valid Loss: 0.57644 | Time: 0.47 seconds\n",
            "Epoch: 229 | Train Loss: 0.57798 | Valid Loss: 0.57747 | Time: 0.46 seconds\n",
            "Epoch: 230 | Train Loss: 0.57713 | Valid Loss: 0.57671 | Time: 0.47 seconds\n",
            "Epoch: 231 | Train Loss: 0.57628 | Valid Loss: 0.57426 | Time: 0.46 seconds\n",
            "Epoch: 232 | Train Loss: 0.57543 | Valid Loss: 0.57434 | Time: 0.47 seconds\n",
            "Epoch: 233 | Train Loss: 0.57458 | Valid Loss: 0.57305 | Time: 0.45 seconds\n",
            "Epoch: 234 | Train Loss: 0.57372 | Valid Loss: 0.57147 | Time: 0.48 seconds\n",
            "Epoch: 235 | Train Loss: 0.57289 | Valid Loss: 0.57189 | Time: 0.48 seconds\n",
            "Epoch: 236 | Train Loss: 0.57203 | Valid Loss: 0.57096 | Time: 0.47 seconds\n",
            "Epoch: 237 | Train Loss: 0.57116 | Valid Loss: 0.56940 | Time: 0.45 seconds\n",
            "Epoch: 238 | Train Loss: 0.57032 | Valid Loss: 0.56845 | Time: 0.48 seconds\n",
            "Epoch: 239 | Train Loss: 0.56946 | Valid Loss: 0.56876 | Time: 0.45 seconds\n",
            "Epoch: 240 | Train Loss: 0.56861 | Valid Loss: 0.56599 | Time: 0.46 seconds\n",
            "Epoch: 241 | Train Loss: 0.56775 | Valid Loss: 0.56691 | Time: 0.45 seconds\n",
            "Epoch: 242 | Train Loss: 0.56689 | Valid Loss: 0.56502 | Time: 0.48 seconds\n",
            "Epoch: 243 | Train Loss: 0.56604 | Valid Loss: 0.56518 | Time: 0.46 seconds\n",
            "Epoch: 244 | Train Loss: 0.56517 | Valid Loss: 0.56369 | Time: 0.46 seconds\n",
            "Epoch: 245 | Train Loss: 0.56431 | Valid Loss: 0.56291 | Time: 0.47 seconds\n",
            "Epoch: 246 | Train Loss: 0.56346 | Valid Loss: 0.56263 | Time: 0.46 seconds\n",
            "Epoch: 247 | Train Loss: 0.56261 | Valid Loss: 0.56141 | Time: 0.46 seconds\n",
            "Epoch: 248 | Train Loss: 0.56173 | Valid Loss: 0.56179 | Time: 0.45 seconds\n",
            "Epoch: 249 | Train Loss: 0.56088 | Valid Loss: 0.55981 | Time: 0.46 seconds\n",
            "Epoch: 250 | Train Loss: 0.56002 | Valid Loss: 0.55938 | Time: 0.46 seconds\n",
            "Epoch: 251 | Train Loss: 0.55915 | Valid Loss: 0.55740 | Time: 0.46 seconds\n",
            "Epoch: 252 | Train Loss: 0.55828 | Valid Loss: 0.55821 | Time: 0.45 seconds\n",
            "Epoch: 253 | Train Loss: 0.55742 | Valid Loss: 0.55535 | Time: 0.47 seconds\n",
            "Epoch: 254 | Train Loss: 0.55655 | Valid Loss: 0.55526 | Time: 0.47 seconds\n",
            "Epoch: 255 | Train Loss: 0.55568 | Valid Loss: 0.55409 | Time: 0.46 seconds\n",
            "Epoch: 256 | Train Loss: 0.55482 | Valid Loss: 0.55126 | Time: 0.46 seconds\n",
            "Epoch: 257 | Train Loss: 0.55397 | Valid Loss: 0.55375 | Time: 0.45 seconds\n",
            "Epoch: 258 | Train Loss: 0.55309 | Valid Loss: 0.55140 | Time: 0.46 seconds\n",
            "Epoch: 259 | Train Loss: 0.55223 | Valid Loss: 0.55123 | Time: 0.48 seconds\n",
            "Epoch: 260 | Train Loss: 0.55136 | Valid Loss: 0.55080 | Time: 0.48 seconds\n",
            "Epoch: 261 | Train Loss: 0.55049 | Valid Loss: 0.55042 | Time: 0.46 seconds\n",
            "Epoch: 262 | Train Loss: 0.54961 | Valid Loss: 0.54914 | Time: 0.48 seconds\n",
            "Epoch: 263 | Train Loss: 0.54875 | Valid Loss: 0.54728 | Time: 0.47 seconds\n",
            "Epoch: 264 | Train Loss: 0.54791 | Valid Loss: 0.54642 | Time: 0.49 seconds\n",
            "Epoch: 265 | Train Loss: 0.54701 | Valid Loss: 0.54669 | Time: 0.46 seconds\n",
            "Epoch: 266 | Train Loss: 0.54615 | Valid Loss: 0.54551 | Time: 0.45 seconds\n",
            "Epoch: 267 | Train Loss: 0.54528 | Valid Loss: 0.54232 | Time: 0.47 seconds\n",
            "Epoch: 268 | Train Loss: 0.54439 | Valid Loss: 0.54422 | Time: 0.45 seconds\n",
            "Epoch: 269 | Train Loss: 0.54353 | Valid Loss: 0.54079 | Time: 0.47 seconds\n",
            "Epoch: 270 | Train Loss: 0.54267 | Valid Loss: 0.54142 | Time: 0.45 seconds\n",
            "Epoch: 271 | Train Loss: 0.54179 | Valid Loss: 0.54193 | Time: 0.45 seconds\n",
            "Epoch: 272 | Train Loss: 0.54092 | Valid Loss: 0.53678 | Time: 0.44 seconds\n",
            "Epoch: 273 | Train Loss: 0.54005 | Valid Loss: 0.53949 | Time: 0.46 seconds\n",
            "Epoch: 274 | Train Loss: 0.53919 | Valid Loss: 0.53797 | Time: 0.45 seconds\n",
            "Epoch: 275 | Train Loss: 0.53830 | Valid Loss: 0.53608 | Time: 0.45 seconds\n",
            "Epoch: 276 | Train Loss: 0.53743 | Valid Loss: 0.53593 | Time: 0.47 seconds\n",
            "Epoch: 277 | Train Loss: 0.53658 | Valid Loss: 0.53343 | Time: 0.45 seconds\n",
            "Epoch: 278 | Train Loss: 0.53569 | Valid Loss: 0.53405 | Time: 0.45 seconds\n",
            "Epoch: 279 | Train Loss: 0.53483 | Valid Loss: 0.53436 | Time: 0.45 seconds\n",
            "Epoch: 280 | Train Loss: 0.53394 | Valid Loss: 0.53194 | Time: 0.46 seconds\n",
            "Epoch: 281 | Train Loss: 0.53309 | Valid Loss: 0.53056 | Time: 0.47 seconds\n",
            "Epoch: 282 | Train Loss: 0.53222 | Valid Loss: 0.53215 | Time: 0.46 seconds\n",
            "Epoch: 283 | Train Loss: 0.53134 | Valid Loss: 0.53060 | Time: 0.44 seconds\n",
            "Epoch: 284 | Train Loss: 0.53045 | Valid Loss: 0.52917 | Time: 0.45 seconds\n",
            "Epoch: 285 | Train Loss: 0.52960 | Valid Loss: 0.52625 | Time: 0.47 seconds\n",
            "Epoch: 286 | Train Loss: 0.52872 | Valid Loss: 0.52656 | Time: 0.44 seconds\n",
            "Epoch: 287 | Train Loss: 0.52784 | Valid Loss: 0.52516 | Time: 0.50 seconds\n",
            "Epoch: 288 | Train Loss: 0.52697 | Valid Loss: 0.52423 | Time: 0.47 seconds\n",
            "Epoch: 289 | Train Loss: 0.52610 | Valid Loss: 0.52609 | Time: 0.45 seconds\n",
            "Epoch: 290 | Train Loss: 0.52521 | Valid Loss: 0.52352 | Time: 0.45 seconds\n",
            "Epoch: 291 | Train Loss: 0.52434 | Valid Loss: 0.52173 | Time: 0.47 seconds\n",
            "Epoch: 292 | Train Loss: 0.52347 | Valid Loss: 0.52193 | Time: 0.44 seconds\n",
            "Epoch: 293 | Train Loss: 0.52260 | Valid Loss: 0.52087 | Time: 0.48 seconds\n",
            "Epoch: 294 | Train Loss: 0.52174 | Valid Loss: 0.52185 | Time: 0.45 seconds\n",
            "Epoch: 295 | Train Loss: 0.52085 | Valid Loss: 0.52065 | Time: 0.45 seconds\n",
            "Epoch: 296 | Train Loss: 0.51995 | Valid Loss: 0.51728 | Time: 0.46 seconds\n",
            "Epoch: 297 | Train Loss: 0.51910 | Valid Loss: 0.51728 | Time: 0.44 seconds\n",
            "Epoch: 298 | Train Loss: 0.51824 | Valid Loss: 0.51679 | Time: 0.47 seconds\n",
            "Epoch: 299 | Train Loss: 0.51734 | Valid Loss: 0.51354 | Time: 0.45 seconds\n",
            "Epoch: 300 | Train Loss: 0.51648 | Valid Loss: 0.51308 | Time: 0.46 seconds\n",
            "Epoch: 301 | Train Loss: 0.51560 | Valid Loss: 0.51230 | Time: 0.45 seconds\n",
            "Epoch: 302 | Train Loss: 0.51475 | Valid Loss: 0.51378 | Time: 0.47 seconds\n",
            "Epoch: 303 | Train Loss: 0.51386 | Valid Loss: 0.51493 | Time: 0.45 seconds\n",
            "Epoch: 304 | Train Loss: 0.51299 | Valid Loss: 0.51212 | Time: 0.44 seconds\n",
            "Epoch: 305 | Train Loss: 0.51212 | Valid Loss: 0.51070 | Time: 0.47 seconds\n",
            "Epoch: 306 | Train Loss: 0.51125 | Valid Loss: 0.50893 | Time: 0.46 seconds\n",
            "Epoch: 307 | Train Loss: 0.51038 | Valid Loss: 0.50929 | Time: 0.46 seconds\n",
            "Epoch: 308 | Train Loss: 0.50951 | Valid Loss: 0.50725 | Time: 0.46 seconds\n",
            "Epoch: 309 | Train Loss: 0.50862 | Valid Loss: 0.50821 | Time: 0.46 seconds\n",
            "Epoch: 310 | Train Loss: 0.50776 | Valid Loss: 0.50669 | Time: 0.48 seconds\n",
            "Epoch: 311 | Train Loss: 0.50689 | Valid Loss: 0.50494 | Time: 0.47 seconds\n",
            "Epoch: 312 | Train Loss: 0.50602 | Valid Loss: 0.50458 | Time: 0.45 seconds\n",
            "Epoch: 313 | Train Loss: 0.50515 | Valid Loss: 0.50328 | Time: 0.47 seconds\n",
            "Epoch: 314 | Train Loss: 0.50427 | Valid Loss: 0.50294 | Time: 0.46 seconds\n",
            "Epoch: 315 | Train Loss: 0.50342 | Valid Loss: 0.50053 | Time: 0.46 seconds\n",
            "Epoch: 316 | Train Loss: 0.50253 | Valid Loss: 0.50061 | Time: 0.48 seconds\n",
            "Epoch: 317 | Train Loss: 0.50167 | Valid Loss: 0.49885 | Time: 0.45 seconds\n",
            "Epoch: 318 | Train Loss: 0.50080 | Valid Loss: 0.49970 | Time: 0.46 seconds\n",
            "Epoch: 319 | Train Loss: 0.49992 | Valid Loss: 0.49781 | Time: 0.46 seconds\n",
            "Epoch: 320 | Train Loss: 0.49906 | Valid Loss: 0.49840 | Time: 0.46 seconds\n",
            "Epoch: 321 | Train Loss: 0.49818 | Valid Loss: 0.49638 | Time: 0.46 seconds\n",
            "Epoch: 322 | Train Loss: 0.49732 | Valid Loss: 0.49793 | Time: 0.47 seconds\n",
            "Epoch: 323 | Train Loss: 0.49646 | Valid Loss: 0.49518 | Time: 0.46 seconds\n",
            "Epoch: 324 | Train Loss: 0.49560 | Valid Loss: 0.49423 | Time: 0.47 seconds\n",
            "Epoch: 325 | Train Loss: 0.49472 | Valid Loss: 0.49462 | Time: 0.46 seconds\n",
            "Epoch: 326 | Train Loss: 0.49385 | Valid Loss: 0.49300 | Time: 0.46 seconds\n",
            "Epoch: 327 | Train Loss: 0.49300 | Valid Loss: 0.49026 | Time: 0.46 seconds\n",
            "Epoch: 328 | Train Loss: 0.49214 | Valid Loss: 0.49074 | Time: 0.45 seconds\n",
            "Epoch: 329 | Train Loss: 0.49127 | Valid Loss: 0.48988 | Time: 0.47 seconds\n",
            "Epoch: 330 | Train Loss: 0.49041 | Valid Loss: 0.48860 | Time: 0.46 seconds\n",
            "Epoch: 331 | Train Loss: 0.48952 | Valid Loss: 0.48769 | Time: 0.46 seconds\n",
            "Epoch: 332 | Train Loss: 0.48868 | Valid Loss: 0.48324 | Time: 0.47 seconds\n",
            "Epoch: 333 | Train Loss: 0.48781 | Valid Loss: 0.48628 | Time: 0.46 seconds\n",
            "Epoch: 334 | Train Loss: 0.48693 | Valid Loss: 0.48356 | Time: 0.46 seconds\n",
            "Epoch: 335 | Train Loss: 0.48609 | Valid Loss: 0.48501 | Time: 0.45 seconds\n",
            "Epoch: 336 | Train Loss: 0.48523 | Valid Loss: 0.48519 | Time: 0.45 seconds\n",
            "Epoch: 337 | Train Loss: 0.48437 | Valid Loss: 0.48199 | Time: 0.45 seconds\n",
            "Epoch: 338 | Train Loss: 0.48350 | Valid Loss: 0.48101 | Time: 0.46 seconds\n",
            "Epoch: 339 | Train Loss: 0.48266 | Valid Loss: 0.47971 | Time: 0.46 seconds\n",
            "Epoch: 340 | Train Loss: 0.48177 | Valid Loss: 0.48116 | Time: 0.45 seconds\n",
            "Epoch: 341 | Train Loss: 0.48093 | Valid Loss: 0.47978 | Time: 0.45 seconds\n",
            "Epoch: 342 | Train Loss: 0.48006 | Valid Loss: 0.47855 | Time: 0.46 seconds\n",
            "Epoch: 343 | Train Loss: 0.47921 | Valid Loss: 0.47645 | Time: 0.46 seconds\n",
            "Epoch: 344 | Train Loss: 0.47837 | Valid Loss: 0.47451 | Time: 0.47 seconds\n",
            "Epoch: 345 | Train Loss: 0.47752 | Valid Loss: 0.47614 | Time: 0.46 seconds\n",
            "Epoch: 346 | Train Loss: 0.47666 | Valid Loss: 0.47413 | Time: 0.46 seconds\n",
            "Epoch: 347 | Train Loss: 0.47580 | Valid Loss: 0.47323 | Time: 0.46 seconds\n",
            "Epoch: 348 | Train Loss: 0.47497 | Valid Loss: 0.47312 | Time: 0.46 seconds\n",
            "Epoch: 349 | Train Loss: 0.47411 | Valid Loss: 0.47316 | Time: 0.47 seconds\n",
            "Epoch: 350 | Train Loss: 0.47324 | Valid Loss: 0.46986 | Time: 0.46 seconds\n",
            "Epoch: 351 | Train Loss: 0.47239 | Valid Loss: 0.46941 | Time: 0.48 seconds\n",
            "Epoch: 352 | Train Loss: 0.47154 | Valid Loss: 0.46933 | Time: 0.45 seconds\n",
            "Epoch: 353 | Train Loss: 0.47070 | Valid Loss: 0.46656 | Time: 0.48 seconds\n",
            "Epoch: 354 | Train Loss: 0.46985 | Valid Loss: 0.46771 | Time: 0.45 seconds\n",
            "Epoch: 355 | Train Loss: 0.46901 | Valid Loss: 0.46674 | Time: 0.49 seconds\n",
            "Epoch: 356 | Train Loss: 0.46817 | Valid Loss: 0.46738 | Time: 0.44 seconds\n",
            "Epoch: 357 | Train Loss: 0.46733 | Valid Loss: 0.46620 | Time: 0.46 seconds\n",
            "Epoch: 358 | Train Loss: 0.46647 | Valid Loss: 0.46252 | Time: 0.45 seconds\n",
            "Epoch: 359 | Train Loss: 0.46567 | Valid Loss: 0.46239 | Time: 0.48 seconds\n",
            "Epoch: 360 | Train Loss: 0.46477 | Valid Loss: 0.46260 | Time: 0.45 seconds\n",
            "Epoch: 361 | Train Loss: 0.46397 | Valid Loss: 0.46187 | Time: 0.45 seconds\n",
            "Epoch: 362 | Train Loss: 0.46313 | Valid Loss: 0.46224 | Time: 0.46 seconds\n",
            "Epoch: 363 | Train Loss: 0.46225 | Valid Loss: 0.46045 | Time: 0.46 seconds\n",
            "Epoch: 364 | Train Loss: 0.46144 | Valid Loss: 0.46099 | Time: 0.45 seconds\n",
            "Epoch: 365 | Train Loss: 0.46059 | Valid Loss: 0.45831 | Time: 0.45 seconds\n",
            "Epoch: 366 | Train Loss: 0.45976 | Valid Loss: 0.45929 | Time: 0.45 seconds\n",
            "Epoch: 367 | Train Loss: 0.45893 | Valid Loss: 0.45778 | Time: 0.45 seconds\n",
            "Epoch: 368 | Train Loss: 0.45809 | Valid Loss: 0.45615 | Time: 0.47 seconds\n",
            "Epoch: 369 | Train Loss: 0.45728 | Valid Loss: 0.45481 | Time: 0.46 seconds\n",
            "Epoch: 370 | Train Loss: 0.45644 | Valid Loss: 0.45395 | Time: 0.45 seconds\n",
            "Epoch: 371 | Train Loss: 0.45559 | Valid Loss: 0.45403 | Time: 0.45 seconds\n",
            "Epoch: 372 | Train Loss: 0.45477 | Valid Loss: 0.45039 | Time: 0.45 seconds\n",
            "Epoch: 373 | Train Loss: 0.45396 | Valid Loss: 0.45193 | Time: 0.45 seconds\n",
            "Epoch: 374 | Train Loss: 0.45314 | Valid Loss: 0.45153 | Time: 0.46 seconds\n",
            "Epoch: 375 | Train Loss: 0.45230 | Valid Loss: 0.45039 | Time: 0.45 seconds\n",
            "Epoch: 376 | Train Loss: 0.45147 | Valid Loss: 0.45086 | Time: 0.44 seconds\n",
            "Epoch: 377 | Train Loss: 0.45061 | Valid Loss: 0.44704 | Time: 0.45 seconds\n",
            "Epoch: 378 | Train Loss: 0.44982 | Valid Loss: 0.44894 | Time: 0.49 seconds\n",
            "Epoch: 379 | Train Loss: 0.44900 | Valid Loss: 0.44701 | Time: 0.45 seconds\n",
            "Epoch: 380 | Train Loss: 0.44817 | Valid Loss: 0.44655 | Time: 0.46 seconds\n",
            "Epoch: 381 | Train Loss: 0.44735 | Valid Loss: 0.44557 | Time: 0.46 seconds\n",
            "Epoch: 382 | Train Loss: 0.44656 | Valid Loss: 0.44323 | Time: 0.46 seconds\n",
            "Epoch: 383 | Train Loss: 0.44569 | Valid Loss: 0.44213 | Time: 0.44 seconds\n",
            "Epoch: 384 | Train Loss: 0.44491 | Valid Loss: 0.44380 | Time: 0.46 seconds\n",
            "Epoch: 385 | Train Loss: 0.44410 | Valid Loss: 0.44212 | Time: 0.45 seconds\n",
            "Epoch: 386 | Train Loss: 0.44330 | Valid Loss: 0.44098 | Time: 0.46 seconds\n",
            "Epoch: 387 | Train Loss: 0.44247 | Valid Loss: 0.44101 | Time: 0.46 seconds\n",
            "Epoch: 388 | Train Loss: 0.44163 | Valid Loss: 0.44002 | Time: 0.45 seconds\n",
            "Epoch: 389 | Train Loss: 0.44080 | Valid Loss: 0.43915 | Time: 0.47 seconds\n",
            "Epoch: 390 | Train Loss: 0.44004 | Valid Loss: 0.43659 | Time: 0.45 seconds\n",
            "Epoch: 391 | Train Loss: 0.43923 | Valid Loss: 0.43766 | Time: 0.45 seconds\n",
            "Epoch: 392 | Train Loss: 0.43844 | Valid Loss: 0.43733 | Time: 0.44 seconds\n",
            "Epoch: 393 | Train Loss: 0.43766 | Valid Loss: 0.43598 | Time: 0.46 seconds\n",
            "Epoch: 394 | Train Loss: 0.43684 | Valid Loss: 0.43599 | Time: 0.47 seconds\n",
            "Epoch: 395 | Train Loss: 0.43600 | Valid Loss: 0.43545 | Time: 0.45 seconds\n",
            "Epoch: 396 | Train Loss: 0.43522 | Valid Loss: 0.43391 | Time: 0.46 seconds\n",
            "Epoch: 397 | Train Loss: 0.43441 | Valid Loss: 0.43072 | Time: 0.45 seconds\n",
            "Epoch: 398 | Train Loss: 0.43364 | Valid Loss: 0.43187 | Time: 0.45 seconds\n",
            "Epoch: 399 | Train Loss: 0.43281 | Valid Loss: 0.42874 | Time: 0.45 seconds\n",
            "Epoch: 400 | Train Loss: 0.43203 | Valid Loss: 0.42991 | Time: 0.45 seconds\n",
            "Epoch: 401 | Train Loss: 0.43124 | Valid Loss: 0.42850 | Time: 0.49 seconds\n",
            "Epoch: 402 | Train Loss: 0.43045 | Valid Loss: 0.42843 | Time: 0.47 seconds\n",
            "Epoch: 403 | Train Loss: 0.42965 | Valid Loss: 0.42727 | Time: 0.45 seconds\n",
            "Epoch: 404 | Train Loss: 0.42885 | Valid Loss: 0.42643 | Time: 0.47 seconds\n",
            "Epoch: 405 | Train Loss: 0.42810 | Valid Loss: 0.42556 | Time: 0.47 seconds\n",
            "Epoch: 406 | Train Loss: 0.42730 | Valid Loss: 0.42532 | Time: 0.46 seconds\n",
            "Epoch: 407 | Train Loss: 0.42650 | Valid Loss: 0.42406 | Time: 0.46 seconds\n",
            "Epoch: 408 | Train Loss: 0.42573 | Valid Loss: 0.42195 | Time: 0.44 seconds\n",
            "Epoch: 409 | Train Loss: 0.42495 | Valid Loss: 0.42405 | Time: 0.46 seconds\n",
            "Epoch: 410 | Train Loss: 0.42417 | Valid Loss: 0.42326 | Time: 0.44 seconds\n",
            "Epoch: 411 | Train Loss: 0.42338 | Valid Loss: 0.42369 | Time: 0.45 seconds\n",
            "Epoch: 412 | Train Loss: 0.42259 | Valid Loss: 0.42317 | Time: 0.48 seconds\n",
            "Epoch: 413 | Train Loss: 0.42184 | Valid Loss: 0.41929 | Time: 0.48 seconds\n",
            "Epoch: 414 | Train Loss: 0.42107 | Valid Loss: 0.41745 | Time: 0.45 seconds\n",
            "Epoch: 415 | Train Loss: 0.42030 | Valid Loss: 0.42077 | Time: 0.46 seconds\n",
            "Epoch: 416 | Train Loss: 0.41949 | Valid Loss: 0.41699 | Time: 0.46 seconds\n",
            "Epoch: 417 | Train Loss: 0.41872 | Valid Loss: 0.41688 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41794 | Valid Loss: 0.41634 | Time: 0.47 seconds\n",
            "Epoch: 419 | Train Loss: 0.41721 | Valid Loss: 0.41594 | Time: 0.49 seconds\n",
            "Epoch: 420 | Train Loss: 0.41642 | Valid Loss: 0.41609 | Time: 0.45 seconds\n",
            "Epoch: 421 | Train Loss: 0.41566 | Valid Loss: 0.41355 | Time: 0.46 seconds\n",
            "Epoch: 422 | Train Loss: 0.41491 | Valid Loss: 0.41590 | Time: 0.47 seconds\n",
            "Epoch: 423 | Train Loss: 0.41412 | Valid Loss: 0.41229 | Time: 0.50 seconds\n",
            "Epoch: 424 | Train Loss: 0.41338 | Valid Loss: 0.41433 | Time: 0.47 seconds\n",
            "Epoch: 425 | Train Loss: 0.41261 | Valid Loss: 0.41129 | Time: 0.46 seconds\n",
            "Epoch: 426 | Train Loss: 0.41186 | Valid Loss: 0.40968 | Time: 0.49 seconds\n",
            "Epoch: 427 | Train Loss: 0.41112 | Valid Loss: 0.40920 | Time: 0.45 seconds\n",
            "Epoch: 428 | Train Loss: 0.41037 | Valid Loss: 0.41099 | Time: 0.46 seconds\n",
            "Epoch: 429 | Train Loss: 0.40955 | Valid Loss: 0.40615 | Time: 0.45 seconds\n",
            "Epoch: 430 | Train Loss: 0.40887 | Valid Loss: 0.40908 | Time: 0.45 seconds\n",
            "Epoch: 431 | Train Loss: 0.40809 | Valid Loss: 0.40509 | Time: 0.47 seconds\n",
            "Epoch: 432 | Train Loss: 0.40734 | Valid Loss: 0.40645 | Time: 0.45 seconds\n",
            "Epoch: 433 | Train Loss: 0.40662 | Valid Loss: 0.40343 | Time: 0.47 seconds\n",
            "Epoch: 434 | Train Loss: 0.40586 | Valid Loss: 0.40472 | Time: 0.45 seconds\n",
            "Epoch: 435 | Train Loss: 0.40512 | Valid Loss: 0.40256 | Time: 0.47 seconds\n",
            "Epoch: 436 | Train Loss: 0.40435 | Valid Loss: 0.40137 | Time: 0.46 seconds\n",
            "Epoch: 437 | Train Loss: 0.40362 | Valid Loss: 0.40245 | Time: 0.49 seconds\n",
            "Epoch: 438 | Train Loss: 0.40291 | Valid Loss: 0.39883 | Time: 0.45 seconds\n",
            "Epoch: 439 | Train Loss: 0.40216 | Valid Loss: 0.40027 | Time: 0.46 seconds\n",
            "Epoch: 440 | Train Loss: 0.40139 | Valid Loss: 0.39914 | Time: 0.45 seconds\n",
            "Epoch: 441 | Train Loss: 0.40066 | Valid Loss: 0.39930 | Time: 0.45 seconds\n",
            "Epoch: 442 | Train Loss: 0.39997 | Valid Loss: 0.39686 | Time: 0.46 seconds\n",
            "Epoch: 443 | Train Loss: 0.39925 | Valid Loss: 0.39768 | Time: 0.46 seconds\n",
            "Epoch: 444 | Train Loss: 0.39850 | Valid Loss: 0.39605 | Time: 0.46 seconds\n",
            "Epoch: 445 | Train Loss: 0.39778 | Valid Loss: 0.39738 | Time: 0.44 seconds\n",
            "Epoch: 446 | Train Loss: 0.39705 | Valid Loss: 0.39477 | Time: 0.48 seconds\n",
            "Epoch: 447 | Train Loss: 0.39633 | Valid Loss: 0.39048 | Time: 0.45 seconds\n",
            "Epoch: 448 | Train Loss: 0.39559 | Valid Loss: 0.39150 | Time: 0.49 seconds\n",
            "Epoch: 449 | Train Loss: 0.39487 | Valid Loss: 0.39221 | Time: 0.44 seconds\n",
            "Epoch: 450 | Train Loss: 0.39416 | Valid Loss: 0.39095 | Time: 0.46 seconds\n",
            "Epoch: 451 | Train Loss: 0.39345 | Valid Loss: 0.39040 | Time: 0.45 seconds\n",
            "Epoch: 452 | Train Loss: 0.39276 | Valid Loss: 0.38883 | Time: 0.46 seconds\n",
            "Epoch: 453 | Train Loss: 0.39203 | Valid Loss: 0.38946 | Time: 0.47 seconds\n",
            "Epoch: 454 | Train Loss: 0.39131 | Valid Loss: 0.38792 | Time: 0.45 seconds\n",
            "Epoch: 455 | Train Loss: 0.39062 | Valid Loss: 0.38695 | Time: 0.46 seconds\n",
            "Epoch: 456 | Train Loss: 0.38987 | Valid Loss: 0.38683 | Time: 0.46 seconds\n",
            "Epoch: 457 | Train Loss: 0.38920 | Valid Loss: 0.38722 | Time: 0.46 seconds\n",
            "Epoch: 458 | Train Loss: 0.38846 | Valid Loss: 0.38556 | Time: 0.47 seconds\n",
            "Epoch: 459 | Train Loss: 0.38781 | Valid Loss: 0.38493 | Time: 0.48 seconds\n",
            "Epoch: 460 | Train Loss: 0.38706 | Valid Loss: 0.38601 | Time: 0.47 seconds\n",
            "Epoch: 461 | Train Loss: 0.38636 | Valid Loss: 0.38537 | Time: 0.46 seconds\n",
            "Epoch: 462 | Train Loss: 0.38563 | Valid Loss: 0.38412 | Time: 0.45 seconds\n",
            "Epoch: 463 | Train Loss: 0.38495 | Valid Loss: 0.38045 | Time: 0.46 seconds\n",
            "Epoch: 464 | Train Loss: 0.38431 | Valid Loss: 0.38407 | Time: 0.45 seconds\n",
            "Epoch: 465 | Train Loss: 0.38358 | Valid Loss: 0.38203 | Time: 0.45 seconds\n",
            "Epoch: 466 | Train Loss: 0.38290 | Valid Loss: 0.38086 | Time: 0.45 seconds\n",
            "Epoch: 467 | Train Loss: 0.38219 | Valid Loss: 0.37993 | Time: 0.45 seconds\n",
            "Epoch: 468 | Train Loss: 0.38150 | Valid Loss: 0.37998 | Time: 0.46 seconds\n",
            "Epoch: 469 | Train Loss: 0.38084 | Valid Loss: 0.37570 | Time: 0.49 seconds\n",
            "Epoch: 470 | Train Loss: 0.38013 | Valid Loss: 0.37780 | Time: 0.46 seconds\n",
            "Epoch: 471 | Train Loss: 0.37947 | Valid Loss: 0.37667 | Time: 0.45 seconds\n",
            "Epoch: 472 | Train Loss: 0.37880 | Valid Loss: 0.37426 | Time: 0.46 seconds\n",
            "Epoch: 473 | Train Loss: 0.37809 | Valid Loss: 0.37637 | Time: 0.45 seconds\n",
            "Epoch: 474 | Train Loss: 0.37747 | Valid Loss: 0.37516 | Time: 0.46 seconds\n",
            "Epoch: 475 | Train Loss: 0.37674 | Valid Loss: 0.37374 | Time: 0.47 seconds\n",
            "Epoch: 476 | Train Loss: 0.37606 | Valid Loss: 0.37469 | Time: 0.46 seconds\n",
            "Epoch: 477 | Train Loss: 0.37537 | Valid Loss: 0.37329 | Time: 0.45 seconds\n",
            "Epoch: 478 | Train Loss: 0.37470 | Valid Loss: 0.37245 | Time: 0.46 seconds\n",
            "Epoch: 479 | Train Loss: 0.37404 | Valid Loss: 0.37180 | Time: 0.47 seconds\n",
            "Epoch: 480 | Train Loss: 0.37341 | Valid Loss: 0.36996 | Time: 0.47 seconds\n",
            "Epoch: 481 | Train Loss: 0.37270 | Valid Loss: 0.36910 | Time: 0.47 seconds\n",
            "Epoch: 482 | Train Loss: 0.37203 | Valid Loss: 0.36722 | Time: 0.46 seconds\n",
            "Epoch: 483 | Train Loss: 0.37140 | Valid Loss: 0.36787 | Time: 0.48 seconds\n",
            "Epoch: 484 | Train Loss: 0.37069 | Valid Loss: 0.36926 | Time: 0.48 seconds\n",
            "Epoch: 485 | Train Loss: 0.37005 | Valid Loss: 0.36724 | Time: 0.45 seconds\n",
            "Epoch: 486 | Train Loss: 0.36939 | Valid Loss: 0.36559 | Time: 0.46 seconds\n",
            "Epoch: 487 | Train Loss: 0.36868 | Valid Loss: 0.36548 | Time: 0.45 seconds\n",
            "Epoch: 488 | Train Loss: 0.36804 | Valid Loss: 0.36567 | Time: 0.46 seconds\n",
            "Epoch: 489 | Train Loss: 0.36742 | Valid Loss: 0.36623 | Time: 0.48 seconds\n",
            "Epoch: 490 | Train Loss: 0.36676 | Valid Loss: 0.36470 | Time: 0.46 seconds\n",
            "Epoch: 491 | Train Loss: 0.36608 | Valid Loss: 0.36211 | Time: 0.46 seconds\n",
            "Epoch: 492 | Train Loss: 0.36544 | Valid Loss: 0.36356 | Time: 0.48 seconds\n",
            "Epoch: 493 | Train Loss: 0.36482 | Valid Loss: 0.36263 | Time: 0.45 seconds\n",
            "Epoch: 494 | Train Loss: 0.36416 | Valid Loss: 0.36084 | Time: 0.45 seconds\n",
            "Epoch: 495 | Train Loss: 0.36353 | Valid Loss: 0.36248 | Time: 0.47 seconds\n",
            "Epoch: 496 | Train Loss: 0.36286 | Valid Loss: 0.36141 | Time: 0.44 seconds\n",
            "Epoch: 497 | Train Loss: 0.36222 | Valid Loss: 0.36221 | Time: 0.46 seconds\n",
            "Epoch: 498 | Train Loss: 0.36164 | Valid Loss: 0.35920 | Time: 0.46 seconds\n",
            "Epoch: 499 | Train Loss: 0.36097 | Valid Loss: 0.35918 | Time: 0.47 seconds\n",
            "Epoch: 500 | Train Loss: 0.36031 | Valid Loss: 0.35728 | Time: 0.45 seconds\n",
            "Epoch: 501 | Train Loss: 0.35968 | Valid Loss: 0.35904 | Time: 0.46 seconds\n",
            "Epoch: 502 | Train Loss: 0.35907 | Valid Loss: 0.35538 | Time: 0.46 seconds\n",
            "Epoch: 503 | Train Loss: 0.35840 | Valid Loss: 0.35512 | Time: 0.47 seconds\n",
            "Epoch: 504 | Train Loss: 0.35781 | Valid Loss: 0.35744 | Time: 0.45 seconds\n",
            "Epoch: 505 | Train Loss: 0.35714 | Valid Loss: 0.35661 | Time: 0.44 seconds\n",
            "Epoch: 506 | Train Loss: 0.35654 | Valid Loss: 0.35479 | Time: 0.47 seconds\n",
            "Epoch: 507 | Train Loss: 0.35591 | Valid Loss: 0.35280 | Time: 0.46 seconds\n",
            "Epoch: 508 | Train Loss: 0.35527 | Valid Loss: 0.35632 | Time: 0.46 seconds\n",
            "Epoch: 509 | Train Loss: 0.35465 | Valid Loss: 0.35225 | Time: 0.47 seconds\n",
            "Epoch: 510 | Train Loss: 0.35405 | Valid Loss: 0.35342 | Time: 0.46 seconds\n",
            "Epoch: 511 | Train Loss: 0.35343 | Valid Loss: 0.35007 | Time: 0.45 seconds\n",
            "Epoch: 512 | Train Loss: 0.35277 | Valid Loss: 0.35144 | Time: 0.46 seconds\n",
            "Epoch: 513 | Train Loss: 0.35217 | Valid Loss: 0.35176 | Time: 0.45 seconds\n",
            "Epoch: 514 | Train Loss: 0.35157 | Valid Loss: 0.35155 | Time: 0.47 seconds\n",
            "Epoch: 515 | Train Loss: 0.35097 | Valid Loss: 0.34786 | Time: 0.47 seconds\n",
            "Epoch: 516 | Train Loss: 0.35034 | Valid Loss: 0.35092 | Time: 0.44 seconds\n",
            "Epoch: 517 | Train Loss: 0.34971 | Valid Loss: 0.34680 | Time: 0.47 seconds\n",
            "Epoch: 518 | Train Loss: 0.34913 | Valid Loss: 0.34719 | Time: 0.45 seconds\n",
            "Epoch: 519 | Train Loss: 0.34851 | Valid Loss: 0.34537 | Time: 0.46 seconds\n",
            "Epoch: 520 | Train Loss: 0.34790 | Valid Loss: 0.34558 | Time: 0.46 seconds\n",
            "Epoch: 521 | Train Loss: 0.34732 | Valid Loss: 0.34412 | Time: 0.48 seconds\n",
            "Epoch: 522 | Train Loss: 0.34673 | Valid Loss: 0.34512 | Time: 0.45 seconds\n",
            "Epoch: 523 | Train Loss: 0.34607 | Valid Loss: 0.34415 | Time: 0.45 seconds\n",
            "Epoch: 524 | Train Loss: 0.34545 | Valid Loss: 0.34148 | Time: 0.47 seconds\n",
            "Epoch: 525 | Train Loss: 0.34488 | Valid Loss: 0.34330 | Time: 0.46 seconds\n",
            "Epoch: 526 | Train Loss: 0.34431 | Valid Loss: 0.34382 | Time: 0.46 seconds\n",
            "Epoch: 527 | Train Loss: 0.34370 | Valid Loss: 0.34231 | Time: 0.45 seconds\n",
            "Epoch: 528 | Train Loss: 0.34314 | Valid Loss: 0.33935 | Time: 0.48 seconds\n",
            "Epoch: 529 | Train Loss: 0.34251 | Valid Loss: 0.33982 | Time: 0.45 seconds\n",
            "Epoch: 530 | Train Loss: 0.34194 | Valid Loss: 0.33992 | Time: 0.46 seconds\n",
            "Epoch: 531 | Train Loss: 0.34135 | Valid Loss: 0.33742 | Time: 0.47 seconds\n",
            "Epoch: 532 | Train Loss: 0.34073 | Valid Loss: 0.34049 | Time: 0.46 seconds\n",
            "Epoch: 533 | Train Loss: 0.34014 | Valid Loss: 0.33786 | Time: 0.45 seconds\n",
            "Epoch: 534 | Train Loss: 0.33958 | Valid Loss: 0.33864 | Time: 0.48 seconds\n",
            "Epoch: 535 | Train Loss: 0.33900 | Valid Loss: 0.33605 | Time: 0.47 seconds\n",
            "Epoch: 536 | Train Loss: 0.33840 | Valid Loss: 0.33634 | Time: 0.48 seconds\n",
            "Epoch: 537 | Train Loss: 0.33780 | Valid Loss: 0.33715 | Time: 0.46 seconds\n",
            "Epoch: 538 | Train Loss: 0.33725 | Valid Loss: 0.33480 | Time: 0.49 seconds\n",
            "Epoch: 539 | Train Loss: 0.33667 | Valid Loss: 0.33459 | Time: 0.48 seconds\n",
            "Epoch: 540 | Train Loss: 0.33608 | Valid Loss: 0.33516 | Time: 0.45 seconds\n",
            "Epoch: 541 | Train Loss: 0.33555 | Valid Loss: 0.33333 | Time: 0.48 seconds\n",
            "Epoch: 542 | Train Loss: 0.33495 | Valid Loss: 0.33180 | Time: 0.47 seconds\n",
            "Epoch: 543 | Train Loss: 0.33440 | Valid Loss: 0.33343 | Time: 0.47 seconds\n",
            "Epoch: 544 | Train Loss: 0.33381 | Valid Loss: 0.33267 | Time: 0.45 seconds\n",
            "Epoch: 545 | Train Loss: 0.33325 | Valid Loss: 0.33028 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33269 | Valid Loss: 0.33219 | Time: 0.48 seconds\n",
            "Epoch: 547 | Train Loss: 0.33211 | Valid Loss: 0.32949 | Time: 0.47 seconds\n",
            "Epoch: 548 | Train Loss: 0.33152 | Valid Loss: 0.33050 | Time: 0.45 seconds\n",
            "Epoch: 549 | Train Loss: 0.33097 | Valid Loss: 0.32797 | Time: 0.48 seconds\n",
            "Epoch: 550 | Train Loss: 0.33040 | Valid Loss: 0.32627 | Time: 0.46 seconds\n",
            "Epoch: 551 | Train Loss: 0.32981 | Valid Loss: 0.32675 | Time: 0.46 seconds\n",
            "Epoch: 552 | Train Loss: 0.32932 | Valid Loss: 0.32512 | Time: 0.47 seconds\n",
            "Epoch: 553 | Train Loss: 0.32869 | Valid Loss: 0.32674 | Time: 0.46 seconds\n",
            "Epoch: 554 | Train Loss: 0.32819 | Valid Loss: 0.32706 | Time: 0.46 seconds\n",
            "Epoch: 555 | Train Loss: 0.32762 | Valid Loss: 0.32528 | Time: 0.45 seconds\n",
            "Epoch: 556 | Train Loss: 0.32704 | Valid Loss: 0.32422 | Time: 0.48 seconds\n",
            "Epoch: 557 | Train Loss: 0.32648 | Valid Loss: 0.32281 | Time: 0.46 seconds\n",
            "Epoch: 558 | Train Loss: 0.32598 | Valid Loss: 0.32222 | Time: 0.46 seconds\n",
            "Epoch: 559 | Train Loss: 0.32539 | Valid Loss: 0.32458 | Time: 0.44 seconds\n",
            "Epoch: 560 | Train Loss: 0.32484 | Valid Loss: 0.32446 | Time: 0.48 seconds\n",
            "Epoch: 561 | Train Loss: 0.32427 | Valid Loss: 0.32333 | Time: 0.45 seconds\n",
            "Epoch: 562 | Train Loss: 0.32373 | Valid Loss: 0.32076 | Time: 0.47 seconds\n",
            "Epoch: 563 | Train Loss: 0.32320 | Valid Loss: 0.32171 | Time: 0.46 seconds\n",
            "Epoch: 564 | Train Loss: 0.32266 | Valid Loss: 0.32201 | Time: 0.45 seconds\n",
            "Epoch: 565 | Train Loss: 0.32212 | Valid Loss: 0.31836 | Time: 0.47 seconds\n",
            "Epoch: 566 | Train Loss: 0.32158 | Valid Loss: 0.32087 | Time: 0.46 seconds\n",
            "Epoch: 567 | Train Loss: 0.32102 | Valid Loss: 0.31748 | Time: 0.46 seconds\n",
            "Epoch: 568 | Train Loss: 0.32051 | Valid Loss: 0.32017 | Time: 0.46 seconds\n",
            "Epoch: 569 | Train Loss: 0.32000 | Valid Loss: 0.31595 | Time: 0.47 seconds\n",
            "Epoch: 570 | Train Loss: 0.31943 | Valid Loss: 0.31696 | Time: 0.45 seconds\n",
            "Epoch: 571 | Train Loss: 0.31891 | Valid Loss: 0.31853 | Time: 0.45 seconds\n",
            "Epoch: 572 | Train Loss: 0.31836 | Valid Loss: 0.31875 | Time: 0.46 seconds\n",
            "Epoch: 573 | Train Loss: 0.31780 | Valid Loss: 0.31456 | Time: 0.45 seconds\n",
            "Epoch: 574 | Train Loss: 0.31729 | Valid Loss: 0.31546 | Time: 0.46 seconds\n",
            "Epoch: 575 | Train Loss: 0.31673 | Valid Loss: 0.31550 | Time: 0.45 seconds\n",
            "Epoch: 576 | Train Loss: 0.31623 | Valid Loss: 0.31351 | Time: 0.46 seconds\n",
            "Epoch: 577 | Train Loss: 0.31571 | Valid Loss: 0.31459 | Time: 0.45 seconds\n",
            "Epoch: 578 | Train Loss: 0.31517 | Valid Loss: 0.31490 | Time: 0.46 seconds\n",
            "Epoch: 579 | Train Loss: 0.31460 | Valid Loss: 0.31375 | Time: 0.44 seconds\n",
            "Epoch: 580 | Train Loss: 0.31408 | Valid Loss: 0.31233 | Time: 0.47 seconds\n",
            "Epoch: 581 | Train Loss: 0.31362 | Valid Loss: 0.31141 | Time: 0.46 seconds\n",
            "Epoch: 582 | Train Loss: 0.31308 | Valid Loss: 0.31066 | Time: 0.46 seconds\n",
            "Epoch: 583 | Train Loss: 0.31255 | Valid Loss: 0.31345 | Time: 0.48 seconds\n",
            "Epoch: 584 | Train Loss: 0.31199 | Valid Loss: 0.30985 | Time: 0.46 seconds\n",
            "Epoch: 585 | Train Loss: 0.31149 | Valid Loss: 0.30981 | Time: 0.46 seconds\n",
            "Epoch: 586 | Train Loss: 0.31099 | Valid Loss: 0.30614 | Time: 0.45 seconds\n",
            "Epoch: 587 | Train Loss: 0.31046 | Valid Loss: 0.30873 | Time: 0.45 seconds\n",
            "Epoch: 588 | Train Loss: 0.30996 | Valid Loss: 0.30779 | Time: 0.44 seconds\n",
            "Epoch: 589 | Train Loss: 0.30943 | Valid Loss: 0.30639 | Time: 0.45 seconds\n",
            "Epoch: 590 | Train Loss: 0.30895 | Valid Loss: 0.30732 | Time: 0.46 seconds\n",
            "Epoch: 591 | Train Loss: 0.30841 | Valid Loss: 0.30600 | Time: 0.48 seconds\n",
            "Epoch: 592 | Train Loss: 0.30793 | Valid Loss: 0.30849 | Time: 0.45 seconds\n",
            "Epoch: 593 | Train Loss: 0.30741 | Valid Loss: 0.30396 | Time: 0.46 seconds\n",
            "Epoch: 594 | Train Loss: 0.30690 | Valid Loss: 0.30450 | Time: 0.46 seconds\n",
            "Epoch: 595 | Train Loss: 0.30636 | Valid Loss: 0.30276 | Time: 0.46 seconds\n",
            "Epoch: 596 | Train Loss: 0.30587 | Valid Loss: 0.30411 | Time: 0.46 seconds\n",
            "Epoch: 597 | Train Loss: 0.30540 | Valid Loss: 0.30358 | Time: 0.45 seconds\n",
            "Epoch: 598 | Train Loss: 0.30488 | Valid Loss: 0.30249 | Time: 0.46 seconds\n",
            "Epoch: 599 | Train Loss: 0.30440 | Valid Loss: 0.30171 | Time: 0.45 seconds\n",
            "Epoch: 600 | Train Loss: 0.30384 | Valid Loss: 0.30100 | Time: 0.48 seconds\n",
            "Epoch: 601 | Train Loss: 0.30337 | Valid Loss: 0.30125 | Time: 0.44 seconds\n",
            "Epoch: 602 | Train Loss: 0.30289 | Valid Loss: 0.30244 | Time: 0.44 seconds\n",
            "Epoch: 603 | Train Loss: 0.30236 | Valid Loss: 0.30024 | Time: 0.47 seconds\n",
            "Epoch: 604 | Train Loss: 0.30188 | Valid Loss: 0.30002 | Time: 0.46 seconds\n",
            "Epoch: 605 | Train Loss: 0.30139 | Valid Loss: 0.30102 | Time: 0.48 seconds\n",
            "Epoch: 606 | Train Loss: 0.30086 | Valid Loss: 0.29807 | Time: 0.48 seconds\n",
            "Epoch: 607 | Train Loss: 0.30038 | Valid Loss: 0.29939 | Time: 0.45 seconds\n",
            "Epoch: 608 | Train Loss: 0.29988 | Valid Loss: 0.29608 | Time: 0.45 seconds\n",
            "Epoch: 609 | Train Loss: 0.29941 | Valid Loss: 0.29705 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29887 | Valid Loss: 0.29718 | Time: 0.44 seconds\n",
            "Epoch: 611 | Train Loss: 0.29840 | Valid Loss: 0.29546 | Time: 0.47 seconds\n",
            "Epoch: 612 | Train Loss: 0.29791 | Valid Loss: 0.29287 | Time: 0.46 seconds\n",
            "Epoch: 613 | Train Loss: 0.29740 | Valid Loss: 0.29572 | Time: 0.44 seconds\n",
            "Epoch: 614 | Train Loss: 0.29697 | Valid Loss: 0.29570 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29648 | Valid Loss: 0.29140 | Time: 0.45 seconds\n",
            "Epoch: 616 | Train Loss: 0.29602 | Valid Loss: 0.29454 | Time: 0.47 seconds\n",
            "Epoch: 617 | Train Loss: 0.29550 | Valid Loss: 0.29255 | Time: 0.45 seconds\n",
            "Epoch: 618 | Train Loss: 0.29500 | Valid Loss: 0.29356 | Time: 0.45 seconds\n",
            "Epoch: 619 | Train Loss: 0.29452 | Valid Loss: 0.29369 | Time: 0.48 seconds\n",
            "Epoch: 620 | Train Loss: 0.29408 | Valid Loss: 0.29190 | Time: 0.47 seconds\n",
            "Epoch: 621 | Train Loss: 0.29355 | Valid Loss: 0.29185 | Time: 0.45 seconds\n",
            "Epoch: 622 | Train Loss: 0.29307 | Valid Loss: 0.29351 | Time: 0.46 seconds\n",
            "Epoch: 623 | Train Loss: 0.29260 | Valid Loss: 0.29198 | Time: 0.45 seconds\n",
            "Epoch: 624 | Train Loss: 0.29213 | Valid Loss: 0.29034 | Time: 0.46 seconds\n",
            "Epoch: 625 | Train Loss: 0.29167 | Valid Loss: 0.29122 | Time: 0.48 seconds\n",
            "Epoch: 626 | Train Loss: 0.29120 | Valid Loss: 0.29062 | Time: 0.45 seconds\n",
            "Epoch: 627 | Train Loss: 0.29071 | Valid Loss: 0.29109 | Time: 0.46 seconds\n",
            "Epoch: 628 | Train Loss: 0.29021 | Valid Loss: 0.28879 | Time: 0.46 seconds\n",
            "Epoch: 629 | Train Loss: 0.28977 | Valid Loss: 0.28862 | Time: 0.48 seconds\n",
            "Epoch: 630 | Train Loss: 0.28928 | Valid Loss: 0.28562 | Time: 0.45 seconds\n",
            "Epoch: 631 | Train Loss: 0.28880 | Valid Loss: 0.28620 | Time: 0.44 seconds\n",
            "Epoch: 632 | Train Loss: 0.28833 | Valid Loss: 0.28568 | Time: 0.45 seconds\n",
            "Epoch: 633 | Train Loss: 0.28786 | Valid Loss: 0.28592 | Time: 0.44 seconds\n",
            "Epoch: 634 | Train Loss: 0.28741 | Valid Loss: 0.28486 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28694 | Valid Loss: 0.28532 | Time: 0.44 seconds\n",
            "Epoch: 636 | Train Loss: 0.28650 | Valid Loss: 0.28488 | Time: 0.46 seconds\n",
            "Epoch: 637 | Train Loss: 0.28601 | Valid Loss: 0.28494 | Time: 0.44 seconds\n",
            "Epoch: 638 | Train Loss: 0.28555 | Valid Loss: 0.28365 | Time: 0.47 seconds\n",
            "Epoch: 639 | Train Loss: 0.28510 | Valid Loss: 0.28473 | Time: 0.45 seconds\n",
            "Epoch: 640 | Train Loss: 0.28464 | Valid Loss: 0.28265 | Time: 0.46 seconds\n",
            "Epoch: 641 | Train Loss: 0.28416 | Valid Loss: 0.28206 | Time: 0.46 seconds\n",
            "Epoch: 642 | Train Loss: 0.28367 | Valid Loss: 0.28273 | Time: 0.45 seconds\n",
            "Epoch: 643 | Train Loss: 0.28327 | Valid Loss: 0.28084 | Time: 0.45 seconds\n",
            "Epoch: 644 | Train Loss: 0.28279 | Valid Loss: 0.28206 | Time: 0.45 seconds\n",
            "Epoch: 645 | Train Loss: 0.28229 | Valid Loss: 0.28168 | Time: 0.45 seconds\n",
            "Epoch: 646 | Train Loss: 0.28187 | Valid Loss: 0.28101 | Time: 0.44 seconds\n",
            "Epoch: 647 | Train Loss: 0.28139 | Valid Loss: 0.28032 | Time: 0.47 seconds\n",
            "Epoch: 648 | Train Loss: 0.28093 | Valid Loss: 0.27954 | Time: 0.45 seconds\n",
            "Epoch: 649 | Train Loss: 0.28051 | Valid Loss: 0.27902 | Time: 0.47 seconds\n",
            "Epoch: 650 | Train Loss: 0.28008 | Valid Loss: 0.27760 | Time: 0.45 seconds\n",
            "Epoch: 651 | Train Loss: 0.27959 | Valid Loss: 0.27847 | Time: 0.43 seconds\n",
            "Epoch: 652 | Train Loss: 0.27921 | Valid Loss: 0.27731 | Time: 0.49 seconds\n",
            "Epoch: 653 | Train Loss: 0.27873 | Valid Loss: 0.27667 | Time: 0.45 seconds\n",
            "Epoch: 654 | Train Loss: 0.27825 | Valid Loss: 0.27637 | Time: 0.47 seconds\n",
            "Epoch: 655 | Train Loss: 0.27780 | Valid Loss: 0.27708 | Time: 0.43 seconds\n",
            "Epoch: 656 | Train Loss: 0.27735 | Valid Loss: 0.27572 | Time: 0.46 seconds\n",
            "Epoch: 657 | Train Loss: 0.27682 | Valid Loss: 0.27751 | Time: 0.46 seconds\n",
            "Epoch: 658 | Train Loss: 0.27646 | Valid Loss: 0.27350 | Time: 0.46 seconds\n",
            "Epoch: 659 | Train Loss: 0.27600 | Valid Loss: 0.27236 | Time: 0.46 seconds\n",
            "Epoch: 660 | Train Loss: 0.27557 | Valid Loss: 0.27264 | Time: 0.45 seconds\n",
            "Epoch: 661 | Train Loss: 0.27510 | Valid Loss: 0.27359 | Time: 0.44 seconds\n",
            "Epoch: 662 | Train Loss: 0.27466 | Valid Loss: 0.27275 | Time: 0.43 seconds\n",
            "Epoch: 663 | Train Loss: 0.27423 | Valid Loss: 0.27224 | Time: 0.47 seconds\n",
            "Epoch: 664 | Train Loss: 0.27379 | Valid Loss: 0.27140 | Time: 0.46 seconds\n",
            "Epoch: 665 | Train Loss: 0.27336 | Valid Loss: 0.27145 | Time: 0.45 seconds\n",
            "Epoch: 666 | Train Loss: 0.27288 | Valid Loss: 0.27350 | Time: 0.45 seconds\n",
            "Epoch: 667 | Train Loss: 0.27248 | Valid Loss: 0.26859 | Time: 0.46 seconds\n",
            "Epoch: 668 | Train Loss: 0.27202 | Valid Loss: 0.26917 | Time: 0.44 seconds\n",
            "Epoch: 669 | Train Loss: 0.27156 | Valid Loss: 0.27038 | Time: 0.46 seconds\n",
            "Epoch: 670 | Train Loss: 0.27114 | Valid Loss: 0.27036 | Time: 0.47 seconds\n",
            "Epoch: 671 | Train Loss: 0.27071 | Valid Loss: 0.26877 | Time: 0.43 seconds\n",
            "Epoch: 672 | Train Loss: 0.27028 | Valid Loss: 0.26861 | Time: 0.45 seconds\n",
            "Epoch: 673 | Train Loss: 0.26983 | Valid Loss: 0.26909 | Time: 0.47 seconds\n",
            "Epoch: 674 | Train Loss: 0.26941 | Valid Loss: 0.26687 | Time: 0.46 seconds\n",
            "Epoch: 675 | Train Loss: 0.26896 | Valid Loss: 0.26496 | Time: 0.48 seconds\n",
            "Epoch: 676 | Train Loss: 0.26853 | Valid Loss: 0.26701 | Time: 0.46 seconds\n",
            "Epoch: 677 | Train Loss: 0.26807 | Valid Loss: 0.26580 | Time: 0.43 seconds\n",
            "Epoch: 678 | Train Loss: 0.26772 | Valid Loss: 0.26572 | Time: 0.46 seconds\n",
            "Epoch: 679 | Train Loss: 0.26727 | Valid Loss: 0.26514 | Time: 0.45 seconds\n",
            "Epoch: 680 | Train Loss: 0.26678 | Valid Loss: 0.26375 | Time: 0.46 seconds\n",
            "Epoch: 681 | Train Loss: 0.26640 | Valid Loss: 0.26304 | Time: 0.48 seconds\n",
            "Epoch: 682 | Train Loss: 0.26595 | Valid Loss: 0.26497 | Time: 0.44 seconds\n",
            "Epoch: 683 | Train Loss: 0.26556 | Valid Loss: 0.26438 | Time: 0.46 seconds\n",
            "Epoch: 684 | Train Loss: 0.26513 | Valid Loss: 0.26211 | Time: 0.45 seconds\n",
            "Epoch: 685 | Train Loss: 0.26466 | Valid Loss: 0.26150 | Time: 0.48 seconds\n",
            "Epoch: 686 | Train Loss: 0.26425 | Valid Loss: 0.26374 | Time: 0.44 seconds\n",
            "Epoch: 687 | Train Loss: 0.26380 | Valid Loss: 0.26216 | Time: 0.46 seconds\n",
            "Epoch: 688 | Train Loss: 0.26339 | Valid Loss: 0.25968 | Time: 0.45 seconds\n",
            "Epoch: 689 | Train Loss: 0.26299 | Valid Loss: 0.26220 | Time: 0.48 seconds\n",
            "Epoch: 690 | Train Loss: 0.26254 | Valid Loss: 0.26138 | Time: 0.44 seconds\n",
            "Epoch: 691 | Train Loss: 0.26214 | Valid Loss: 0.26190 | Time: 0.45 seconds\n",
            "Epoch: 692 | Train Loss: 0.26171 | Valid Loss: 0.26131 | Time: 0.45 seconds\n",
            "Epoch: 693 | Train Loss: 0.26129 | Valid Loss: 0.25919 | Time: 0.46 seconds\n",
            "Epoch: 694 | Train Loss: 0.26088 | Valid Loss: 0.25935 | Time: 0.45 seconds\n",
            "Epoch: 695 | Train Loss: 0.26045 | Valid Loss: 0.25831 | Time: 0.45 seconds\n",
            "Epoch: 696 | Train Loss: 0.26003 | Valid Loss: 0.25785 | Time: 0.46 seconds\n",
            "Epoch: 697 | Train Loss: 0.25962 | Valid Loss: 0.25831 | Time: 0.44 seconds\n",
            "Epoch: 698 | Train Loss: 0.25927 | Valid Loss: 0.25671 | Time: 0.49 seconds\n",
            "Epoch: 699 | Train Loss: 0.25882 | Valid Loss: 0.25593 | Time: 0.45 seconds\n",
            "Epoch: 700 | Train Loss: 0.25840 | Valid Loss: 0.25536 | Time: 0.46 seconds\n",
            "Epoch: 701 | Train Loss: 0.25797 | Valid Loss: 0.25742 | Time: 0.45 seconds\n",
            "Epoch: 702 | Train Loss: 0.25754 | Valid Loss: 0.25672 | Time: 0.44 seconds\n",
            "Epoch: 703 | Train Loss: 0.25711 | Valid Loss: 0.25533 | Time: 0.46 seconds\n",
            "Epoch: 704 | Train Loss: 0.25672 | Valid Loss: 0.25885 | Time: 0.45 seconds\n",
            "Epoch: 705 | Train Loss: 0.25630 | Valid Loss: 0.25219 | Time: 0.46 seconds\n",
            "Epoch: 706 | Train Loss: 0.25591 | Valid Loss: 0.25560 | Time: 0.44 seconds\n",
            "Epoch: 707 | Train Loss: 0.25547 | Valid Loss: 0.25263 | Time: 0.47 seconds\n",
            "Epoch: 708 | Train Loss: 0.25508 | Valid Loss: 0.25305 | Time: 0.44 seconds\n",
            "Epoch: 709 | Train Loss: 0.25466 | Valid Loss: 0.25196 | Time: 0.46 seconds\n",
            "Epoch: 710 | Train Loss: 0.25428 | Valid Loss: 0.25222 | Time: 0.45 seconds\n",
            "Epoch: 711 | Train Loss: 0.25385 | Valid Loss: 0.25341 | Time: 0.44 seconds\n",
            "Epoch: 712 | Train Loss: 0.25346 | Valid Loss: 0.25257 | Time: 0.45 seconds\n",
            "Epoch: 713 | Train Loss: 0.25305 | Valid Loss: 0.25222 | Time: 0.45 seconds\n",
            "Epoch: 714 | Train Loss: 0.25267 | Valid Loss: 0.25156 | Time: 0.45 seconds\n",
            "Epoch: 715 | Train Loss: 0.25223 | Valid Loss: 0.24953 | Time: 0.45 seconds\n",
            "Epoch: 716 | Train Loss: 0.25184 | Valid Loss: 0.25181 | Time: 0.45 seconds\n",
            "Epoch: 717 | Train Loss: 0.25143 | Valid Loss: 0.24983 | Time: 0.43 seconds\n",
            "Epoch: 718 | Train Loss: 0.25105 | Valid Loss: 0.25224 | Time: 0.46 seconds\n",
            "Epoch: 719 | Train Loss: 0.25065 | Valid Loss: 0.24968 | Time: 0.47 seconds\n",
            "Epoch: 720 | Train Loss: 0.25026 | Valid Loss: 0.24874 | Time: 0.45 seconds\n",
            "Epoch: 721 | Train Loss: 0.24985 | Valid Loss: 0.24856 | Time: 0.48 seconds\n",
            "Epoch: 722 | Train Loss: 0.24942 | Valid Loss: 0.24833 | Time: 0.46 seconds\n",
            "Epoch: 723 | Train Loss: 0.24903 | Valid Loss: 0.24625 | Time: 0.46 seconds\n",
            "Epoch: 724 | Train Loss: 0.24864 | Valid Loss: 0.24879 | Time: 0.45 seconds\n",
            "Epoch: 725 | Train Loss: 0.24824 | Valid Loss: 0.24608 | Time: 0.47 seconds\n",
            "Epoch: 726 | Train Loss: 0.24787 | Valid Loss: 0.24810 | Time: 0.46 seconds\n",
            "Epoch: 727 | Train Loss: 0.24746 | Valid Loss: 0.24591 | Time: 0.46 seconds\n",
            "Epoch: 728 | Train Loss: 0.24707 | Valid Loss: 0.24547 | Time: 0.45 seconds\n",
            "Epoch: 729 | Train Loss: 0.24669 | Valid Loss: 0.24607 | Time: 0.45 seconds\n",
            "Epoch: 730 | Train Loss: 0.24630 | Valid Loss: 0.24558 | Time: 0.47 seconds\n",
            "Epoch: 731 | Train Loss: 0.24592 | Valid Loss: 0.24395 | Time: 0.44 seconds\n",
            "Epoch: 732 | Train Loss: 0.24550 | Valid Loss: 0.24464 | Time: 0.45 seconds\n",
            "Epoch: 733 | Train Loss: 0.24511 | Valid Loss: 0.24383 | Time: 0.45 seconds\n",
            "Epoch: 734 | Train Loss: 0.24469 | Valid Loss: 0.24249 | Time: 0.45 seconds\n",
            "Epoch: 735 | Train Loss: 0.24432 | Valid Loss: 0.24372 | Time: 0.45 seconds\n",
            "Epoch: 736 | Train Loss: 0.24393 | Valid Loss: 0.24252 | Time: 0.46 seconds\n",
            "Epoch: 737 | Train Loss: 0.24355 | Valid Loss: 0.24245 | Time: 0.47 seconds\n",
            "Epoch: 738 | Train Loss: 0.24315 | Valid Loss: 0.24150 | Time: 0.47 seconds\n",
            "Epoch: 739 | Train Loss: 0.24277 | Valid Loss: 0.24043 | Time: 0.46 seconds\n",
            "Epoch: 740 | Train Loss: 0.24237 | Valid Loss: 0.24166 | Time: 0.45 seconds\n",
            "Epoch: 741 | Train Loss: 0.24203 | Valid Loss: 0.23915 | Time: 0.46 seconds\n",
            "Epoch: 742 | Train Loss: 0.24160 | Valid Loss: 0.23942 | Time: 0.46 seconds\n",
            "Epoch: 743 | Train Loss: 0.24120 | Valid Loss: 0.24004 | Time: 0.45 seconds\n",
            "Epoch: 744 | Train Loss: 0.24081 | Valid Loss: 0.23875 | Time: 0.47 seconds\n",
            "Epoch: 745 | Train Loss: 0.24047 | Valid Loss: 0.24017 | Time: 0.46 seconds\n",
            "Epoch: 746 | Train Loss: 0.24007 | Valid Loss: 0.23834 | Time: 0.45 seconds\n",
            "Epoch: 747 | Train Loss: 0.23965 | Valid Loss: 0.23856 | Time: 0.47 seconds\n",
            "Epoch: 748 | Train Loss: 0.23933 | Valid Loss: 0.23825 | Time: 0.45 seconds\n",
            "Epoch: 749 | Train Loss: 0.23891 | Valid Loss: 0.23851 | Time: 0.45 seconds\n",
            "Epoch: 750 | Train Loss: 0.23856 | Valid Loss: 0.23587 | Time: 0.47 seconds\n",
            "Epoch: 751 | Train Loss: 0.23819 | Valid Loss: 0.23792 | Time: 0.48 seconds\n",
            "Epoch: 752 | Train Loss: 0.23783 | Valid Loss: 0.23671 | Time: 0.47 seconds\n",
            "Epoch: 753 | Train Loss: 0.23741 | Valid Loss: 0.23534 | Time: 0.47 seconds\n",
            "Epoch: 754 | Train Loss: 0.23705 | Valid Loss: 0.23393 | Time: 0.47 seconds\n",
            "Epoch: 755 | Train Loss: 0.23664 | Valid Loss: 0.23524 | Time: 0.45 seconds\n",
            "Epoch: 756 | Train Loss: 0.23632 | Valid Loss: 0.23541 | Time: 0.45 seconds\n",
            "Epoch: 757 | Train Loss: 0.23591 | Valid Loss: 0.23337 | Time: 0.46 seconds\n",
            "Epoch: 758 | Train Loss: 0.23553 | Valid Loss: 0.23527 | Time: 0.46 seconds\n",
            "Epoch: 759 | Train Loss: 0.23516 | Valid Loss: 0.23360 | Time: 0.44 seconds\n",
            "Epoch: 760 | Train Loss: 0.23477 | Valid Loss: 0.23304 | Time: 0.47 seconds\n",
            "Epoch: 761 | Train Loss: 0.23440 | Valid Loss: 0.23403 | Time: 0.45 seconds\n",
            "Epoch: 762 | Train Loss: 0.23405 | Valid Loss: 0.23321 | Time: 0.44 seconds\n",
            "Epoch: 763 | Train Loss: 0.23368 | Valid Loss: 0.23174 | Time: 0.47 seconds\n",
            "Epoch: 764 | Train Loss: 0.23330 | Valid Loss: 0.23181 | Time: 0.45 seconds\n",
            "Epoch: 765 | Train Loss: 0.23293 | Valid Loss: 0.23335 | Time: 0.46 seconds\n",
            "Epoch: 766 | Train Loss: 0.23255 | Valid Loss: 0.23063 | Time: 0.46 seconds\n",
            "Epoch: 767 | Train Loss: 0.23215 | Valid Loss: 0.22964 | Time: 0.45 seconds\n",
            "Epoch: 768 | Train Loss: 0.23176 | Valid Loss: 0.23078 | Time: 0.46 seconds\n",
            "Epoch: 769 | Train Loss: 0.23143 | Valid Loss: 0.23149 | Time: 0.44 seconds\n",
            "Epoch: 770 | Train Loss: 0.23107 | Valid Loss: 0.22982 | Time: 0.46 seconds\n",
            "Epoch: 771 | Train Loss: 0.23068 | Valid Loss: 0.22944 | Time: 0.46 seconds\n",
            "Epoch: 772 | Train Loss: 0.23032 | Valid Loss: 0.22731 | Time: 0.47 seconds\n",
            "Epoch: 773 | Train Loss: 0.22996 | Valid Loss: 0.22790 | Time: 0.45 seconds\n",
            "Epoch: 774 | Train Loss: 0.22965 | Valid Loss: 0.22826 | Time: 0.45 seconds\n",
            "Epoch: 775 | Train Loss: 0.22922 | Valid Loss: 0.22715 | Time: 0.47 seconds\n",
            "Epoch: 776 | Train Loss: 0.22889 | Valid Loss: 0.22901 | Time: 0.45 seconds\n",
            "Epoch: 777 | Train Loss: 0.22853 | Valid Loss: 0.22746 | Time: 0.45 seconds\n",
            "Epoch: 778 | Train Loss: 0.22812 | Valid Loss: 0.22597 | Time: 0.45 seconds\n",
            "Epoch: 779 | Train Loss: 0.22778 | Valid Loss: 0.22713 | Time: 0.46 seconds\n",
            "Epoch: 780 | Train Loss: 0.22743 | Valid Loss: 0.22754 | Time: 0.46 seconds\n",
            "Epoch: 781 | Train Loss: 0.22709 | Valid Loss: 0.22631 | Time: 0.46 seconds\n",
            "Epoch: 782 | Train Loss: 0.22670 | Valid Loss: 0.22582 | Time: 0.44 seconds\n",
            "Epoch: 783 | Train Loss: 0.22635 | Valid Loss: 0.22552 | Time: 0.46 seconds\n",
            "Epoch: 784 | Train Loss: 0.22601 | Valid Loss: 0.22548 | Time: 0.45 seconds\n",
            "Epoch: 785 | Train Loss: 0.22563 | Valid Loss: 0.22505 | Time: 0.46 seconds\n",
            "Epoch: 786 | Train Loss: 0.22526 | Valid Loss: 0.22249 | Time: 0.45 seconds\n",
            "Epoch: 787 | Train Loss: 0.22491 | Valid Loss: 0.22364 | Time: 0.44 seconds\n",
            "Epoch: 788 | Train Loss: 0.22454 | Valid Loss: 0.22507 | Time: 0.47 seconds\n",
            "Epoch: 789 | Train Loss: 0.22419 | Valid Loss: 0.22555 | Time: 0.44 seconds\n",
            "Epoch: 790 | Train Loss: 0.22389 | Valid Loss: 0.22372 | Time: 0.46 seconds\n",
            "Epoch: 791 | Train Loss: 0.22348 | Valid Loss: 0.22151 | Time: 0.47 seconds\n",
            "Epoch: 792 | Train Loss: 0.22314 | Valid Loss: 0.22265 | Time: 0.45 seconds\n",
            "Epoch: 793 | Train Loss: 0.22275 | Valid Loss: 0.22269 | Time: 0.44 seconds\n",
            "Epoch: 794 | Train Loss: 0.22244 | Valid Loss: 0.22248 | Time: 0.45 seconds\n",
            "Epoch: 795 | Train Loss: 0.22206 | Valid Loss: 0.21938 | Time: 0.45 seconds\n",
            "Epoch: 796 | Train Loss: 0.22170 | Valid Loss: 0.21890 | Time: 0.45 seconds\n",
            "Epoch: 797 | Train Loss: 0.22138 | Valid Loss: 0.22084 | Time: 0.47 seconds\n",
            "Epoch: 798 | Train Loss: 0.22103 | Valid Loss: 0.21945 | Time: 0.45 seconds\n",
            "Epoch: 799 | Train Loss: 0.22068 | Valid Loss: 0.22090 | Time: 0.45 seconds\n",
            "Epoch: 800 | Train Loss: 0.22029 | Valid Loss: 0.21875 | Time: 0.44 seconds\n",
            "Epoch: 801 | Train Loss: 0.21996 | Valid Loss: 0.21777 | Time: 0.46 seconds\n",
            "Epoch: 802 | Train Loss: 0.21963 | Valid Loss: 0.21747 | Time: 0.45 seconds\n",
            "Epoch: 803 | Train Loss: 0.21924 | Valid Loss: 0.21723 | Time: 0.47 seconds\n",
            "Epoch: 804 | Train Loss: 0.21892 | Valid Loss: 0.21886 | Time: 0.46 seconds\n",
            "Epoch: 805 | Train Loss: 0.21857 | Valid Loss: 0.21760 | Time: 0.47 seconds\n",
            "Epoch: 806 | Train Loss: 0.21826 | Valid Loss: 0.21579 | Time: 0.45 seconds\n",
            "Epoch: 807 | Train Loss: 0.21789 | Valid Loss: 0.21694 | Time: 0.45 seconds\n",
            "Epoch: 808 | Train Loss: 0.21756 | Valid Loss: 0.21588 | Time: 0.47 seconds\n",
            "Epoch: 809 | Train Loss: 0.21722 | Valid Loss: 0.21491 | Time: 0.44 seconds\n",
            "Epoch: 810 | Train Loss: 0.21686 | Valid Loss: 0.21551 | Time: 0.45 seconds\n",
            "Epoch: 811 | Train Loss: 0.21650 | Valid Loss: 0.21574 | Time: 0.44 seconds\n",
            "Epoch: 812 | Train Loss: 0.21615 | Valid Loss: 0.21387 | Time: 0.47 seconds\n",
            "Epoch: 813 | Train Loss: 0.21581 | Valid Loss: 0.21587 | Time: 0.44 seconds\n",
            "Epoch: 814 | Train Loss: 0.21544 | Valid Loss: 0.21333 | Time: 0.51 seconds\n",
            "Epoch: 815 | Train Loss: 0.21516 | Valid Loss: 0.21261 | Time: 0.45 seconds\n",
            "Epoch: 816 | Train Loss: 0.21481 | Valid Loss: 0.21322 | Time: 0.47 seconds\n",
            "Epoch: 817 | Train Loss: 0.21446 | Valid Loss: 0.21393 | Time: 0.46 seconds\n",
            "Epoch: 818 | Train Loss: 0.21416 | Valid Loss: 0.21227 | Time: 0.45 seconds\n",
            "Epoch: 819 | Train Loss: 0.21380 | Valid Loss: 0.21193 | Time: 0.47 seconds\n",
            "Epoch: 820 | Train Loss: 0.21345 | Valid Loss: 0.21183 | Time: 0.46 seconds\n",
            "Epoch: 821 | Train Loss: 0.21309 | Valid Loss: 0.21214 | Time: 0.46 seconds\n",
            "Epoch: 822 | Train Loss: 0.21275 | Valid Loss: 0.21129 | Time: 0.45 seconds\n",
            "Epoch: 823 | Train Loss: 0.21243 | Valid Loss: 0.21167 | Time: 0.46 seconds\n",
            "Epoch: 824 | Train Loss: 0.21211 | Valid Loss: 0.21165 | Time: 0.43 seconds\n",
            "Epoch: 825 | Train Loss: 0.21176 | Valid Loss: 0.21130 | Time: 0.46 seconds\n",
            "Epoch: 826 | Train Loss: 0.21140 | Valid Loss: 0.21020 | Time: 0.45 seconds\n",
            "Epoch: 827 | Train Loss: 0.21105 | Valid Loss: 0.21002 | Time: 0.47 seconds\n",
            "Epoch: 828 | Train Loss: 0.21078 | Valid Loss: 0.20959 | Time: 0.47 seconds\n",
            "Epoch: 829 | Train Loss: 0.21042 | Valid Loss: 0.20992 | Time: 0.44 seconds\n",
            "Epoch: 830 | Train Loss: 0.21008 | Valid Loss: 0.20727 | Time: 0.46 seconds\n",
            "Epoch: 831 | Train Loss: 0.20975 | Valid Loss: 0.20826 | Time: 0.45 seconds\n",
            "Epoch: 832 | Train Loss: 0.20943 | Valid Loss: 0.20754 | Time: 0.46 seconds\n",
            "Epoch: 833 | Train Loss: 0.20909 | Valid Loss: 0.20814 | Time: 0.47 seconds\n",
            "Epoch: 834 | Train Loss: 0.20877 | Valid Loss: 0.20749 | Time: 0.48 seconds\n",
            "Epoch: 835 | Train Loss: 0.20847 | Valid Loss: 0.20815 | Time: 0.44 seconds\n",
            "Epoch: 836 | Train Loss: 0.20812 | Valid Loss: 0.20641 | Time: 0.46 seconds\n",
            "Epoch: 837 | Train Loss: 0.20772 | Valid Loss: 0.20752 | Time: 0.46 seconds\n",
            "Epoch: 838 | Train Loss: 0.20741 | Valid Loss: 0.20655 | Time: 0.44 seconds\n",
            "Epoch: 839 | Train Loss: 0.20714 | Valid Loss: 0.20644 | Time: 0.44 seconds\n",
            "Epoch: 840 | Train Loss: 0.20677 | Valid Loss: 0.20525 | Time: 0.45 seconds\n",
            "Epoch: 841 | Train Loss: 0.20647 | Valid Loss: 0.20395 | Time: 0.47 seconds\n",
            "Epoch: 842 | Train Loss: 0.20615 | Valid Loss: 0.20470 | Time: 0.44 seconds\n",
            "Epoch: 843 | Train Loss: 0.20578 | Valid Loss: 0.20612 | Time: 0.46 seconds\n",
            "Epoch: 844 | Train Loss: 0.20548 | Valid Loss: 0.20442 | Time: 0.45 seconds\n",
            "Epoch: 845 | Train Loss: 0.20516 | Valid Loss: 0.20415 | Time: 0.47 seconds\n",
            "Epoch: 846 | Train Loss: 0.20482 | Valid Loss: 0.20341 | Time: 0.46 seconds\n",
            "Epoch: 847 | Train Loss: 0.20450 | Valid Loss: 0.20451 | Time: 0.45 seconds\n",
            "Epoch: 848 | Train Loss: 0.20422 | Valid Loss: 0.20261 | Time: 0.46 seconds\n",
            "Epoch: 849 | Train Loss: 0.20384 | Valid Loss: 0.20374 | Time: 0.44 seconds\n",
            "Epoch: 850 | Train Loss: 0.20351 | Valid Loss: 0.20238 | Time: 0.48 seconds\n",
            "Epoch: 851 | Train Loss: 0.20321 | Valid Loss: 0.20324 | Time: 0.45 seconds\n",
            "Epoch: 852 | Train Loss: 0.20291 | Valid Loss: 0.20227 | Time: 0.46 seconds\n",
            "Epoch: 853 | Train Loss: 0.20258 | Valid Loss: 0.20198 | Time: 0.45 seconds\n",
            "Epoch: 854 | Train Loss: 0.20223 | Valid Loss: 0.20070 | Time: 0.46 seconds\n",
            "Epoch: 855 | Train Loss: 0.20193 | Valid Loss: 0.19979 | Time: 0.46 seconds\n",
            "Epoch: 856 | Train Loss: 0.20164 | Valid Loss: 0.20122 | Time: 0.46 seconds\n",
            "Epoch: 857 | Train Loss: 0.20130 | Valid Loss: 0.20043 | Time: 0.46 seconds\n",
            "Epoch: 858 | Train Loss: 0.20098 | Valid Loss: 0.20028 | Time: 0.45 seconds\n",
            "Epoch: 859 | Train Loss: 0.20066 | Valid Loss: 0.19978 | Time: 0.46 seconds\n",
            "Epoch: 860 | Train Loss: 0.20033 | Valid Loss: 0.19743 | Time: 0.48 seconds\n",
            "Epoch: 861 | Train Loss: 0.20004 | Valid Loss: 0.19923 | Time: 0.47 seconds\n",
            "Epoch: 862 | Train Loss: 0.19968 | Valid Loss: 0.19890 | Time: 0.45 seconds\n",
            "Epoch: 863 | Train Loss: 0.19939 | Valid Loss: 0.19792 | Time: 0.46 seconds\n",
            "Epoch: 864 | Train Loss: 0.19906 | Valid Loss: 0.19904 | Time: 0.46 seconds\n",
            "Epoch: 865 | Train Loss: 0.19878 | Valid Loss: 0.19694 | Time: 0.47 seconds\n",
            "Epoch: 866 | Train Loss: 0.19844 | Valid Loss: 0.19689 | Time: 0.45 seconds\n",
            "Epoch: 867 | Train Loss: 0.19815 | Valid Loss: 0.19722 | Time: 0.44 seconds\n",
            "Epoch: 868 | Train Loss: 0.19785 | Valid Loss: 0.19789 | Time: 0.47 seconds\n",
            "Epoch: 869 | Train Loss: 0.19750 | Valid Loss: 0.19667 | Time: 0.45 seconds\n",
            "Epoch: 870 | Train Loss: 0.19724 | Valid Loss: 0.19647 | Time: 0.46 seconds\n",
            "Epoch: 871 | Train Loss: 0.19688 | Valid Loss: 0.19462 | Time: 0.47 seconds\n",
            "Epoch: 872 | Train Loss: 0.19657 | Valid Loss: 0.19467 | Time: 0.45 seconds\n",
            "Epoch: 873 | Train Loss: 0.19628 | Valid Loss: 0.19462 | Time: 0.47 seconds\n",
            "Epoch: 874 | Train Loss: 0.19596 | Valid Loss: 0.19523 | Time: 0.46 seconds\n",
            "Epoch: 875 | Train Loss: 0.19564 | Valid Loss: 0.19366 | Time: 0.45 seconds\n",
            "Epoch: 876 | Train Loss: 0.19535 | Valid Loss: 0.19372 | Time: 0.46 seconds\n",
            "Epoch: 877 | Train Loss: 0.19501 | Valid Loss: 0.19475 | Time: 0.45 seconds\n",
            "Epoch: 878 | Train Loss: 0.19471 | Valid Loss: 0.19363 | Time: 0.47 seconds\n",
            "Epoch: 879 | Train Loss: 0.19442 | Valid Loss: 0.19326 | Time: 0.47 seconds\n",
            "Epoch: 880 | Train Loss: 0.19409 | Valid Loss: 0.19229 | Time: 0.46 seconds\n",
            "Epoch: 881 | Train Loss: 0.19379 | Valid Loss: 0.19330 | Time: 0.45 seconds\n",
            "Epoch: 882 | Train Loss: 0.19352 | Valid Loss: 0.19262 | Time: 0.47 seconds\n",
            "Epoch: 883 | Train Loss: 0.19322 | Valid Loss: 0.19215 | Time: 0.47 seconds\n",
            "Epoch: 884 | Train Loss: 0.19286 | Valid Loss: 0.19245 | Time: 0.46 seconds\n",
            "Epoch: 885 | Train Loss: 0.19259 | Valid Loss: 0.19065 | Time: 0.46 seconds\n",
            "Epoch: 886 | Train Loss: 0.19230 | Valid Loss: 0.19056 | Time: 0.46 seconds\n",
            "Epoch: 887 | Train Loss: 0.19197 | Valid Loss: 0.19189 | Time: 0.45 seconds\n",
            "Epoch: 888 | Train Loss: 0.19166 | Valid Loss: 0.19099 | Time: 0.45 seconds\n",
            "Epoch: 889 | Train Loss: 0.19138 | Valid Loss: 0.19153 | Time: 0.45 seconds\n",
            "Epoch: 890 | Train Loss: 0.19105 | Valid Loss: 0.19107 | Time: 0.46 seconds\n",
            "Epoch: 891 | Train Loss: 0.19079 | Valid Loss: 0.18906 | Time: 0.48 seconds\n",
            "Epoch: 892 | Train Loss: 0.19047 | Valid Loss: 0.18924 | Time: 0.45 seconds\n",
            "Epoch: 893 | Train Loss: 0.19017 | Valid Loss: 0.18905 | Time: 0.45 seconds\n",
            "Epoch: 894 | Train Loss: 0.18990 | Valid Loss: 0.18881 | Time: 0.46 seconds\n",
            "Epoch: 895 | Train Loss: 0.18956 | Valid Loss: 0.18906 | Time: 0.45 seconds\n",
            "Epoch: 896 | Train Loss: 0.18927 | Valid Loss: 0.18833 | Time: 0.44 seconds\n",
            "Epoch: 897 | Train Loss: 0.18898 | Valid Loss: 0.18692 | Time: 0.47 seconds\n",
            "Epoch: 898 | Train Loss: 0.18869 | Valid Loss: 0.18780 | Time: 0.45 seconds\n",
            "Epoch: 899 | Train Loss: 0.18840 | Valid Loss: 0.18659 | Time: 0.46 seconds\n",
            "Epoch: 900 | Train Loss: 0.18811 | Valid Loss: 0.18801 | Time: 0.44 seconds\n",
            "Epoch: 901 | Train Loss: 0.18779 | Valid Loss: 0.18670 | Time: 0.45 seconds\n",
            "Epoch: 902 | Train Loss: 0.18752 | Valid Loss: 0.18610 | Time: 0.44 seconds\n",
            "Epoch: 903 | Train Loss: 0.18719 | Valid Loss: 0.18579 | Time: 0.45 seconds\n",
            "Epoch: 904 | Train Loss: 0.18695 | Valid Loss: 0.18591 | Time: 0.45 seconds\n",
            "Epoch: 905 | Train Loss: 0.18661 | Valid Loss: 0.18691 | Time: 0.47 seconds\n",
            "Epoch: 906 | Train Loss: 0.18631 | Valid Loss: 0.18561 | Time: 0.47 seconds\n",
            "Epoch: 907 | Train Loss: 0.18604 | Valid Loss: 0.18461 | Time: 0.44 seconds\n",
            "Epoch: 908 | Train Loss: 0.18573 | Valid Loss: 0.18509 | Time: 0.45 seconds\n",
            "Epoch: 909 | Train Loss: 0.18545 | Valid Loss: 0.18347 | Time: 0.44 seconds\n",
            "Epoch: 910 | Train Loss: 0.18516 | Valid Loss: 0.18595 | Time: 0.46 seconds\n",
            "Epoch: 911 | Train Loss: 0.18490 | Valid Loss: 0.18450 | Time: 0.44 seconds\n",
            "Epoch: 912 | Train Loss: 0.18457 | Valid Loss: 0.18281 | Time: 0.46 seconds\n",
            "Epoch: 913 | Train Loss: 0.18429 | Valid Loss: 0.18312 | Time: 0.45 seconds\n",
            "Epoch: 914 | Train Loss: 0.18402 | Valid Loss: 0.18368 | Time: 0.45 seconds\n",
            "Epoch: 915 | Train Loss: 0.18369 | Valid Loss: 0.18168 | Time: 0.45 seconds\n",
            "Epoch: 916 | Train Loss: 0.18343 | Valid Loss: 0.18280 | Time: 0.45 seconds\n",
            "Epoch: 917 | Train Loss: 0.18312 | Valid Loss: 0.18349 | Time: 0.46 seconds\n",
            "Epoch: 918 | Train Loss: 0.18285 | Valid Loss: 0.18208 | Time: 0.44 seconds\n",
            "Epoch: 919 | Train Loss: 0.18257 | Valid Loss: 0.18208 | Time: 0.47 seconds\n",
            "Epoch: 920 | Train Loss: 0.18227 | Valid Loss: 0.18137 | Time: 0.45 seconds\n",
            "Epoch: 921 | Train Loss: 0.18197 | Valid Loss: 0.18166 | Time: 0.46 seconds\n",
            "Epoch: 922 | Train Loss: 0.18168 | Valid Loss: 0.18007 | Time: 0.48 seconds\n",
            "Epoch: 923 | Train Loss: 0.18142 | Valid Loss: 0.18119 | Time: 0.45 seconds\n",
            "Epoch: 924 | Train Loss: 0.18111 | Valid Loss: 0.18097 | Time: 0.45 seconds\n",
            "Epoch: 925 | Train Loss: 0.18086 | Valid Loss: 0.17898 | Time: 0.45 seconds\n",
            "Epoch: 926 | Train Loss: 0.18057 | Valid Loss: 0.17958 | Time: 0.47 seconds\n",
            "Epoch: 927 | Train Loss: 0.18028 | Valid Loss: 0.17923 | Time: 0.44 seconds\n",
            "Epoch: 928 | Train Loss: 0.17995 | Valid Loss: 0.17980 | Time: 0.47 seconds\n",
            "Epoch: 929 | Train Loss: 0.17969 | Valid Loss: 0.17886 | Time: 0.47 seconds\n",
            "Epoch: 930 | Train Loss: 0.17941 | Valid Loss: 0.17966 | Time: 0.47 seconds\n",
            "Epoch: 931 | Train Loss: 0.17915 | Valid Loss: 0.17869 | Time: 0.44 seconds\n",
            "Epoch: 932 | Train Loss: 0.17885 | Valid Loss: 0.17763 | Time: 0.48 seconds\n",
            "Epoch: 933 | Train Loss: 0.17856 | Valid Loss: 0.17664 | Time: 0.48 seconds\n",
            "Epoch: 934 | Train Loss: 0.17829 | Valid Loss: 0.17675 | Time: 0.46 seconds\n",
            "Epoch: 935 | Train Loss: 0.17801 | Valid Loss: 0.17775 | Time: 0.45 seconds\n",
            "Epoch: 936 | Train Loss: 0.17772 | Valid Loss: 0.17684 | Time: 0.45 seconds\n",
            "Epoch: 937 | Train Loss: 0.17744 | Valid Loss: 0.17741 | Time: 0.46 seconds\n",
            "Epoch: 938 | Train Loss: 0.17721 | Valid Loss: 0.17616 | Time: 0.45 seconds\n",
            "Epoch: 939 | Train Loss: 0.17694 | Valid Loss: 0.17571 | Time: 0.47 seconds\n",
            "Epoch: 940 | Train Loss: 0.17664 | Valid Loss: 0.17504 | Time: 0.45 seconds\n",
            "Epoch: 941 | Train Loss: 0.17636 | Valid Loss: 0.17529 | Time: 0.47 seconds\n",
            "Epoch: 942 | Train Loss: 0.17608 | Valid Loss: 0.17500 | Time: 0.46 seconds\n",
            "Epoch: 943 | Train Loss: 0.17583 | Valid Loss: 0.17573 | Time: 0.46 seconds\n",
            "Epoch: 944 | Train Loss: 0.17554 | Valid Loss: 0.17454 | Time: 0.46 seconds\n",
            "Epoch: 945 | Train Loss: 0.17529 | Valid Loss: 0.17467 | Time: 0.46 seconds\n",
            "Epoch: 946 | Train Loss: 0.17498 | Valid Loss: 0.17287 | Time: 0.49 seconds\n",
            "Epoch: 947 | Train Loss: 0.17468 | Valid Loss: 0.17395 | Time: 0.47 seconds\n",
            "Epoch: 948 | Train Loss: 0.17446 | Valid Loss: 0.17422 | Time: 0.46 seconds\n",
            "Epoch: 949 | Train Loss: 0.17413 | Valid Loss: 0.17321 | Time: 0.44 seconds\n",
            "Epoch: 950 | Train Loss: 0.17386 | Valid Loss: 0.17371 | Time: 0.45 seconds\n",
            "Epoch: 951 | Train Loss: 0.17362 | Valid Loss: 0.17310 | Time: 0.45 seconds\n",
            "Epoch: 952 | Train Loss: 0.17329 | Valid Loss: 0.17148 | Time: 0.49 seconds\n",
            "Epoch: 953 | Train Loss: 0.17305 | Valid Loss: 0.17196 | Time: 0.44 seconds\n",
            "Epoch: 954 | Train Loss: 0.17279 | Valid Loss: 0.17230 | Time: 0.46 seconds\n",
            "Epoch: 955 | Train Loss: 0.17250 | Valid Loss: 0.17132 | Time: 0.44 seconds\n",
            "Epoch: 956 | Train Loss: 0.17223 | Valid Loss: 0.17151 | Time: 0.46 seconds\n",
            "Epoch: 957 | Train Loss: 0.17197 | Valid Loss: 0.17176 | Time: 0.46 seconds\n",
            "Epoch: 958 | Train Loss: 0.17173 | Valid Loss: 0.17056 | Time: 0.45 seconds\n",
            "Epoch: 959 | Train Loss: 0.17144 | Valid Loss: 0.17058 | Time: 0.45 seconds\n",
            "Epoch: 960 | Train Loss: 0.17118 | Valid Loss: 0.17080 | Time: 0.45 seconds\n",
            "Epoch: 961 | Train Loss: 0.17090 | Valid Loss: 0.17057 | Time: 0.46 seconds\n",
            "Epoch: 962 | Train Loss: 0.17062 | Valid Loss: 0.16989 | Time: 0.44 seconds\n",
            "Epoch: 963 | Train Loss: 0.17036 | Valid Loss: 0.17094 | Time: 0.46 seconds\n",
            "Epoch: 964 | Train Loss: 0.17009 | Valid Loss: 0.16956 | Time: 0.45 seconds\n",
            "Epoch: 965 | Train Loss: 0.16986 | Valid Loss: 0.16931 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16959 | Valid Loss: 0.16958 | Time: 0.45 seconds\n",
            "Epoch: 967 | Train Loss: 0.16933 | Valid Loss: 0.16758 | Time: 0.45 seconds\n",
            "Epoch: 968 | Train Loss: 0.16906 | Valid Loss: 0.17003 | Time: 0.46 seconds\n",
            "Epoch: 969 | Train Loss: 0.16874 | Valid Loss: 0.16760 | Time: 0.44 seconds\n",
            "Epoch: 970 | Train Loss: 0.16854 | Valid Loss: 0.16749 | Time: 0.45 seconds\n",
            "Epoch: 971 | Train Loss: 0.16824 | Valid Loss: 0.16794 | Time: 0.45 seconds\n",
            "Epoch: 972 | Train Loss: 0.16800 | Valid Loss: 0.16704 | Time: 0.47 seconds\n",
            "Epoch: 973 | Train Loss: 0.16773 | Valid Loss: 0.16657 | Time: 0.47 seconds\n",
            "Epoch: 974 | Train Loss: 0.16747 | Valid Loss: 0.16667 | Time: 0.46 seconds\n",
            "Epoch: 975 | Train Loss: 0.16719 | Valid Loss: 0.16689 | Time: 0.45 seconds\n",
            "Epoch: 976 | Train Loss: 0.16690 | Valid Loss: 0.16660 | Time: 0.45 seconds\n",
            "Epoch: 977 | Train Loss: 0.16667 | Valid Loss: 0.16485 | Time: 0.46 seconds\n",
            "Epoch: 978 | Train Loss: 0.16642 | Valid Loss: 0.16796 | Time: 0.45 seconds\n",
            "Epoch: 979 | Train Loss: 0.16617 | Valid Loss: 0.16586 | Time: 0.45 seconds\n",
            "Epoch: 980 | Train Loss: 0.16592 | Valid Loss: 0.16568 | Time: 0.46 seconds\n",
            "Epoch: 981 | Train Loss: 0.16563 | Valid Loss: 0.16652 | Time: 0.45 seconds\n",
            "Epoch: 982 | Train Loss: 0.16541 | Valid Loss: 0.16387 | Time: 0.46 seconds\n",
            "Epoch: 983 | Train Loss: 0.16516 | Valid Loss: 0.16432 | Time: 0.45 seconds\n",
            "Epoch: 984 | Train Loss: 0.16486 | Valid Loss: 0.16190 | Time: 0.46 seconds\n",
            "Epoch: 985 | Train Loss: 0.16462 | Valid Loss: 0.16471 | Time: 0.45 seconds\n",
            "Epoch: 986 | Train Loss: 0.16438 | Valid Loss: 0.16259 | Time: 0.45 seconds\n",
            "Epoch: 987 | Train Loss: 0.16411 | Valid Loss: 0.16247 | Time: 0.46 seconds\n",
            "Epoch: 988 | Train Loss: 0.16387 | Valid Loss: 0.16171 | Time: 0.46 seconds\n",
            "Epoch: 989 | Train Loss: 0.16359 | Valid Loss: 0.16311 | Time: 0.44 seconds\n",
            "Epoch: 990 | Train Loss: 0.16334 | Valid Loss: 0.16193 | Time: 0.47 seconds\n",
            "Epoch: 991 | Train Loss: 0.16310 | Valid Loss: 0.16125 | Time: 0.45 seconds\n",
            "Epoch: 992 | Train Loss: 0.16283 | Valid Loss: 0.16201 | Time: 0.45 seconds\n",
            "Epoch: 993 | Train Loss: 0.16259 | Valid Loss: 0.16244 | Time: 0.44 seconds\n",
            "Epoch: 994 | Train Loss: 0.16234 | Valid Loss: 0.16296 | Time: 0.46 seconds\n",
            "Epoch: 995 | Train Loss: 0.16206 | Valid Loss: 0.16151 | Time: 0.45 seconds\n",
            "Epoch: 996 | Train Loss: 0.16182 | Valid Loss: 0.16109 | Time: 0.45 seconds\n",
            "Epoch: 997 | Train Loss: 0.16156 | Valid Loss: 0.16050 | Time: 0.45 seconds\n",
            "Epoch: 998 | Train Loss: 0.16131 | Valid Loss: 0.16180 | Time: 0.46 seconds\n",
            "Epoch: 999 | Train Loss: 0.16108 | Valid Loss: 0.16083 | Time: 0.45 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16081 | Valid Loss: 0.15942 | Time: 0.46 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 1000\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.66 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 1]: 32.77649\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 2...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71491 | Valid Loss: 0.71196 | Time: 0.45 seconds\n",
            "Epoch: 2 | Train Loss: 0.71436 | Valid Loss: 0.71401 | Time: 0.45 seconds\n",
            "Epoch: 3 | Train Loss: 0.71383 | Valid Loss: 0.71449 | Time: 0.45 seconds\n",
            "Epoch: 4 | Train Loss: 0.71332 | Valid Loss: 0.71337 | Time: 0.46 seconds\n",
            "Epoch: 5 | Train Loss: 0.71285 | Valid Loss: 0.71277 | Time: 0.46 seconds\n",
            "Epoch: 6 | Train Loss: 0.71238 | Valid Loss: 0.71254 | Time: 0.45 seconds\n",
            "Epoch: 7 | Train Loss: 0.71193 | Valid Loss: 0.71231 | Time: 0.45 seconds\n",
            "Epoch: 8 | Train Loss: 0.71150 | Valid Loss: 0.71150 | Time: 0.47 seconds\n",
            "Epoch: 9 | Train Loss: 0.71111 | Valid Loss: 0.71121 | Time: 0.46 seconds\n",
            "Epoch: 10 | Train Loss: 0.71069 | Valid Loss: 0.71038 | Time: 0.46 seconds\n",
            "Epoch: 11 | Train Loss: 0.71028 | Valid Loss: 0.71090 | Time: 0.45 seconds\n",
            "Epoch: 12 | Train Loss: 0.70990 | Valid Loss: 0.70990 | Time: 0.47 seconds\n",
            "Epoch: 13 | Train Loss: 0.70953 | Valid Loss: 0.70956 | Time: 0.46 seconds\n",
            "Epoch: 14 | Train Loss: 0.70916 | Valid Loss: 0.70991 | Time: 0.48 seconds\n",
            "Epoch: 15 | Train Loss: 0.70880 | Valid Loss: 0.70923 | Time: 0.47 seconds\n",
            "Epoch: 16 | Train Loss: 0.70845 | Valid Loss: 0.70905 | Time: 0.46 seconds\n",
            "Epoch: 17 | Train Loss: 0.70811 | Valid Loss: 0.70844 | Time: 0.46 seconds\n",
            "Epoch: 18 | Train Loss: 0.70776 | Valid Loss: 0.70785 | Time: 0.47 seconds\n",
            "Epoch: 19 | Train Loss: 0.70744 | Valid Loss: 0.70760 | Time: 0.46 seconds\n",
            "Epoch: 20 | Train Loss: 0.70710 | Valid Loss: 0.70766 | Time: 0.47 seconds\n",
            "Epoch: 21 | Train Loss: 0.70677 | Valid Loss: 0.70732 | Time: 0.46 seconds\n",
            "Epoch: 22 | Train Loss: 0.70644 | Valid Loss: 0.70677 | Time: 0.45 seconds\n",
            "Epoch: 23 | Train Loss: 0.70612 | Valid Loss: 0.70609 | Time: 0.48 seconds\n",
            "Epoch: 24 | Train Loss: 0.70581 | Valid Loss: 0.70576 | Time: 0.46 seconds\n",
            "Epoch: 25 | Train Loss: 0.70549 | Valid Loss: 0.70576 | Time: 0.47 seconds\n",
            "Epoch: 26 | Train Loss: 0.70517 | Valid Loss: 0.70577 | Time: 0.45 seconds\n",
            "Epoch: 27 | Train Loss: 0.70486 | Valid Loss: 0.70502 | Time: 0.47 seconds\n",
            "Epoch: 28 | Train Loss: 0.70452 | Valid Loss: 0.70469 | Time: 0.45 seconds\n",
            "Epoch: 29 | Train Loss: 0.70423 | Valid Loss: 0.70386 | Time: 0.46 seconds\n",
            "Epoch: 30 | Train Loss: 0.70390 | Valid Loss: 0.70362 | Time: 0.48 seconds\n",
            "Epoch: 31 | Train Loss: 0.70359 | Valid Loss: 0.70386 | Time: 0.46 seconds\n",
            "Epoch: 32 | Train Loss: 0.70329 | Valid Loss: 0.70313 | Time: 0.46 seconds\n",
            "Epoch: 33 | Train Loss: 0.70295 | Valid Loss: 0.70365 | Time: 0.45 seconds\n",
            "Epoch: 34 | Train Loss: 0.70263 | Valid Loss: 0.70266 | Time: 0.47 seconds\n",
            "Epoch: 35 | Train Loss: 0.70232 | Valid Loss: 0.70263 | Time: 0.48 seconds\n",
            "Epoch: 36 | Train Loss: 0.70201 | Valid Loss: 0.70203 | Time: 0.47 seconds\n",
            "Epoch: 37 | Train Loss: 0.70169 | Valid Loss: 0.70228 | Time: 0.47 seconds\n",
            "Epoch: 38 | Train Loss: 0.70137 | Valid Loss: 0.70161 | Time: 0.47 seconds\n",
            "Epoch: 39 | Train Loss: 0.70103 | Valid Loss: 0.70075 | Time: 0.47 seconds\n",
            "Epoch: 40 | Train Loss: 0.70071 | Valid Loss: 0.70057 | Time: 0.47 seconds\n",
            "Epoch: 41 | Train Loss: 0.70038 | Valid Loss: 0.70073 | Time: 0.45 seconds\n",
            "Epoch: 42 | Train Loss: 0.70004 | Valid Loss: 0.70016 | Time: 0.46 seconds\n",
            "Epoch: 43 | Train Loss: 0.69971 | Valid Loss: 0.69991 | Time: 0.49 seconds\n",
            "Epoch: 44 | Train Loss: 0.69938 | Valid Loss: 0.69934 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69902 | Valid Loss: 0.69894 | Time: 0.46 seconds\n",
            "Epoch: 46 | Train Loss: 0.69868 | Valid Loss: 0.69841 | Time: 0.46 seconds\n",
            "Epoch: 47 | Train Loss: 0.69833 | Valid Loss: 0.69904 | Time: 0.46 seconds\n",
            "Epoch: 48 | Train Loss: 0.69797 | Valid Loss: 0.69829 | Time: 0.45 seconds\n",
            "Epoch: 49 | Train Loss: 0.69762 | Valid Loss: 0.69765 | Time: 0.48 seconds\n",
            "Epoch: 50 | Train Loss: 0.69726 | Valid Loss: 0.69729 | Time: 0.46 seconds\n",
            "Epoch: 51 | Train Loss: 0.69690 | Valid Loss: 0.69674 | Time: 0.47 seconds\n",
            "Epoch: 52 | Train Loss: 0.69653 | Valid Loss: 0.69652 | Time: 0.45 seconds\n",
            "Epoch: 53 | Train Loss: 0.69614 | Valid Loss: 0.69658 | Time: 0.46 seconds\n",
            "Epoch: 54 | Train Loss: 0.69577 | Valid Loss: 0.69605 | Time: 0.46 seconds\n",
            "Epoch: 55 | Train Loss: 0.69539 | Valid Loss: 0.69516 | Time: 0.48 seconds\n",
            "Epoch: 56 | Train Loss: 0.69502 | Valid Loss: 0.69547 | Time: 0.45 seconds\n",
            "Epoch: 57 | Train Loss: 0.69461 | Valid Loss: 0.69462 | Time: 0.45 seconds\n",
            "Epoch: 58 | Train Loss: 0.69423 | Valid Loss: 0.69409 | Time: 0.49 seconds\n",
            "Epoch: 59 | Train Loss: 0.69384 | Valid Loss: 0.69437 | Time: 0.45 seconds\n",
            "Epoch: 60 | Train Loss: 0.69344 | Valid Loss: 0.69388 | Time: 0.47 seconds\n",
            "Epoch: 61 | Train Loss: 0.69303 | Valid Loss: 0.69317 | Time: 0.46 seconds\n",
            "Epoch: 62 | Train Loss: 0.69263 | Valid Loss: 0.69325 | Time: 0.47 seconds\n",
            "Epoch: 63 | Train Loss: 0.69222 | Valid Loss: 0.69240 | Time: 0.46 seconds\n",
            "Epoch: 64 | Train Loss: 0.69178 | Valid Loss: 0.69122 | Time: 0.47 seconds\n",
            "Epoch: 65 | Train Loss: 0.69137 | Valid Loss: 0.69150 | Time: 0.49 seconds\n",
            "Epoch: 66 | Train Loss: 0.69095 | Valid Loss: 0.69135 | Time: 0.48 seconds\n",
            "Epoch: 67 | Train Loss: 0.69052 | Valid Loss: 0.69099 | Time: 0.47 seconds\n",
            "Epoch: 68 | Train Loss: 0.69007 | Valid Loss: 0.69038 | Time: 0.47 seconds\n",
            "Epoch: 69 | Train Loss: 0.68964 | Valid Loss: 0.68936 | Time: 0.47 seconds\n",
            "Epoch: 70 | Train Loss: 0.68920 | Valid Loss: 0.68878 | Time: 0.45 seconds\n",
            "Epoch: 71 | Train Loss: 0.68875 | Valid Loss: 0.68869 | Time: 0.48 seconds\n",
            "Epoch: 72 | Train Loss: 0.68830 | Valid Loss: 0.68863 | Time: 0.46 seconds\n",
            "Epoch: 73 | Train Loss: 0.68785 | Valid Loss: 0.68726 | Time: 0.47 seconds\n",
            "Epoch: 74 | Train Loss: 0.68737 | Valid Loss: 0.68742 | Time: 0.44 seconds\n",
            "Epoch: 75 | Train Loss: 0.68693 | Valid Loss: 0.68681 | Time: 0.48 seconds\n",
            "Epoch: 76 | Train Loss: 0.68644 | Valid Loss: 0.68661 | Time: 0.49 seconds\n",
            "Epoch: 77 | Train Loss: 0.68599 | Valid Loss: 0.68566 | Time: 0.50 seconds\n",
            "Epoch: 78 | Train Loss: 0.68551 | Valid Loss: 0.68578 | Time: 0.46 seconds\n",
            "Epoch: 79 | Train Loss: 0.68502 | Valid Loss: 0.68562 | Time: 0.47 seconds\n",
            "Epoch: 80 | Train Loss: 0.68455 | Valid Loss: 0.68515 | Time: 0.46 seconds\n",
            "Epoch: 81 | Train Loss: 0.68405 | Valid Loss: 0.68454 | Time: 0.49 seconds\n",
            "Epoch: 82 | Train Loss: 0.68356 | Valid Loss: 0.68394 | Time: 0.46 seconds\n",
            "Epoch: 83 | Train Loss: 0.68308 | Valid Loss: 0.68300 | Time: 0.47 seconds\n",
            "Epoch: 84 | Train Loss: 0.68257 | Valid Loss: 0.68305 | Time: 0.46 seconds\n",
            "Epoch: 85 | Train Loss: 0.68207 | Valid Loss: 0.68309 | Time: 0.45 seconds\n",
            "Epoch: 86 | Train Loss: 0.68156 | Valid Loss: 0.68159 | Time: 0.47 seconds\n",
            "Epoch: 87 | Train Loss: 0.68105 | Valid Loss: 0.68167 | Time: 0.48 seconds\n",
            "Epoch: 88 | Train Loss: 0.68054 | Valid Loss: 0.68186 | Time: 0.47 seconds\n",
            "Epoch: 89 | Train Loss: 0.68001 | Valid Loss: 0.68055 | Time: 0.46 seconds\n",
            "Epoch: 90 | Train Loss: 0.67949 | Valid Loss: 0.67973 | Time: 0.48 seconds\n",
            "Epoch: 91 | Train Loss: 0.67895 | Valid Loss: 0.67962 | Time: 0.48 seconds\n",
            "Epoch: 92 | Train Loss: 0.67845 | Valid Loss: 0.67866 | Time: 0.49 seconds\n",
            "Epoch: 93 | Train Loss: 0.67789 | Valid Loss: 0.67774 | Time: 0.46 seconds\n",
            "Epoch: 94 | Train Loss: 0.67736 | Valid Loss: 0.67753 | Time: 0.48 seconds\n",
            "Epoch: 95 | Train Loss: 0.67682 | Valid Loss: 0.67679 | Time: 0.45 seconds\n",
            "Epoch: 96 | Train Loss: 0.67627 | Valid Loss: 0.67714 | Time: 0.48 seconds\n",
            "Epoch: 97 | Train Loss: 0.67572 | Valid Loss: 0.67574 | Time: 0.46 seconds\n",
            "Epoch: 98 | Train Loss: 0.67516 | Valid Loss: 0.67512 | Time: 0.46 seconds\n",
            "Epoch: 99 | Train Loss: 0.67460 | Valid Loss: 0.67406 | Time: 0.48 seconds\n",
            "Epoch: 100 | Train Loss: 0.67405 | Valid Loss: 0.67408 | Time: 0.46 seconds\n",
            "Epoch: 101 | Train Loss: 0.67347 | Valid Loss: 0.67447 | Time: 0.48 seconds\n",
            "Epoch: 102 | Train Loss: 0.67290 | Valid Loss: 0.67359 | Time: 0.49 seconds\n",
            "Epoch: 103 | Train Loss: 0.67233 | Valid Loss: 0.67248 | Time: 0.48 seconds\n",
            "Epoch: 104 | Train Loss: 0.67175 | Valid Loss: 0.67135 | Time: 0.46 seconds\n",
            "Epoch: 105 | Train Loss: 0.67117 | Valid Loss: 0.67177 | Time: 0.47 seconds\n",
            "Epoch: 106 | Train Loss: 0.67058 | Valid Loss: 0.67115 | Time: 0.46 seconds\n",
            "Epoch: 107 | Train Loss: 0.67000 | Valid Loss: 0.67062 | Time: 0.48 seconds\n",
            "Epoch: 108 | Train Loss: 0.66939 | Valid Loss: 0.66978 | Time: 0.48 seconds\n",
            "Epoch: 109 | Train Loss: 0.66880 | Valid Loss: 0.66948 | Time: 0.50 seconds\n",
            "Epoch: 110 | Train Loss: 0.66819 | Valid Loss: 0.66890 | Time: 0.46 seconds\n",
            "Epoch: 111 | Train Loss: 0.66759 | Valid Loss: 0.66857 | Time: 0.46 seconds\n",
            "Epoch: 112 | Train Loss: 0.66697 | Valid Loss: 0.66856 | Time: 0.47 seconds\n",
            "Epoch: 113 | Train Loss: 0.66637 | Valid Loss: 0.66636 | Time: 0.47 seconds\n",
            "Epoch: 114 | Train Loss: 0.66575 | Valid Loss: 0.66608 | Time: 0.47 seconds\n",
            "Epoch: 115 | Train Loss: 0.66513 | Valid Loss: 0.66600 | Time: 0.46 seconds\n",
            "Epoch: 116 | Train Loss: 0.66450 | Valid Loss: 0.66528 | Time: 0.46 seconds\n",
            "Epoch: 117 | Train Loss: 0.66388 | Valid Loss: 0.66506 | Time: 0.47 seconds\n",
            "Epoch: 118 | Train Loss: 0.66324 | Valid Loss: 0.66364 | Time: 0.48 seconds\n",
            "Epoch: 119 | Train Loss: 0.66261 | Valid Loss: 0.66325 | Time: 0.46 seconds\n",
            "Epoch: 120 | Train Loss: 0.66197 | Valid Loss: 0.66229 | Time: 0.47 seconds\n",
            "Epoch: 121 | Train Loss: 0.66132 | Valid Loss: 0.66163 | Time: 0.46 seconds\n",
            "Epoch: 122 | Train Loss: 0.66068 | Valid Loss: 0.66101 | Time: 0.47 seconds\n",
            "Epoch: 123 | Train Loss: 0.66003 | Valid Loss: 0.66034 | Time: 0.45 seconds\n",
            "Epoch: 124 | Train Loss: 0.65938 | Valid Loss: 0.66041 | Time: 0.47 seconds\n",
            "Epoch: 125 | Train Loss: 0.65873 | Valid Loss: 0.65996 | Time: 0.47 seconds\n",
            "Epoch: 126 | Train Loss: 0.65805 | Valid Loss: 0.65803 | Time: 0.50 seconds\n",
            "Epoch: 127 | Train Loss: 0.65740 | Valid Loss: 0.65799 | Time: 0.47 seconds\n",
            "Epoch: 128 | Train Loss: 0.65672 | Valid Loss: 0.65778 | Time: 0.47 seconds\n",
            "Epoch: 129 | Train Loss: 0.65606 | Valid Loss: 0.65601 | Time: 0.48 seconds\n",
            "Epoch: 130 | Train Loss: 0.65539 | Valid Loss: 0.65606 | Time: 0.48 seconds\n",
            "Epoch: 131 | Train Loss: 0.65471 | Valid Loss: 0.65477 | Time: 0.49 seconds\n",
            "Epoch: 132 | Train Loss: 0.65402 | Valid Loss: 0.65459 | Time: 0.52 seconds\n",
            "Epoch: 133 | Train Loss: 0.65336 | Valid Loss: 0.65297 | Time: 0.47 seconds\n",
            "Epoch: 134 | Train Loss: 0.65266 | Valid Loss: 0.65302 | Time: 0.46 seconds\n",
            "Epoch: 135 | Train Loss: 0.65197 | Valid Loss: 0.65254 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65129 | Valid Loss: 0.65128 | Time: 0.46 seconds\n",
            "Epoch: 137 | Train Loss: 0.65060 | Valid Loss: 0.65046 | Time: 0.49 seconds\n",
            "Epoch: 138 | Train Loss: 0.64989 | Valid Loss: 0.65028 | Time: 0.46 seconds\n",
            "Epoch: 139 | Train Loss: 0.64919 | Valid Loss: 0.64999 | Time: 0.47 seconds\n",
            "Epoch: 140 | Train Loss: 0.64848 | Valid Loss: 0.64997 | Time: 0.46 seconds\n",
            "Epoch: 141 | Train Loss: 0.64778 | Valid Loss: 0.64834 | Time: 0.46 seconds\n",
            "Epoch: 142 | Train Loss: 0.64707 | Valid Loss: 0.64777 | Time: 0.49 seconds\n",
            "Epoch: 143 | Train Loss: 0.64636 | Valid Loss: 0.64686 | Time: 0.47 seconds\n",
            "Epoch: 144 | Train Loss: 0.64564 | Valid Loss: 0.64687 | Time: 0.48 seconds\n",
            "Epoch: 145 | Train Loss: 0.64493 | Valid Loss: 0.64533 | Time: 0.47 seconds\n",
            "Epoch: 146 | Train Loss: 0.64422 | Valid Loss: 0.64487 | Time: 0.49 seconds\n",
            "Epoch: 147 | Train Loss: 0.64350 | Valid Loss: 0.64363 | Time: 0.46 seconds\n",
            "Epoch: 148 | Train Loss: 0.64277 | Valid Loss: 0.64375 | Time: 0.48 seconds\n",
            "Epoch: 149 | Train Loss: 0.64204 | Valid Loss: 0.64185 | Time: 0.46 seconds\n",
            "Epoch: 150 | Train Loss: 0.64131 | Valid Loss: 0.64141 | Time: 0.47 seconds\n",
            "Epoch: 151 | Train Loss: 0.64057 | Valid Loss: 0.64124 | Time: 0.48 seconds\n",
            "Epoch: 152 | Train Loss: 0.63984 | Valid Loss: 0.64045 | Time: 0.46 seconds\n",
            "Epoch: 153 | Train Loss: 0.63909 | Valid Loss: 0.64002 | Time: 0.46 seconds\n",
            "Epoch: 154 | Train Loss: 0.63836 | Valid Loss: 0.63863 | Time: 0.48 seconds\n",
            "Epoch: 155 | Train Loss: 0.63762 | Valid Loss: 0.63790 | Time: 0.48 seconds\n",
            "Epoch: 156 | Train Loss: 0.63687 | Valid Loss: 0.63737 | Time: 0.48 seconds\n",
            "Epoch: 157 | Train Loss: 0.63611 | Valid Loss: 0.63848 | Time: 0.48 seconds\n",
            "Epoch: 158 | Train Loss: 0.63537 | Valid Loss: 0.63528 | Time: 0.46 seconds\n",
            "Epoch: 159 | Train Loss: 0.63461 | Valid Loss: 0.63507 | Time: 0.47 seconds\n",
            "Epoch: 160 | Train Loss: 0.63387 | Valid Loss: 0.63361 | Time: 0.46 seconds\n",
            "Epoch: 161 | Train Loss: 0.63311 | Valid Loss: 0.63376 | Time: 0.46 seconds\n",
            "Epoch: 162 | Train Loss: 0.63236 | Valid Loss: 0.63299 | Time: 0.46 seconds\n",
            "Epoch: 163 | Train Loss: 0.63159 | Valid Loss: 0.63200 | Time: 0.47 seconds\n",
            "Epoch: 164 | Train Loss: 0.63083 | Valid Loss: 0.63115 | Time: 0.47 seconds\n",
            "Epoch: 165 | Train Loss: 0.63006 | Valid Loss: 0.63188 | Time: 0.46 seconds\n",
            "Epoch: 166 | Train Loss: 0.62929 | Valid Loss: 0.63092 | Time: 0.47 seconds\n",
            "Epoch: 167 | Train Loss: 0.62851 | Valid Loss: 0.62925 | Time: 0.46 seconds\n",
            "Epoch: 168 | Train Loss: 0.62776 | Valid Loss: 0.62795 | Time: 0.47 seconds\n",
            "Epoch: 169 | Train Loss: 0.62699 | Valid Loss: 0.62795 | Time: 0.45 seconds\n",
            "Epoch: 170 | Train Loss: 0.62620 | Valid Loss: 0.62700 | Time: 0.48 seconds\n",
            "Epoch: 171 | Train Loss: 0.62543 | Valid Loss: 0.62726 | Time: 0.46 seconds\n",
            "Epoch: 172 | Train Loss: 0.62465 | Valid Loss: 0.62491 | Time: 0.50 seconds\n",
            "Epoch: 173 | Train Loss: 0.62388 | Valid Loss: 0.62378 | Time: 0.47 seconds\n",
            "Epoch: 174 | Train Loss: 0.62310 | Valid Loss: 0.62278 | Time: 0.47 seconds\n",
            "Epoch: 175 | Train Loss: 0.62230 | Valid Loss: 0.62395 | Time: 0.46 seconds\n",
            "Epoch: 176 | Train Loss: 0.62151 | Valid Loss: 0.62217 | Time: 0.51 seconds\n",
            "Epoch: 177 | Train Loss: 0.62073 | Valid Loss: 0.62159 | Time: 0.46 seconds\n",
            "Epoch: 178 | Train Loss: 0.61995 | Valid Loss: 0.62080 | Time: 0.46 seconds\n",
            "Epoch: 179 | Train Loss: 0.61916 | Valid Loss: 0.62055 | Time: 0.46 seconds\n",
            "Epoch: 180 | Train Loss: 0.61837 | Valid Loss: 0.61959 | Time: 0.47 seconds\n",
            "Epoch: 181 | Train Loss: 0.61758 | Valid Loss: 0.61846 | Time: 0.48 seconds\n",
            "Epoch: 182 | Train Loss: 0.61677 | Valid Loss: 0.61867 | Time: 0.46 seconds\n",
            "Epoch: 183 | Train Loss: 0.61598 | Valid Loss: 0.61720 | Time: 0.47 seconds\n",
            "Epoch: 184 | Train Loss: 0.61518 | Valid Loss: 0.61505 | Time: 0.46 seconds\n",
            "Epoch: 185 | Train Loss: 0.61439 | Valid Loss: 0.61526 | Time: 0.46 seconds\n",
            "Epoch: 186 | Train Loss: 0.61358 | Valid Loss: 0.61350 | Time: 0.47 seconds\n",
            "Epoch: 187 | Train Loss: 0.61278 | Valid Loss: 0.61440 | Time: 0.46 seconds\n",
            "Epoch: 188 | Train Loss: 0.61198 | Valid Loss: 0.61324 | Time: 0.48 seconds\n",
            "Epoch: 189 | Train Loss: 0.61115 | Valid Loss: 0.61321 | Time: 0.47 seconds\n",
            "Epoch: 190 | Train Loss: 0.61035 | Valid Loss: 0.61091 | Time: 0.46 seconds\n",
            "Epoch: 191 | Train Loss: 0.60956 | Valid Loss: 0.61071 | Time: 0.47 seconds\n",
            "Epoch: 192 | Train Loss: 0.60874 | Valid Loss: 0.60992 | Time: 0.47 seconds\n",
            "Epoch: 193 | Train Loss: 0.60793 | Valid Loss: 0.60974 | Time: 0.48 seconds\n",
            "Epoch: 194 | Train Loss: 0.60711 | Valid Loss: 0.60837 | Time: 0.47 seconds\n",
            "Epoch: 195 | Train Loss: 0.60630 | Valid Loss: 0.60827 | Time: 0.46 seconds\n",
            "Epoch: 196 | Train Loss: 0.60549 | Valid Loss: 0.60612 | Time: 0.47 seconds\n",
            "Epoch: 197 | Train Loss: 0.60468 | Valid Loss: 0.60578 | Time: 0.46 seconds\n",
            "Epoch: 198 | Train Loss: 0.60385 | Valid Loss: 0.60441 | Time: 0.50 seconds\n",
            "Epoch: 199 | Train Loss: 0.60305 | Valid Loss: 0.60410 | Time: 0.48 seconds\n",
            "Epoch: 200 | Train Loss: 0.60222 | Valid Loss: 0.60287 | Time: 0.48 seconds\n",
            "Epoch: 201 | Train Loss: 0.60141 | Valid Loss: 0.60239 | Time: 0.47 seconds\n",
            "Epoch: 202 | Train Loss: 0.60058 | Valid Loss: 0.60138 | Time: 0.47 seconds\n",
            "Epoch: 203 | Train Loss: 0.59976 | Valid Loss: 0.60044 | Time: 0.47 seconds\n",
            "Epoch: 204 | Train Loss: 0.59893 | Valid Loss: 0.60036 | Time: 0.49 seconds\n",
            "Epoch: 205 | Train Loss: 0.59811 | Valid Loss: 0.59927 | Time: 0.47 seconds\n",
            "Epoch: 206 | Train Loss: 0.59728 | Valid Loss: 0.59754 | Time: 0.48 seconds\n",
            "Epoch: 207 | Train Loss: 0.59646 | Valid Loss: 0.59741 | Time: 0.46 seconds\n",
            "Epoch: 208 | Train Loss: 0.59563 | Valid Loss: 0.59707 | Time: 0.47 seconds\n",
            "Epoch: 209 | Train Loss: 0.59479 | Valid Loss: 0.59616 | Time: 0.47 seconds\n",
            "Epoch: 210 | Train Loss: 0.59397 | Valid Loss: 0.59522 | Time: 0.46 seconds\n",
            "Epoch: 211 | Train Loss: 0.59313 | Valid Loss: 0.59303 | Time: 0.46 seconds\n",
            "Epoch: 212 | Train Loss: 0.59230 | Valid Loss: 0.59401 | Time: 0.46 seconds\n",
            "Epoch: 213 | Train Loss: 0.59147 | Valid Loss: 0.59184 | Time: 0.48 seconds\n",
            "Epoch: 214 | Train Loss: 0.59064 | Valid Loss: 0.59143 | Time: 0.49 seconds\n",
            "Epoch: 215 | Train Loss: 0.58981 | Valid Loss: 0.59098 | Time: 0.47 seconds\n",
            "Epoch: 216 | Train Loss: 0.58896 | Valid Loss: 0.59032 | Time: 0.46 seconds\n",
            "Epoch: 217 | Train Loss: 0.58812 | Valid Loss: 0.58881 | Time: 0.46 seconds\n",
            "Epoch: 218 | Train Loss: 0.58729 | Valid Loss: 0.58788 | Time: 0.47 seconds\n",
            "Epoch: 219 | Train Loss: 0.58644 | Valid Loss: 0.58752 | Time: 0.48 seconds\n",
            "Epoch: 220 | Train Loss: 0.58561 | Valid Loss: 0.58725 | Time: 0.46 seconds\n",
            "Epoch: 221 | Train Loss: 0.58476 | Valid Loss: 0.58576 | Time: 0.49 seconds\n",
            "Epoch: 222 | Train Loss: 0.58394 | Valid Loss: 0.58429 | Time: 0.46 seconds\n",
            "Epoch: 223 | Train Loss: 0.58308 | Valid Loss: 0.58362 | Time: 0.46 seconds\n",
            "Epoch: 224 | Train Loss: 0.58225 | Valid Loss: 0.58273 | Time: 0.46 seconds\n",
            "Epoch: 225 | Train Loss: 0.58141 | Valid Loss: 0.58244 | Time: 0.47 seconds\n",
            "Epoch: 226 | Train Loss: 0.58055 | Valid Loss: 0.58149 | Time: 0.47 seconds\n",
            "Epoch: 227 | Train Loss: 0.57971 | Valid Loss: 0.58170 | Time: 0.46 seconds\n",
            "Epoch: 228 | Train Loss: 0.57887 | Valid Loss: 0.58002 | Time: 0.47 seconds\n",
            "Epoch: 229 | Train Loss: 0.57801 | Valid Loss: 0.57926 | Time: 0.45 seconds\n",
            "Epoch: 230 | Train Loss: 0.57716 | Valid Loss: 0.57955 | Time: 0.45 seconds\n",
            "Epoch: 231 | Train Loss: 0.57632 | Valid Loss: 0.57777 | Time: 0.45 seconds\n",
            "Epoch: 232 | Train Loss: 0.57547 | Valid Loss: 0.57619 | Time: 0.48 seconds\n",
            "Epoch: 233 | Train Loss: 0.57461 | Valid Loss: 0.57566 | Time: 0.48 seconds\n",
            "Epoch: 234 | Train Loss: 0.57376 | Valid Loss: 0.57505 | Time: 0.48 seconds\n",
            "Epoch: 235 | Train Loss: 0.57291 | Valid Loss: 0.57272 | Time: 0.46 seconds\n",
            "Epoch: 236 | Train Loss: 0.57206 | Valid Loss: 0.57194 | Time: 0.46 seconds\n",
            "Epoch: 237 | Train Loss: 0.57120 | Valid Loss: 0.57413 | Time: 0.46 seconds\n",
            "Epoch: 238 | Train Loss: 0.57035 | Valid Loss: 0.57115 | Time: 0.47 seconds\n",
            "Epoch: 239 | Train Loss: 0.56949 | Valid Loss: 0.57032 | Time: 0.46 seconds\n",
            "Epoch: 240 | Train Loss: 0.56864 | Valid Loss: 0.56940 | Time: 0.47 seconds\n",
            "Epoch: 241 | Train Loss: 0.56779 | Valid Loss: 0.57088 | Time: 0.47 seconds\n",
            "Epoch: 242 | Train Loss: 0.56693 | Valid Loss: 0.56794 | Time: 0.46 seconds\n",
            "Epoch: 243 | Train Loss: 0.56607 | Valid Loss: 0.56845 | Time: 0.46 seconds\n",
            "Epoch: 244 | Train Loss: 0.56522 | Valid Loss: 0.56726 | Time: 0.47 seconds\n",
            "Epoch: 245 | Train Loss: 0.56437 | Valid Loss: 0.56417 | Time: 0.46 seconds\n",
            "Epoch: 246 | Train Loss: 0.56350 | Valid Loss: 0.56571 | Time: 0.46 seconds\n",
            "Epoch: 247 | Train Loss: 0.56262 | Valid Loss: 0.56424 | Time: 0.46 seconds\n",
            "Epoch: 248 | Train Loss: 0.56177 | Valid Loss: 0.56349 | Time: 0.47 seconds\n",
            "Epoch: 249 | Train Loss: 0.56091 | Valid Loss: 0.56262 | Time: 0.45 seconds\n",
            "Epoch: 250 | Train Loss: 0.56004 | Valid Loss: 0.56130 | Time: 0.47 seconds\n",
            "Epoch: 251 | Train Loss: 0.55918 | Valid Loss: 0.56069 | Time: 0.46 seconds\n",
            "Epoch: 252 | Train Loss: 0.55832 | Valid Loss: 0.56141 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55745 | Valid Loss: 0.55690 | Time: 0.46 seconds\n",
            "Epoch: 254 | Train Loss: 0.55660 | Valid Loss: 0.55945 | Time: 0.47 seconds\n",
            "Epoch: 255 | Train Loss: 0.55573 | Valid Loss: 0.55806 | Time: 0.45 seconds\n",
            "Epoch: 256 | Train Loss: 0.55486 | Valid Loss: 0.55463 | Time: 0.46 seconds\n",
            "Epoch: 257 | Train Loss: 0.55399 | Valid Loss: 0.55522 | Time: 0.46 seconds\n",
            "Epoch: 258 | Train Loss: 0.55313 | Valid Loss: 0.55260 | Time: 0.46 seconds\n",
            "Epoch: 259 | Train Loss: 0.55226 | Valid Loss: 0.55302 | Time: 0.47 seconds\n",
            "Epoch: 260 | Train Loss: 0.55141 | Valid Loss: 0.55354 | Time: 0.47 seconds\n",
            "Epoch: 261 | Train Loss: 0.55054 | Valid Loss: 0.54958 | Time: 0.48 seconds\n",
            "Epoch: 262 | Train Loss: 0.54966 | Valid Loss: 0.55224 | Time: 0.46 seconds\n",
            "Epoch: 263 | Train Loss: 0.54880 | Valid Loss: 0.55006 | Time: 0.45 seconds\n",
            "Epoch: 264 | Train Loss: 0.54791 | Valid Loss: 0.54924 | Time: 0.46 seconds\n",
            "Epoch: 265 | Train Loss: 0.54706 | Valid Loss: 0.54953 | Time: 0.47 seconds\n",
            "Epoch: 266 | Train Loss: 0.54620 | Valid Loss: 0.54713 | Time: 0.49 seconds\n",
            "Epoch: 267 | Train Loss: 0.54532 | Valid Loss: 0.54581 | Time: 0.46 seconds\n",
            "Epoch: 268 | Train Loss: 0.54445 | Valid Loss: 0.54548 | Time: 0.49 seconds\n",
            "Epoch: 269 | Train Loss: 0.54359 | Valid Loss: 0.54486 | Time: 0.46 seconds\n",
            "Epoch: 270 | Train Loss: 0.54272 | Valid Loss: 0.54416 | Time: 0.48 seconds\n",
            "Epoch: 271 | Train Loss: 0.54185 | Valid Loss: 0.54390 | Time: 0.47 seconds\n",
            "Epoch: 272 | Train Loss: 0.54097 | Valid Loss: 0.54448 | Time: 0.45 seconds\n",
            "Epoch: 273 | Train Loss: 0.54010 | Valid Loss: 0.54246 | Time: 0.45 seconds\n",
            "Epoch: 274 | Train Loss: 0.53923 | Valid Loss: 0.54046 | Time: 0.46 seconds\n",
            "Epoch: 275 | Train Loss: 0.53837 | Valid Loss: 0.53985 | Time: 0.46 seconds\n",
            "Epoch: 276 | Train Loss: 0.53747 | Valid Loss: 0.53934 | Time: 0.47 seconds\n",
            "Epoch: 277 | Train Loss: 0.53661 | Valid Loss: 0.53774 | Time: 0.45 seconds\n",
            "Epoch: 278 | Train Loss: 0.53577 | Valid Loss: 0.53706 | Time: 0.45 seconds\n",
            "Epoch: 279 | Train Loss: 0.53486 | Valid Loss: 0.53844 | Time: 0.47 seconds\n",
            "Epoch: 280 | Train Loss: 0.53400 | Valid Loss: 0.53826 | Time: 0.45 seconds\n",
            "Epoch: 281 | Train Loss: 0.53311 | Valid Loss: 0.53516 | Time: 0.47 seconds\n",
            "Epoch: 282 | Train Loss: 0.53226 | Valid Loss: 0.53330 | Time: 0.46 seconds\n",
            "Epoch: 283 | Train Loss: 0.53137 | Valid Loss: 0.53126 | Time: 0.46 seconds\n",
            "Epoch: 284 | Train Loss: 0.53050 | Valid Loss: 0.53409 | Time: 0.46 seconds\n",
            "Epoch: 285 | Train Loss: 0.52963 | Valid Loss: 0.53182 | Time: 0.45 seconds\n",
            "Epoch: 286 | Train Loss: 0.52877 | Valid Loss: 0.52921 | Time: 0.47 seconds\n",
            "Epoch: 287 | Train Loss: 0.52788 | Valid Loss: 0.52959 | Time: 0.45 seconds\n",
            "Epoch: 288 | Train Loss: 0.52701 | Valid Loss: 0.52822 | Time: 0.46 seconds\n",
            "Epoch: 289 | Train Loss: 0.52613 | Valid Loss: 0.52748 | Time: 0.47 seconds\n",
            "Epoch: 290 | Train Loss: 0.52528 | Valid Loss: 0.52706 | Time: 0.46 seconds\n",
            "Epoch: 291 | Train Loss: 0.52440 | Valid Loss: 0.52537 | Time: 0.47 seconds\n",
            "Epoch: 292 | Train Loss: 0.52351 | Valid Loss: 0.52556 | Time: 0.46 seconds\n",
            "Epoch: 293 | Train Loss: 0.52263 | Valid Loss: 0.52618 | Time: 0.45 seconds\n",
            "Epoch: 294 | Train Loss: 0.52177 | Valid Loss: 0.52361 | Time: 0.46 seconds\n",
            "Epoch: 295 | Train Loss: 0.52089 | Valid Loss: 0.52162 | Time: 0.46 seconds\n",
            "Epoch: 296 | Train Loss: 0.52003 | Valid Loss: 0.52054 | Time: 0.46 seconds\n",
            "Epoch: 297 | Train Loss: 0.51915 | Valid Loss: 0.52168 | Time: 0.45 seconds\n",
            "Epoch: 298 | Train Loss: 0.51827 | Valid Loss: 0.51922 | Time: 0.47 seconds\n",
            "Epoch: 299 | Train Loss: 0.51740 | Valid Loss: 0.51628 | Time: 0.46 seconds\n",
            "Epoch: 300 | Train Loss: 0.51652 | Valid Loss: 0.51874 | Time: 0.44 seconds\n",
            "Epoch: 301 | Train Loss: 0.51565 | Valid Loss: 0.51549 | Time: 0.47 seconds\n",
            "Epoch: 302 | Train Loss: 0.51479 | Valid Loss: 0.51575 | Time: 0.46 seconds\n",
            "Epoch: 303 | Train Loss: 0.51390 | Valid Loss: 0.51546 | Time: 0.46 seconds\n",
            "Epoch: 304 | Train Loss: 0.51303 | Valid Loss: 0.51326 | Time: 0.45 seconds\n",
            "Epoch: 305 | Train Loss: 0.51215 | Valid Loss: 0.51394 | Time: 0.45 seconds\n",
            "Epoch: 306 | Train Loss: 0.51131 | Valid Loss: 0.51263 | Time: 0.46 seconds\n",
            "Epoch: 307 | Train Loss: 0.51041 | Valid Loss: 0.51184 | Time: 0.47 seconds\n",
            "Epoch: 308 | Train Loss: 0.50955 | Valid Loss: 0.50999 | Time: 0.46 seconds\n",
            "Epoch: 309 | Train Loss: 0.50867 | Valid Loss: 0.51133 | Time: 0.45 seconds\n",
            "Epoch: 310 | Train Loss: 0.50781 | Valid Loss: 0.50800 | Time: 0.46 seconds\n",
            "Epoch: 311 | Train Loss: 0.50692 | Valid Loss: 0.50771 | Time: 0.46 seconds\n",
            "Epoch: 312 | Train Loss: 0.50607 | Valid Loss: 0.50580 | Time: 0.49 seconds\n",
            "Epoch: 313 | Train Loss: 0.50520 | Valid Loss: 0.50690 | Time: 0.45 seconds\n",
            "Epoch: 314 | Train Loss: 0.50432 | Valid Loss: 0.50307 | Time: 0.47 seconds\n",
            "Epoch: 315 | Train Loss: 0.50346 | Valid Loss: 0.50575 | Time: 0.46 seconds\n",
            "Epoch: 316 | Train Loss: 0.50258 | Valid Loss: 0.50343 | Time: 0.46 seconds\n",
            "Epoch: 317 | Train Loss: 0.50171 | Valid Loss: 0.50463 | Time: 0.46 seconds\n",
            "Epoch: 318 | Train Loss: 0.50083 | Valid Loss: 0.50362 | Time: 0.46 seconds\n",
            "Epoch: 319 | Train Loss: 0.49997 | Valid Loss: 0.49948 | Time: 0.46 seconds\n",
            "Epoch: 320 | Train Loss: 0.49910 | Valid Loss: 0.49935 | Time: 0.45 seconds\n",
            "Epoch: 321 | Train Loss: 0.49824 | Valid Loss: 0.49939 | Time: 0.46 seconds\n",
            "Epoch: 322 | Train Loss: 0.49738 | Valid Loss: 0.49919 | Time: 0.48 seconds\n",
            "Epoch: 323 | Train Loss: 0.49650 | Valid Loss: 0.49798 | Time: 0.46 seconds\n",
            "Epoch: 324 | Train Loss: 0.49564 | Valid Loss: 0.49676 | Time: 0.46 seconds\n",
            "Epoch: 325 | Train Loss: 0.49479 | Valid Loss: 0.49563 | Time: 0.46 seconds\n",
            "Epoch: 326 | Train Loss: 0.49392 | Valid Loss: 0.49520 | Time: 0.46 seconds\n",
            "Epoch: 327 | Train Loss: 0.49304 | Valid Loss: 0.49569 | Time: 0.47 seconds\n",
            "Epoch: 328 | Train Loss: 0.49218 | Valid Loss: 0.49241 | Time: 0.46 seconds\n",
            "Epoch: 329 | Train Loss: 0.49131 | Valid Loss: 0.49304 | Time: 0.46 seconds\n",
            "Epoch: 330 | Train Loss: 0.49046 | Valid Loss: 0.49271 | Time: 0.44 seconds\n",
            "Epoch: 331 | Train Loss: 0.48960 | Valid Loss: 0.49118 | Time: 0.46 seconds\n",
            "Epoch: 332 | Train Loss: 0.48872 | Valid Loss: 0.49200 | Time: 0.46 seconds\n",
            "Epoch: 333 | Train Loss: 0.48787 | Valid Loss: 0.48874 | Time: 0.45 seconds\n",
            "Epoch: 334 | Train Loss: 0.48700 | Valid Loss: 0.48933 | Time: 0.49 seconds\n",
            "Epoch: 335 | Train Loss: 0.48614 | Valid Loss: 0.48857 | Time: 0.50 seconds\n",
            "Epoch: 336 | Train Loss: 0.48527 | Valid Loss: 0.49048 | Time: 0.45 seconds\n",
            "Epoch: 337 | Train Loss: 0.48441 | Valid Loss: 0.48617 | Time: 0.47 seconds\n",
            "Epoch: 338 | Train Loss: 0.48357 | Valid Loss: 0.48412 | Time: 0.47 seconds\n",
            "Epoch: 339 | Train Loss: 0.48271 | Valid Loss: 0.48421 | Time: 0.45 seconds\n",
            "Epoch: 340 | Train Loss: 0.48184 | Valid Loss: 0.48449 | Time: 0.45 seconds\n",
            "Epoch: 341 | Train Loss: 0.48095 | Valid Loss: 0.48075 | Time: 0.45 seconds\n",
            "Epoch: 342 | Train Loss: 0.48014 | Valid Loss: 0.48175 | Time: 0.45 seconds\n",
            "Epoch: 343 | Train Loss: 0.47927 | Valid Loss: 0.48225 | Time: 0.47 seconds\n",
            "Epoch: 344 | Train Loss: 0.47842 | Valid Loss: 0.47875 | Time: 0.47 seconds\n",
            "Epoch: 345 | Train Loss: 0.47755 | Valid Loss: 0.47880 | Time: 0.47 seconds\n",
            "Epoch: 346 | Train Loss: 0.47670 | Valid Loss: 0.47849 | Time: 0.46 seconds\n",
            "Epoch: 347 | Train Loss: 0.47586 | Valid Loss: 0.47648 | Time: 0.46 seconds\n",
            "Epoch: 348 | Train Loss: 0.47500 | Valid Loss: 0.47479 | Time: 0.46 seconds\n",
            "Epoch: 349 | Train Loss: 0.47415 | Valid Loss: 0.47774 | Time: 0.47 seconds\n",
            "Epoch: 350 | Train Loss: 0.47329 | Valid Loss: 0.47437 | Time: 0.46 seconds\n",
            "Epoch: 351 | Train Loss: 0.47246 | Valid Loss: 0.47413 | Time: 0.47 seconds\n",
            "Epoch: 352 | Train Loss: 0.47162 | Valid Loss: 0.47513 | Time: 0.47 seconds\n",
            "Epoch: 353 | Train Loss: 0.47076 | Valid Loss: 0.47386 | Time: 0.48 seconds\n",
            "Epoch: 354 | Train Loss: 0.46993 | Valid Loss: 0.47104 | Time: 0.46 seconds\n",
            "Epoch: 355 | Train Loss: 0.46906 | Valid Loss: 0.46901 | Time: 0.47 seconds\n",
            "Epoch: 356 | Train Loss: 0.46823 | Valid Loss: 0.47074 | Time: 0.45 seconds\n",
            "Epoch: 357 | Train Loss: 0.46737 | Valid Loss: 0.46960 | Time: 0.45 seconds\n",
            "Epoch: 358 | Train Loss: 0.46653 | Valid Loss: 0.46745 | Time: 0.47 seconds\n",
            "Epoch: 359 | Train Loss: 0.46570 | Valid Loss: 0.46733 | Time: 0.45 seconds\n",
            "Epoch: 360 | Train Loss: 0.46486 | Valid Loss: 0.46569 | Time: 0.46 seconds\n",
            "Epoch: 361 | Train Loss: 0.46401 | Valid Loss: 0.46427 | Time: 0.46 seconds\n",
            "Epoch: 362 | Train Loss: 0.46316 | Valid Loss: 0.46428 | Time: 0.46 seconds\n",
            "Epoch: 363 | Train Loss: 0.46233 | Valid Loss: 0.46330 | Time: 0.45 seconds\n",
            "Epoch: 364 | Train Loss: 0.46148 | Valid Loss: 0.46396 | Time: 0.46 seconds\n",
            "Epoch: 365 | Train Loss: 0.46067 | Valid Loss: 0.46172 | Time: 0.46 seconds\n",
            "Epoch: 366 | Train Loss: 0.45982 | Valid Loss: 0.46310 | Time: 0.44 seconds\n",
            "Epoch: 367 | Train Loss: 0.45899 | Valid Loss: 0.46194 | Time: 0.45 seconds\n",
            "Epoch: 368 | Train Loss: 0.45814 | Valid Loss: 0.46006 | Time: 0.48 seconds\n",
            "Epoch: 369 | Train Loss: 0.45733 | Valid Loss: 0.46003 | Time: 0.48 seconds\n",
            "Epoch: 370 | Train Loss: 0.45653 | Valid Loss: 0.45708 | Time: 0.47 seconds\n",
            "Epoch: 371 | Train Loss: 0.45566 | Valid Loss: 0.45848 | Time: 0.46 seconds\n",
            "Epoch: 372 | Train Loss: 0.45483 | Valid Loss: 0.45826 | Time: 0.44 seconds\n",
            "Epoch: 373 | Train Loss: 0.45402 | Valid Loss: 0.45492 | Time: 0.48 seconds\n",
            "Epoch: 374 | Train Loss: 0.45317 | Valid Loss: 0.45390 | Time: 0.45 seconds\n",
            "Epoch: 375 | Train Loss: 0.45234 | Valid Loss: 0.45410 | Time: 0.44 seconds\n",
            "Epoch: 376 | Train Loss: 0.45150 | Valid Loss: 0.45274 | Time: 0.46 seconds\n",
            "Epoch: 377 | Train Loss: 0.45066 | Valid Loss: 0.45257 | Time: 0.49 seconds\n",
            "Epoch: 378 | Train Loss: 0.44988 | Valid Loss: 0.45004 | Time: 0.47 seconds\n",
            "Epoch: 379 | Train Loss: 0.44906 | Valid Loss: 0.45078 | Time: 0.45 seconds\n",
            "Epoch: 380 | Train Loss: 0.44827 | Valid Loss: 0.45098 | Time: 0.48 seconds\n",
            "Epoch: 381 | Train Loss: 0.44743 | Valid Loss: 0.45020 | Time: 0.46 seconds\n",
            "Epoch: 382 | Train Loss: 0.44662 | Valid Loss: 0.44953 | Time: 0.46 seconds\n",
            "Epoch: 383 | Train Loss: 0.44578 | Valid Loss: 0.44779 | Time: 0.47 seconds\n",
            "Epoch: 384 | Train Loss: 0.44498 | Valid Loss: 0.44590 | Time: 0.46 seconds\n",
            "Epoch: 385 | Train Loss: 0.44416 | Valid Loss: 0.44550 | Time: 0.46 seconds\n",
            "Epoch: 386 | Train Loss: 0.44333 | Valid Loss: 0.44474 | Time: 0.50 seconds\n",
            "Epoch: 387 | Train Loss: 0.44254 | Valid Loss: 0.44397 | Time: 0.47 seconds\n",
            "Epoch: 388 | Train Loss: 0.44171 | Valid Loss: 0.44393 | Time: 0.46 seconds\n",
            "Epoch: 389 | Train Loss: 0.44090 | Valid Loss: 0.44354 | Time: 0.48 seconds\n",
            "Epoch: 390 | Train Loss: 0.44011 | Valid Loss: 0.44124 | Time: 0.47 seconds\n",
            "Epoch: 391 | Train Loss: 0.43930 | Valid Loss: 0.44075 | Time: 0.47 seconds\n",
            "Epoch: 392 | Train Loss: 0.43850 | Valid Loss: 0.43727 | Time: 0.46 seconds\n",
            "Epoch: 393 | Train Loss: 0.43769 | Valid Loss: 0.43906 | Time: 0.45 seconds\n",
            "Epoch: 394 | Train Loss: 0.43688 | Valid Loss: 0.43807 | Time: 0.46 seconds\n",
            "Epoch: 395 | Train Loss: 0.43608 | Valid Loss: 0.43711 | Time: 0.46 seconds\n",
            "Epoch: 396 | Train Loss: 0.43530 | Valid Loss: 0.43446 | Time: 0.47 seconds\n",
            "Epoch: 397 | Train Loss: 0.43451 | Valid Loss: 0.43724 | Time: 0.47 seconds\n",
            "Epoch: 398 | Train Loss: 0.43367 | Valid Loss: 0.43609 | Time: 0.46 seconds\n",
            "Epoch: 399 | Train Loss: 0.43289 | Valid Loss: 0.43486 | Time: 0.46 seconds\n",
            "Epoch: 400 | Train Loss: 0.43210 | Valid Loss: 0.43345 | Time: 0.46 seconds\n",
            "Epoch: 401 | Train Loss: 0.43129 | Valid Loss: 0.43119 | Time: 0.47 seconds\n",
            "Epoch: 402 | Train Loss: 0.43055 | Valid Loss: 0.43045 | Time: 0.46 seconds\n",
            "Epoch: 403 | Train Loss: 0.42972 | Valid Loss: 0.43207 | Time: 0.48 seconds\n",
            "Epoch: 404 | Train Loss: 0.42892 | Valid Loss: 0.43015 | Time: 0.47 seconds\n",
            "Epoch: 405 | Train Loss: 0.42815 | Valid Loss: 0.43205 | Time: 0.44 seconds\n",
            "Epoch: 406 | Train Loss: 0.42734 | Valid Loss: 0.42953 | Time: 0.47 seconds\n",
            "Epoch: 407 | Train Loss: 0.42656 | Valid Loss: 0.42848 | Time: 0.45 seconds\n",
            "Epoch: 408 | Train Loss: 0.42575 | Valid Loss: 0.42790 | Time: 0.46 seconds\n",
            "Epoch: 409 | Train Loss: 0.42498 | Valid Loss: 0.42700 | Time: 0.47 seconds\n",
            "Epoch: 410 | Train Loss: 0.42423 | Valid Loss: 0.42587 | Time: 0.46 seconds\n",
            "Epoch: 411 | Train Loss: 0.42346 | Valid Loss: 0.42568 | Time: 0.47 seconds\n",
            "Epoch: 412 | Train Loss: 0.42266 | Valid Loss: 0.42366 | Time: 0.45 seconds\n",
            "Epoch: 413 | Train Loss: 0.42188 | Valid Loss: 0.42141 | Time: 0.47 seconds\n",
            "Epoch: 414 | Train Loss: 0.42111 | Valid Loss: 0.42260 | Time: 0.44 seconds\n",
            "Epoch: 415 | Train Loss: 0.42036 | Valid Loss: 0.42435 | Time: 0.45 seconds\n",
            "Epoch: 416 | Train Loss: 0.41956 | Valid Loss: 0.42202 | Time: 0.45 seconds\n",
            "Epoch: 417 | Train Loss: 0.41877 | Valid Loss: 0.42210 | Time: 0.45 seconds\n",
            "Epoch: 418 | Train Loss: 0.41802 | Valid Loss: 0.42051 | Time: 0.45 seconds\n",
            "Epoch: 419 | Train Loss: 0.41726 | Valid Loss: 0.41911 | Time: 0.46 seconds\n",
            "Epoch: 420 | Train Loss: 0.41651 | Valid Loss: 0.41902 | Time: 0.47 seconds\n",
            "Epoch: 421 | Train Loss: 0.41572 | Valid Loss: 0.41771 | Time: 0.45 seconds\n",
            "Epoch: 422 | Train Loss: 0.41498 | Valid Loss: 0.41618 | Time: 0.47 seconds\n",
            "Epoch: 423 | Train Loss: 0.41422 | Valid Loss: 0.41691 | Time: 0.45 seconds\n",
            "Epoch: 424 | Train Loss: 0.41344 | Valid Loss: 0.41529 | Time: 0.46 seconds\n",
            "Epoch: 425 | Train Loss: 0.41270 | Valid Loss: 0.41485 | Time: 0.47 seconds\n",
            "Epoch: 426 | Train Loss: 0.41191 | Valid Loss: 0.41302 | Time: 0.49 seconds\n",
            "Epoch: 427 | Train Loss: 0.41118 | Valid Loss: 0.41363 | Time: 0.45 seconds\n",
            "Epoch: 428 | Train Loss: 0.41038 | Valid Loss: 0.41254 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40970 | Valid Loss: 0.41163 | Time: 0.45 seconds\n",
            "Epoch: 430 | Train Loss: 0.40891 | Valid Loss: 0.41313 | Time: 0.47 seconds\n",
            "Epoch: 431 | Train Loss: 0.40817 | Valid Loss: 0.40925 | Time: 0.45 seconds\n",
            "Epoch: 432 | Train Loss: 0.40739 | Valid Loss: 0.40840 | Time: 0.46 seconds\n",
            "Epoch: 433 | Train Loss: 0.40666 | Valid Loss: 0.40753 | Time: 0.48 seconds\n",
            "Epoch: 434 | Train Loss: 0.40593 | Valid Loss: 0.40778 | Time: 0.44 seconds\n",
            "Epoch: 435 | Train Loss: 0.40517 | Valid Loss: 0.40322 | Time: 0.45 seconds\n",
            "Epoch: 436 | Train Loss: 0.40444 | Valid Loss: 0.40619 | Time: 0.44 seconds\n",
            "Epoch: 437 | Train Loss: 0.40371 | Valid Loss: 0.40402 | Time: 0.46 seconds\n",
            "Epoch: 438 | Train Loss: 0.40296 | Valid Loss: 0.40474 | Time: 0.44 seconds\n",
            "Epoch: 439 | Train Loss: 0.40220 | Valid Loss: 0.40462 | Time: 0.47 seconds\n",
            "Epoch: 440 | Train Loss: 0.40147 | Valid Loss: 0.40262 | Time: 0.46 seconds\n",
            "Epoch: 441 | Train Loss: 0.40074 | Valid Loss: 0.40230 | Time: 0.48 seconds\n",
            "Epoch: 442 | Train Loss: 0.40004 | Valid Loss: 0.40278 | Time: 0.45 seconds\n",
            "Epoch: 443 | Train Loss: 0.39933 | Valid Loss: 0.40100 | Time: 0.46 seconds\n",
            "Epoch: 444 | Train Loss: 0.39856 | Valid Loss: 0.39831 | Time: 0.49 seconds\n",
            "Epoch: 445 | Train Loss: 0.39785 | Valid Loss: 0.40040 | Time: 0.45 seconds\n",
            "Epoch: 446 | Train Loss: 0.39713 | Valid Loss: 0.40084 | Time: 0.48 seconds\n",
            "Epoch: 447 | Train Loss: 0.39640 | Valid Loss: 0.39893 | Time: 0.46 seconds\n",
            "Epoch: 448 | Train Loss: 0.39565 | Valid Loss: 0.39842 | Time: 0.49 seconds\n",
            "Epoch: 449 | Train Loss: 0.39496 | Valid Loss: 0.39561 | Time: 0.47 seconds\n",
            "Epoch: 450 | Train Loss: 0.39424 | Valid Loss: 0.39613 | Time: 0.47 seconds\n",
            "Epoch: 451 | Train Loss: 0.39351 | Valid Loss: 0.39460 | Time: 0.45 seconds\n",
            "Epoch: 452 | Train Loss: 0.39279 | Valid Loss: 0.39532 | Time: 0.47 seconds\n",
            "Epoch: 453 | Train Loss: 0.39210 | Valid Loss: 0.39457 | Time: 0.46 seconds\n",
            "Epoch: 454 | Train Loss: 0.39138 | Valid Loss: 0.39180 | Time: 0.46 seconds\n",
            "Epoch: 455 | Train Loss: 0.39065 | Valid Loss: 0.39411 | Time: 0.48 seconds\n",
            "Epoch: 456 | Train Loss: 0.38995 | Valid Loss: 0.39093 | Time: 0.47 seconds\n",
            "Epoch: 457 | Train Loss: 0.38926 | Valid Loss: 0.39012 | Time: 0.48 seconds\n",
            "Epoch: 458 | Train Loss: 0.38854 | Valid Loss: 0.39128 | Time: 0.46 seconds\n",
            "Epoch: 459 | Train Loss: 0.38782 | Valid Loss: 0.39202 | Time: 0.46 seconds\n",
            "Epoch: 460 | Train Loss: 0.38715 | Valid Loss: 0.38971 | Time: 0.45 seconds\n",
            "Epoch: 461 | Train Loss: 0.38644 | Valid Loss: 0.38864 | Time: 0.47 seconds\n",
            "Epoch: 462 | Train Loss: 0.38574 | Valid Loss: 0.38656 | Time: 0.46 seconds\n",
            "Epoch: 463 | Train Loss: 0.38506 | Valid Loss: 0.38714 | Time: 0.48 seconds\n",
            "Epoch: 464 | Train Loss: 0.38434 | Valid Loss: 0.38689 | Time: 0.46 seconds\n",
            "Epoch: 465 | Train Loss: 0.38365 | Valid Loss: 0.38635 | Time: 0.50 seconds\n",
            "Epoch: 466 | Train Loss: 0.38298 | Valid Loss: 0.38486 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38226 | Valid Loss: 0.38500 | Time: 0.45 seconds\n",
            "Epoch: 468 | Train Loss: 0.38155 | Valid Loss: 0.38427 | Time: 0.46 seconds\n",
            "Epoch: 469 | Train Loss: 0.38091 | Valid Loss: 0.38359 | Time: 0.48 seconds\n",
            "Epoch: 470 | Train Loss: 0.38020 | Valid Loss: 0.38271 | Time: 0.47 seconds\n",
            "Epoch: 471 | Train Loss: 0.37951 | Valid Loss: 0.38210 | Time: 0.46 seconds\n",
            "Epoch: 472 | Train Loss: 0.37883 | Valid Loss: 0.38142 | Time: 0.47 seconds\n",
            "Epoch: 473 | Train Loss: 0.37817 | Valid Loss: 0.37966 | Time: 0.49 seconds\n",
            "Epoch: 474 | Train Loss: 0.37750 | Valid Loss: 0.37896 | Time: 0.47 seconds\n",
            "Epoch: 475 | Train Loss: 0.37678 | Valid Loss: 0.37706 | Time: 0.47 seconds\n",
            "Epoch: 476 | Train Loss: 0.37615 | Valid Loss: 0.37932 | Time: 0.46 seconds\n",
            "Epoch: 477 | Train Loss: 0.37543 | Valid Loss: 0.37778 | Time: 0.45 seconds\n",
            "Epoch: 478 | Train Loss: 0.37475 | Valid Loss: 0.37720 | Time: 0.48 seconds\n",
            "Epoch: 479 | Train Loss: 0.37413 | Valid Loss: 0.37477 | Time: 0.46 seconds\n",
            "Epoch: 480 | Train Loss: 0.37344 | Valid Loss: 0.37273 | Time: 0.46 seconds\n",
            "Epoch: 481 | Train Loss: 0.37277 | Valid Loss: 0.37563 | Time: 0.46 seconds\n",
            "Epoch: 482 | Train Loss: 0.37208 | Valid Loss: 0.37421 | Time: 0.45 seconds\n",
            "Epoch: 483 | Train Loss: 0.37143 | Valid Loss: 0.37288 | Time: 0.45 seconds\n",
            "Epoch: 484 | Train Loss: 0.37076 | Valid Loss: 0.37145 | Time: 0.47 seconds\n",
            "Epoch: 485 | Train Loss: 0.37012 | Valid Loss: 0.37067 | Time: 0.46 seconds\n",
            "Epoch: 486 | Train Loss: 0.36943 | Valid Loss: 0.37147 | Time: 0.45 seconds\n",
            "Epoch: 487 | Train Loss: 0.36881 | Valid Loss: 0.37085 | Time: 0.46 seconds\n",
            "Epoch: 488 | Train Loss: 0.36818 | Valid Loss: 0.36943 | Time: 0.46 seconds\n",
            "Epoch: 489 | Train Loss: 0.36748 | Valid Loss: 0.37012 | Time: 0.44 seconds\n",
            "Epoch: 490 | Train Loss: 0.36682 | Valid Loss: 0.36789 | Time: 0.46 seconds\n",
            "Epoch: 491 | Train Loss: 0.36618 | Valid Loss: 0.36763 | Time: 0.47 seconds\n",
            "Epoch: 492 | Train Loss: 0.36553 | Valid Loss: 0.36850 | Time: 0.47 seconds\n",
            "Epoch: 493 | Train Loss: 0.36490 | Valid Loss: 0.36547 | Time: 0.48 seconds\n",
            "Epoch: 494 | Train Loss: 0.36425 | Valid Loss: 0.36511 | Time: 0.46 seconds\n",
            "Epoch: 495 | Train Loss: 0.36360 | Valid Loss: 0.36697 | Time: 0.45 seconds\n",
            "Epoch: 496 | Train Loss: 0.36293 | Valid Loss: 0.36529 | Time: 0.46 seconds\n",
            "Epoch: 497 | Train Loss: 0.36233 | Valid Loss: 0.36302 | Time: 0.47 seconds\n",
            "Epoch: 498 | Train Loss: 0.36169 | Valid Loss: 0.36278 | Time: 0.47 seconds\n",
            "Epoch: 499 | Train Loss: 0.36102 | Valid Loss: 0.36336 | Time: 0.45 seconds\n",
            "Epoch: 500 | Train Loss: 0.36043 | Valid Loss: 0.36370 | Time: 0.44 seconds\n",
            "Epoch: 501 | Train Loss: 0.35974 | Valid Loss: 0.36237 | Time: 0.47 seconds\n",
            "Epoch: 502 | Train Loss: 0.35908 | Valid Loss: 0.36351 | Time: 0.46 seconds\n",
            "Epoch: 503 | Train Loss: 0.35849 | Valid Loss: 0.36130 | Time: 0.46 seconds\n",
            "Epoch: 504 | Train Loss: 0.35785 | Valid Loss: 0.35930 | Time: 0.47 seconds\n",
            "Epoch: 505 | Train Loss: 0.35724 | Valid Loss: 0.36005 | Time: 0.46 seconds\n",
            "Epoch: 506 | Train Loss: 0.35661 | Valid Loss: 0.35829 | Time: 0.47 seconds\n",
            "Epoch: 507 | Train Loss: 0.35599 | Valid Loss: 0.35831 | Time: 0.46 seconds\n",
            "Epoch: 508 | Train Loss: 0.35536 | Valid Loss: 0.35914 | Time: 0.45 seconds\n",
            "Epoch: 509 | Train Loss: 0.35473 | Valid Loss: 0.35659 | Time: 0.49 seconds\n",
            "Epoch: 510 | Train Loss: 0.35415 | Valid Loss: 0.35749 | Time: 0.48 seconds\n",
            "Epoch: 511 | Train Loss: 0.35350 | Valid Loss: 0.35588 | Time: 0.45 seconds\n",
            "Epoch: 512 | Train Loss: 0.35283 | Valid Loss: 0.35490 | Time: 0.47 seconds\n",
            "Epoch: 513 | Train Loss: 0.35222 | Valid Loss: 0.35510 | Time: 0.46 seconds\n",
            "Epoch: 514 | Train Loss: 0.35164 | Valid Loss: 0.35332 | Time: 0.47 seconds\n",
            "Epoch: 515 | Train Loss: 0.35104 | Valid Loss: 0.35252 | Time: 0.47 seconds\n",
            "Epoch: 516 | Train Loss: 0.35041 | Valid Loss: 0.35354 | Time: 0.50 seconds\n",
            "Epoch: 517 | Train Loss: 0.34977 | Valid Loss: 0.35276 | Time: 0.44 seconds\n",
            "Epoch: 518 | Train Loss: 0.34919 | Valid Loss: 0.35103 | Time: 0.46 seconds\n",
            "Epoch: 519 | Train Loss: 0.34858 | Valid Loss: 0.35133 | Time: 0.46 seconds\n",
            "Epoch: 520 | Train Loss: 0.34796 | Valid Loss: 0.35091 | Time: 0.47 seconds\n",
            "Epoch: 521 | Train Loss: 0.34740 | Valid Loss: 0.35132 | Time: 0.45 seconds\n",
            "Epoch: 522 | Train Loss: 0.34677 | Valid Loss: 0.34916 | Time: 0.46 seconds\n",
            "Epoch: 523 | Train Loss: 0.34618 | Valid Loss: 0.34987 | Time: 0.49 seconds\n",
            "Epoch: 524 | Train Loss: 0.34556 | Valid Loss: 0.34703 | Time: 0.45 seconds\n",
            "Epoch: 525 | Train Loss: 0.34500 | Valid Loss: 0.34696 | Time: 0.47 seconds\n",
            "Epoch: 526 | Train Loss: 0.34440 | Valid Loss: 0.34654 | Time: 0.46 seconds\n",
            "Epoch: 527 | Train Loss: 0.34378 | Valid Loss: 0.34535 | Time: 0.46 seconds\n",
            "Epoch: 528 | Train Loss: 0.34316 | Valid Loss: 0.34459 | Time: 0.46 seconds\n",
            "Epoch: 529 | Train Loss: 0.34260 | Valid Loss: 0.34471 | Time: 0.46 seconds\n",
            "Epoch: 530 | Train Loss: 0.34201 | Valid Loss: 0.34208 | Time: 0.48 seconds\n",
            "Epoch: 531 | Train Loss: 0.34141 | Valid Loss: 0.34390 | Time: 0.47 seconds\n",
            "Epoch: 532 | Train Loss: 0.34080 | Valid Loss: 0.34122 | Time: 0.47 seconds\n",
            "Epoch: 533 | Train Loss: 0.34025 | Valid Loss: 0.34472 | Time: 0.46 seconds\n",
            "Epoch: 534 | Train Loss: 0.33964 | Valid Loss: 0.34251 | Time: 0.46 seconds\n",
            "Epoch: 535 | Train Loss: 0.33908 | Valid Loss: 0.34009 | Time: 0.45 seconds\n",
            "Epoch: 536 | Train Loss: 0.33851 | Valid Loss: 0.34072 | Time: 0.47 seconds\n",
            "Epoch: 537 | Train Loss: 0.33791 | Valid Loss: 0.34041 | Time: 0.45 seconds\n",
            "Epoch: 538 | Train Loss: 0.33732 | Valid Loss: 0.34045 | Time: 0.49 seconds\n",
            "Epoch: 539 | Train Loss: 0.33674 | Valid Loss: 0.33859 | Time: 0.45 seconds\n",
            "Epoch: 540 | Train Loss: 0.33614 | Valid Loss: 0.34077 | Time: 0.46 seconds\n",
            "Epoch: 541 | Train Loss: 0.33558 | Valid Loss: 0.33852 | Time: 0.45 seconds\n",
            "Epoch: 542 | Train Loss: 0.33503 | Valid Loss: 0.33785 | Time: 0.46 seconds\n",
            "Epoch: 543 | Train Loss: 0.33445 | Valid Loss: 0.33473 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33384 | Valid Loss: 0.33551 | Time: 0.47 seconds\n",
            "Epoch: 545 | Train Loss: 0.33328 | Valid Loss: 0.33629 | Time: 0.45 seconds\n",
            "Epoch: 546 | Train Loss: 0.33275 | Valid Loss: 0.33645 | Time: 0.44 seconds\n",
            "Epoch: 547 | Train Loss: 0.33214 | Valid Loss: 0.33324 | Time: 0.47 seconds\n",
            "Epoch: 548 | Train Loss: 0.33157 | Valid Loss: 0.33223 | Time: 0.46 seconds\n",
            "Epoch: 549 | Train Loss: 0.33100 | Valid Loss: 0.33254 | Time: 0.47 seconds\n",
            "Epoch: 550 | Train Loss: 0.33048 | Valid Loss: 0.33157 | Time: 0.46 seconds\n",
            "Epoch: 551 | Train Loss: 0.32992 | Valid Loss: 0.33090 | Time: 0.46 seconds\n",
            "Epoch: 552 | Train Loss: 0.32934 | Valid Loss: 0.33188 | Time: 0.46 seconds\n",
            "Epoch: 553 | Train Loss: 0.32881 | Valid Loss: 0.33149 | Time: 0.45 seconds\n",
            "Epoch: 554 | Train Loss: 0.32825 | Valid Loss: 0.33098 | Time: 0.44 seconds\n",
            "Epoch: 555 | Train Loss: 0.32770 | Valid Loss: 0.32834 | Time: 0.45 seconds\n",
            "Epoch: 556 | Train Loss: 0.32712 | Valid Loss: 0.33070 | Time: 0.46 seconds\n",
            "Epoch: 557 | Train Loss: 0.32656 | Valid Loss: 0.32913 | Time: 0.45 seconds\n",
            "Epoch: 558 | Train Loss: 0.32599 | Valid Loss: 0.32713 | Time: 0.46 seconds\n",
            "Epoch: 559 | Train Loss: 0.32548 | Valid Loss: 0.32661 | Time: 0.47 seconds\n",
            "Epoch: 560 | Train Loss: 0.32491 | Valid Loss: 0.33045 | Time: 0.46 seconds\n",
            "Epoch: 561 | Train Loss: 0.32438 | Valid Loss: 0.32836 | Time: 0.46 seconds\n",
            "Epoch: 562 | Train Loss: 0.32382 | Valid Loss: 0.32478 | Time: 0.48 seconds\n",
            "Epoch: 563 | Train Loss: 0.32323 | Valid Loss: 0.32428 | Time: 0.45 seconds\n",
            "Epoch: 564 | Train Loss: 0.32273 | Valid Loss: 0.32494 | Time: 0.46 seconds\n",
            "Epoch: 565 | Train Loss: 0.32219 | Valid Loss: 0.32556 | Time: 0.46 seconds\n",
            "Epoch: 566 | Train Loss: 0.32164 | Valid Loss: 0.32494 | Time: 0.44 seconds\n",
            "Epoch: 567 | Train Loss: 0.32109 | Valid Loss: 0.32432 | Time: 0.46 seconds\n",
            "Epoch: 568 | Train Loss: 0.32058 | Valid Loss: 0.32310 | Time: 0.46 seconds\n",
            "Epoch: 569 | Train Loss: 0.32001 | Valid Loss: 0.32289 | Time: 0.48 seconds\n",
            "Epoch: 570 | Train Loss: 0.31948 | Valid Loss: 0.32267 | Time: 0.45 seconds\n",
            "Epoch: 571 | Train Loss: 0.31898 | Valid Loss: 0.32223 | Time: 0.48 seconds\n",
            "Epoch: 572 | Train Loss: 0.31841 | Valid Loss: 0.32053 | Time: 0.45 seconds\n",
            "Epoch: 573 | Train Loss: 0.31790 | Valid Loss: 0.31796 | Time: 0.46 seconds\n",
            "Epoch: 574 | Train Loss: 0.31737 | Valid Loss: 0.32188 | Time: 0.47 seconds\n",
            "Epoch: 575 | Train Loss: 0.31681 | Valid Loss: 0.31637 | Time: 0.46 seconds\n",
            "Epoch: 576 | Train Loss: 0.31631 | Valid Loss: 0.31710 | Time: 0.44 seconds\n",
            "Epoch: 577 | Train Loss: 0.31574 | Valid Loss: 0.31764 | Time: 0.45 seconds\n",
            "Epoch: 578 | Train Loss: 0.31527 | Valid Loss: 0.31771 | Time: 0.47 seconds\n",
            "Epoch: 579 | Train Loss: 0.31469 | Valid Loss: 0.31691 | Time: 0.46 seconds\n",
            "Epoch: 580 | Train Loss: 0.31415 | Valid Loss: 0.31913 | Time: 0.48 seconds\n",
            "Epoch: 581 | Train Loss: 0.31371 | Valid Loss: 0.31534 | Time: 0.48 seconds\n",
            "Epoch: 582 | Train Loss: 0.31312 | Valid Loss: 0.31635 | Time: 0.47 seconds\n",
            "Epoch: 583 | Train Loss: 0.31264 | Valid Loss: 0.31697 | Time: 0.45 seconds\n",
            "Epoch: 584 | Train Loss: 0.31210 | Valid Loss: 0.31454 | Time: 0.49 seconds\n",
            "Epoch: 585 | Train Loss: 0.31157 | Valid Loss: 0.31394 | Time: 0.46 seconds\n",
            "Epoch: 586 | Train Loss: 0.31108 | Valid Loss: 0.31326 | Time: 0.48 seconds\n",
            "Epoch: 587 | Train Loss: 0.31055 | Valid Loss: 0.31258 | Time: 0.47 seconds\n",
            "Epoch: 588 | Train Loss: 0.31004 | Valid Loss: 0.31281 | Time: 0.45 seconds\n",
            "Epoch: 589 | Train Loss: 0.30955 | Valid Loss: 0.31244 | Time: 0.49 seconds\n",
            "Epoch: 590 | Train Loss: 0.30896 | Valid Loss: 0.31078 | Time: 0.46 seconds\n",
            "Epoch: 591 | Train Loss: 0.30850 | Valid Loss: 0.31038 | Time: 0.49 seconds\n",
            "Epoch: 592 | Train Loss: 0.30797 | Valid Loss: 0.31235 | Time: 0.46 seconds\n",
            "Epoch: 593 | Train Loss: 0.30749 | Valid Loss: 0.30848 | Time: 0.47 seconds\n",
            "Epoch: 594 | Train Loss: 0.30698 | Valid Loss: 0.30888 | Time: 0.46 seconds\n",
            "Epoch: 595 | Train Loss: 0.30644 | Valid Loss: 0.30801 | Time: 0.47 seconds\n",
            "Epoch: 596 | Train Loss: 0.30596 | Valid Loss: 0.30730 | Time: 0.47 seconds\n",
            "Epoch: 597 | Train Loss: 0.30543 | Valid Loss: 0.30537 | Time: 0.49 seconds\n",
            "Epoch: 598 | Train Loss: 0.30494 | Valid Loss: 0.30750 | Time: 0.45 seconds\n",
            "Epoch: 599 | Train Loss: 0.30445 | Valid Loss: 0.30555 | Time: 0.46 seconds\n",
            "Epoch: 600 | Train Loss: 0.30393 | Valid Loss: 0.30415 | Time: 0.45 seconds\n",
            "Epoch: 601 | Train Loss: 0.30342 | Valid Loss: 0.30650 | Time: 0.46 seconds\n",
            "Epoch: 602 | Train Loss: 0.30294 | Valid Loss: 0.30403 | Time: 0.46 seconds\n",
            "Epoch: 603 | Train Loss: 0.30242 | Valid Loss: 0.30430 | Time: 0.46 seconds\n",
            "Epoch: 604 | Train Loss: 0.30193 | Valid Loss: 0.30409 | Time: 0.47 seconds\n",
            "Epoch: 605 | Train Loss: 0.30145 | Valid Loss: 0.30356 | Time: 0.49 seconds\n",
            "Epoch: 606 | Train Loss: 0.30093 | Valid Loss: 0.30396 | Time: 0.47 seconds\n",
            "Epoch: 607 | Train Loss: 0.30041 | Valid Loss: 0.30186 | Time: 0.47 seconds\n",
            "Epoch: 608 | Train Loss: 0.29995 | Valid Loss: 0.30227 | Time: 0.46 seconds\n",
            "Epoch: 609 | Train Loss: 0.29945 | Valid Loss: 0.30185 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29898 | Valid Loss: 0.29787 | Time: 0.47 seconds\n",
            "Epoch: 611 | Train Loss: 0.29850 | Valid Loss: 0.30100 | Time: 0.47 seconds\n",
            "Epoch: 612 | Train Loss: 0.29798 | Valid Loss: 0.29944 | Time: 0.46 seconds\n",
            "Epoch: 613 | Train Loss: 0.29747 | Valid Loss: 0.30021 | Time: 0.46 seconds\n",
            "Epoch: 614 | Train Loss: 0.29703 | Valid Loss: 0.29844 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29655 | Valid Loss: 0.29768 | Time: 0.47 seconds\n",
            "Epoch: 616 | Train Loss: 0.29602 | Valid Loss: 0.29816 | Time: 0.46 seconds\n",
            "Epoch: 617 | Train Loss: 0.29556 | Valid Loss: 0.30100 | Time: 0.46 seconds\n",
            "Epoch: 618 | Train Loss: 0.29512 | Valid Loss: 0.29794 | Time: 0.47 seconds\n",
            "Epoch: 619 | Train Loss: 0.29463 | Valid Loss: 0.29716 | Time: 0.46 seconds\n",
            "Epoch: 620 | Train Loss: 0.29412 | Valid Loss: 0.29495 | Time: 0.46 seconds\n",
            "Epoch: 621 | Train Loss: 0.29361 | Valid Loss: 0.29673 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29314 | Valid Loss: 0.29793 | Time: 0.44 seconds\n",
            "Epoch: 623 | Train Loss: 0.29264 | Valid Loss: 0.29585 | Time: 0.46 seconds\n",
            "Epoch: 624 | Train Loss: 0.29217 | Valid Loss: 0.29309 | Time: 0.48 seconds\n",
            "Epoch: 625 | Train Loss: 0.29173 | Valid Loss: 0.29551 | Time: 0.46 seconds\n",
            "Epoch: 626 | Train Loss: 0.29124 | Valid Loss: 0.29197 | Time: 0.46 seconds\n",
            "Epoch: 627 | Train Loss: 0.29075 | Valid Loss: 0.29384 | Time: 0.45 seconds\n",
            "Epoch: 628 | Train Loss: 0.29027 | Valid Loss: 0.29242 | Time: 0.45 seconds\n",
            "Epoch: 629 | Train Loss: 0.28981 | Valid Loss: 0.29319 | Time: 0.45 seconds\n",
            "Epoch: 630 | Train Loss: 0.28937 | Valid Loss: 0.29138 | Time: 0.49 seconds\n",
            "Epoch: 631 | Train Loss: 0.28888 | Valid Loss: 0.29060 | Time: 0.46 seconds\n",
            "Epoch: 632 | Train Loss: 0.28840 | Valid Loss: 0.28980 | Time: 0.47 seconds\n",
            "Epoch: 633 | Train Loss: 0.28796 | Valid Loss: 0.28909 | Time: 0.46 seconds\n",
            "Epoch: 634 | Train Loss: 0.28746 | Valid Loss: 0.28989 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28700 | Valid Loss: 0.28894 | Time: 0.45 seconds\n",
            "Epoch: 636 | Train Loss: 0.28657 | Valid Loss: 0.28877 | Time: 0.45 seconds\n",
            "Epoch: 637 | Train Loss: 0.28608 | Valid Loss: 0.28818 | Time: 0.47 seconds\n",
            "Epoch: 638 | Train Loss: 0.28561 | Valid Loss: 0.28575 | Time: 0.46 seconds\n",
            "Epoch: 639 | Train Loss: 0.28512 | Valid Loss: 0.28720 | Time: 0.47 seconds\n",
            "Epoch: 640 | Train Loss: 0.28468 | Valid Loss: 0.28658 | Time: 0.45 seconds\n",
            "Epoch: 641 | Train Loss: 0.28422 | Valid Loss: 0.28592 | Time: 0.45 seconds\n",
            "Epoch: 642 | Train Loss: 0.28379 | Valid Loss: 0.28549 | Time: 0.47 seconds\n",
            "Epoch: 643 | Train Loss: 0.28327 | Valid Loss: 0.28399 | Time: 0.47 seconds\n",
            "Epoch: 644 | Train Loss: 0.28285 | Valid Loss: 0.28437 | Time: 0.47 seconds\n",
            "Epoch: 645 | Train Loss: 0.28237 | Valid Loss: 0.28432 | Time: 0.46 seconds\n",
            "Epoch: 646 | Train Loss: 0.28196 | Valid Loss: 0.28366 | Time: 0.46 seconds\n",
            "Epoch: 647 | Train Loss: 0.28149 | Valid Loss: 0.28301 | Time: 0.45 seconds\n",
            "Epoch: 648 | Train Loss: 0.28101 | Valid Loss: 0.28174 | Time: 0.49 seconds\n",
            "Epoch: 649 | Train Loss: 0.28058 | Valid Loss: 0.27995 | Time: 0.48 seconds\n",
            "Epoch: 650 | Train Loss: 0.28006 | Valid Loss: 0.27842 | Time: 0.48 seconds\n",
            "Epoch: 651 | Train Loss: 0.27968 | Valid Loss: 0.28059 | Time: 0.46 seconds\n",
            "Epoch: 652 | Train Loss: 0.27920 | Valid Loss: 0.28015 | Time: 0.45 seconds\n",
            "Epoch: 653 | Train Loss: 0.27877 | Valid Loss: 0.28157 | Time: 0.46 seconds\n",
            "Epoch: 654 | Train Loss: 0.27827 | Valid Loss: 0.28180 | Time: 0.48 seconds\n",
            "Epoch: 655 | Train Loss: 0.27789 | Valid Loss: 0.27889 | Time: 0.46 seconds\n",
            "Epoch: 656 | Train Loss: 0.27739 | Valid Loss: 0.27858 | Time: 0.45 seconds\n",
            "Epoch: 657 | Train Loss: 0.27694 | Valid Loss: 0.27751 | Time: 0.47 seconds\n",
            "Epoch: 658 | Train Loss: 0.27649 | Valid Loss: 0.27788 | Time: 0.44 seconds\n",
            "Epoch: 659 | Train Loss: 0.27605 | Valid Loss: 0.27615 | Time: 0.46 seconds\n",
            "Epoch: 660 | Train Loss: 0.27561 | Valid Loss: 0.27775 | Time: 0.46 seconds\n",
            "Epoch: 661 | Train Loss: 0.27515 | Valid Loss: 0.27669 | Time: 0.47 seconds\n",
            "Epoch: 662 | Train Loss: 0.27475 | Valid Loss: 0.27661 | Time: 0.44 seconds\n",
            "Epoch: 663 | Train Loss: 0.27433 | Valid Loss: 0.27848 | Time: 0.45 seconds\n",
            "Epoch: 664 | Train Loss: 0.27386 | Valid Loss: 0.27608 | Time: 0.45 seconds\n",
            "Epoch: 665 | Train Loss: 0.27343 | Valid Loss: 0.27511 | Time: 0.48 seconds\n",
            "Epoch: 666 | Train Loss: 0.27295 | Valid Loss: 0.27469 | Time: 0.44 seconds\n",
            "Epoch: 667 | Train Loss: 0.27255 | Valid Loss: 0.27386 | Time: 0.46 seconds\n",
            "Epoch: 668 | Train Loss: 0.27204 | Valid Loss: 0.27451 | Time: 0.43 seconds\n",
            "Epoch: 669 | Train Loss: 0.27161 | Valid Loss: 0.27273 | Time: 0.45 seconds\n",
            "Epoch: 670 | Train Loss: 0.27123 | Valid Loss: 0.27475 | Time: 0.48 seconds\n",
            "Epoch: 671 | Train Loss: 0.27072 | Valid Loss: 0.27020 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27032 | Valid Loss: 0.27388 | Time: 0.47 seconds\n",
            "Epoch: 673 | Train Loss: 0.26987 | Valid Loss: 0.27256 | Time: 0.44 seconds\n",
            "Epoch: 674 | Train Loss: 0.26950 | Valid Loss: 0.27113 | Time: 0.46 seconds\n",
            "Epoch: 675 | Train Loss: 0.26903 | Valid Loss: 0.27080 | Time: 0.45 seconds\n",
            "Epoch: 676 | Train Loss: 0.26857 | Valid Loss: 0.26841 | Time: 0.51 seconds\n",
            "Epoch: 677 | Train Loss: 0.26817 | Valid Loss: 0.26790 | Time: 0.47 seconds\n",
            "Epoch: 678 | Train Loss: 0.26774 | Valid Loss: 0.27134 | Time: 0.46 seconds\n",
            "Epoch: 679 | Train Loss: 0.26731 | Valid Loss: 0.27044 | Time: 0.45 seconds\n",
            "Epoch: 680 | Train Loss: 0.26684 | Valid Loss: 0.26848 | Time: 0.45 seconds\n",
            "Epoch: 681 | Train Loss: 0.26647 | Valid Loss: 0.26753 | Time: 0.47 seconds\n",
            "Epoch: 682 | Train Loss: 0.26603 | Valid Loss: 0.26882 | Time: 0.45 seconds\n",
            "Epoch: 683 | Train Loss: 0.26558 | Valid Loss: 0.26710 | Time: 0.48 seconds\n",
            "Epoch: 684 | Train Loss: 0.26522 | Valid Loss: 0.26772 | Time: 0.46 seconds\n",
            "Epoch: 685 | Train Loss: 0.26475 | Valid Loss: 0.26650 | Time: 0.47 seconds\n",
            "Epoch: 686 | Train Loss: 0.26430 | Valid Loss: 0.26662 | Time: 0.45 seconds\n",
            "Epoch: 687 | Train Loss: 0.26388 | Valid Loss: 0.26523 | Time: 0.47 seconds\n",
            "Epoch: 688 | Train Loss: 0.26347 | Valid Loss: 0.26376 | Time: 0.47 seconds\n",
            "Epoch: 689 | Train Loss: 0.26304 | Valid Loss: 0.26470 | Time: 0.45 seconds\n",
            "Epoch: 690 | Train Loss: 0.26264 | Valid Loss: 0.26557 | Time: 0.46 seconds\n",
            "Epoch: 691 | Train Loss: 0.26221 | Valid Loss: 0.26476 | Time: 0.46 seconds\n",
            "Epoch: 692 | Train Loss: 0.26180 | Valid Loss: 0.26401 | Time: 0.48 seconds\n",
            "Epoch: 693 | Train Loss: 0.26134 | Valid Loss: 0.26193 | Time: 0.46 seconds\n",
            "Epoch: 694 | Train Loss: 0.26097 | Valid Loss: 0.26301 | Time: 0.47 seconds\n",
            "Epoch: 695 | Train Loss: 0.26055 | Valid Loss: 0.26173 | Time: 0.44 seconds\n",
            "Epoch: 696 | Train Loss: 0.26010 | Valid Loss: 0.26104 | Time: 0.48 seconds\n",
            "Epoch: 697 | Train Loss: 0.25968 | Valid Loss: 0.26363 | Time: 0.46 seconds\n",
            "Epoch: 698 | Train Loss: 0.25928 | Valid Loss: 0.26086 | Time: 0.47 seconds\n",
            "Epoch: 699 | Train Loss: 0.25885 | Valid Loss: 0.26168 | Time: 0.47 seconds\n",
            "Epoch: 700 | Train Loss: 0.25845 | Valid Loss: 0.26038 | Time: 0.46 seconds\n",
            "Epoch: 701 | Train Loss: 0.25809 | Valid Loss: 0.26104 | Time: 0.47 seconds\n",
            "Epoch: 702 | Train Loss: 0.25758 | Valid Loss: 0.25883 | Time: 0.46 seconds\n",
            "Epoch: 703 | Train Loss: 0.25723 | Valid Loss: 0.25923 | Time: 0.46 seconds\n",
            "Epoch: 704 | Train Loss: 0.25677 | Valid Loss: 0.25941 | Time: 0.45 seconds\n",
            "Epoch: 705 | Train Loss: 0.25641 | Valid Loss: 0.25758 | Time: 0.48 seconds\n",
            "Epoch: 706 | Train Loss: 0.25593 | Valid Loss: 0.25744 | Time: 0.47 seconds\n",
            "Epoch: 707 | Train Loss: 0.25553 | Valid Loss: 0.25817 | Time: 0.46 seconds\n",
            "Epoch: 708 | Train Loss: 0.25516 | Valid Loss: 0.25780 | Time: 0.46 seconds\n",
            "Epoch: 709 | Train Loss: 0.25472 | Valid Loss: 0.25754 | Time: 0.46 seconds\n",
            "Epoch: 710 | Train Loss: 0.25430 | Valid Loss: 0.25500 | Time: 0.46 seconds\n",
            "Epoch: 711 | Train Loss: 0.25394 | Valid Loss: 0.25608 | Time: 0.47 seconds\n",
            "Epoch: 712 | Train Loss: 0.25356 | Valid Loss: 0.25558 | Time: 0.46 seconds\n",
            "Epoch: 713 | Train Loss: 0.25312 | Valid Loss: 0.25569 | Time: 0.48 seconds\n",
            "Epoch: 714 | Train Loss: 0.25271 | Valid Loss: 0.25474 | Time: 0.48 seconds\n",
            "Epoch: 715 | Train Loss: 0.25232 | Valid Loss: 0.25524 | Time: 0.45 seconds\n",
            "Epoch: 716 | Train Loss: 0.25191 | Valid Loss: 0.25272 | Time: 0.46 seconds\n",
            "Epoch: 717 | Train Loss: 0.25154 | Valid Loss: 0.25391 | Time: 0.47 seconds\n",
            "Epoch: 718 | Train Loss: 0.25113 | Valid Loss: 0.25379 | Time: 0.47 seconds\n",
            "Epoch: 719 | Train Loss: 0.25073 | Valid Loss: 0.25332 | Time: 0.45 seconds\n",
            "Epoch: 720 | Train Loss: 0.25031 | Valid Loss: 0.25205 | Time: 0.47 seconds\n",
            "Epoch: 721 | Train Loss: 0.24990 | Valid Loss: 0.25220 | Time: 0.46 seconds\n",
            "Epoch: 722 | Train Loss: 0.24952 | Valid Loss: 0.25199 | Time: 0.48 seconds\n",
            "Epoch: 723 | Train Loss: 0.24910 | Valid Loss: 0.25223 | Time: 0.45 seconds\n",
            "Epoch: 724 | Train Loss: 0.24871 | Valid Loss: 0.25255 | Time: 0.47 seconds\n",
            "Epoch: 725 | Train Loss: 0.24832 | Valid Loss: 0.25017 | Time: 0.46 seconds\n",
            "Epoch: 726 | Train Loss: 0.24791 | Valid Loss: 0.24994 | Time: 0.48 seconds\n",
            "Epoch: 727 | Train Loss: 0.24750 | Valid Loss: 0.25128 | Time: 0.46 seconds\n",
            "Epoch: 728 | Train Loss: 0.24713 | Valid Loss: 0.25161 | Time: 0.46 seconds\n",
            "Epoch: 729 | Train Loss: 0.24673 | Valid Loss: 0.24961 | Time: 0.48 seconds\n",
            "Epoch: 730 | Train Loss: 0.24635 | Valid Loss: 0.24907 | Time: 0.45 seconds\n",
            "Epoch: 731 | Train Loss: 0.24592 | Valid Loss: 0.24907 | Time: 0.47 seconds\n",
            "Epoch: 732 | Train Loss: 0.24552 | Valid Loss: 0.24599 | Time: 0.46 seconds\n",
            "Epoch: 733 | Train Loss: 0.24520 | Valid Loss: 0.24649 | Time: 0.47 seconds\n",
            "Epoch: 734 | Train Loss: 0.24477 | Valid Loss: 0.24742 | Time: 0.45 seconds\n",
            "Epoch: 735 | Train Loss: 0.24439 | Valid Loss: 0.24471 | Time: 0.47 seconds\n",
            "Epoch: 736 | Train Loss: 0.24400 | Valid Loss: 0.24791 | Time: 0.45 seconds\n",
            "Epoch: 737 | Train Loss: 0.24361 | Valid Loss: 0.24630 | Time: 0.46 seconds\n",
            "Epoch: 738 | Train Loss: 0.24321 | Valid Loss: 0.24541 | Time: 0.45 seconds\n",
            "Epoch: 739 | Train Loss: 0.24281 | Valid Loss: 0.24425 | Time: 0.48 seconds\n",
            "Epoch: 740 | Train Loss: 0.24239 | Valid Loss: 0.24450 | Time: 0.45 seconds\n",
            "Epoch: 741 | Train Loss: 0.24205 | Valid Loss: 0.24391 | Time: 0.47 seconds\n",
            "Epoch: 742 | Train Loss: 0.24168 | Valid Loss: 0.24427 | Time: 0.47 seconds\n",
            "Epoch: 743 | Train Loss: 0.24126 | Valid Loss: 0.24554 | Time: 0.46 seconds\n",
            "Epoch: 744 | Train Loss: 0.24089 | Valid Loss: 0.24178 | Time: 0.47 seconds\n",
            "Epoch: 745 | Train Loss: 0.24052 | Valid Loss: 0.24149 | Time: 0.48 seconds\n",
            "Epoch: 746 | Train Loss: 0.24014 | Valid Loss: 0.24247 | Time: 0.46 seconds\n",
            "Epoch: 747 | Train Loss: 0.23974 | Valid Loss: 0.24217 | Time: 0.45 seconds\n",
            "Epoch: 748 | Train Loss: 0.23938 | Valid Loss: 0.24296 | Time: 0.46 seconds\n",
            "Epoch: 749 | Train Loss: 0.23895 | Valid Loss: 0.24105 | Time: 0.45 seconds\n",
            "Epoch: 750 | Train Loss: 0.23860 | Valid Loss: 0.24038 | Time: 0.46 seconds\n",
            "Epoch: 751 | Train Loss: 0.23823 | Valid Loss: 0.23923 | Time: 0.47 seconds\n",
            "Epoch: 752 | Train Loss: 0.23786 | Valid Loss: 0.24081 | Time: 0.45 seconds\n",
            "Epoch: 753 | Train Loss: 0.23741 | Valid Loss: 0.23874 | Time: 0.48 seconds\n",
            "Epoch: 754 | Train Loss: 0.23707 | Valid Loss: 0.23925 | Time: 0.46 seconds\n",
            "Epoch: 755 | Train Loss: 0.23673 | Valid Loss: 0.23735 | Time: 0.47 seconds\n",
            "Epoch: 756 | Train Loss: 0.23637 | Valid Loss: 0.23932 | Time: 0.45 seconds\n",
            "Epoch: 757 | Train Loss: 0.23594 | Valid Loss: 0.23926 | Time: 0.48 seconds\n",
            "Epoch: 758 | Train Loss: 0.23558 | Valid Loss: 0.23853 | Time: 0.45 seconds\n",
            "Epoch: 759 | Train Loss: 0.23519 | Valid Loss: 0.23829 | Time: 0.46 seconds\n",
            "Epoch: 760 | Train Loss: 0.23482 | Valid Loss: 0.23665 | Time: 0.47 seconds\n",
            "Epoch: 761 | Train Loss: 0.23447 | Valid Loss: 0.23579 | Time: 0.45 seconds\n",
            "Epoch: 762 | Train Loss: 0.23409 | Valid Loss: 0.23653 | Time: 0.47 seconds\n",
            "Epoch: 763 | Train Loss: 0.23373 | Valid Loss: 0.23702 | Time: 0.45 seconds\n",
            "Epoch: 764 | Train Loss: 0.23333 | Valid Loss: 0.23520 | Time: 0.48 seconds\n",
            "Epoch: 765 | Train Loss: 0.23297 | Valid Loss: 0.23472 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23255 | Valid Loss: 0.23479 | Time: 0.45 seconds\n",
            "Epoch: 767 | Train Loss: 0.23223 | Valid Loss: 0.23444 | Time: 0.50 seconds\n",
            "Epoch: 768 | Train Loss: 0.23186 | Valid Loss: 0.23338 | Time: 0.46 seconds\n",
            "Epoch: 769 | Train Loss: 0.23149 | Valid Loss: 0.23532 | Time: 0.48 seconds\n",
            "Epoch: 770 | Train Loss: 0.23114 | Valid Loss: 0.23203 | Time: 0.46 seconds\n",
            "Epoch: 771 | Train Loss: 0.23077 | Valid Loss: 0.23298 | Time: 0.45 seconds\n",
            "Epoch: 772 | Train Loss: 0.23038 | Valid Loss: 0.23189 | Time: 0.46 seconds\n",
            "Epoch: 773 | Train Loss: 0.23003 | Valid Loss: 0.23262 | Time: 0.46 seconds\n",
            "Epoch: 774 | Train Loss: 0.22965 | Valid Loss: 0.23164 | Time: 0.46 seconds\n",
            "Epoch: 775 | Train Loss: 0.22932 | Valid Loss: 0.23256 | Time: 0.47 seconds\n",
            "Epoch: 776 | Train Loss: 0.22891 | Valid Loss: 0.23137 | Time: 0.46 seconds\n",
            "Epoch: 777 | Train Loss: 0.22860 | Valid Loss: 0.23113 | Time: 0.48 seconds\n",
            "Epoch: 778 | Train Loss: 0.22822 | Valid Loss: 0.23011 | Time: 0.47 seconds\n",
            "Epoch: 779 | Train Loss: 0.22784 | Valid Loss: 0.22868 | Time: 0.46 seconds\n",
            "Epoch: 780 | Train Loss: 0.22747 | Valid Loss: 0.23020 | Time: 0.45 seconds\n",
            "Epoch: 781 | Train Loss: 0.22711 | Valid Loss: 0.23024 | Time: 0.49 seconds\n",
            "Epoch: 782 | Train Loss: 0.22679 | Valid Loss: 0.23001 | Time: 0.46 seconds\n",
            "Epoch: 783 | Train Loss: 0.22642 | Valid Loss: 0.22988 | Time: 0.45 seconds\n",
            "Epoch: 784 | Train Loss: 0.22604 | Valid Loss: 0.22939 | Time: 0.46 seconds\n",
            "Epoch: 785 | Train Loss: 0.22569 | Valid Loss: 0.22677 | Time: 0.45 seconds\n",
            "Epoch: 786 | Train Loss: 0.22532 | Valid Loss: 0.22802 | Time: 0.46 seconds\n",
            "Epoch: 787 | Train Loss: 0.22499 | Valid Loss: 0.22641 | Time: 0.46 seconds\n",
            "Epoch: 788 | Train Loss: 0.22461 | Valid Loss: 0.22547 | Time: 0.46 seconds\n",
            "Epoch: 789 | Train Loss: 0.22424 | Valid Loss: 0.22656 | Time: 0.47 seconds\n",
            "Epoch: 790 | Train Loss: 0.22387 | Valid Loss: 0.22468 | Time: 0.50 seconds\n",
            "Epoch: 791 | Train Loss: 0.22353 | Valid Loss: 0.22523 | Time: 0.46 seconds\n",
            "Epoch: 792 | Train Loss: 0.22319 | Valid Loss: 0.22454 | Time: 0.45 seconds\n",
            "Epoch: 793 | Train Loss: 0.22283 | Valid Loss: 0.22560 | Time: 0.46 seconds\n",
            "Epoch: 794 | Train Loss: 0.22247 | Valid Loss: 0.22447 | Time: 0.45 seconds\n",
            "Epoch: 795 | Train Loss: 0.22211 | Valid Loss: 0.22412 | Time: 0.46 seconds\n",
            "Epoch: 796 | Train Loss: 0.22181 | Valid Loss: 0.22384 | Time: 0.47 seconds\n",
            "Epoch: 797 | Train Loss: 0.22142 | Valid Loss: 0.22382 | Time: 0.47 seconds\n",
            "Epoch: 798 | Train Loss: 0.22109 | Valid Loss: 0.22382 | Time: 0.46 seconds\n",
            "Epoch: 799 | Train Loss: 0.22074 | Valid Loss: 0.22388 | Time: 0.46 seconds\n",
            "Epoch: 800 | Train Loss: 0.22038 | Valid Loss: 0.22174 | Time: 0.47 seconds\n",
            "Epoch: 801 | Train Loss: 0.22003 | Valid Loss: 0.22104 | Time: 0.47 seconds\n",
            "Epoch: 802 | Train Loss: 0.21970 | Valid Loss: 0.22011 | Time: 0.45 seconds\n",
            "Epoch: 803 | Train Loss: 0.21934 | Valid Loss: 0.22152 | Time: 0.43 seconds\n",
            "Epoch: 804 | Train Loss: 0.21897 | Valid Loss: 0.22012 | Time: 0.45 seconds\n",
            "Epoch: 805 | Train Loss: 0.21862 | Valid Loss: 0.21895 | Time: 0.45 seconds\n",
            "Epoch: 806 | Train Loss: 0.21829 | Valid Loss: 0.21928 | Time: 0.46 seconds\n",
            "Epoch: 807 | Train Loss: 0.21796 | Valid Loss: 0.22189 | Time: 0.44 seconds\n",
            "Epoch: 808 | Train Loss: 0.21760 | Valid Loss: 0.21914 | Time: 0.47 seconds\n",
            "Epoch: 809 | Train Loss: 0.21725 | Valid Loss: 0.21891 | Time: 0.49 seconds\n",
            "Epoch: 810 | Train Loss: 0.21688 | Valid Loss: 0.21856 | Time: 0.48 seconds\n",
            "Epoch: 811 | Train Loss: 0.21657 | Valid Loss: 0.22008 | Time: 0.47 seconds\n",
            "Epoch: 812 | Train Loss: 0.21623 | Valid Loss: 0.21779 | Time: 0.49 seconds\n",
            "Epoch: 813 | Train Loss: 0.21585 | Valid Loss: 0.21805 | Time: 0.49 seconds\n",
            "Epoch: 814 | Train Loss: 0.21554 | Valid Loss: 0.21743 | Time: 0.47 seconds\n",
            "Epoch: 815 | Train Loss: 0.21518 | Valid Loss: 0.21820 | Time: 0.45 seconds\n",
            "Epoch: 816 | Train Loss: 0.21488 | Valid Loss: 0.21726 | Time: 0.46 seconds\n",
            "Epoch: 817 | Train Loss: 0.21452 | Valid Loss: 0.21533 | Time: 0.47 seconds\n",
            "Epoch: 818 | Train Loss: 0.21415 | Valid Loss: 0.21818 | Time: 0.45 seconds\n",
            "Epoch: 819 | Train Loss: 0.21384 | Valid Loss: 0.21578 | Time: 0.47 seconds\n",
            "Epoch: 820 | Train Loss: 0.21349 | Valid Loss: 0.21507 | Time: 0.45 seconds\n",
            "Epoch: 821 | Train Loss: 0.21315 | Valid Loss: 0.21642 | Time: 0.47 seconds\n",
            "Epoch: 822 | Train Loss: 0.21281 | Valid Loss: 0.21513 | Time: 0.46 seconds\n",
            "Epoch: 823 | Train Loss: 0.21248 | Valid Loss: 0.21428 | Time: 0.48 seconds\n",
            "Epoch: 824 | Train Loss: 0.21219 | Valid Loss: 0.21471 | Time: 0.46 seconds\n",
            "Epoch: 825 | Train Loss: 0.21180 | Valid Loss: 0.21307 | Time: 0.47 seconds\n",
            "Epoch: 826 | Train Loss: 0.21144 | Valid Loss: 0.21352 | Time: 0.44 seconds\n",
            "Epoch: 827 | Train Loss: 0.21112 | Valid Loss: 0.21336 | Time: 0.45 seconds\n",
            "Epoch: 828 | Train Loss: 0.21078 | Valid Loss: 0.21274 | Time: 0.47 seconds\n",
            "Epoch: 829 | Train Loss: 0.21044 | Valid Loss: 0.21277 | Time: 0.45 seconds\n",
            "Epoch: 830 | Train Loss: 0.21013 | Valid Loss: 0.21058 | Time: 0.48 seconds\n",
            "Epoch: 831 | Train Loss: 0.20982 | Valid Loss: 0.21225 | Time: 0.44 seconds\n",
            "Epoch: 832 | Train Loss: 0.20945 | Valid Loss: 0.21141 | Time: 0.47 seconds\n",
            "Epoch: 833 | Train Loss: 0.20913 | Valid Loss: 0.21173 | Time: 0.44 seconds\n",
            "Epoch: 834 | Train Loss: 0.20880 | Valid Loss: 0.21233 | Time: 0.46 seconds\n",
            "Epoch: 835 | Train Loss: 0.20850 | Valid Loss: 0.21121 | Time: 0.45 seconds\n",
            "Epoch: 836 | Train Loss: 0.20817 | Valid Loss: 0.21136 | Time: 0.50 seconds\n",
            "Epoch: 837 | Train Loss: 0.20784 | Valid Loss: 0.20918 | Time: 0.46 seconds\n",
            "Epoch: 838 | Train Loss: 0.20748 | Valid Loss: 0.20849 | Time: 0.45 seconds\n",
            "Epoch: 839 | Train Loss: 0.20719 | Valid Loss: 0.20789 | Time: 0.48 seconds\n",
            "Epoch: 840 | Train Loss: 0.20685 | Valid Loss: 0.20806 | Time: 0.48 seconds\n",
            "Epoch: 841 | Train Loss: 0.20649 | Valid Loss: 0.20898 | Time: 0.47 seconds\n",
            "Epoch: 842 | Train Loss: 0.20622 | Valid Loss: 0.20741 | Time: 0.46 seconds\n",
            "Epoch: 843 | Train Loss: 0.20584 | Valid Loss: 0.20772 | Time: 0.46 seconds\n",
            "Epoch: 844 | Train Loss: 0.20551 | Valid Loss: 0.20831 | Time: 0.45 seconds\n",
            "Epoch: 845 | Train Loss: 0.20520 | Valid Loss: 0.20666 | Time: 0.48 seconds\n",
            "Epoch: 846 | Train Loss: 0.20491 | Valid Loss: 0.20807 | Time: 0.46 seconds\n",
            "Epoch: 847 | Train Loss: 0.20455 | Valid Loss: 0.20671 | Time: 0.49 seconds\n",
            "Epoch: 848 | Train Loss: 0.20422 | Valid Loss: 0.20542 | Time: 0.46 seconds\n",
            "Epoch: 849 | Train Loss: 0.20389 | Valid Loss: 0.20569 | Time: 0.46 seconds\n",
            "Epoch: 850 | Train Loss: 0.20358 | Valid Loss: 0.20588 | Time: 0.46 seconds\n",
            "Epoch: 851 | Train Loss: 0.20327 | Valid Loss: 0.20580 | Time: 0.45 seconds\n",
            "Epoch: 852 | Train Loss: 0.20293 | Valid Loss: 0.20577 | Time: 0.47 seconds\n",
            "Epoch: 853 | Train Loss: 0.20260 | Valid Loss: 0.20543 | Time: 0.48 seconds\n",
            "Epoch: 854 | Train Loss: 0.20236 | Valid Loss: 0.20371 | Time: 0.48 seconds\n",
            "Epoch: 855 | Train Loss: 0.20202 | Valid Loss: 0.20332 | Time: 0.45 seconds\n",
            "Epoch: 856 | Train Loss: 0.20168 | Valid Loss: 0.20286 | Time: 0.48 seconds\n",
            "Epoch: 857 | Train Loss: 0.20133 | Valid Loss: 0.20234 | Time: 0.48 seconds\n",
            "Epoch: 858 | Train Loss: 0.20101 | Valid Loss: 0.20287 | Time: 0.50 seconds\n",
            "Epoch: 859 | Train Loss: 0.20072 | Valid Loss: 0.20190 | Time: 0.45 seconds\n",
            "Epoch: 860 | Train Loss: 0.20039 | Valid Loss: 0.20224 | Time: 0.46 seconds\n",
            "Epoch: 861 | Train Loss: 0.20006 | Valid Loss: 0.20143 | Time: 0.45 seconds\n",
            "Epoch: 862 | Train Loss: 0.19974 | Valid Loss: 0.19998 | Time: 0.46 seconds\n",
            "Epoch: 863 | Train Loss: 0.19939 | Valid Loss: 0.20199 | Time: 0.45 seconds\n",
            "Epoch: 864 | Train Loss: 0.19912 | Valid Loss: 0.20319 | Time: 0.44 seconds\n",
            "Epoch: 865 | Train Loss: 0.19880 | Valid Loss: 0.19994 | Time: 0.47 seconds\n",
            "Epoch: 866 | Train Loss: 0.19852 | Valid Loss: 0.20027 | Time: 0.46 seconds\n",
            "Epoch: 867 | Train Loss: 0.19820 | Valid Loss: 0.20039 | Time: 0.46 seconds\n",
            "Epoch: 868 | Train Loss: 0.19788 | Valid Loss: 0.19828 | Time: 0.45 seconds\n",
            "Epoch: 869 | Train Loss: 0.19756 | Valid Loss: 0.19904 | Time: 0.47 seconds\n",
            "Epoch: 870 | Train Loss: 0.19727 | Valid Loss: 0.19861 | Time: 0.45 seconds\n",
            "Epoch: 871 | Train Loss: 0.19693 | Valid Loss: 0.19894 | Time: 0.46 seconds\n",
            "Epoch: 872 | Train Loss: 0.19662 | Valid Loss: 0.19673 | Time: 0.45 seconds\n",
            "Epoch: 873 | Train Loss: 0.19631 | Valid Loss: 0.19919 | Time: 0.45 seconds\n",
            "Epoch: 874 | Train Loss: 0.19600 | Valid Loss: 0.19714 | Time: 0.45 seconds\n",
            "Epoch: 875 | Train Loss: 0.19573 | Valid Loss: 0.19824 | Time: 0.46 seconds\n",
            "Epoch: 876 | Train Loss: 0.19541 | Valid Loss: 0.19655 | Time: 0.46 seconds\n",
            "Epoch: 877 | Train Loss: 0.19507 | Valid Loss: 0.19790 | Time: 0.45 seconds\n",
            "Epoch: 878 | Train Loss: 0.19477 | Valid Loss: 0.19819 | Time: 0.46 seconds\n",
            "Epoch: 879 | Train Loss: 0.19446 | Valid Loss: 0.19547 | Time: 0.45 seconds\n",
            "Epoch: 880 | Train Loss: 0.19416 | Valid Loss: 0.19597 | Time: 0.45 seconds\n",
            "Epoch: 881 | Train Loss: 0.19386 | Valid Loss: 0.19430 | Time: 0.45 seconds\n",
            "Epoch: 882 | Train Loss: 0.19352 | Valid Loss: 0.19579 | Time: 0.46 seconds\n",
            "Epoch: 883 | Train Loss: 0.19325 | Valid Loss: 0.19424 | Time: 0.47 seconds\n",
            "Epoch: 884 | Train Loss: 0.19293 | Valid Loss: 0.19466 | Time: 0.45 seconds\n",
            "Epoch: 885 | Train Loss: 0.19265 | Valid Loss: 0.19339 | Time: 0.46 seconds\n",
            "Epoch: 886 | Train Loss: 0.19233 | Valid Loss: 0.19270 | Time: 0.46 seconds\n",
            "Epoch: 887 | Train Loss: 0.19199 | Valid Loss: 0.19537 | Time: 0.47 seconds\n",
            "Epoch: 888 | Train Loss: 0.19168 | Valid Loss: 0.19307 | Time: 0.46 seconds\n",
            "Epoch: 889 | Train Loss: 0.19143 | Valid Loss: 0.19252 | Time: 0.46 seconds\n",
            "Epoch: 890 | Train Loss: 0.19114 | Valid Loss: 0.19452 | Time: 0.44 seconds\n",
            "Epoch: 891 | Train Loss: 0.19081 | Valid Loss: 0.19425 | Time: 0.45 seconds\n",
            "Epoch: 892 | Train Loss: 0.19052 | Valid Loss: 0.19291 | Time: 0.45 seconds\n",
            "Epoch: 893 | Train Loss: 0.19024 | Valid Loss: 0.19157 | Time: 0.45 seconds\n",
            "Epoch: 894 | Train Loss: 0.18994 | Valid Loss: 0.19220 | Time: 0.45 seconds\n",
            "Epoch: 895 | Train Loss: 0.18965 | Valid Loss: 0.19108 | Time: 0.47 seconds\n",
            "Epoch: 896 | Train Loss: 0.18933 | Valid Loss: 0.19085 | Time: 0.48 seconds\n",
            "Epoch: 897 | Train Loss: 0.18901 | Valid Loss: 0.19125 | Time: 0.46 seconds\n",
            "Epoch: 898 | Train Loss: 0.18874 | Valid Loss: 0.19129 | Time: 0.47 seconds\n",
            "Epoch: 899 | Train Loss: 0.18843 | Valid Loss: 0.18962 | Time: 0.46 seconds\n",
            "Epoch: 900 | Train Loss: 0.18812 | Valid Loss: 0.19061 | Time: 0.47 seconds\n",
            "Epoch: 901 | Train Loss: 0.18786 | Valid Loss: 0.18847 | Time: 0.46 seconds\n",
            "Epoch: 902 | Train Loss: 0.18752 | Valid Loss: 0.18927 | Time: 0.44 seconds\n",
            "Epoch: 903 | Train Loss: 0.18727 | Valid Loss: 0.19005 | Time: 0.45 seconds\n",
            "Epoch: 904 | Train Loss: 0.18695 | Valid Loss: 0.19059 | Time: 0.46 seconds\n",
            "Epoch: 905 | Train Loss: 0.18663 | Valid Loss: 0.19019 | Time: 0.46 seconds\n",
            "Epoch: 906 | Train Loss: 0.18633 | Valid Loss: 0.18949 | Time: 0.44 seconds\n",
            "Epoch: 907 | Train Loss: 0.18608 | Valid Loss: 0.18649 | Time: 0.46 seconds\n",
            "Epoch: 908 | Train Loss: 0.18576 | Valid Loss: 0.18647 | Time: 0.47 seconds\n",
            "Epoch: 909 | Train Loss: 0.18552 | Valid Loss: 0.18679 | Time: 0.45 seconds\n",
            "Epoch: 910 | Train Loss: 0.18520 | Valid Loss: 0.18732 | Time: 0.44 seconds\n",
            "Epoch: 911 | Train Loss: 0.18489 | Valid Loss: 0.18694 | Time: 0.44 seconds\n",
            "Epoch: 912 | Train Loss: 0.18462 | Valid Loss: 0.18742 | Time: 0.46 seconds\n",
            "Epoch: 913 | Train Loss: 0.18431 | Valid Loss: 0.18672 | Time: 0.45 seconds\n",
            "Epoch: 914 | Train Loss: 0.18404 | Valid Loss: 0.18514 | Time: 0.46 seconds\n",
            "Epoch: 915 | Train Loss: 0.18373 | Valid Loss: 0.18587 | Time: 0.46 seconds\n",
            "Epoch: 916 | Train Loss: 0.18345 | Valid Loss: 0.18406 | Time: 0.46 seconds\n",
            "Epoch: 917 | Train Loss: 0.18317 | Valid Loss: 0.18489 | Time: 0.44 seconds\n",
            "Epoch: 918 | Train Loss: 0.18290 | Valid Loss: 0.18447 | Time: 0.46 seconds\n",
            "Epoch: 919 | Train Loss: 0.18261 | Valid Loss: 0.18409 | Time: 0.44 seconds\n",
            "Epoch: 920 | Train Loss: 0.18230 | Valid Loss: 0.18430 | Time: 0.47 seconds\n",
            "Epoch: 921 | Train Loss: 0.18204 | Valid Loss: 0.18431 | Time: 0.46 seconds\n",
            "Epoch: 922 | Train Loss: 0.18172 | Valid Loss: 0.18285 | Time: 0.45 seconds\n",
            "Epoch: 923 | Train Loss: 0.18144 | Valid Loss: 0.18240 | Time: 0.47 seconds\n",
            "Epoch: 924 | Train Loss: 0.18117 | Valid Loss: 0.18318 | Time: 0.46 seconds\n",
            "Epoch: 925 | Train Loss: 0.18089 | Valid Loss: 0.18373 | Time: 0.45 seconds\n",
            "Epoch: 926 | Train Loss: 0.18062 | Valid Loss: 0.18331 | Time: 0.44 seconds\n",
            "Epoch: 927 | Train Loss: 0.18032 | Valid Loss: 0.18226 | Time: 0.46 seconds\n",
            "Epoch: 928 | Train Loss: 0.18001 | Valid Loss: 0.18264 | Time: 0.45 seconds\n",
            "Epoch: 929 | Train Loss: 0.17971 | Valid Loss: 0.18177 | Time: 0.46 seconds\n",
            "Epoch: 930 | Train Loss: 0.17947 | Valid Loss: 0.18145 | Time: 0.46 seconds\n",
            "Epoch: 931 | Train Loss: 0.17918 | Valid Loss: 0.18039 | Time: 0.45 seconds\n",
            "Epoch: 932 | Train Loss: 0.17889 | Valid Loss: 0.18149 | Time: 0.47 seconds\n",
            "Epoch: 933 | Train Loss: 0.17864 | Valid Loss: 0.18190 | Time: 0.44 seconds\n",
            "Epoch: 934 | Train Loss: 0.17834 | Valid Loss: 0.17881 | Time: 0.47 seconds\n",
            "Epoch: 935 | Train Loss: 0.17805 | Valid Loss: 0.17960 | Time: 0.44 seconds\n",
            "Epoch: 936 | Train Loss: 0.17778 | Valid Loss: 0.17948 | Time: 0.47 seconds\n",
            "Epoch: 937 | Train Loss: 0.17750 | Valid Loss: 0.18056 | Time: 0.45 seconds\n",
            "Epoch: 938 | Train Loss: 0.17724 | Valid Loss: 0.17942 | Time: 0.45 seconds\n",
            "Epoch: 939 | Train Loss: 0.17696 | Valid Loss: 0.17801 | Time: 0.45 seconds\n",
            "Epoch: 940 | Train Loss: 0.17664 | Valid Loss: 0.17874 | Time: 0.44 seconds\n",
            "Epoch: 941 | Train Loss: 0.17641 | Valid Loss: 0.17824 | Time: 0.48 seconds\n",
            "Epoch: 942 | Train Loss: 0.17613 | Valid Loss: 0.17904 | Time: 0.47 seconds\n",
            "Epoch: 943 | Train Loss: 0.17582 | Valid Loss: 0.17739 | Time: 0.47 seconds\n",
            "Epoch: 944 | Train Loss: 0.17556 | Valid Loss: 0.17890 | Time: 0.44 seconds\n",
            "Epoch: 945 | Train Loss: 0.17532 | Valid Loss: 0.17711 | Time: 0.48 seconds\n",
            "Epoch: 946 | Train Loss: 0.17504 | Valid Loss: 0.17701 | Time: 0.46 seconds\n",
            "Epoch: 947 | Train Loss: 0.17474 | Valid Loss: 0.17613 | Time: 0.46 seconds\n",
            "Epoch: 948 | Train Loss: 0.17448 | Valid Loss: 0.17563 | Time: 0.45 seconds\n",
            "Epoch: 949 | Train Loss: 0.17417 | Valid Loss: 0.17524 | Time: 0.48 seconds\n",
            "Epoch: 950 | Train Loss: 0.17391 | Valid Loss: 0.17502 | Time: 0.46 seconds\n",
            "Epoch: 951 | Train Loss: 0.17366 | Valid Loss: 0.17552 | Time: 0.45 seconds\n",
            "Epoch: 952 | Train Loss: 0.17338 | Valid Loss: 0.17472 | Time: 0.48 seconds\n",
            "Epoch: 953 | Train Loss: 0.17309 | Valid Loss: 0.17466 | Time: 0.47 seconds\n",
            "Epoch: 954 | Train Loss: 0.17285 | Valid Loss: 0.17302 | Time: 0.47 seconds\n",
            "Epoch: 955 | Train Loss: 0.17256 | Valid Loss: 0.17386 | Time: 0.48 seconds\n",
            "Epoch: 956 | Train Loss: 0.17231 | Valid Loss: 0.17384 | Time: 0.46 seconds\n",
            "Epoch: 957 | Train Loss: 0.17203 | Valid Loss: 0.17374 | Time: 0.44 seconds\n",
            "Epoch: 958 | Train Loss: 0.17176 | Valid Loss: 0.17357 | Time: 0.46 seconds\n",
            "Epoch: 959 | Train Loss: 0.17146 | Valid Loss: 0.17422 | Time: 0.45 seconds\n",
            "Epoch: 960 | Train Loss: 0.17121 | Valid Loss: 0.17287 | Time: 0.48 seconds\n",
            "Epoch: 961 | Train Loss: 0.17091 | Valid Loss: 0.17362 | Time: 0.45 seconds\n",
            "Epoch: 962 | Train Loss: 0.17065 | Valid Loss: 0.17262 | Time: 0.46 seconds\n",
            "Epoch: 963 | Train Loss: 0.17040 | Valid Loss: 0.17160 | Time: 0.48 seconds\n",
            "Epoch: 964 | Train Loss: 0.17016 | Valid Loss: 0.17157 | Time: 0.46 seconds\n",
            "Epoch: 965 | Train Loss: 0.16989 | Valid Loss: 0.17261 | Time: 0.46 seconds\n",
            "Epoch: 966 | Train Loss: 0.16963 | Valid Loss: 0.17032 | Time: 0.46 seconds\n",
            "Epoch: 967 | Train Loss: 0.16935 | Valid Loss: 0.17125 | Time: 0.45 seconds\n",
            "Epoch: 968 | Train Loss: 0.16909 | Valid Loss: 0.17100 | Time: 0.45 seconds\n",
            "Epoch: 969 | Train Loss: 0.16885 | Valid Loss: 0.17111 | Time: 0.46 seconds\n",
            "Epoch: 970 | Train Loss: 0.16851 | Valid Loss: 0.16964 | Time: 0.49 seconds\n",
            "Epoch: 971 | Train Loss: 0.16828 | Valid Loss: 0.16943 | Time: 0.47 seconds\n",
            "Epoch: 972 | Train Loss: 0.16803 | Valid Loss: 0.17058 | Time: 0.45 seconds\n",
            "Epoch: 973 | Train Loss: 0.16777 | Valid Loss: 0.17009 | Time: 0.48 seconds\n",
            "Epoch: 974 | Train Loss: 0.16752 | Valid Loss: 0.16892 | Time: 0.47 seconds\n",
            "Epoch: 975 | Train Loss: 0.16728 | Valid Loss: 0.16995 | Time: 0.45 seconds\n",
            "Epoch: 976 | Train Loss: 0.16699 | Valid Loss: 0.16886 | Time: 0.47 seconds\n",
            "Epoch: 977 | Train Loss: 0.16672 | Valid Loss: 0.16887 | Time: 0.46 seconds\n",
            "Epoch: 978 | Train Loss: 0.16647 | Valid Loss: 0.16857 | Time: 0.48 seconds\n",
            "Epoch: 979 | Train Loss: 0.16623 | Valid Loss: 0.16800 | Time: 0.47 seconds\n",
            "Epoch: 980 | Train Loss: 0.16595 | Valid Loss: 0.16748 | Time: 0.48 seconds\n",
            "Epoch: 981 | Train Loss: 0.16571 | Valid Loss: 0.16721 | Time: 0.47 seconds\n",
            "Epoch: 982 | Train Loss: 0.16542 | Valid Loss: 0.16623 | Time: 0.47 seconds\n",
            "Epoch: 983 | Train Loss: 0.16519 | Valid Loss: 0.16739 | Time: 0.47 seconds\n",
            "Epoch: 984 | Train Loss: 0.16491 | Valid Loss: 0.16664 | Time: 0.50 seconds\n",
            "Epoch: 985 | Train Loss: 0.16466 | Valid Loss: 0.16592 | Time: 0.47 seconds\n",
            "Epoch: 986 | Train Loss: 0.16440 | Valid Loss: 0.16735 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16415 | Valid Loss: 0.16689 | Time: 0.47 seconds\n",
            "Epoch: 988 | Train Loss: 0.16389 | Valid Loss: 0.16554 | Time: 0.46 seconds\n",
            "Epoch: 989 | Train Loss: 0.16367 | Valid Loss: 0.16593 | Time: 0.46 seconds\n",
            "Epoch: 990 | Train Loss: 0.16338 | Valid Loss: 0.16543 | Time: 0.47 seconds\n",
            "Epoch: 991 | Train Loss: 0.16313 | Valid Loss: 0.16504 | Time: 0.47 seconds\n",
            "Epoch: 992 | Train Loss: 0.16290 | Valid Loss: 0.16434 | Time: 0.47 seconds\n",
            "Epoch: 993 | Train Loss: 0.16262 | Valid Loss: 0.16416 | Time: 0.47 seconds\n",
            "Epoch: 994 | Train Loss: 0.16237 | Valid Loss: 0.16465 | Time: 0.46 seconds\n",
            "Epoch: 995 | Train Loss: 0.16213 | Valid Loss: 0.16395 | Time: 0.46 seconds\n",
            "Epoch: 996 | Train Loss: 0.16186 | Valid Loss: 0.16390 | Time: 0.45 seconds\n",
            "Epoch: 997 | Train Loss: 0.16161 | Valid Loss: 0.16301 | Time: 0.49 seconds\n",
            "Epoch: 998 | Train Loss: 0.16136 | Valid Loss: 0.16424 | Time: 0.45 seconds\n",
            "Epoch: 999 | Train Loss: 0.16109 | Valid Loss: 0.16480 | Time: 0.45 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16084 | Valid Loss: 0.16268 | Time: 0.48 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 1000\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.74 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 2]: 33.05209\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 3...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71490 | Valid Loss: 0.71110 | Time: 0.47 seconds\n",
            "Epoch: 2 | Train Loss: 0.71435 | Valid Loss: 0.71248 | Time: 0.46 seconds\n",
            "Epoch: 3 | Train Loss: 0.71384 | Valid Loss: 0.71310 | Time: 0.48 seconds\n",
            "Epoch: 4 | Train Loss: 0.71333 | Valid Loss: 0.71277 | Time: 0.44 seconds\n",
            "Epoch: 5 | Train Loss: 0.71286 | Valid Loss: 0.71108 | Time: 0.46 seconds\n",
            "Epoch: 6 | Train Loss: 0.71239 | Valid Loss: 0.71094 | Time: 0.46 seconds\n",
            "Epoch: 7 | Train Loss: 0.71194 | Valid Loss: 0.71100 | Time: 0.44 seconds\n",
            "Epoch: 8 | Train Loss: 0.71152 | Valid Loss: 0.71041 | Time: 0.47 seconds\n",
            "Epoch: 9 | Train Loss: 0.71109 | Valid Loss: 0.70978 | Time: 0.46 seconds\n",
            "Epoch: 10 | Train Loss: 0.71068 | Valid Loss: 0.70988 | Time: 0.46 seconds\n",
            "Epoch: 11 | Train Loss: 0.71029 | Valid Loss: 0.70945 | Time: 0.46 seconds\n",
            "Epoch: 12 | Train Loss: 0.70991 | Valid Loss: 0.70871 | Time: 0.48 seconds\n",
            "Epoch: 13 | Train Loss: 0.70953 | Valid Loss: 0.70912 | Time: 0.45 seconds\n",
            "Epoch: 14 | Train Loss: 0.70917 | Valid Loss: 0.70851 | Time: 0.47 seconds\n",
            "Epoch: 15 | Train Loss: 0.70881 | Valid Loss: 0.70795 | Time: 0.46 seconds\n",
            "Epoch: 16 | Train Loss: 0.70845 | Valid Loss: 0.70723 | Time: 0.46 seconds\n",
            "Epoch: 17 | Train Loss: 0.70811 | Valid Loss: 0.70740 | Time: 0.46 seconds\n",
            "Epoch: 18 | Train Loss: 0.70776 | Valid Loss: 0.70710 | Time: 0.45 seconds\n",
            "Epoch: 19 | Train Loss: 0.70744 | Valid Loss: 0.70608 | Time: 0.47 seconds\n",
            "Epoch: 20 | Train Loss: 0.70711 | Valid Loss: 0.70665 | Time: 0.45 seconds\n",
            "Epoch: 21 | Train Loss: 0.70678 | Valid Loss: 0.70655 | Time: 0.46 seconds\n",
            "Epoch: 22 | Train Loss: 0.70644 | Valid Loss: 0.70532 | Time: 0.46 seconds\n",
            "Epoch: 23 | Train Loss: 0.70612 | Valid Loss: 0.70514 | Time: 0.47 seconds\n",
            "Epoch: 24 | Train Loss: 0.70581 | Valid Loss: 0.70462 | Time: 0.46 seconds\n",
            "Epoch: 25 | Train Loss: 0.70549 | Valid Loss: 0.70441 | Time: 0.47 seconds\n",
            "Epoch: 26 | Train Loss: 0.70517 | Valid Loss: 0.70451 | Time: 0.44 seconds\n",
            "Epoch: 27 | Train Loss: 0.70486 | Valid Loss: 0.70435 | Time: 0.46 seconds\n",
            "Epoch: 28 | Train Loss: 0.70454 | Valid Loss: 0.70410 | Time: 0.49 seconds\n",
            "Epoch: 29 | Train Loss: 0.70423 | Valid Loss: 0.70338 | Time: 0.45 seconds\n",
            "Epoch: 30 | Train Loss: 0.70392 | Valid Loss: 0.70319 | Time: 0.47 seconds\n",
            "Epoch: 31 | Train Loss: 0.70360 | Valid Loss: 0.70325 | Time: 0.48 seconds\n",
            "Epoch: 32 | Train Loss: 0.70329 | Valid Loss: 0.70257 | Time: 0.48 seconds\n",
            "Epoch: 33 | Train Loss: 0.70296 | Valid Loss: 0.70160 | Time: 0.46 seconds\n",
            "Epoch: 34 | Train Loss: 0.70264 | Valid Loss: 0.70238 | Time: 0.47 seconds\n",
            "Epoch: 35 | Train Loss: 0.70232 | Valid Loss: 0.70161 | Time: 0.46 seconds\n",
            "Epoch: 36 | Train Loss: 0.70201 | Valid Loss: 0.70202 | Time: 0.46 seconds\n",
            "Epoch: 37 | Train Loss: 0.70169 | Valid Loss: 0.70133 | Time: 0.47 seconds\n",
            "Epoch: 38 | Train Loss: 0.70137 | Valid Loss: 0.70022 | Time: 0.46 seconds\n",
            "Epoch: 39 | Train Loss: 0.70104 | Valid Loss: 0.70086 | Time: 0.45 seconds\n",
            "Epoch: 40 | Train Loss: 0.70071 | Valid Loss: 0.70031 | Time: 0.46 seconds\n",
            "Epoch: 41 | Train Loss: 0.70039 | Valid Loss: 0.69924 | Time: 0.47 seconds\n",
            "Epoch: 42 | Train Loss: 0.70004 | Valid Loss: 0.69939 | Time: 0.47 seconds\n",
            "Epoch: 43 | Train Loss: 0.69970 | Valid Loss: 0.69894 | Time: 0.47 seconds\n",
            "Epoch: 44 | Train Loss: 0.69936 | Valid Loss: 0.69874 | Time: 0.46 seconds\n",
            "Epoch: 45 | Train Loss: 0.69904 | Valid Loss: 0.69793 | Time: 0.48 seconds\n",
            "Epoch: 46 | Train Loss: 0.69868 | Valid Loss: 0.69824 | Time: 0.45 seconds\n",
            "Epoch: 47 | Train Loss: 0.69832 | Valid Loss: 0.69837 | Time: 0.46 seconds\n",
            "Epoch: 48 | Train Loss: 0.69796 | Valid Loss: 0.69673 | Time: 0.46 seconds\n",
            "Epoch: 49 | Train Loss: 0.69761 | Valid Loss: 0.69649 | Time: 0.49 seconds\n",
            "Epoch: 50 | Train Loss: 0.69726 | Valid Loss: 0.69705 | Time: 0.45 seconds\n",
            "Epoch: 51 | Train Loss: 0.69691 | Valid Loss: 0.69652 | Time: 0.43 seconds\n",
            "Epoch: 52 | Train Loss: 0.69652 | Valid Loss: 0.69565 | Time: 0.47 seconds\n",
            "Epoch: 53 | Train Loss: 0.69614 | Valid Loss: 0.69556 | Time: 0.45 seconds\n",
            "Epoch: 54 | Train Loss: 0.69578 | Valid Loss: 0.69561 | Time: 0.49 seconds\n",
            "Epoch: 55 | Train Loss: 0.69541 | Valid Loss: 0.69508 | Time: 0.45 seconds\n",
            "Epoch: 56 | Train Loss: 0.69500 | Valid Loss: 0.69442 | Time: 0.45 seconds\n",
            "Epoch: 57 | Train Loss: 0.69462 | Valid Loss: 0.69377 | Time: 0.45 seconds\n",
            "Epoch: 58 | Train Loss: 0.69423 | Valid Loss: 0.69379 | Time: 0.45 seconds\n",
            "Epoch: 59 | Train Loss: 0.69383 | Valid Loss: 0.69293 | Time: 0.45 seconds\n",
            "Epoch: 60 | Train Loss: 0.69343 | Valid Loss: 0.69298 | Time: 0.45 seconds\n",
            "Epoch: 61 | Train Loss: 0.69303 | Valid Loss: 0.69281 | Time: 0.47 seconds\n",
            "Epoch: 62 | Train Loss: 0.69263 | Valid Loss: 0.69196 | Time: 0.48 seconds\n",
            "Epoch: 63 | Train Loss: 0.69221 | Valid Loss: 0.69179 | Time: 0.49 seconds\n",
            "Epoch: 64 | Train Loss: 0.69179 | Valid Loss: 0.69149 | Time: 0.44 seconds\n",
            "Epoch: 65 | Train Loss: 0.69136 | Valid Loss: 0.69050 | Time: 0.47 seconds\n",
            "Epoch: 66 | Train Loss: 0.69094 | Valid Loss: 0.68993 | Time: 0.46 seconds\n",
            "Epoch: 67 | Train Loss: 0.69052 | Valid Loss: 0.69003 | Time: 0.45 seconds\n",
            "Epoch: 68 | Train Loss: 0.69008 | Valid Loss: 0.68994 | Time: 0.46 seconds\n",
            "Epoch: 69 | Train Loss: 0.68963 | Valid Loss: 0.68835 | Time: 0.47 seconds\n",
            "Epoch: 70 | Train Loss: 0.68918 | Valid Loss: 0.68870 | Time: 0.46 seconds\n",
            "Epoch: 71 | Train Loss: 0.68874 | Valid Loss: 0.68841 | Time: 0.44 seconds\n",
            "Epoch: 72 | Train Loss: 0.68830 | Valid Loss: 0.68764 | Time: 0.45 seconds\n",
            "Epoch: 73 | Train Loss: 0.68784 | Valid Loss: 0.68675 | Time: 0.45 seconds\n",
            "Epoch: 74 | Train Loss: 0.68740 | Valid Loss: 0.68686 | Time: 0.47 seconds\n",
            "Epoch: 75 | Train Loss: 0.68692 | Valid Loss: 0.68610 | Time: 0.46 seconds\n",
            "Epoch: 76 | Train Loss: 0.68646 | Valid Loss: 0.68524 | Time: 0.45 seconds\n",
            "Epoch: 77 | Train Loss: 0.68599 | Valid Loss: 0.68528 | Time: 0.44 seconds\n",
            "Epoch: 78 | Train Loss: 0.68551 | Valid Loss: 0.68448 | Time: 0.46 seconds\n",
            "Epoch: 79 | Train Loss: 0.68503 | Valid Loss: 0.68439 | Time: 0.45 seconds\n",
            "Epoch: 80 | Train Loss: 0.68454 | Valid Loss: 0.68352 | Time: 0.44 seconds\n",
            "Epoch: 81 | Train Loss: 0.68406 | Valid Loss: 0.68358 | Time: 0.46 seconds\n",
            "Epoch: 82 | Train Loss: 0.68357 | Valid Loss: 0.68281 | Time: 0.45 seconds\n",
            "Epoch: 83 | Train Loss: 0.68308 | Valid Loss: 0.68270 | Time: 0.48 seconds\n",
            "Epoch: 84 | Train Loss: 0.68257 | Valid Loss: 0.68210 | Time: 0.46 seconds\n",
            "Epoch: 85 | Train Loss: 0.68205 | Valid Loss: 0.68142 | Time: 0.47 seconds\n",
            "Epoch: 86 | Train Loss: 0.68157 | Valid Loss: 0.68139 | Time: 0.45 seconds\n",
            "Epoch: 87 | Train Loss: 0.68105 | Valid Loss: 0.68020 | Time: 0.46 seconds\n",
            "Epoch: 88 | Train Loss: 0.68053 | Valid Loss: 0.68035 | Time: 0.45 seconds\n",
            "Epoch: 89 | Train Loss: 0.68002 | Valid Loss: 0.67928 | Time: 0.47 seconds\n",
            "Epoch: 90 | Train Loss: 0.67950 | Valid Loss: 0.67908 | Time: 0.46 seconds\n",
            "Epoch: 91 | Train Loss: 0.67895 | Valid Loss: 0.67814 | Time: 0.46 seconds\n",
            "Epoch: 92 | Train Loss: 0.67844 | Valid Loss: 0.67827 | Time: 0.48 seconds\n",
            "Epoch: 93 | Train Loss: 0.67790 | Valid Loss: 0.67734 | Time: 0.45 seconds\n",
            "Epoch: 94 | Train Loss: 0.67735 | Valid Loss: 0.67684 | Time: 0.48 seconds\n",
            "Epoch: 95 | Train Loss: 0.67681 | Valid Loss: 0.67639 | Time: 0.47 seconds\n",
            "Epoch: 96 | Train Loss: 0.67627 | Valid Loss: 0.67518 | Time: 0.47 seconds\n",
            "Epoch: 97 | Train Loss: 0.67572 | Valid Loss: 0.67532 | Time: 0.46 seconds\n",
            "Epoch: 98 | Train Loss: 0.67517 | Valid Loss: 0.67402 | Time: 0.48 seconds\n",
            "Epoch: 99 | Train Loss: 0.67460 | Valid Loss: 0.67469 | Time: 0.45 seconds\n",
            "Epoch: 100 | Train Loss: 0.67403 | Valid Loss: 0.67315 | Time: 0.48 seconds\n",
            "Epoch: 101 | Train Loss: 0.67348 | Valid Loss: 0.67316 | Time: 0.46 seconds\n",
            "Epoch: 102 | Train Loss: 0.67289 | Valid Loss: 0.67209 | Time: 0.45 seconds\n",
            "Epoch: 103 | Train Loss: 0.67233 | Valid Loss: 0.67199 | Time: 0.46 seconds\n",
            "Epoch: 104 | Train Loss: 0.67174 | Valid Loss: 0.67081 | Time: 0.45 seconds\n",
            "Epoch: 105 | Train Loss: 0.67117 | Valid Loss: 0.67082 | Time: 0.48 seconds\n",
            "Epoch: 106 | Train Loss: 0.67057 | Valid Loss: 0.67038 | Time: 0.45 seconds\n",
            "Epoch: 107 | Train Loss: 0.66999 | Valid Loss: 0.66943 | Time: 0.49 seconds\n",
            "Epoch: 108 | Train Loss: 0.66939 | Valid Loss: 0.66887 | Time: 0.46 seconds\n",
            "Epoch: 109 | Train Loss: 0.66879 | Valid Loss: 0.66798 | Time: 0.47 seconds\n",
            "Epoch: 110 | Train Loss: 0.66818 | Valid Loss: 0.66759 | Time: 0.46 seconds\n",
            "Epoch: 111 | Train Loss: 0.66758 | Valid Loss: 0.66710 | Time: 0.47 seconds\n",
            "Epoch: 112 | Train Loss: 0.66698 | Valid Loss: 0.66662 | Time: 0.46 seconds\n",
            "Epoch: 113 | Train Loss: 0.66636 | Valid Loss: 0.66600 | Time: 0.47 seconds\n",
            "Epoch: 114 | Train Loss: 0.66574 | Valid Loss: 0.66529 | Time: 0.48 seconds\n",
            "Epoch: 115 | Train Loss: 0.66511 | Valid Loss: 0.66396 | Time: 0.45 seconds\n",
            "Epoch: 116 | Train Loss: 0.66449 | Valid Loss: 0.66380 | Time: 0.46 seconds\n",
            "Epoch: 117 | Train Loss: 0.66386 | Valid Loss: 0.66363 | Time: 0.46 seconds\n",
            "Epoch: 118 | Train Loss: 0.66324 | Valid Loss: 0.66299 | Time: 0.48 seconds\n",
            "Epoch: 119 | Train Loss: 0.66259 | Valid Loss: 0.66116 | Time: 0.46 seconds\n",
            "Epoch: 120 | Train Loss: 0.66196 | Valid Loss: 0.66167 | Time: 0.47 seconds\n",
            "Epoch: 121 | Train Loss: 0.66133 | Valid Loss: 0.66100 | Time: 0.45 seconds\n",
            "Epoch: 122 | Train Loss: 0.66068 | Valid Loss: 0.65982 | Time: 0.47 seconds\n",
            "Epoch: 123 | Train Loss: 0.66003 | Valid Loss: 0.65994 | Time: 0.45 seconds\n",
            "Epoch: 124 | Train Loss: 0.65936 | Valid Loss: 0.65865 | Time: 0.47 seconds\n",
            "Epoch: 125 | Train Loss: 0.65871 | Valid Loss: 0.65775 | Time: 0.45 seconds\n",
            "Epoch: 126 | Train Loss: 0.65806 | Valid Loss: 0.65728 | Time: 0.46 seconds\n",
            "Epoch: 127 | Train Loss: 0.65739 | Valid Loss: 0.65677 | Time: 0.47 seconds\n",
            "Epoch: 128 | Train Loss: 0.65672 | Valid Loss: 0.65536 | Time: 0.46 seconds\n",
            "Epoch: 129 | Train Loss: 0.65605 | Valid Loss: 0.65539 | Time: 0.48 seconds\n",
            "Epoch: 130 | Train Loss: 0.65538 | Valid Loss: 0.65498 | Time: 0.45 seconds\n",
            "Epoch: 131 | Train Loss: 0.65471 | Valid Loss: 0.65400 | Time: 0.47 seconds\n",
            "Epoch: 132 | Train Loss: 0.65403 | Valid Loss: 0.65216 | Time: 0.46 seconds\n",
            "Epoch: 133 | Train Loss: 0.65335 | Valid Loss: 0.65165 | Time: 0.45 seconds\n",
            "Epoch: 134 | Train Loss: 0.65265 | Valid Loss: 0.65104 | Time: 0.45 seconds\n",
            "Epoch: 135 | Train Loss: 0.65196 | Valid Loss: 0.65135 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65127 | Valid Loss: 0.65102 | Time: 0.45 seconds\n",
            "Epoch: 137 | Train Loss: 0.65059 | Valid Loss: 0.65048 | Time: 0.45 seconds\n",
            "Epoch: 138 | Train Loss: 0.64989 | Valid Loss: 0.64870 | Time: 0.46 seconds\n",
            "Epoch: 139 | Train Loss: 0.64918 | Valid Loss: 0.64876 | Time: 0.46 seconds\n",
            "Epoch: 140 | Train Loss: 0.64847 | Valid Loss: 0.64910 | Time: 0.45 seconds\n",
            "Epoch: 141 | Train Loss: 0.64778 | Valid Loss: 0.64698 | Time: 0.47 seconds\n",
            "Epoch: 142 | Train Loss: 0.64707 | Valid Loss: 0.64660 | Time: 0.48 seconds\n",
            "Epoch: 143 | Train Loss: 0.64634 | Valid Loss: 0.64590 | Time: 0.45 seconds\n",
            "Epoch: 144 | Train Loss: 0.64563 | Valid Loss: 0.64435 | Time: 0.48 seconds\n",
            "Epoch: 145 | Train Loss: 0.64493 | Valid Loss: 0.64437 | Time: 0.46 seconds\n",
            "Epoch: 146 | Train Loss: 0.64419 | Valid Loss: 0.64340 | Time: 0.45 seconds\n",
            "Epoch: 147 | Train Loss: 0.64348 | Valid Loss: 0.64241 | Time: 0.47 seconds\n",
            "Epoch: 148 | Train Loss: 0.64275 | Valid Loss: 0.64183 | Time: 0.45 seconds\n",
            "Epoch: 149 | Train Loss: 0.64202 | Valid Loss: 0.64122 | Time: 0.46 seconds\n",
            "Epoch: 150 | Train Loss: 0.64129 | Valid Loss: 0.64083 | Time: 0.45 seconds\n",
            "Epoch: 151 | Train Loss: 0.64056 | Valid Loss: 0.63865 | Time: 0.47 seconds\n",
            "Epoch: 152 | Train Loss: 0.63982 | Valid Loss: 0.64019 | Time: 0.46 seconds\n",
            "Epoch: 153 | Train Loss: 0.63909 | Valid Loss: 0.63860 | Time: 0.46 seconds\n",
            "Epoch: 154 | Train Loss: 0.63835 | Valid Loss: 0.63600 | Time: 0.46 seconds\n",
            "Epoch: 155 | Train Loss: 0.63761 | Valid Loss: 0.63829 | Time: 0.45 seconds\n",
            "Epoch: 156 | Train Loss: 0.63686 | Valid Loss: 0.63558 | Time: 0.46 seconds\n",
            "Epoch: 157 | Train Loss: 0.63611 | Valid Loss: 0.63469 | Time: 0.48 seconds\n",
            "Epoch: 158 | Train Loss: 0.63535 | Valid Loss: 0.63492 | Time: 0.46 seconds\n",
            "Epoch: 159 | Train Loss: 0.63460 | Valid Loss: 0.63396 | Time: 0.48 seconds\n",
            "Epoch: 160 | Train Loss: 0.63385 | Valid Loss: 0.63344 | Time: 0.47 seconds\n",
            "Epoch: 161 | Train Loss: 0.63309 | Valid Loss: 0.63231 | Time: 0.46 seconds\n",
            "Epoch: 162 | Train Loss: 0.63233 | Valid Loss: 0.63287 | Time: 0.46 seconds\n",
            "Epoch: 163 | Train Loss: 0.63158 | Valid Loss: 0.63086 | Time: 0.46 seconds\n",
            "Epoch: 164 | Train Loss: 0.63082 | Valid Loss: 0.63085 | Time: 0.47 seconds\n",
            "Epoch: 165 | Train Loss: 0.63005 | Valid Loss: 0.62979 | Time: 0.45 seconds\n",
            "Epoch: 166 | Train Loss: 0.62928 | Valid Loss: 0.62814 | Time: 0.47 seconds\n",
            "Epoch: 167 | Train Loss: 0.62851 | Valid Loss: 0.62765 | Time: 0.47 seconds\n",
            "Epoch: 168 | Train Loss: 0.62775 | Valid Loss: 0.62778 | Time: 0.46 seconds\n",
            "Epoch: 169 | Train Loss: 0.62697 | Valid Loss: 0.62681 | Time: 0.46 seconds\n",
            "Epoch: 170 | Train Loss: 0.62619 | Valid Loss: 0.62539 | Time: 0.49 seconds\n",
            "Epoch: 171 | Train Loss: 0.62542 | Valid Loss: 0.62615 | Time: 0.47 seconds\n",
            "Epoch: 172 | Train Loss: 0.62464 | Valid Loss: 0.62402 | Time: 0.46 seconds\n",
            "Epoch: 173 | Train Loss: 0.62386 | Valid Loss: 0.62310 | Time: 0.48 seconds\n",
            "Epoch: 174 | Train Loss: 0.62308 | Valid Loss: 0.62177 | Time: 0.45 seconds\n",
            "Epoch: 175 | Train Loss: 0.62229 | Valid Loss: 0.62183 | Time: 0.46 seconds\n",
            "Epoch: 176 | Train Loss: 0.62151 | Valid Loss: 0.61996 | Time: 0.48 seconds\n",
            "Epoch: 177 | Train Loss: 0.62072 | Valid Loss: 0.62055 | Time: 0.47 seconds\n",
            "Epoch: 178 | Train Loss: 0.61993 | Valid Loss: 0.61917 | Time: 0.46 seconds\n",
            "Epoch: 179 | Train Loss: 0.61913 | Valid Loss: 0.61851 | Time: 0.48 seconds\n",
            "Epoch: 180 | Train Loss: 0.61835 | Valid Loss: 0.61783 | Time: 0.46 seconds\n",
            "Epoch: 181 | Train Loss: 0.61756 | Valid Loss: 0.61673 | Time: 0.45 seconds\n",
            "Epoch: 182 | Train Loss: 0.61676 | Valid Loss: 0.61615 | Time: 0.46 seconds\n",
            "Epoch: 183 | Train Loss: 0.61597 | Valid Loss: 0.61524 | Time: 0.46 seconds\n",
            "Epoch: 184 | Train Loss: 0.61517 | Valid Loss: 0.61516 | Time: 0.47 seconds\n",
            "Epoch: 185 | Train Loss: 0.61436 | Valid Loss: 0.61417 | Time: 0.45 seconds\n",
            "Epoch: 186 | Train Loss: 0.61356 | Valid Loss: 0.61236 | Time: 0.47 seconds\n",
            "Epoch: 187 | Train Loss: 0.61276 | Valid Loss: 0.61176 | Time: 0.45 seconds\n",
            "Epoch: 188 | Train Loss: 0.61195 | Valid Loss: 0.61108 | Time: 0.46 seconds\n",
            "Epoch: 189 | Train Loss: 0.61116 | Valid Loss: 0.60979 | Time: 0.47 seconds\n",
            "Epoch: 190 | Train Loss: 0.61033 | Valid Loss: 0.60938 | Time: 0.46 seconds\n",
            "Epoch: 191 | Train Loss: 0.60954 | Valid Loss: 0.60881 | Time: 0.45 seconds\n",
            "Epoch: 192 | Train Loss: 0.60872 | Valid Loss: 0.60809 | Time: 0.46 seconds\n",
            "Epoch: 193 | Train Loss: 0.60791 | Valid Loss: 0.60575 | Time: 0.46 seconds\n",
            "Epoch: 194 | Train Loss: 0.60710 | Valid Loss: 0.60898 | Time: 0.46 seconds\n",
            "Epoch: 195 | Train Loss: 0.60630 | Valid Loss: 0.60434 | Time: 0.46 seconds\n",
            "Epoch: 196 | Train Loss: 0.60547 | Valid Loss: 0.60483 | Time: 0.46 seconds\n",
            "Epoch: 197 | Train Loss: 0.60466 | Valid Loss: 0.60417 | Time: 0.45 seconds\n",
            "Epoch: 198 | Train Loss: 0.60384 | Valid Loss: 0.60279 | Time: 0.46 seconds\n",
            "Epoch: 199 | Train Loss: 0.60303 | Valid Loss: 0.60258 | Time: 0.48 seconds\n",
            "Epoch: 200 | Train Loss: 0.60220 | Valid Loss: 0.60200 | Time: 0.46 seconds\n",
            "Epoch: 201 | Train Loss: 0.60138 | Valid Loss: 0.60120 | Time: 0.46 seconds\n",
            "Epoch: 202 | Train Loss: 0.60056 | Valid Loss: 0.59886 | Time: 0.45 seconds\n",
            "Epoch: 203 | Train Loss: 0.59974 | Valid Loss: 0.59961 | Time: 0.46 seconds\n",
            "Epoch: 204 | Train Loss: 0.59892 | Valid Loss: 0.59907 | Time: 0.46 seconds\n",
            "Epoch: 205 | Train Loss: 0.59808 | Valid Loss: 0.59623 | Time: 0.46 seconds\n",
            "Epoch: 206 | Train Loss: 0.59727 | Valid Loss: 0.59627 | Time: 0.46 seconds\n",
            "Epoch: 207 | Train Loss: 0.59643 | Valid Loss: 0.59622 | Time: 0.45 seconds\n",
            "Epoch: 208 | Train Loss: 0.59561 | Valid Loss: 0.59398 | Time: 0.47 seconds\n",
            "Epoch: 209 | Train Loss: 0.59478 | Valid Loss: 0.59530 | Time: 0.46 seconds\n",
            "Epoch: 210 | Train Loss: 0.59394 | Valid Loss: 0.59333 | Time: 0.47 seconds\n",
            "Epoch: 211 | Train Loss: 0.59312 | Valid Loss: 0.59197 | Time: 0.45 seconds\n",
            "Epoch: 212 | Train Loss: 0.59227 | Valid Loss: 0.59040 | Time: 0.46 seconds\n",
            "Epoch: 213 | Train Loss: 0.59145 | Valid Loss: 0.59112 | Time: 0.45 seconds\n",
            "Epoch: 214 | Train Loss: 0.59062 | Valid Loss: 0.58913 | Time: 0.45 seconds\n",
            "Epoch: 215 | Train Loss: 0.58980 | Valid Loss: 0.58928 | Time: 0.47 seconds\n",
            "Epoch: 216 | Train Loss: 0.58896 | Valid Loss: 0.58838 | Time: 0.45 seconds\n",
            "Epoch: 217 | Train Loss: 0.58812 | Valid Loss: 0.58815 | Time: 0.47 seconds\n",
            "Epoch: 218 | Train Loss: 0.58727 | Valid Loss: 0.58683 | Time: 0.45 seconds\n",
            "Epoch: 219 | Train Loss: 0.58643 | Valid Loss: 0.58662 | Time: 0.47 seconds\n",
            "Epoch: 220 | Train Loss: 0.58559 | Valid Loss: 0.58505 | Time: 0.46 seconds\n",
            "Epoch: 221 | Train Loss: 0.58474 | Valid Loss: 0.58297 | Time: 0.46 seconds\n",
            "Epoch: 222 | Train Loss: 0.58391 | Valid Loss: 0.58179 | Time: 0.47 seconds\n",
            "Epoch: 223 | Train Loss: 0.58306 | Valid Loss: 0.58347 | Time: 0.46 seconds\n",
            "Epoch: 224 | Train Loss: 0.58222 | Valid Loss: 0.58069 | Time: 0.47 seconds\n",
            "Epoch: 225 | Train Loss: 0.58137 | Valid Loss: 0.58016 | Time: 0.46 seconds\n",
            "Epoch: 226 | Train Loss: 0.58053 | Valid Loss: 0.58041 | Time: 0.46 seconds\n",
            "Epoch: 227 | Train Loss: 0.57968 | Valid Loss: 0.57865 | Time: 0.45 seconds\n",
            "Epoch: 228 | Train Loss: 0.57884 | Valid Loss: 0.57826 | Time: 0.48 seconds\n",
            "Epoch: 229 | Train Loss: 0.57798 | Valid Loss: 0.57672 | Time: 0.47 seconds\n",
            "Epoch: 230 | Train Loss: 0.57714 | Valid Loss: 0.57592 | Time: 0.47 seconds\n",
            "Epoch: 231 | Train Loss: 0.57629 | Valid Loss: 0.57428 | Time: 0.46 seconds\n",
            "Epoch: 232 | Train Loss: 0.57543 | Valid Loss: 0.57507 | Time: 0.46 seconds\n",
            "Epoch: 233 | Train Loss: 0.57459 | Valid Loss: 0.57275 | Time: 0.46 seconds\n",
            "Epoch: 234 | Train Loss: 0.57373 | Valid Loss: 0.57353 | Time: 0.48 seconds\n",
            "Epoch: 235 | Train Loss: 0.57289 | Valid Loss: 0.57188 | Time: 0.47 seconds\n",
            "Epoch: 236 | Train Loss: 0.57204 | Valid Loss: 0.57077 | Time: 0.46 seconds\n",
            "Epoch: 237 | Train Loss: 0.57119 | Valid Loss: 0.57058 | Time: 0.46 seconds\n",
            "Epoch: 238 | Train Loss: 0.57032 | Valid Loss: 0.56864 | Time: 0.46 seconds\n",
            "Epoch: 239 | Train Loss: 0.56947 | Valid Loss: 0.56814 | Time: 0.49 seconds\n",
            "Epoch: 240 | Train Loss: 0.56862 | Valid Loss: 0.56877 | Time: 0.45 seconds\n",
            "Epoch: 241 | Train Loss: 0.56775 | Valid Loss: 0.56775 | Time: 0.48 seconds\n",
            "Epoch: 242 | Train Loss: 0.56690 | Valid Loss: 0.56492 | Time: 0.46 seconds\n",
            "Epoch: 243 | Train Loss: 0.56605 | Valid Loss: 0.56599 | Time: 0.47 seconds\n",
            "Epoch: 244 | Train Loss: 0.56519 | Valid Loss: 0.56542 | Time: 0.48 seconds\n",
            "Epoch: 245 | Train Loss: 0.56432 | Valid Loss: 0.56481 | Time: 0.48 seconds\n",
            "Epoch: 246 | Train Loss: 0.56349 | Valid Loss: 0.56295 | Time: 0.45 seconds\n",
            "Epoch: 247 | Train Loss: 0.56261 | Valid Loss: 0.56048 | Time: 0.47 seconds\n",
            "Epoch: 248 | Train Loss: 0.56174 | Valid Loss: 0.56078 | Time: 0.47 seconds\n",
            "Epoch: 249 | Train Loss: 0.56089 | Valid Loss: 0.56058 | Time: 0.45 seconds\n",
            "Epoch: 250 | Train Loss: 0.56002 | Valid Loss: 0.56101 | Time: 0.46 seconds\n",
            "Epoch: 251 | Train Loss: 0.55916 | Valid Loss: 0.55819 | Time: 0.46 seconds\n",
            "Epoch: 252 | Train Loss: 0.55830 | Valid Loss: 0.55750 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55743 | Valid Loss: 0.55706 | Time: 0.47 seconds\n",
            "Epoch: 254 | Train Loss: 0.55657 | Valid Loss: 0.55667 | Time: 0.46 seconds\n",
            "Epoch: 255 | Train Loss: 0.55570 | Valid Loss: 0.55600 | Time: 0.45 seconds\n",
            "Epoch: 256 | Train Loss: 0.55484 | Valid Loss: 0.55520 | Time: 0.48 seconds\n",
            "Epoch: 257 | Train Loss: 0.55398 | Valid Loss: 0.55227 | Time: 0.47 seconds\n",
            "Epoch: 258 | Train Loss: 0.55310 | Valid Loss: 0.55175 | Time: 0.48 seconds\n",
            "Epoch: 259 | Train Loss: 0.55224 | Valid Loss: 0.55074 | Time: 0.45 seconds\n",
            "Epoch: 260 | Train Loss: 0.55137 | Valid Loss: 0.55022 | Time: 0.46 seconds\n",
            "Epoch: 261 | Train Loss: 0.55051 | Valid Loss: 0.55100 | Time: 0.45 seconds\n",
            "Epoch: 262 | Train Loss: 0.54963 | Valid Loss: 0.54997 | Time: 0.46 seconds\n",
            "Epoch: 263 | Train Loss: 0.54877 | Valid Loss: 0.54663 | Time: 0.47 seconds\n",
            "Epoch: 264 | Train Loss: 0.54791 | Valid Loss: 0.54794 | Time: 0.45 seconds\n",
            "Epoch: 265 | Train Loss: 0.54703 | Valid Loss: 0.54558 | Time: 0.45 seconds\n",
            "Epoch: 266 | Train Loss: 0.54616 | Valid Loss: 0.54399 | Time: 0.45 seconds\n",
            "Epoch: 267 | Train Loss: 0.54529 | Valid Loss: 0.54463 | Time: 0.46 seconds\n",
            "Epoch: 268 | Train Loss: 0.54443 | Valid Loss: 0.54397 | Time: 0.47 seconds\n",
            "Epoch: 269 | Train Loss: 0.54354 | Valid Loss: 0.54332 | Time: 0.47 seconds\n",
            "Epoch: 270 | Train Loss: 0.54269 | Valid Loss: 0.54244 | Time: 0.45 seconds\n",
            "Epoch: 271 | Train Loss: 0.54181 | Valid Loss: 0.54153 | Time: 0.46 seconds\n",
            "Epoch: 272 | Train Loss: 0.54095 | Valid Loss: 0.53939 | Time: 0.46 seconds\n",
            "Epoch: 273 | Train Loss: 0.54008 | Valid Loss: 0.53901 | Time: 0.48 seconds\n",
            "Epoch: 274 | Train Loss: 0.53921 | Valid Loss: 0.53851 | Time: 0.48 seconds\n",
            "Epoch: 275 | Train Loss: 0.53833 | Valid Loss: 0.53699 | Time: 0.46 seconds\n",
            "Epoch: 276 | Train Loss: 0.53745 | Valid Loss: 0.53668 | Time: 0.46 seconds\n",
            "Epoch: 277 | Train Loss: 0.53657 | Valid Loss: 0.53427 | Time: 0.46 seconds\n",
            "Epoch: 278 | Train Loss: 0.53573 | Valid Loss: 0.53404 | Time: 0.47 seconds\n",
            "Epoch: 279 | Train Loss: 0.53484 | Valid Loss: 0.53376 | Time: 0.47 seconds\n",
            "Epoch: 280 | Train Loss: 0.53396 | Valid Loss: 0.53363 | Time: 0.49 seconds\n",
            "Epoch: 281 | Train Loss: 0.53309 | Valid Loss: 0.53208 | Time: 0.46 seconds\n",
            "Epoch: 282 | Train Loss: 0.53221 | Valid Loss: 0.53072 | Time: 0.48 seconds\n",
            "Epoch: 283 | Train Loss: 0.53134 | Valid Loss: 0.53098 | Time: 0.45 seconds\n",
            "Epoch: 284 | Train Loss: 0.53046 | Valid Loss: 0.52964 | Time: 0.47 seconds\n",
            "Epoch: 285 | Train Loss: 0.52961 | Valid Loss: 0.52966 | Time: 0.47 seconds\n",
            "Epoch: 286 | Train Loss: 0.52873 | Valid Loss: 0.52835 | Time: 0.45 seconds\n",
            "Epoch: 287 | Train Loss: 0.52785 | Valid Loss: 0.52616 | Time: 0.46 seconds\n",
            "Epoch: 288 | Train Loss: 0.52698 | Valid Loss: 0.52652 | Time: 0.44 seconds\n",
            "Epoch: 289 | Train Loss: 0.52611 | Valid Loss: 0.52476 | Time: 0.48 seconds\n",
            "Epoch: 290 | Train Loss: 0.52524 | Valid Loss: 0.52538 | Time: 0.47 seconds\n",
            "Epoch: 291 | Train Loss: 0.52436 | Valid Loss: 0.52273 | Time: 0.48 seconds\n",
            "Epoch: 292 | Train Loss: 0.52350 | Valid Loss: 0.52208 | Time: 0.46 seconds\n",
            "Epoch: 293 | Train Loss: 0.52261 | Valid Loss: 0.52195 | Time: 0.48 seconds\n",
            "Epoch: 294 | Train Loss: 0.52174 | Valid Loss: 0.52234 | Time: 0.46 seconds\n",
            "Epoch: 295 | Train Loss: 0.52086 | Valid Loss: 0.51883 | Time: 0.49 seconds\n",
            "Epoch: 296 | Train Loss: 0.51997 | Valid Loss: 0.51889 | Time: 0.46 seconds\n",
            "Epoch: 297 | Train Loss: 0.51912 | Valid Loss: 0.52030 | Time: 0.46 seconds\n",
            "Epoch: 298 | Train Loss: 0.51825 | Valid Loss: 0.51759 | Time: 0.46 seconds\n",
            "Epoch: 299 | Train Loss: 0.51737 | Valid Loss: 0.51707 | Time: 0.46 seconds\n",
            "Epoch: 300 | Train Loss: 0.51651 | Valid Loss: 0.51442 | Time: 0.46 seconds\n",
            "Epoch: 301 | Train Loss: 0.51561 | Valid Loss: 0.51341 | Time: 0.46 seconds\n",
            "Epoch: 302 | Train Loss: 0.51474 | Valid Loss: 0.51455 | Time: 0.45 seconds\n",
            "Epoch: 303 | Train Loss: 0.51388 | Valid Loss: 0.51459 | Time: 0.45 seconds\n",
            "Epoch: 304 | Train Loss: 0.51301 | Valid Loss: 0.51263 | Time: 0.45 seconds\n",
            "Epoch: 305 | Train Loss: 0.51213 | Valid Loss: 0.51054 | Time: 0.44 seconds\n",
            "Epoch: 306 | Train Loss: 0.51126 | Valid Loss: 0.51167 | Time: 0.47 seconds\n",
            "Epoch: 307 | Train Loss: 0.51038 | Valid Loss: 0.51054 | Time: 0.46 seconds\n",
            "Epoch: 308 | Train Loss: 0.50952 | Valid Loss: 0.50982 | Time: 0.45 seconds\n",
            "Epoch: 309 | Train Loss: 0.50864 | Valid Loss: 0.50709 | Time: 0.48 seconds\n",
            "Epoch: 310 | Train Loss: 0.50778 | Valid Loss: 0.50586 | Time: 0.47 seconds\n",
            "Epoch: 311 | Train Loss: 0.50689 | Valid Loss: 0.50718 | Time: 0.46 seconds\n",
            "Epoch: 312 | Train Loss: 0.50603 | Valid Loss: 0.50417 | Time: 0.46 seconds\n",
            "Epoch: 313 | Train Loss: 0.50517 | Valid Loss: 0.50438 | Time: 0.47 seconds\n",
            "Epoch: 314 | Train Loss: 0.50430 | Valid Loss: 0.50239 | Time: 0.46 seconds\n",
            "Epoch: 315 | Train Loss: 0.50343 | Valid Loss: 0.50240 | Time: 0.50 seconds\n",
            "Epoch: 316 | Train Loss: 0.50255 | Valid Loss: 0.50176 | Time: 0.47 seconds\n",
            "Epoch: 317 | Train Loss: 0.50169 | Valid Loss: 0.49931 | Time: 0.47 seconds\n",
            "Epoch: 318 | Train Loss: 0.50082 | Valid Loss: 0.49961 | Time: 0.45 seconds\n",
            "Epoch: 319 | Train Loss: 0.49994 | Valid Loss: 0.50074 | Time: 0.45 seconds\n",
            "Epoch: 320 | Train Loss: 0.49908 | Valid Loss: 0.49952 | Time: 0.47 seconds\n",
            "Epoch: 321 | Train Loss: 0.49821 | Valid Loss: 0.49576 | Time: 0.45 seconds\n",
            "Epoch: 322 | Train Loss: 0.49734 | Valid Loss: 0.49609 | Time: 0.47 seconds\n",
            "Epoch: 323 | Train Loss: 0.49648 | Valid Loss: 0.49507 | Time: 0.46 seconds\n",
            "Epoch: 324 | Train Loss: 0.49562 | Valid Loss: 0.49394 | Time: 0.47 seconds\n",
            "Epoch: 325 | Train Loss: 0.49475 | Valid Loss: 0.49372 | Time: 0.49 seconds\n",
            "Epoch: 326 | Train Loss: 0.49388 | Valid Loss: 0.49278 | Time: 0.48 seconds\n",
            "Epoch: 327 | Train Loss: 0.49301 | Valid Loss: 0.49137 | Time: 0.48 seconds\n",
            "Epoch: 328 | Train Loss: 0.49216 | Valid Loss: 0.49260 | Time: 0.47 seconds\n",
            "Epoch: 329 | Train Loss: 0.49129 | Valid Loss: 0.48898 | Time: 0.54 seconds\n",
            "Epoch: 330 | Train Loss: 0.49042 | Valid Loss: 0.49000 | Time: 0.47 seconds\n",
            "Epoch: 331 | Train Loss: 0.48957 | Valid Loss: 0.48998 | Time: 0.47 seconds\n",
            "Epoch: 332 | Train Loss: 0.48870 | Valid Loss: 0.48682 | Time: 0.47 seconds\n",
            "Epoch: 333 | Train Loss: 0.48782 | Valid Loss: 0.48725 | Time: 0.46 seconds\n",
            "Epoch: 334 | Train Loss: 0.48696 | Valid Loss: 0.48603 | Time: 0.46 seconds\n",
            "Epoch: 335 | Train Loss: 0.48612 | Valid Loss: 0.48501 | Time: 0.52 seconds\n",
            "Epoch: 336 | Train Loss: 0.48525 | Valid Loss: 0.48410 | Time: 0.46 seconds\n",
            "Epoch: 337 | Train Loss: 0.48439 | Valid Loss: 0.48345 | Time: 0.48 seconds\n",
            "Epoch: 338 | Train Loss: 0.48350 | Valid Loss: 0.48377 | Time: 0.44 seconds\n",
            "Epoch: 339 | Train Loss: 0.48268 | Valid Loss: 0.48228 | Time: 0.46 seconds\n",
            "Epoch: 340 | Train Loss: 0.48181 | Valid Loss: 0.48022 | Time: 0.46 seconds\n",
            "Epoch: 341 | Train Loss: 0.48093 | Valid Loss: 0.48088 | Time: 0.45 seconds\n",
            "Epoch: 342 | Train Loss: 0.48010 | Valid Loss: 0.47925 | Time: 0.46 seconds\n",
            "Epoch: 343 | Train Loss: 0.47928 | Valid Loss: 0.47896 | Time: 0.46 seconds\n",
            "Epoch: 344 | Train Loss: 0.47839 | Valid Loss: 0.47774 | Time: 0.48 seconds\n",
            "Epoch: 345 | Train Loss: 0.47752 | Valid Loss: 0.47724 | Time: 0.48 seconds\n",
            "Epoch: 346 | Train Loss: 0.47669 | Valid Loss: 0.47608 | Time: 0.52 seconds\n",
            "Epoch: 347 | Train Loss: 0.47584 | Valid Loss: 0.47461 | Time: 0.54 seconds\n",
            "Epoch: 348 | Train Loss: 0.47497 | Valid Loss: 0.47454 | Time: 0.47 seconds\n",
            "Epoch: 349 | Train Loss: 0.47412 | Valid Loss: 0.47334 | Time: 0.48 seconds\n",
            "Epoch: 350 | Train Loss: 0.47328 | Valid Loss: 0.47171 | Time: 0.50 seconds\n",
            "Epoch: 351 | Train Loss: 0.47244 | Valid Loss: 0.47200 | Time: 0.46 seconds\n",
            "Epoch: 352 | Train Loss: 0.47156 | Valid Loss: 0.46757 | Time: 0.47 seconds\n",
            "Epoch: 353 | Train Loss: 0.47073 | Valid Loss: 0.46958 | Time: 0.46 seconds\n",
            "Epoch: 354 | Train Loss: 0.46989 | Valid Loss: 0.46966 | Time: 0.47 seconds\n",
            "Epoch: 355 | Train Loss: 0.46903 | Valid Loss: 0.46870 | Time: 0.44 seconds\n",
            "Epoch: 356 | Train Loss: 0.46820 | Valid Loss: 0.46621 | Time: 0.47 seconds\n",
            "Epoch: 357 | Train Loss: 0.46735 | Valid Loss: 0.46575 | Time: 0.46 seconds\n",
            "Epoch: 358 | Train Loss: 0.46649 | Valid Loss: 0.46791 | Time: 0.46 seconds\n",
            "Epoch: 359 | Train Loss: 0.46566 | Valid Loss: 0.46386 | Time: 0.47 seconds\n",
            "Epoch: 360 | Train Loss: 0.46483 | Valid Loss: 0.46477 | Time: 0.45 seconds\n",
            "Epoch: 361 | Train Loss: 0.46396 | Valid Loss: 0.46053 | Time: 0.46 seconds\n",
            "Epoch: 362 | Train Loss: 0.46314 | Valid Loss: 0.46307 | Time: 0.45 seconds\n",
            "Epoch: 363 | Train Loss: 0.46229 | Valid Loss: 0.46207 | Time: 0.46 seconds\n",
            "Epoch: 364 | Train Loss: 0.46146 | Valid Loss: 0.46301 | Time: 0.46 seconds\n",
            "Epoch: 365 | Train Loss: 0.46065 | Valid Loss: 0.46078 | Time: 0.46 seconds\n",
            "Epoch: 366 | Train Loss: 0.45979 | Valid Loss: 0.46144 | Time: 0.46 seconds\n",
            "Epoch: 367 | Train Loss: 0.45895 | Valid Loss: 0.45641 | Time: 0.49 seconds\n",
            "Epoch: 368 | Train Loss: 0.45814 | Valid Loss: 0.45657 | Time: 0.46 seconds\n",
            "Epoch: 369 | Train Loss: 0.45729 | Valid Loss: 0.45542 | Time: 0.48 seconds\n",
            "Epoch: 370 | Train Loss: 0.45648 | Valid Loss: 0.45508 | Time: 0.46 seconds\n",
            "Epoch: 371 | Train Loss: 0.45563 | Valid Loss: 0.45441 | Time: 0.47 seconds\n",
            "Epoch: 372 | Train Loss: 0.45482 | Valid Loss: 0.45140 | Time: 0.52 seconds\n",
            "Epoch: 373 | Train Loss: 0.45398 | Valid Loss: 0.45180 | Time: 0.50 seconds\n",
            "Epoch: 374 | Train Loss: 0.45314 | Valid Loss: 0.45253 | Time: 0.45 seconds\n",
            "Epoch: 375 | Train Loss: 0.45231 | Valid Loss: 0.45090 | Time: 0.46 seconds\n",
            "Epoch: 376 | Train Loss: 0.45150 | Valid Loss: 0.45020 | Time: 0.49 seconds\n",
            "Epoch: 377 | Train Loss: 0.45066 | Valid Loss: 0.44963 | Time: 0.47 seconds\n",
            "Epoch: 378 | Train Loss: 0.44983 | Valid Loss: 0.44959 | Time: 0.47 seconds\n",
            "Epoch: 379 | Train Loss: 0.44904 | Valid Loss: 0.44644 | Time: 0.48 seconds\n",
            "Epoch: 380 | Train Loss: 0.44821 | Valid Loss: 0.44756 | Time: 0.46 seconds\n",
            "Epoch: 381 | Train Loss: 0.44736 | Valid Loss: 0.44578 | Time: 0.46 seconds\n",
            "Epoch: 382 | Train Loss: 0.44657 | Valid Loss: 0.44537 | Time: 0.47 seconds\n",
            "Epoch: 383 | Train Loss: 0.44574 | Valid Loss: 0.44531 | Time: 0.45 seconds\n",
            "Epoch: 384 | Train Loss: 0.44496 | Valid Loss: 0.44504 | Time: 0.48 seconds\n",
            "Epoch: 385 | Train Loss: 0.44414 | Valid Loss: 0.44360 | Time: 0.46 seconds\n",
            "Epoch: 386 | Train Loss: 0.44331 | Valid Loss: 0.44180 | Time: 0.46 seconds\n",
            "Epoch: 387 | Train Loss: 0.44247 | Valid Loss: 0.44340 | Time: 0.46 seconds\n",
            "Epoch: 388 | Train Loss: 0.44167 | Valid Loss: 0.44211 | Time: 0.45 seconds\n",
            "Epoch: 389 | Train Loss: 0.44089 | Valid Loss: 0.44055 | Time: 0.45 seconds\n",
            "Epoch: 390 | Train Loss: 0.44011 | Valid Loss: 0.43987 | Time: 0.48 seconds\n",
            "Epoch: 391 | Train Loss: 0.43928 | Valid Loss: 0.43784 | Time: 0.47 seconds\n",
            "Epoch: 392 | Train Loss: 0.43844 | Valid Loss: 0.44103 | Time: 0.45 seconds\n",
            "Epoch: 393 | Train Loss: 0.43768 | Valid Loss: 0.43812 | Time: 0.45 seconds\n",
            "Epoch: 394 | Train Loss: 0.43688 | Valid Loss: 0.43679 | Time: 0.46 seconds\n",
            "Epoch: 395 | Train Loss: 0.43606 | Valid Loss: 0.43615 | Time: 0.47 seconds\n",
            "Epoch: 396 | Train Loss: 0.43524 | Valid Loss: 0.43506 | Time: 0.46 seconds\n",
            "Epoch: 397 | Train Loss: 0.43447 | Valid Loss: 0.43542 | Time: 0.45 seconds\n",
            "Epoch: 398 | Train Loss: 0.43367 | Valid Loss: 0.43314 | Time: 0.49 seconds\n",
            "Epoch: 399 | Train Loss: 0.43287 | Valid Loss: 0.43112 | Time: 0.47 seconds\n",
            "Epoch: 400 | Train Loss: 0.43207 | Valid Loss: 0.42880 | Time: 0.47 seconds\n",
            "Epoch: 401 | Train Loss: 0.43124 | Valid Loss: 0.43141 | Time: 0.46 seconds\n",
            "Epoch: 402 | Train Loss: 0.43049 | Valid Loss: 0.43036 | Time: 0.46 seconds\n",
            "Epoch: 403 | Train Loss: 0.42970 | Valid Loss: 0.42964 | Time: 0.46 seconds\n",
            "Epoch: 404 | Train Loss: 0.42891 | Valid Loss: 0.42805 | Time: 0.48 seconds\n",
            "Epoch: 405 | Train Loss: 0.42813 | Valid Loss: 0.42758 | Time: 0.46 seconds\n",
            "Epoch: 406 | Train Loss: 0.42734 | Valid Loss: 0.42658 | Time: 0.46 seconds\n",
            "Epoch: 407 | Train Loss: 0.42652 | Valid Loss: 0.42692 | Time: 0.45 seconds\n",
            "Epoch: 408 | Train Loss: 0.42576 | Valid Loss: 0.42697 | Time: 0.46 seconds\n",
            "Epoch: 409 | Train Loss: 0.42497 | Valid Loss: 0.42482 | Time: 0.48 seconds\n",
            "Epoch: 410 | Train Loss: 0.42423 | Valid Loss: 0.42289 | Time: 0.46 seconds\n",
            "Epoch: 411 | Train Loss: 0.42342 | Valid Loss: 0.42285 | Time: 0.48 seconds\n",
            "Epoch: 412 | Train Loss: 0.42266 | Valid Loss: 0.42191 | Time: 0.46 seconds\n",
            "Epoch: 413 | Train Loss: 0.42185 | Valid Loss: 0.42019 | Time: 0.46 seconds\n",
            "Epoch: 414 | Train Loss: 0.42108 | Valid Loss: 0.41897 | Time: 0.47 seconds\n",
            "Epoch: 415 | Train Loss: 0.42033 | Valid Loss: 0.41950 | Time: 0.45 seconds\n",
            "Epoch: 416 | Train Loss: 0.41952 | Valid Loss: 0.41898 | Time: 0.46 seconds\n",
            "Epoch: 417 | Train Loss: 0.41876 | Valid Loss: 0.41824 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41799 | Valid Loss: 0.41701 | Time: 0.46 seconds\n",
            "Epoch: 419 | Train Loss: 0.41723 | Valid Loss: 0.41629 | Time: 0.47 seconds\n",
            "Epoch: 420 | Train Loss: 0.41648 | Valid Loss: 0.41621 | Time: 0.46 seconds\n",
            "Epoch: 421 | Train Loss: 0.41572 | Valid Loss: 0.41542 | Time: 0.47 seconds\n",
            "Epoch: 422 | Train Loss: 0.41492 | Valid Loss: 0.41358 | Time: 0.47 seconds\n",
            "Epoch: 423 | Train Loss: 0.41418 | Valid Loss: 0.41258 | Time: 0.46 seconds\n",
            "Epoch: 424 | Train Loss: 0.41343 | Valid Loss: 0.41363 | Time: 0.46 seconds\n",
            "Epoch: 425 | Train Loss: 0.41267 | Valid Loss: 0.41082 | Time: 0.46 seconds\n",
            "Epoch: 426 | Train Loss: 0.41189 | Valid Loss: 0.41302 | Time: 0.47 seconds\n",
            "Epoch: 427 | Train Loss: 0.41114 | Valid Loss: 0.41138 | Time: 0.45 seconds\n",
            "Epoch: 428 | Train Loss: 0.41037 | Valid Loss: 0.40838 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40965 | Valid Loss: 0.40829 | Time: 0.45 seconds\n",
            "Epoch: 430 | Train Loss: 0.40892 | Valid Loss: 0.40954 | Time: 0.47 seconds\n",
            "Epoch: 431 | Train Loss: 0.40814 | Valid Loss: 0.40858 | Time: 0.46 seconds\n",
            "Epoch: 432 | Train Loss: 0.40738 | Valid Loss: 0.40642 | Time: 0.45 seconds\n",
            "Epoch: 433 | Train Loss: 0.40663 | Valid Loss: 0.40623 | Time: 0.46 seconds\n",
            "Epoch: 434 | Train Loss: 0.40592 | Valid Loss: 0.40568 | Time: 0.45 seconds\n",
            "Epoch: 435 | Train Loss: 0.40515 | Valid Loss: 0.40555 | Time: 0.47 seconds\n",
            "Epoch: 436 | Train Loss: 0.40446 | Valid Loss: 0.40200 | Time: 0.46 seconds\n",
            "Epoch: 437 | Train Loss: 0.40366 | Valid Loss: 0.40079 | Time: 0.47 seconds\n",
            "Epoch: 438 | Train Loss: 0.40295 | Valid Loss: 0.40221 | Time: 0.45 seconds\n",
            "Epoch: 439 | Train Loss: 0.40217 | Valid Loss: 0.40240 | Time: 0.45 seconds\n",
            "Epoch: 440 | Train Loss: 0.40148 | Valid Loss: 0.40131 | Time: 0.46 seconds\n",
            "Epoch: 441 | Train Loss: 0.40073 | Valid Loss: 0.40068 | Time: 0.46 seconds\n",
            "Epoch: 442 | Train Loss: 0.39999 | Valid Loss: 0.40113 | Time: 0.47 seconds\n",
            "Epoch: 443 | Train Loss: 0.39928 | Valid Loss: 0.39760 | Time: 0.46 seconds\n",
            "Epoch: 444 | Train Loss: 0.39857 | Valid Loss: 0.39774 | Time: 0.48 seconds\n",
            "Epoch: 445 | Train Loss: 0.39781 | Valid Loss: 0.39709 | Time: 0.46 seconds\n",
            "Epoch: 446 | Train Loss: 0.39710 | Valid Loss: 0.39622 | Time: 0.48 seconds\n",
            "Epoch: 447 | Train Loss: 0.39640 | Valid Loss: 0.39754 | Time: 0.46 seconds\n",
            "Epoch: 448 | Train Loss: 0.39567 | Valid Loss: 0.39577 | Time: 0.47 seconds\n",
            "Epoch: 449 | Train Loss: 0.39494 | Valid Loss: 0.39251 | Time: 0.46 seconds\n",
            "Epoch: 450 | Train Loss: 0.39421 | Valid Loss: 0.39383 | Time: 0.46 seconds\n",
            "Epoch: 451 | Train Loss: 0.39348 | Valid Loss: 0.39343 | Time: 0.45 seconds\n",
            "Epoch: 452 | Train Loss: 0.39278 | Valid Loss: 0.39238 | Time: 0.46 seconds\n",
            "Epoch: 453 | Train Loss: 0.39206 | Valid Loss: 0.39184 | Time: 0.47 seconds\n",
            "Epoch: 454 | Train Loss: 0.39135 | Valid Loss: 0.38921 | Time: 0.45 seconds\n",
            "Epoch: 455 | Train Loss: 0.39064 | Valid Loss: 0.38967 | Time: 0.46 seconds\n",
            "Epoch: 456 | Train Loss: 0.38996 | Valid Loss: 0.38738 | Time: 0.46 seconds\n",
            "Epoch: 457 | Train Loss: 0.38920 | Valid Loss: 0.38996 | Time: 0.48 seconds\n",
            "Epoch: 458 | Train Loss: 0.38851 | Valid Loss: 0.38891 | Time: 0.46 seconds\n",
            "Epoch: 459 | Train Loss: 0.38781 | Valid Loss: 0.38651 | Time: 0.47 seconds\n",
            "Epoch: 460 | Train Loss: 0.38713 | Valid Loss: 0.38825 | Time: 0.45 seconds\n",
            "Epoch: 461 | Train Loss: 0.38641 | Valid Loss: 0.38554 | Time: 0.47 seconds\n",
            "Epoch: 462 | Train Loss: 0.38570 | Valid Loss: 0.38489 | Time: 0.45 seconds\n",
            "Epoch: 463 | Train Loss: 0.38503 | Valid Loss: 0.38315 | Time: 0.47 seconds\n",
            "Epoch: 464 | Train Loss: 0.38430 | Valid Loss: 0.38433 | Time: 0.45 seconds\n",
            "Epoch: 465 | Train Loss: 0.38361 | Valid Loss: 0.38327 | Time: 0.46 seconds\n",
            "Epoch: 466 | Train Loss: 0.38291 | Valid Loss: 0.38123 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38223 | Valid Loss: 0.38054 | Time: 0.45 seconds\n",
            "Epoch: 468 | Train Loss: 0.38156 | Valid Loss: 0.37922 | Time: 0.47 seconds\n",
            "Epoch: 469 | Train Loss: 0.38089 | Valid Loss: 0.37868 | Time: 0.46 seconds\n",
            "Epoch: 470 | Train Loss: 0.38019 | Valid Loss: 0.37861 | Time: 0.47 seconds\n",
            "Epoch: 471 | Train Loss: 0.37951 | Valid Loss: 0.37807 | Time: 0.46 seconds\n",
            "Epoch: 472 | Train Loss: 0.37879 | Valid Loss: 0.37701 | Time: 0.46 seconds\n",
            "Epoch: 473 | Train Loss: 0.37813 | Valid Loss: 0.37724 | Time: 0.45 seconds\n",
            "Epoch: 474 | Train Loss: 0.37747 | Valid Loss: 0.37513 | Time: 0.47 seconds\n",
            "Epoch: 475 | Train Loss: 0.37673 | Valid Loss: 0.37848 | Time: 0.45 seconds\n",
            "Epoch: 476 | Train Loss: 0.37610 | Valid Loss: 0.37638 | Time: 0.44 seconds\n",
            "Epoch: 477 | Train Loss: 0.37541 | Valid Loss: 0.37285 | Time: 0.46 seconds\n",
            "Epoch: 478 | Train Loss: 0.37474 | Valid Loss: 0.37375 | Time: 0.45 seconds\n",
            "Epoch: 479 | Train Loss: 0.37410 | Valid Loss: 0.37356 | Time: 0.48 seconds\n",
            "Epoch: 480 | Train Loss: 0.37340 | Valid Loss: 0.37419 | Time: 0.44 seconds\n",
            "Epoch: 481 | Train Loss: 0.37275 | Valid Loss: 0.37180 | Time: 0.46 seconds\n",
            "Epoch: 482 | Train Loss: 0.37207 | Valid Loss: 0.37154 | Time: 0.46 seconds\n",
            "Epoch: 483 | Train Loss: 0.37138 | Valid Loss: 0.37297 | Time: 0.47 seconds\n",
            "Epoch: 484 | Train Loss: 0.37077 | Valid Loss: 0.37000 | Time: 0.46 seconds\n",
            "Epoch: 485 | Train Loss: 0.37011 | Valid Loss: 0.37077 | Time: 0.46 seconds\n",
            "Epoch: 486 | Train Loss: 0.36941 | Valid Loss: 0.37010 | Time: 0.47 seconds\n",
            "Epoch: 487 | Train Loss: 0.36882 | Valid Loss: 0.36653 | Time: 0.45 seconds\n",
            "Epoch: 488 | Train Loss: 0.36812 | Valid Loss: 0.36725 | Time: 0.46 seconds\n",
            "Epoch: 489 | Train Loss: 0.36749 | Valid Loss: 0.36392 | Time: 0.46 seconds\n",
            "Epoch: 490 | Train Loss: 0.36681 | Valid Loss: 0.36624 | Time: 0.45 seconds\n",
            "Epoch: 491 | Train Loss: 0.36613 | Valid Loss: 0.36528 | Time: 0.46 seconds\n",
            "Epoch: 492 | Train Loss: 0.36552 | Valid Loss: 0.36545 | Time: 0.45 seconds\n",
            "Epoch: 493 | Train Loss: 0.36487 | Valid Loss: 0.36299 | Time: 0.46 seconds\n",
            "Epoch: 494 | Train Loss: 0.36420 | Valid Loss: 0.36418 | Time: 0.47 seconds\n",
            "Epoch: 495 | Train Loss: 0.36358 | Valid Loss: 0.36229 | Time: 0.45 seconds\n",
            "Epoch: 496 | Train Loss: 0.36294 | Valid Loss: 0.36380 | Time: 0.45 seconds\n",
            "Epoch: 497 | Train Loss: 0.36231 | Valid Loss: 0.36098 | Time: 0.47 seconds\n",
            "Epoch: 498 | Train Loss: 0.36165 | Valid Loss: 0.36136 | Time: 0.46 seconds\n",
            "Epoch: 499 | Train Loss: 0.36101 | Valid Loss: 0.36006 | Time: 0.47 seconds\n",
            "Epoch: 500 | Train Loss: 0.36035 | Valid Loss: 0.35957 | Time: 0.46 seconds\n",
            "Epoch: 501 | Train Loss: 0.35976 | Valid Loss: 0.35865 | Time: 0.47 seconds\n",
            "Epoch: 502 | Train Loss: 0.35911 | Valid Loss: 0.35774 | Time: 0.45 seconds\n",
            "Epoch: 503 | Train Loss: 0.35846 | Valid Loss: 0.35535 | Time: 0.49 seconds\n",
            "Epoch: 504 | Train Loss: 0.35783 | Valid Loss: 0.35812 | Time: 0.46 seconds\n",
            "Epoch: 505 | Train Loss: 0.35720 | Valid Loss: 0.35603 | Time: 0.48 seconds\n",
            "Epoch: 506 | Train Loss: 0.35656 | Valid Loss: 0.35496 | Time: 0.47 seconds\n",
            "Epoch: 507 | Train Loss: 0.35598 | Valid Loss: 0.35537 | Time: 0.45 seconds\n",
            "Epoch: 508 | Train Loss: 0.35531 | Valid Loss: 0.35683 | Time: 0.47 seconds\n",
            "Epoch: 509 | Train Loss: 0.35470 | Valid Loss: 0.35119 | Time: 0.47 seconds\n",
            "Epoch: 510 | Train Loss: 0.35408 | Valid Loss: 0.35302 | Time: 0.48 seconds\n",
            "Epoch: 511 | Train Loss: 0.35345 | Valid Loss: 0.35242 | Time: 0.45 seconds\n",
            "Epoch: 512 | Train Loss: 0.35281 | Valid Loss: 0.35393 | Time: 0.47 seconds\n",
            "Epoch: 513 | Train Loss: 0.35219 | Valid Loss: 0.34973 | Time: 0.46 seconds\n",
            "Epoch: 514 | Train Loss: 0.35164 | Valid Loss: 0.35008 | Time: 0.48 seconds\n",
            "Epoch: 515 | Train Loss: 0.35099 | Valid Loss: 0.34978 | Time: 0.45 seconds\n",
            "Epoch: 516 | Train Loss: 0.35037 | Valid Loss: 0.35145 | Time: 0.48 seconds\n",
            "Epoch: 517 | Train Loss: 0.34977 | Valid Loss: 0.34861 | Time: 0.47 seconds\n",
            "Epoch: 518 | Train Loss: 0.34917 | Valid Loss: 0.34992 | Time: 0.47 seconds\n",
            "Epoch: 519 | Train Loss: 0.34858 | Valid Loss: 0.34713 | Time: 0.45 seconds\n",
            "Epoch: 520 | Train Loss: 0.34793 | Valid Loss: 0.34573 | Time: 0.48 seconds\n",
            "Epoch: 521 | Train Loss: 0.34738 | Valid Loss: 0.34611 | Time: 0.47 seconds\n",
            "Epoch: 522 | Train Loss: 0.34674 | Valid Loss: 0.34752 | Time: 0.46 seconds\n",
            "Epoch: 523 | Train Loss: 0.34615 | Valid Loss: 0.34537 | Time: 0.47 seconds\n",
            "Epoch: 524 | Train Loss: 0.34554 | Valid Loss: 0.34364 | Time: 0.46 seconds\n",
            "Epoch: 525 | Train Loss: 0.34493 | Valid Loss: 0.34460 | Time: 0.49 seconds\n",
            "Epoch: 526 | Train Loss: 0.34437 | Valid Loss: 0.34605 | Time: 0.45 seconds\n",
            "Epoch: 527 | Train Loss: 0.34376 | Valid Loss: 0.34199 | Time: 0.48 seconds\n",
            "Epoch: 528 | Train Loss: 0.34316 | Valid Loss: 0.34153 | Time: 0.46 seconds\n",
            "Epoch: 529 | Train Loss: 0.34256 | Valid Loss: 0.34067 | Time: 0.50 seconds\n",
            "Epoch: 530 | Train Loss: 0.34196 | Valid Loss: 0.34056 | Time: 0.46 seconds\n",
            "Epoch: 531 | Train Loss: 0.34138 | Valid Loss: 0.34291 | Time: 0.45 seconds\n",
            "Epoch: 532 | Train Loss: 0.34080 | Valid Loss: 0.34026 | Time: 0.47 seconds\n",
            "Epoch: 533 | Train Loss: 0.34020 | Valid Loss: 0.33901 | Time: 0.45 seconds\n",
            "Epoch: 534 | Train Loss: 0.33965 | Valid Loss: 0.33935 | Time: 0.48 seconds\n",
            "Epoch: 535 | Train Loss: 0.33904 | Valid Loss: 0.33951 | Time: 0.46 seconds\n",
            "Epoch: 536 | Train Loss: 0.33844 | Valid Loss: 0.33941 | Time: 0.47 seconds\n",
            "Epoch: 537 | Train Loss: 0.33793 | Valid Loss: 0.34045 | Time: 0.47 seconds\n",
            "Epoch: 538 | Train Loss: 0.33730 | Valid Loss: 0.33719 | Time: 0.47 seconds\n",
            "Epoch: 539 | Train Loss: 0.33672 | Valid Loss: 0.33878 | Time: 0.47 seconds\n",
            "Epoch: 540 | Train Loss: 0.33612 | Valid Loss: 0.33519 | Time: 0.48 seconds\n",
            "Epoch: 541 | Train Loss: 0.33559 | Valid Loss: 0.33521 | Time: 0.46 seconds\n",
            "Epoch: 542 | Train Loss: 0.33501 | Valid Loss: 0.33425 | Time: 0.48 seconds\n",
            "Epoch: 543 | Train Loss: 0.33440 | Valid Loss: 0.33461 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33385 | Valid Loss: 0.33473 | Time: 0.48 seconds\n",
            "Epoch: 545 | Train Loss: 0.33328 | Valid Loss: 0.33305 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33268 | Valid Loss: 0.33068 | Time: 0.46 seconds\n",
            "Epoch: 547 | Train Loss: 0.33216 | Valid Loss: 0.33281 | Time: 0.48 seconds\n",
            "Epoch: 548 | Train Loss: 0.33159 | Valid Loss: 0.33007 | Time: 0.46 seconds\n",
            "Epoch: 549 | Train Loss: 0.33099 | Valid Loss: 0.33117 | Time: 0.47 seconds\n",
            "Epoch: 550 | Train Loss: 0.33045 | Valid Loss: 0.32959 | Time: 0.50 seconds\n",
            "Epoch: 551 | Train Loss: 0.32989 | Valid Loss: 0.33010 | Time: 0.48 seconds\n",
            "Epoch: 552 | Train Loss: 0.32932 | Valid Loss: 0.32929 | Time: 0.48 seconds\n",
            "Epoch: 553 | Train Loss: 0.32873 | Valid Loss: 0.32959 | Time: 0.48 seconds\n",
            "Epoch: 554 | Train Loss: 0.32822 | Valid Loss: 0.32622 | Time: 0.47 seconds\n",
            "Epoch: 555 | Train Loss: 0.32766 | Valid Loss: 0.32797 | Time: 0.48 seconds\n",
            "Epoch: 556 | Train Loss: 0.32710 | Valid Loss: 0.32861 | Time: 0.47 seconds\n",
            "Epoch: 557 | Train Loss: 0.32656 | Valid Loss: 0.32597 | Time: 0.46 seconds\n",
            "Epoch: 558 | Train Loss: 0.32597 | Valid Loss: 0.32820 | Time: 0.45 seconds\n",
            "Epoch: 559 | Train Loss: 0.32545 | Valid Loss: 0.32452 | Time: 0.48 seconds\n",
            "Epoch: 560 | Train Loss: 0.32494 | Valid Loss: 0.32531 | Time: 0.46 seconds\n",
            "Epoch: 561 | Train Loss: 0.32441 | Valid Loss: 0.32341 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32381 | Valid Loss: 0.32006 | Time: 0.48 seconds\n",
            "Epoch: 563 | Train Loss: 0.32327 | Valid Loss: 0.32228 | Time: 0.46 seconds\n",
            "Epoch: 564 | Train Loss: 0.32271 | Valid Loss: 0.32012 | Time: 0.48 seconds\n",
            "Epoch: 565 | Train Loss: 0.32217 | Valid Loss: 0.31935 | Time: 0.46 seconds\n",
            "Epoch: 566 | Train Loss: 0.32162 | Valid Loss: 0.32114 | Time: 0.46 seconds\n",
            "Epoch: 567 | Train Loss: 0.32108 | Valid Loss: 0.32104 | Time: 0.48 seconds\n",
            "Epoch: 568 | Train Loss: 0.32056 | Valid Loss: 0.31995 | Time: 0.48 seconds\n",
            "Epoch: 569 | Train Loss: 0.32001 | Valid Loss: 0.32029 | Time: 0.46 seconds\n",
            "Epoch: 570 | Train Loss: 0.31948 | Valid Loss: 0.31913 | Time: 0.46 seconds\n",
            "Epoch: 571 | Train Loss: 0.31892 | Valid Loss: 0.31651 | Time: 0.47 seconds\n",
            "Epoch: 572 | Train Loss: 0.31841 | Valid Loss: 0.31661 | Time: 0.45 seconds\n",
            "Epoch: 573 | Train Loss: 0.31786 | Valid Loss: 0.31614 | Time: 0.47 seconds\n",
            "Epoch: 574 | Train Loss: 0.31735 | Valid Loss: 0.31777 | Time: 0.45 seconds\n",
            "Epoch: 575 | Train Loss: 0.31682 | Valid Loss: 0.31671 | Time: 0.46 seconds\n",
            "Epoch: 576 | Train Loss: 0.31630 | Valid Loss: 0.31343 | Time: 0.46 seconds\n",
            "Epoch: 577 | Train Loss: 0.31577 | Valid Loss: 0.31495 | Time: 0.47 seconds\n",
            "Epoch: 578 | Train Loss: 0.31522 | Valid Loss: 0.31454 | Time: 0.46 seconds\n",
            "Epoch: 579 | Train Loss: 0.31472 | Valid Loss: 0.31431 | Time: 0.48 seconds\n",
            "Epoch: 580 | Train Loss: 0.31419 | Valid Loss: 0.31344 | Time: 0.47 seconds\n",
            "Epoch: 581 | Train Loss: 0.31366 | Valid Loss: 0.31489 | Time: 0.48 seconds\n",
            "Epoch: 582 | Train Loss: 0.31313 | Valid Loss: 0.31385 | Time: 0.45 seconds\n",
            "Epoch: 583 | Train Loss: 0.31260 | Valid Loss: 0.31195 | Time: 0.47 seconds\n",
            "Epoch: 584 | Train Loss: 0.31204 | Valid Loss: 0.31207 | Time: 0.46 seconds\n",
            "Epoch: 585 | Train Loss: 0.31157 | Valid Loss: 0.31065 | Time: 0.46 seconds\n",
            "Epoch: 586 | Train Loss: 0.31107 | Valid Loss: 0.31090 | Time: 0.47 seconds\n",
            "Epoch: 587 | Train Loss: 0.31049 | Valid Loss: 0.30876 | Time: 0.46 seconds\n",
            "Epoch: 588 | Train Loss: 0.31002 | Valid Loss: 0.31057 | Time: 0.48 seconds\n",
            "Epoch: 589 | Train Loss: 0.30949 | Valid Loss: 0.30999 | Time: 0.45 seconds\n",
            "Epoch: 590 | Train Loss: 0.30899 | Valid Loss: 0.30828 | Time: 0.49 seconds\n",
            "Epoch: 591 | Train Loss: 0.30852 | Valid Loss: 0.30791 | Time: 0.48 seconds\n",
            "Epoch: 592 | Train Loss: 0.30796 | Valid Loss: 0.30751 | Time: 0.49 seconds\n",
            "Epoch: 593 | Train Loss: 0.30745 | Valid Loss: 0.30763 | Time: 0.46 seconds\n",
            "Epoch: 594 | Train Loss: 0.30697 | Valid Loss: 0.30798 | Time: 0.46 seconds\n",
            "Epoch: 595 | Train Loss: 0.30644 | Valid Loss: 0.30712 | Time: 0.46 seconds\n",
            "Epoch: 596 | Train Loss: 0.30595 | Valid Loss: 0.30612 | Time: 0.46 seconds\n",
            "Epoch: 597 | Train Loss: 0.30548 | Valid Loss: 0.30492 | Time: 0.47 seconds\n",
            "Epoch: 598 | Train Loss: 0.30493 | Valid Loss: 0.30309 | Time: 0.50 seconds\n",
            "Epoch: 599 | Train Loss: 0.30441 | Valid Loss: 0.30441 | Time: 0.48 seconds\n",
            "Epoch: 600 | Train Loss: 0.30393 | Valid Loss: 0.30273 | Time: 0.46 seconds\n",
            "Epoch: 601 | Train Loss: 0.30340 | Valid Loss: 0.30239 | Time: 0.47 seconds\n",
            "Epoch: 602 | Train Loss: 0.30290 | Valid Loss: 0.30259 | Time: 0.47 seconds\n",
            "Epoch: 603 | Train Loss: 0.30242 | Valid Loss: 0.30250 | Time: 0.47 seconds\n",
            "Epoch: 604 | Train Loss: 0.30192 | Valid Loss: 0.30126 | Time: 0.46 seconds\n",
            "Epoch: 605 | Train Loss: 0.30144 | Valid Loss: 0.30089 | Time: 0.48 seconds\n",
            "Epoch: 606 | Train Loss: 0.30092 | Valid Loss: 0.29976 | Time: 0.47 seconds\n",
            "Epoch: 607 | Train Loss: 0.30043 | Valid Loss: 0.29924 | Time: 0.47 seconds\n",
            "Epoch: 608 | Train Loss: 0.29996 | Valid Loss: 0.29725 | Time: 0.47 seconds\n",
            "Epoch: 609 | Train Loss: 0.29948 | Valid Loss: 0.29976 | Time: 0.46 seconds\n",
            "Epoch: 610 | Train Loss: 0.29894 | Valid Loss: 0.29966 | Time: 0.48 seconds\n",
            "Epoch: 611 | Train Loss: 0.29847 | Valid Loss: 0.29864 | Time: 0.46 seconds\n",
            "Epoch: 612 | Train Loss: 0.29796 | Valid Loss: 0.29811 | Time: 0.48 seconds\n",
            "Epoch: 613 | Train Loss: 0.29751 | Valid Loss: 0.29547 | Time: 0.47 seconds\n",
            "Epoch: 614 | Train Loss: 0.29703 | Valid Loss: 0.29572 | Time: 0.47 seconds\n",
            "Epoch: 615 | Train Loss: 0.29653 | Valid Loss: 0.29591 | Time: 0.45 seconds\n",
            "Epoch: 616 | Train Loss: 0.29603 | Valid Loss: 0.29593 | Time: 0.48 seconds\n",
            "Epoch: 617 | Train Loss: 0.29554 | Valid Loss: 0.29572 | Time: 0.45 seconds\n",
            "Epoch: 618 | Train Loss: 0.29505 | Valid Loss: 0.29315 | Time: 0.47 seconds\n",
            "Epoch: 619 | Train Loss: 0.29460 | Valid Loss: 0.29471 | Time: 0.46 seconds\n",
            "Epoch: 620 | Train Loss: 0.29409 | Valid Loss: 0.29193 | Time: 0.47 seconds\n",
            "Epoch: 621 | Train Loss: 0.29362 | Valid Loss: 0.29224 | Time: 0.46 seconds\n",
            "Epoch: 622 | Train Loss: 0.29313 | Valid Loss: 0.29332 | Time: 0.45 seconds\n",
            "Epoch: 623 | Train Loss: 0.29264 | Valid Loss: 0.29198 | Time: 0.47 seconds\n",
            "Epoch: 624 | Train Loss: 0.29218 | Valid Loss: 0.29194 | Time: 0.48 seconds\n",
            "Epoch: 625 | Train Loss: 0.29171 | Valid Loss: 0.29094 | Time: 0.48 seconds\n",
            "Epoch: 626 | Train Loss: 0.29123 | Valid Loss: 0.29195 | Time: 0.46 seconds\n",
            "Epoch: 627 | Train Loss: 0.29074 | Valid Loss: 0.28873 | Time: 0.48 seconds\n",
            "Epoch: 628 | Train Loss: 0.29023 | Valid Loss: 0.28865 | Time: 0.48 seconds\n",
            "Epoch: 629 | Train Loss: 0.28980 | Valid Loss: 0.29026 | Time: 0.47 seconds\n",
            "Epoch: 630 | Train Loss: 0.28935 | Valid Loss: 0.29007 | Time: 0.46 seconds\n",
            "Epoch: 631 | Train Loss: 0.28891 | Valid Loss: 0.28809 | Time: 0.50 seconds\n",
            "Epoch: 632 | Train Loss: 0.28837 | Valid Loss: 0.28963 | Time: 0.49 seconds\n",
            "Epoch: 633 | Train Loss: 0.28797 | Valid Loss: 0.28665 | Time: 0.47 seconds\n",
            "Epoch: 634 | Train Loss: 0.28747 | Valid Loss: 0.28771 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28702 | Valid Loss: 0.28653 | Time: 0.47 seconds\n",
            "Epoch: 636 | Train Loss: 0.28652 | Valid Loss: 0.28368 | Time: 0.47 seconds\n",
            "Epoch: 637 | Train Loss: 0.28609 | Valid Loss: 0.28542 | Time: 0.48 seconds\n",
            "Epoch: 638 | Train Loss: 0.28560 | Valid Loss: 0.28441 | Time: 0.46 seconds\n",
            "Epoch: 639 | Train Loss: 0.28514 | Valid Loss: 0.28587 | Time: 0.46 seconds\n",
            "Epoch: 640 | Train Loss: 0.28471 | Valid Loss: 0.28457 | Time: 0.46 seconds\n",
            "Epoch: 641 | Train Loss: 0.28421 | Valid Loss: 0.28379 | Time: 0.47 seconds\n",
            "Epoch: 642 | Train Loss: 0.28374 | Valid Loss: 0.28513 | Time: 0.47 seconds\n",
            "Epoch: 643 | Train Loss: 0.28331 | Valid Loss: 0.28295 | Time: 0.47 seconds\n",
            "Epoch: 644 | Train Loss: 0.28280 | Valid Loss: 0.28070 | Time: 0.49 seconds\n",
            "Epoch: 645 | Train Loss: 0.28233 | Valid Loss: 0.28187 | Time: 0.46 seconds\n",
            "Epoch: 646 | Train Loss: 0.28193 | Valid Loss: 0.28148 | Time: 0.47 seconds\n",
            "Epoch: 647 | Train Loss: 0.28146 | Valid Loss: 0.28231 | Time: 0.49 seconds\n",
            "Epoch: 648 | Train Loss: 0.28101 | Valid Loss: 0.28184 | Time: 0.47 seconds\n",
            "Epoch: 649 | Train Loss: 0.28057 | Valid Loss: 0.28126 | Time: 0.46 seconds\n",
            "Epoch: 650 | Train Loss: 0.28008 | Valid Loss: 0.28074 | Time: 0.47 seconds\n",
            "Epoch: 651 | Train Loss: 0.27967 | Valid Loss: 0.28135 | Time: 0.47 seconds\n",
            "Epoch: 652 | Train Loss: 0.27915 | Valid Loss: 0.27740 | Time: 0.48 seconds\n",
            "Epoch: 653 | Train Loss: 0.27875 | Valid Loss: 0.27818 | Time: 0.47 seconds\n",
            "Epoch: 654 | Train Loss: 0.27832 | Valid Loss: 0.27814 | Time: 0.46 seconds\n",
            "Epoch: 655 | Train Loss: 0.27782 | Valid Loss: 0.28011 | Time: 0.47 seconds\n",
            "Epoch: 656 | Train Loss: 0.27737 | Valid Loss: 0.27761 | Time: 0.46 seconds\n",
            "Epoch: 657 | Train Loss: 0.27698 | Valid Loss: 0.27508 | Time: 0.47 seconds\n",
            "Epoch: 658 | Train Loss: 0.27649 | Valid Loss: 0.27433 | Time: 0.47 seconds\n",
            "Epoch: 659 | Train Loss: 0.27608 | Valid Loss: 0.27454 | Time: 0.48 seconds\n",
            "Epoch: 660 | Train Loss: 0.27563 | Valid Loss: 0.27604 | Time: 0.45 seconds\n",
            "Epoch: 661 | Train Loss: 0.27517 | Valid Loss: 0.27447 | Time: 0.46 seconds\n",
            "Epoch: 662 | Train Loss: 0.27471 | Valid Loss: 0.27370 | Time: 0.47 seconds\n",
            "Epoch: 663 | Train Loss: 0.27425 | Valid Loss: 0.27518 | Time: 0.48 seconds\n",
            "Epoch: 664 | Train Loss: 0.27382 | Valid Loss: 0.27315 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27337 | Valid Loss: 0.27263 | Time: 0.47 seconds\n",
            "Epoch: 666 | Train Loss: 0.27292 | Valid Loss: 0.27159 | Time: 0.50 seconds\n",
            "Epoch: 667 | Train Loss: 0.27248 | Valid Loss: 0.27235 | Time: 0.46 seconds\n",
            "Epoch: 668 | Train Loss: 0.27207 | Valid Loss: 0.27205 | Time: 0.47 seconds\n",
            "Epoch: 669 | Train Loss: 0.27167 | Valid Loss: 0.27320 | Time: 0.46 seconds\n",
            "Epoch: 670 | Train Loss: 0.27120 | Valid Loss: 0.27129 | Time: 0.48 seconds\n",
            "Epoch: 671 | Train Loss: 0.27076 | Valid Loss: 0.26800 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27033 | Valid Loss: 0.26949 | Time: 0.49 seconds\n",
            "Epoch: 673 | Train Loss: 0.26991 | Valid Loss: 0.27005 | Time: 0.46 seconds\n",
            "Epoch: 674 | Train Loss: 0.26944 | Valid Loss: 0.27000 | Time: 0.47 seconds\n",
            "Epoch: 675 | Train Loss: 0.26904 | Valid Loss: 0.26929 | Time: 0.46 seconds\n",
            "Epoch: 676 | Train Loss: 0.26859 | Valid Loss: 0.26829 | Time: 0.47 seconds\n",
            "Epoch: 677 | Train Loss: 0.26818 | Valid Loss: 0.26791 | Time: 0.48 seconds\n",
            "Epoch: 678 | Train Loss: 0.26772 | Valid Loss: 0.26699 | Time: 0.49 seconds\n",
            "Epoch: 679 | Train Loss: 0.26729 | Valid Loss: 0.26722 | Time: 0.47 seconds\n",
            "Epoch: 680 | Train Loss: 0.26687 | Valid Loss: 0.26727 | Time: 0.47 seconds\n",
            "Epoch: 681 | Train Loss: 0.26644 | Valid Loss: 0.26658 | Time: 0.48 seconds\n",
            "Epoch: 682 | Train Loss: 0.26603 | Valid Loss: 0.26406 | Time: 0.46 seconds\n",
            "Epoch: 683 | Train Loss: 0.26556 | Valid Loss: 0.26629 | Time: 0.47 seconds\n",
            "Epoch: 684 | Train Loss: 0.26513 | Valid Loss: 0.26635 | Time: 0.48 seconds\n",
            "Epoch: 685 | Train Loss: 0.26470 | Valid Loss: 0.26403 | Time: 0.47 seconds\n",
            "Epoch: 686 | Train Loss: 0.26428 | Valid Loss: 0.26395 | Time: 0.47 seconds\n",
            "Epoch: 687 | Train Loss: 0.26386 | Valid Loss: 0.26486 | Time: 0.48 seconds\n",
            "Epoch: 688 | Train Loss: 0.26346 | Valid Loss: 0.26362 | Time: 0.48 seconds\n",
            "Epoch: 689 | Train Loss: 0.26303 | Valid Loss: 0.26431 | Time: 0.47 seconds\n",
            "Epoch: 690 | Train Loss: 0.26259 | Valid Loss: 0.26402 | Time: 0.46 seconds\n",
            "Epoch: 691 | Train Loss: 0.26220 | Valid Loss: 0.26294 | Time: 0.47 seconds\n",
            "Epoch: 692 | Train Loss: 0.26179 | Valid Loss: 0.26140 | Time: 0.48 seconds\n",
            "Epoch: 693 | Train Loss: 0.26133 | Valid Loss: 0.26071 | Time: 0.47 seconds\n",
            "Epoch: 694 | Train Loss: 0.26093 | Valid Loss: 0.26112 | Time: 0.47 seconds\n",
            "Epoch: 695 | Train Loss: 0.26049 | Valid Loss: 0.26170 | Time: 0.48 seconds\n",
            "Epoch: 696 | Train Loss: 0.26009 | Valid Loss: 0.26045 | Time: 0.48 seconds\n",
            "Epoch: 697 | Train Loss: 0.25968 | Valid Loss: 0.25939 | Time: 0.47 seconds\n",
            "Epoch: 698 | Train Loss: 0.25929 | Valid Loss: 0.25959 | Time: 0.46 seconds\n",
            "Epoch: 699 | Train Loss: 0.25886 | Valid Loss: 0.25660 | Time: 0.48 seconds\n",
            "Epoch: 700 | Train Loss: 0.25841 | Valid Loss: 0.25727 | Time: 0.47 seconds\n",
            "Epoch: 701 | Train Loss: 0.25801 | Valid Loss: 0.25734 | Time: 0.48 seconds\n",
            "Epoch: 702 | Train Loss: 0.25756 | Valid Loss: 0.25795 | Time: 0.46 seconds\n",
            "Epoch: 703 | Train Loss: 0.25717 | Valid Loss: 0.25773 | Time: 0.46 seconds\n",
            "Epoch: 704 | Train Loss: 0.25682 | Valid Loss: 0.25791 | Time: 0.45 seconds\n",
            "Epoch: 705 | Train Loss: 0.25640 | Valid Loss: 0.25578 | Time: 0.48 seconds\n",
            "Epoch: 706 | Train Loss: 0.25596 | Valid Loss: 0.25536 | Time: 0.48 seconds\n",
            "Epoch: 707 | Train Loss: 0.25553 | Valid Loss: 0.25517 | Time: 0.49 seconds\n",
            "Epoch: 708 | Train Loss: 0.25515 | Valid Loss: 0.25478 | Time: 0.47 seconds\n",
            "Epoch: 709 | Train Loss: 0.25469 | Valid Loss: 0.25487 | Time: 0.47 seconds\n",
            "Epoch: 710 | Train Loss: 0.25430 | Valid Loss: 0.25493 | Time: 0.46 seconds\n",
            "Epoch: 711 | Train Loss: 0.25389 | Valid Loss: 0.25272 | Time: 0.48 seconds\n",
            "Epoch: 712 | Train Loss: 0.25347 | Valid Loss: 0.25382 | Time: 0.47 seconds\n",
            "Epoch: 713 | Train Loss: 0.25313 | Valid Loss: 0.25385 | Time: 0.46 seconds\n",
            "Epoch: 714 | Train Loss: 0.25269 | Valid Loss: 0.25080 | Time: 0.48 seconds\n",
            "Epoch: 715 | Train Loss: 0.25232 | Valid Loss: 0.25188 | Time: 0.46 seconds\n",
            "Epoch: 716 | Train Loss: 0.25191 | Valid Loss: 0.25018 | Time: 0.47 seconds\n",
            "Epoch: 717 | Train Loss: 0.25151 | Valid Loss: 0.25226 | Time: 0.45 seconds\n",
            "Epoch: 718 | Train Loss: 0.25112 | Valid Loss: 0.24975 | Time: 0.49 seconds\n",
            "Epoch: 719 | Train Loss: 0.25069 | Valid Loss: 0.25135 | Time: 0.46 seconds\n",
            "Epoch: 720 | Train Loss: 0.25031 | Valid Loss: 0.24998 | Time: 0.48 seconds\n",
            "Epoch: 721 | Train Loss: 0.24991 | Valid Loss: 0.25005 | Time: 0.46 seconds\n",
            "Epoch: 722 | Train Loss: 0.24956 | Valid Loss: 0.25045 | Time: 0.47 seconds\n",
            "Epoch: 723 | Train Loss: 0.24912 | Valid Loss: 0.24995 | Time: 0.45 seconds\n",
            "Epoch: 724 | Train Loss: 0.24870 | Valid Loss: 0.24636 | Time: 0.47 seconds\n",
            "Epoch: 725 | Train Loss: 0.24830 | Valid Loss: 0.24647 | Time: 0.45 seconds\n",
            "Epoch: 726 | Train Loss: 0.24789 | Valid Loss: 0.24639 | Time: 0.49 seconds\n",
            "Epoch: 727 | Train Loss: 0.24750 | Valid Loss: 0.24761 | Time: 0.45 seconds\n",
            "Epoch: 728 | Train Loss: 0.24710 | Valid Loss: 0.24771 | Time: 0.45 seconds\n",
            "Epoch: 729 | Train Loss: 0.24676 | Valid Loss: 0.24845 | Time: 0.47 seconds\n",
            "Epoch: 730 | Train Loss: 0.24636 | Valid Loss: 0.24832 | Time: 0.47 seconds\n",
            "Epoch: 731 | Train Loss: 0.24592 | Valid Loss: 0.24732 | Time: 0.48 seconds\n",
            "Epoch: 732 | Train Loss: 0.24556 | Valid Loss: 0.24703 | Time: 0.47 seconds\n",
            "Epoch: 733 | Train Loss: 0.24515 | Valid Loss: 0.24521 | Time: 0.47 seconds\n",
            "Epoch: 734 | Train Loss: 0.24479 | Valid Loss: 0.24295 | Time: 0.46 seconds\n",
            "Epoch: 735 | Train Loss: 0.24442 | Valid Loss: 0.24625 | Time: 0.47 seconds\n",
            "Epoch: 736 | Train Loss: 0.24401 | Valid Loss: 0.24264 | Time: 0.49 seconds\n",
            "Epoch: 737 | Train Loss: 0.24359 | Valid Loss: 0.24294 | Time: 0.47 seconds\n",
            "Epoch: 738 | Train Loss: 0.24320 | Valid Loss: 0.24240 | Time: 0.47 seconds\n",
            "Epoch: 739 | Train Loss: 0.24286 | Valid Loss: 0.24393 | Time: 0.47 seconds\n",
            "Epoch: 740 | Train Loss: 0.24240 | Valid Loss: 0.24338 | Time: 0.46 seconds\n",
            "Epoch: 741 | Train Loss: 0.24202 | Valid Loss: 0.24326 | Time: 0.47 seconds\n",
            "Epoch: 742 | Train Loss: 0.24165 | Valid Loss: 0.24473 | Time: 0.47 seconds\n",
            "Epoch: 743 | Train Loss: 0.24129 | Valid Loss: 0.24260 | Time: 0.48 seconds\n",
            "Epoch: 744 | Train Loss: 0.24090 | Valid Loss: 0.24087 | Time: 0.48 seconds\n",
            "Epoch: 745 | Train Loss: 0.24050 | Valid Loss: 0.24268 | Time: 0.46 seconds\n",
            "Epoch: 746 | Train Loss: 0.24015 | Valid Loss: 0.23956 | Time: 0.48 seconds\n",
            "Epoch: 747 | Train Loss: 0.23976 | Valid Loss: 0.23883 | Time: 0.47 seconds\n",
            "Epoch: 748 | Train Loss: 0.23935 | Valid Loss: 0.24002 | Time: 0.47 seconds\n",
            "Epoch: 749 | Train Loss: 0.23895 | Valid Loss: 0.23874 | Time: 0.46 seconds\n",
            "Epoch: 750 | Train Loss: 0.23861 | Valid Loss: 0.23742 | Time: 0.49 seconds\n",
            "Epoch: 751 | Train Loss: 0.23824 | Valid Loss: 0.23888 | Time: 0.46 seconds\n",
            "Epoch: 752 | Train Loss: 0.23783 | Valid Loss: 0.23812 | Time: 0.50 seconds\n",
            "Epoch: 753 | Train Loss: 0.23746 | Valid Loss: 0.24004 | Time: 0.48 seconds\n",
            "Epoch: 754 | Train Loss: 0.23708 | Valid Loss: 0.23590 | Time: 0.49 seconds\n",
            "Epoch: 755 | Train Loss: 0.23670 | Valid Loss: 0.23641 | Time: 0.46 seconds\n",
            "Epoch: 756 | Train Loss: 0.23633 | Valid Loss: 0.23710 | Time: 0.46 seconds\n",
            "Epoch: 757 | Train Loss: 0.23597 | Valid Loss: 0.23499 | Time: 0.49 seconds\n",
            "Epoch: 758 | Train Loss: 0.23559 | Valid Loss: 0.23459 | Time: 0.46 seconds\n",
            "Epoch: 759 | Train Loss: 0.23520 | Valid Loss: 0.23481 | Time: 0.49 seconds\n",
            "Epoch: 760 | Train Loss: 0.23487 | Valid Loss: 0.23509 | Time: 0.45 seconds\n",
            "Epoch: 761 | Train Loss: 0.23448 | Valid Loss: 0.23404 | Time: 0.48 seconds\n",
            "Epoch: 762 | Train Loss: 0.23414 | Valid Loss: 0.23511 | Time: 0.45 seconds\n",
            "Epoch: 763 | Train Loss: 0.23373 | Valid Loss: 0.23489 | Time: 0.46 seconds\n",
            "Epoch: 764 | Train Loss: 0.23331 | Valid Loss: 0.23267 | Time: 0.46 seconds\n",
            "Epoch: 765 | Train Loss: 0.23298 | Valid Loss: 0.23416 | Time: 0.49 seconds\n",
            "Epoch: 766 | Train Loss: 0.23261 | Valid Loss: 0.23188 | Time: 0.47 seconds\n",
            "Epoch: 767 | Train Loss: 0.23220 | Valid Loss: 0.23276 | Time: 0.48 seconds\n",
            "Epoch: 768 | Train Loss: 0.23188 | Valid Loss: 0.23095 | Time: 0.47 seconds\n",
            "Epoch: 769 | Train Loss: 0.23149 | Valid Loss: 0.23199 | Time: 0.45 seconds\n",
            "Epoch: 770 | Train Loss: 0.23114 | Valid Loss: 0.23196 | Time: 0.48 seconds\n",
            "Epoch: 771 | Train Loss: 0.23075 | Valid Loss: 0.22934 | Time: 0.48 seconds\n",
            "Epoch: 772 | Train Loss: 0.23036 | Valid Loss: 0.23091 | Time: 0.49 seconds\n",
            "Epoch: 773 | Train Loss: 0.23000 | Valid Loss: 0.22985 | Time: 0.49 seconds\n",
            "Epoch: 774 | Train Loss: 0.22965 | Valid Loss: 0.22938 | Time: 0.48 seconds\n",
            "Epoch: 775 | Train Loss: 0.22931 | Valid Loss: 0.22693 | Time: 0.46 seconds\n",
            "Epoch: 776 | Train Loss: 0.22892 | Valid Loss: 0.22938 | Time: 0.46 seconds\n",
            "Epoch: 777 | Train Loss: 0.22855 | Valid Loss: 0.22709 | Time: 0.47 seconds\n",
            "Epoch: 778 | Train Loss: 0.22820 | Valid Loss: 0.22658 | Time: 0.47 seconds\n",
            "Epoch: 779 | Train Loss: 0.22781 | Valid Loss: 0.22770 | Time: 0.46 seconds\n",
            "Epoch: 780 | Train Loss: 0.22746 | Valid Loss: 0.22660 | Time: 0.46 seconds\n",
            "Epoch: 781 | Train Loss: 0.22712 | Valid Loss: 0.22850 | Time: 0.47 seconds\n",
            "Epoch: 782 | Train Loss: 0.22680 | Valid Loss: 0.22628 | Time: 0.48 seconds\n",
            "Epoch: 783 | Train Loss: 0.22640 | Valid Loss: 0.22567 | Time: 0.47 seconds\n",
            "Epoch: 784 | Train Loss: 0.22605 | Valid Loss: 0.22688 | Time: 0.45 seconds\n",
            "Epoch: 785 | Train Loss: 0.22567 | Valid Loss: 0.22676 | Time: 0.47 seconds\n",
            "Epoch: 786 | Train Loss: 0.22532 | Valid Loss: 0.22646 | Time: 0.45 seconds\n",
            "Epoch: 787 | Train Loss: 0.22496 | Valid Loss: 0.22409 | Time: 0.47 seconds\n",
            "Epoch: 788 | Train Loss: 0.22460 | Valid Loss: 0.22564 | Time: 0.47 seconds\n",
            "Epoch: 789 | Train Loss: 0.22425 | Valid Loss: 0.22444 | Time: 0.46 seconds\n",
            "Epoch: 790 | Train Loss: 0.22389 | Valid Loss: 0.22270 | Time: 0.46 seconds\n",
            "Epoch: 791 | Train Loss: 0.22353 | Valid Loss: 0.22401 | Time: 0.46 seconds\n",
            "Epoch: 792 | Train Loss: 0.22319 | Valid Loss: 0.22327 | Time: 0.48 seconds\n",
            "Epoch: 793 | Train Loss: 0.22280 | Valid Loss: 0.22059 | Time: 0.48 seconds\n",
            "Epoch: 794 | Train Loss: 0.22243 | Valid Loss: 0.22252 | Time: 0.46 seconds\n",
            "Epoch: 795 | Train Loss: 0.22210 | Valid Loss: 0.22186 | Time: 0.46 seconds\n",
            "Epoch: 796 | Train Loss: 0.22178 | Valid Loss: 0.22095 | Time: 0.46 seconds\n",
            "Epoch: 797 | Train Loss: 0.22139 | Valid Loss: 0.22100 | Time: 0.45 seconds\n",
            "Epoch: 798 | Train Loss: 0.22106 | Valid Loss: 0.22008 | Time: 0.48 seconds\n",
            "Epoch: 799 | Train Loss: 0.22070 | Valid Loss: 0.21908 | Time: 0.46 seconds\n",
            "Epoch: 800 | Train Loss: 0.22037 | Valid Loss: 0.22227 | Time: 0.47 seconds\n",
            "Epoch: 801 | Train Loss: 0.22002 | Valid Loss: 0.21914 | Time: 0.46 seconds\n",
            "Epoch: 802 | Train Loss: 0.21969 | Valid Loss: 0.21882 | Time: 0.47 seconds\n",
            "Epoch: 803 | Train Loss: 0.21927 | Valid Loss: 0.21734 | Time: 0.48 seconds\n",
            "Epoch: 804 | Train Loss: 0.21897 | Valid Loss: 0.21789 | Time: 0.46 seconds\n",
            "Epoch: 805 | Train Loss: 0.21863 | Valid Loss: 0.21902 | Time: 0.46 seconds\n",
            "Epoch: 806 | Train Loss: 0.21826 | Valid Loss: 0.21939 | Time: 0.46 seconds\n",
            "Epoch: 807 | Train Loss: 0.21792 | Valid Loss: 0.21748 | Time: 0.50 seconds\n",
            "Epoch: 808 | Train Loss: 0.21757 | Valid Loss: 0.21722 | Time: 0.49 seconds\n",
            "Epoch: 809 | Train Loss: 0.21721 | Valid Loss: 0.21583 | Time: 0.48 seconds\n",
            "Epoch: 810 | Train Loss: 0.21692 | Valid Loss: 0.21699 | Time: 0.45 seconds\n",
            "Epoch: 811 | Train Loss: 0.21656 | Valid Loss: 0.21702 | Time: 0.47 seconds\n",
            "Epoch: 812 | Train Loss: 0.21620 | Valid Loss: 0.21661 | Time: 0.46 seconds\n",
            "Epoch: 813 | Train Loss: 0.21589 | Valid Loss: 0.21767 | Time: 0.48 seconds\n",
            "Epoch: 814 | Train Loss: 0.21557 | Valid Loss: 0.21561 | Time: 0.47 seconds\n",
            "Epoch: 815 | Train Loss: 0.21520 | Valid Loss: 0.21478 | Time: 0.50 seconds\n",
            "Epoch: 816 | Train Loss: 0.21486 | Valid Loss: 0.21466 | Time: 0.47 seconds\n",
            "Epoch: 817 | Train Loss: 0.21453 | Valid Loss: 0.21696 | Time: 0.49 seconds\n",
            "Epoch: 818 | Train Loss: 0.21418 | Valid Loss: 0.21564 | Time: 0.47 seconds\n",
            "Epoch: 819 | Train Loss: 0.21381 | Valid Loss: 0.21411 | Time: 0.47 seconds\n",
            "Epoch: 820 | Train Loss: 0.21351 | Valid Loss: 0.21348 | Time: 0.46 seconds\n",
            "Epoch: 821 | Train Loss: 0.21314 | Valid Loss: 0.21426 | Time: 0.47 seconds\n",
            "Epoch: 822 | Train Loss: 0.21283 | Valid Loss: 0.21221 | Time: 0.47 seconds\n",
            "Epoch: 823 | Train Loss: 0.21248 | Valid Loss: 0.21135 | Time: 0.48 seconds\n",
            "Epoch: 824 | Train Loss: 0.21211 | Valid Loss: 0.21142 | Time: 0.47 seconds\n",
            "Epoch: 825 | Train Loss: 0.21180 | Valid Loss: 0.21093 | Time: 0.46 seconds\n",
            "Epoch: 826 | Train Loss: 0.21144 | Valid Loss: 0.21022 | Time: 0.48 seconds\n",
            "Epoch: 827 | Train Loss: 0.21111 | Valid Loss: 0.21296 | Time: 0.47 seconds\n",
            "Epoch: 828 | Train Loss: 0.21078 | Valid Loss: 0.21018 | Time: 0.48 seconds\n",
            "Epoch: 829 | Train Loss: 0.21044 | Valid Loss: 0.21081 | Time: 0.48 seconds\n",
            "Epoch: 830 | Train Loss: 0.21014 | Valid Loss: 0.20930 | Time: 0.49 seconds\n",
            "Epoch: 831 | Train Loss: 0.20976 | Valid Loss: 0.20963 | Time: 0.46 seconds\n",
            "Epoch: 832 | Train Loss: 0.20947 | Valid Loss: 0.20888 | Time: 0.48 seconds\n",
            "Epoch: 833 | Train Loss: 0.20912 | Valid Loss: 0.20938 | Time: 0.46 seconds\n",
            "Epoch: 834 | Train Loss: 0.20881 | Valid Loss: 0.20854 | Time: 0.45 seconds\n",
            "Epoch: 835 | Train Loss: 0.20849 | Valid Loss: 0.20784 | Time: 0.47 seconds\n",
            "Epoch: 836 | Train Loss: 0.20815 | Valid Loss: 0.20996 | Time: 0.45 seconds\n",
            "Epoch: 837 | Train Loss: 0.20785 | Valid Loss: 0.20695 | Time: 0.48 seconds\n",
            "Epoch: 838 | Train Loss: 0.20748 | Valid Loss: 0.20710 | Time: 0.46 seconds\n",
            "Epoch: 839 | Train Loss: 0.20716 | Valid Loss: 0.20655 | Time: 0.48 seconds\n",
            "Epoch: 840 | Train Loss: 0.20682 | Valid Loss: 0.20640 | Time: 0.47 seconds\n",
            "Epoch: 841 | Train Loss: 0.20651 | Valid Loss: 0.20672 | Time: 0.48 seconds\n",
            "Epoch: 842 | Train Loss: 0.20620 | Valid Loss: 0.20587 | Time: 0.46 seconds\n",
            "Epoch: 843 | Train Loss: 0.20585 | Valid Loss: 0.20616 | Time: 0.48 seconds\n",
            "Epoch: 844 | Train Loss: 0.20553 | Valid Loss: 0.20638 | Time: 0.46 seconds\n",
            "Epoch: 845 | Train Loss: 0.20517 | Valid Loss: 0.20430 | Time: 0.47 seconds\n",
            "Epoch: 846 | Train Loss: 0.20487 | Valid Loss: 0.20598 | Time: 0.46 seconds\n",
            "Epoch: 847 | Train Loss: 0.20454 | Valid Loss: 0.20539 | Time: 0.47 seconds\n",
            "Epoch: 848 | Train Loss: 0.20422 | Valid Loss: 0.20412 | Time: 0.47 seconds\n",
            "Epoch: 849 | Train Loss: 0.20392 | Valid Loss: 0.20462 | Time: 0.46 seconds\n",
            "Epoch: 850 | Train Loss: 0.20357 | Valid Loss: 0.20466 | Time: 0.47 seconds\n",
            "Epoch: 851 | Train Loss: 0.20325 | Valid Loss: 0.20382 | Time: 0.48 seconds\n",
            "Epoch: 852 | Train Loss: 0.20295 | Valid Loss: 0.20356 | Time: 0.48 seconds\n",
            "Epoch: 853 | Train Loss: 0.20261 | Valid Loss: 0.20280 | Time: 0.46 seconds\n",
            "Epoch: 854 | Train Loss: 0.20230 | Valid Loss: 0.20400 | Time: 0.49 seconds\n",
            "Epoch: 855 | Train Loss: 0.20199 | Valid Loss: 0.20277 | Time: 0.46 seconds\n",
            "Epoch: 856 | Train Loss: 0.20165 | Valid Loss: 0.20013 | Time: 0.47 seconds\n",
            "Epoch: 857 | Train Loss: 0.20135 | Valid Loss: 0.20163 | Time: 0.47 seconds\n",
            "Epoch: 858 | Train Loss: 0.20104 | Valid Loss: 0.20287 | Time: 0.47 seconds\n",
            "Epoch: 859 | Train Loss: 0.20069 | Valid Loss: 0.20066 | Time: 0.45 seconds\n",
            "Epoch: 860 | Train Loss: 0.20039 | Valid Loss: 0.20288 | Time: 0.46 seconds\n",
            "Epoch: 861 | Train Loss: 0.20007 | Valid Loss: 0.19907 | Time: 0.48 seconds\n",
            "Epoch: 862 | Train Loss: 0.19976 | Valid Loss: 0.20082 | Time: 0.46 seconds\n",
            "Epoch: 863 | Train Loss: 0.19942 | Valid Loss: 0.19882 | Time: 0.48 seconds\n",
            "Epoch: 864 | Train Loss: 0.19909 | Valid Loss: 0.19905 | Time: 0.46 seconds\n",
            "Epoch: 865 | Train Loss: 0.19883 | Valid Loss: 0.19901 | Time: 0.47 seconds\n",
            "Epoch: 866 | Train Loss: 0.19849 | Valid Loss: 0.19933 | Time: 0.45 seconds\n",
            "Epoch: 867 | Train Loss: 0.19816 | Valid Loss: 0.19822 | Time: 0.47 seconds\n",
            "Epoch: 868 | Train Loss: 0.19786 | Valid Loss: 0.19656 | Time: 0.46 seconds\n",
            "Epoch: 869 | Train Loss: 0.19753 | Valid Loss: 0.19759 | Time: 0.48 seconds\n",
            "Epoch: 870 | Train Loss: 0.19724 | Valid Loss: 0.19712 | Time: 0.46 seconds\n",
            "Epoch: 871 | Train Loss: 0.19688 | Valid Loss: 0.19566 | Time: 0.46 seconds\n",
            "Epoch: 872 | Train Loss: 0.19661 | Valid Loss: 0.19654 | Time: 0.48 seconds\n",
            "Epoch: 873 | Train Loss: 0.19633 | Valid Loss: 0.19639 | Time: 0.46 seconds\n",
            "Epoch: 874 | Train Loss: 0.19599 | Valid Loss: 0.19531 | Time: 0.47 seconds\n",
            "Epoch: 875 | Train Loss: 0.19570 | Valid Loss: 0.19581 | Time: 0.47 seconds\n",
            "Epoch: 876 | Train Loss: 0.19537 | Valid Loss: 0.19613 | Time: 0.46 seconds\n",
            "Epoch: 877 | Train Loss: 0.19506 | Valid Loss: 0.19291 | Time: 0.46 seconds\n",
            "Epoch: 878 | Train Loss: 0.19477 | Valid Loss: 0.19500 | Time: 0.49 seconds\n",
            "Epoch: 879 | Train Loss: 0.19447 | Valid Loss: 0.19455 | Time: 0.47 seconds\n",
            "Epoch: 880 | Train Loss: 0.19416 | Valid Loss: 0.19295 | Time: 0.47 seconds\n",
            "Epoch: 881 | Train Loss: 0.19387 | Valid Loss: 0.19319 | Time: 0.46 seconds\n",
            "Epoch: 882 | Train Loss: 0.19359 | Valid Loss: 0.19464 | Time: 0.47 seconds\n",
            "Epoch: 883 | Train Loss: 0.19325 | Valid Loss: 0.19502 | Time: 0.47 seconds\n",
            "Epoch: 884 | Train Loss: 0.19293 | Valid Loss: 0.19259 | Time: 0.49 seconds\n",
            "Epoch: 885 | Train Loss: 0.19263 | Valid Loss: 0.19375 | Time: 0.48 seconds\n",
            "Epoch: 886 | Train Loss: 0.19232 | Valid Loss: 0.19265 | Time: 0.46 seconds\n",
            "Epoch: 887 | Train Loss: 0.19204 | Valid Loss: 0.19283 | Time: 0.49 seconds\n",
            "Epoch: 888 | Train Loss: 0.19171 | Valid Loss: 0.19126 | Time: 0.46 seconds\n",
            "Epoch: 889 | Train Loss: 0.19141 | Valid Loss: 0.19115 | Time: 0.46 seconds\n",
            "Epoch: 890 | Train Loss: 0.19111 | Valid Loss: 0.18950 | Time: 0.47 seconds\n",
            "Epoch: 891 | Train Loss: 0.19082 | Valid Loss: 0.19183 | Time: 0.50 seconds\n",
            "Epoch: 892 | Train Loss: 0.19051 | Valid Loss: 0.19084 | Time: 0.46 seconds\n",
            "Epoch: 893 | Train Loss: 0.19020 | Valid Loss: 0.18984 | Time: 0.46 seconds\n",
            "Epoch: 894 | Train Loss: 0.18991 | Valid Loss: 0.19044 | Time: 0.47 seconds\n",
            "Epoch: 895 | Train Loss: 0.18960 | Valid Loss: 0.18951 | Time: 0.48 seconds\n",
            "Epoch: 897 | Train Loss: 0.18901 | Valid Loss: 0.18968 | Time: 0.48 seconds\n",
            "Epoch: 898 | Train Loss: 0.18873 | Valid Loss: 0.18851 | Time: 0.45 seconds\n",
            "Epoch: 899 | Train Loss: 0.18844 | Valid Loss: 0.18884 | Time: 0.44 seconds\n",
            "Epoch: 900 | Train Loss: 0.18811 | Valid Loss: 0.18755 | Time: 0.49 seconds\n",
            "Epoch: 901 | Train Loss: 0.18788 | Valid Loss: 0.18716 | Time: 0.46 seconds\n",
            "Epoch: 902 | Train Loss: 0.18754 | Valid Loss: 0.18753 | Time: 0.45 seconds\n",
            "Epoch: 903 | Train Loss: 0.18727 | Valid Loss: 0.18721 | Time: 0.45 seconds\n",
            "Epoch: 904 | Train Loss: 0.18694 | Valid Loss: 0.18819 | Time: 0.45 seconds\n",
            "Epoch: 905 | Train Loss: 0.18666 | Valid Loss: 0.18646 | Time: 0.46 seconds\n",
            "Epoch: 906 | Train Loss: 0.18637 | Valid Loss: 0.18697 | Time: 0.45 seconds\n",
            "Epoch: 907 | Train Loss: 0.18607 | Valid Loss: 0.18711 | Time: 0.44 seconds\n",
            "Epoch: 908 | Train Loss: 0.18576 | Valid Loss: 0.18644 | Time: 0.47 seconds\n",
            "Epoch: 909 | Train Loss: 0.18548 | Valid Loss: 0.18714 | Time: 0.46 seconds\n",
            "Epoch: 910 | Train Loss: 0.18518 | Valid Loss: 0.18569 | Time: 0.45 seconds\n",
            "Epoch: 911 | Train Loss: 0.18488 | Valid Loss: 0.18485 | Time: 0.46 seconds\n",
            "Epoch: 912 | Train Loss: 0.18458 | Valid Loss: 0.18534 | Time: 0.45 seconds\n",
            "Epoch: 913 | Train Loss: 0.18432 | Valid Loss: 0.18332 | Time: 0.46 seconds\n",
            "Epoch: 914 | Train Loss: 0.18405 | Valid Loss: 0.18343 | Time: 0.45 seconds\n",
            "Epoch: 915 | Train Loss: 0.18373 | Valid Loss: 0.18371 | Time: 0.45 seconds\n",
            "Epoch: 916 | Train Loss: 0.18343 | Valid Loss: 0.18388 | Time: 0.45 seconds\n",
            "Epoch: 917 | Train Loss: 0.18316 | Valid Loss: 0.18369 | Time: 0.45 seconds\n",
            "Epoch: 918 | Train Loss: 0.18288 | Valid Loss: 0.18204 | Time: 0.48 seconds\n",
            "Epoch: 919 | Train Loss: 0.18258 | Valid Loss: 0.18222 | Time: 0.45 seconds\n",
            "Epoch: 920 | Train Loss: 0.18231 | Valid Loss: 0.18189 | Time: 0.46 seconds\n",
            "Epoch: 921 | Train Loss: 0.18200 | Valid Loss: 0.18074 | Time: 0.46 seconds\n",
            "Epoch: 922 | Train Loss: 0.18174 | Valid Loss: 0.18075 | Time: 0.46 seconds\n",
            "Epoch: 923 | Train Loss: 0.18143 | Valid Loss: 0.17962 | Time: 0.46 seconds\n",
            "Epoch: 924 | Train Loss: 0.18115 | Valid Loss: 0.18143 | Time: 0.48 seconds\n",
            "Epoch: 925 | Train Loss: 0.18087 | Valid Loss: 0.18117 | Time: 0.45 seconds\n",
            "Epoch: 926 | Train Loss: 0.18057 | Valid Loss: 0.18085 | Time: 0.45 seconds\n",
            "Epoch: 927 | Train Loss: 0.18029 | Valid Loss: 0.18123 | Time: 0.46 seconds\n",
            "Epoch: 928 | Train Loss: 0.18003 | Valid Loss: 0.18027 | Time: 0.44 seconds\n",
            "Epoch: 929 | Train Loss: 0.17976 | Valid Loss: 0.18150 | Time: 0.45 seconds\n",
            "Epoch: 930 | Train Loss: 0.17944 | Valid Loss: 0.17947 | Time: 0.45 seconds\n",
            "Epoch: 931 | Train Loss: 0.17917 | Valid Loss: 0.17929 | Time: 0.46 seconds\n",
            "Epoch: 932 | Train Loss: 0.17889 | Valid Loss: 0.17942 | Time: 0.46 seconds\n",
            "Epoch: 933 | Train Loss: 0.17865 | Valid Loss: 0.18017 | Time: 0.45 seconds\n",
            "Epoch: 934 | Train Loss: 0.17835 | Valid Loss: 0.17900 | Time: 0.46 seconds\n",
            "Epoch: 935 | Train Loss: 0.17802 | Valid Loss: 0.17679 | Time: 0.47 seconds\n",
            "Epoch: 936 | Train Loss: 0.17778 | Valid Loss: 0.17837 | Time: 0.45 seconds\n",
            "Epoch: 937 | Train Loss: 0.17749 | Valid Loss: 0.17707 | Time: 0.45 seconds\n",
            "Epoch: 938 | Train Loss: 0.17723 | Valid Loss: 0.17782 | Time: 0.47 seconds\n",
            "Epoch: 939 | Train Loss: 0.17694 | Valid Loss: 0.17833 | Time: 0.46 seconds\n",
            "Epoch: 940 | Train Loss: 0.17671 | Valid Loss: 0.17680 | Time: 0.45 seconds\n",
            "Epoch: 941 | Train Loss: 0.17639 | Valid Loss: 0.17520 | Time: 0.48 seconds\n",
            "Epoch: 942 | Train Loss: 0.17610 | Valid Loss: 0.17657 | Time: 0.47 seconds\n",
            "Epoch: 943 | Train Loss: 0.17585 | Valid Loss: 0.17549 | Time: 0.47 seconds\n",
            "Epoch: 944 | Train Loss: 0.17557 | Valid Loss: 0.17533 | Time: 0.46 seconds\n",
            "Epoch: 945 | Train Loss: 0.17529 | Valid Loss: 0.17501 | Time: 0.46 seconds\n",
            "Epoch: 946 | Train Loss: 0.17499 | Valid Loss: 0.17593 | Time: 0.48 seconds\n",
            "Epoch: 947 | Train Loss: 0.17474 | Valid Loss: 0.17309 | Time: 0.45 seconds\n",
            "Epoch: 948 | Train Loss: 0.17445 | Valid Loss: 0.17417 | Time: 0.45 seconds\n",
            "Epoch: 949 | Train Loss: 0.17420 | Valid Loss: 0.17458 | Time: 0.47 seconds\n",
            "Epoch: 950 | Train Loss: 0.17391 | Valid Loss: 0.17400 | Time: 0.45 seconds\n",
            "Epoch: 951 | Train Loss: 0.17367 | Valid Loss: 0.17482 | Time: 0.46 seconds\n",
            "Epoch: 952 | Train Loss: 0.17338 | Valid Loss: 0.17238 | Time: 0.47 seconds\n",
            "Epoch: 953 | Train Loss: 0.17310 | Valid Loss: 0.17304 | Time: 0.46 seconds\n",
            "Epoch: 954 | Train Loss: 0.17284 | Valid Loss: 0.17349 | Time: 0.45 seconds\n",
            "Epoch: 955 | Train Loss: 0.17256 | Valid Loss: 0.17397 | Time: 0.46 seconds\n",
            "Epoch: 956 | Train Loss: 0.17230 | Valid Loss: 0.17182 | Time: 0.46 seconds\n",
            "Epoch: 957 | Train Loss: 0.17203 | Valid Loss: 0.17239 | Time: 0.45 seconds\n",
            "Epoch: 958 | Train Loss: 0.17176 | Valid Loss: 0.17263 | Time: 0.45 seconds\n",
            "Epoch: 959 | Train Loss: 0.17150 | Valid Loss: 0.17239 | Time: 0.46 seconds\n",
            "Epoch: 960 | Train Loss: 0.17120 | Valid Loss: 0.17216 | Time: 0.45 seconds\n",
            "Epoch: 961 | Train Loss: 0.17095 | Valid Loss: 0.17159 | Time: 0.47 seconds\n",
            "Epoch: 962 | Train Loss: 0.17067 | Valid Loss: 0.17234 | Time: 0.46 seconds\n",
            "Epoch: 963 | Train Loss: 0.17042 | Valid Loss: 0.17070 | Time: 0.45 seconds\n",
            "Epoch: 964 | Train Loss: 0.17015 | Valid Loss: 0.16929 | Time: 0.48 seconds\n",
            "Epoch: 965 | Train Loss: 0.16987 | Valid Loss: 0.16913 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16962 | Valid Loss: 0.16969 | Time: 0.47 seconds\n",
            "Epoch: 967 | Train Loss: 0.16938 | Valid Loss: 0.16925 | Time: 0.44 seconds\n",
            "Epoch: 968 | Train Loss: 0.16912 | Valid Loss: 0.17061 | Time: 0.46 seconds\n",
            "Epoch: 969 | Train Loss: 0.16882 | Valid Loss: 0.16942 | Time: 0.45 seconds\n",
            "Epoch: 970 | Train Loss: 0.16856 | Valid Loss: 0.16842 | Time: 0.48 seconds\n",
            "Epoch: 971 | Train Loss: 0.16827 | Valid Loss: 0.16797 | Time: 0.47 seconds\n",
            "Epoch: 972 | Train Loss: 0.16802 | Valid Loss: 0.16859 | Time: 0.45 seconds\n",
            "Epoch: 973 | Train Loss: 0.16778 | Valid Loss: 0.16806 | Time: 0.48 seconds\n",
            "Epoch: 974 | Train Loss: 0.16750 | Valid Loss: 0.16825 | Time: 0.43 seconds\n",
            "Epoch: 975 | Train Loss: 0.16726 | Valid Loss: 0.16722 | Time: 0.47 seconds\n",
            "Epoch: 976 | Train Loss: 0.16699 | Valid Loss: 0.16640 | Time: 0.46 seconds\n",
            "Epoch: 977 | Train Loss: 0.16671 | Valid Loss: 0.16643 | Time: 0.46 seconds\n",
            "Epoch: 978 | Train Loss: 0.16649 | Valid Loss: 0.16567 | Time: 0.46 seconds\n",
            "Epoch: 979 | Train Loss: 0.16622 | Valid Loss: 0.16764 | Time: 0.47 seconds\n",
            "Epoch: 980 | Train Loss: 0.16595 | Valid Loss: 0.16605 | Time: 0.46 seconds\n",
            "Epoch: 981 | Train Loss: 0.16567 | Valid Loss: 0.16709 | Time: 0.44 seconds\n",
            "Epoch: 982 | Train Loss: 0.16545 | Valid Loss: 0.16596 | Time: 0.46 seconds\n",
            "Epoch: 983 | Train Loss: 0.16517 | Valid Loss: 0.16403 | Time: 0.46 seconds\n",
            "Epoch: 984 | Train Loss: 0.16493 | Valid Loss: 0.16503 | Time: 0.46 seconds\n",
            "Epoch: 985 | Train Loss: 0.16471 | Valid Loss: 0.16529 | Time: 0.44 seconds\n",
            "Epoch: 986 | Train Loss: 0.16440 | Valid Loss: 0.16526 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16413 | Valid Loss: 0.16468 | Time: 0.44 seconds\n",
            "Epoch: 988 | Train Loss: 0.16390 | Valid Loss: 0.16478 | Time: 0.45 seconds\n",
            "Epoch: 989 | Train Loss: 0.16362 | Valid Loss: 0.16322 | Time: 0.46 seconds\n",
            "Epoch: 990 | Train Loss: 0.16342 | Valid Loss: 0.16394 | Time: 0.44 seconds\n",
            "Epoch: 991 | Train Loss: 0.16313 | Valid Loss: 0.16301 | Time: 0.47 seconds\n",
            "Epoch: 992 | Train Loss: 0.16290 | Valid Loss: 0.16378 | Time: 0.44 seconds\n",
            "Epoch: 993 | Train Loss: 0.16258 | Valid Loss: 0.16313 | Time: 0.47 seconds\n",
            "Epoch: 994 | Train Loss: 0.16233 | Valid Loss: 0.16143 | Time: 0.47 seconds\n",
            "Epoch: 995 | Train Loss: 0.16210 | Valid Loss: 0.16262 | Time: 0.46 seconds\n",
            "Epoch: 996 | Train Loss: 0.16184 | Valid Loss: 0.16149 | Time: 0.44 seconds\n",
            "Epoch: 997 | Train Loss: 0.16161 | Valid Loss: 0.16124 | Time: 0.47 seconds\n",
            "Epoch: 998 | Train Loss: 0.16135 | Valid Loss: 0.16020 | Time: 0.45 seconds\n",
            "Epoch: 999 | Train Loss: 0.16110 | Valid Loss: 0.16054 | Time: 0.45 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16088 | Valid Loss: 0.16131 | Time: 0.46 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 998\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.76 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 3]: 33.37374\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3QV5dbH8e9OIYU0IBBKgER6kGZoFhQEFcULeukqyrVgww4KFlBeO3qtWLErRsTGVRQVg1hpSq+RHlpoIYEEUvb7xzlAxEBCOMnknLM/a53lmZlnJvtxWL9MpjwjqooxxhjvF+B0AcYYYzzDAt0YY3yEBboxxvgIC3RjjPERFujGGOMjLNCNMcZHWKAbY4yPsEA3Pk9E1olID6frMKa8WaAbY4yPsEA3fklEQkTkWRHZ7P48KyIh7mWxIvKliOwRkV0i8pOIBLiX3SMi6SKSJSIrRaS7sz0x5oggpwswxiH3AZ2BtoACXwD3Aw8AdwGbgJrutp0BFZFmwHCgg6puFpEEILBiyzbm2OwI3firy4FxqrpdVTOAh4Ah7mV5QB2goarmqepP6hr0qAAIAZJEJFhV16nqX45Ub0wxLNCNv6oLrC8yvd49D2A8kAZ8KyJrRGQUgKqmAbcDDwLbRSRFROpiTCVhgW781WagYZHpBu55qGqWqt6lqqcAvYE7D50rV9VJqnqWe10FnqjYso05Ngt04y+CRST00Af4ELhfRGqKSCwwBngfQEQuFpHGIiJAJq5TLYUi0kxEznVfPM0FcoBCZ7pjzD9ZoBt/MQ1XAB/6hALzgEXAYuAP4GF32ybA90A28Bvwkqqm4jp//jiwA9gK1AJGV1wXjDk+sRdcGGOMb7AjdGOM8REW6MYY4yMs0I0xxkdYoBtjjI9w7NH/2NhYTUhIKNO6+/bto2rVqp4tqJKzPvsH67N/OJk+z58/f4eq1ixumWOBnpCQwLx588q07syZM+natatnC6rkrM/+wfrsH06mzyKy/ljL7JSLMcb4CAt0Y4zxERboxhjjI2w8dGOM18jLy2PTpk3k5uY6XcpJiY6OZvny5cdtExoaSnx8PMHBwaXergW6McZrbNq0icjISBISEnCNneadsrKyiIyMPOZyVWXnzp1s2rSJxMTEUm/XTrkYY7xGbm4uNWrU8OowLw0RoUaNGif8l4gFujHGq/h6mB9Sln56X6AvW0bCW2/Bvn1OV2KMMZWK1wX6/s+mc8+7F3F1rS8pfPtdyMtzuiRjjJ/Ys2cPL7300gmvd9FFF7Fnz55yqOjvvC7Qn8y7g8kM5K39A6nxn39xVcwXzL5tEmRmOl2aMcbHHSvQ8/Pzj7vetGnTiImJKa+yDitVoItITxFZKSJph16Ye9TyZ0RkgfuzSkTK7VfRLbfA3Xev4IP3CmnXuoB39/ej8/OXER+TzX2nfsHBr2dAob0VzBjjeaNGjeKvv/6ibdu2dOjQgS5dutC7d2+SkpIAuOSSS0hOTqZly5a89tprh9dLSEhgx44drFu3jhYtWnDLLbfQsmVLzj//fHJycjxWX4m3LYpIIDABOA/YBMwVkamquuxQG1W9o0j7W4B2HqvwKDVqwIUXbqVr1+ZcdkUsa9bAM6O388qU2jy6tA9vXLSVs8K+4bb+mznz/m4ENGlUXqUYY5x0++2wYIFnt9m2LTz77DEXP/744yxZsoQFCxYwc+ZMevXqxZIlSw7fWvjmm29SvXp1cnJy6NChA3379qVGjRp/28bq1auZOHEib7/9NgMGDOCTTz7hiiuu8Ej5pTlC7wikqeoaVT0IpAB9jtN+MK4X8FaIU06BFz6qxe7MQCa/f5BOyQXMyOvC2e9eS2DTRsQGZ/LTA9+Clz+IYIypfDp27Pi3+8Sff/552rRpQ+fOndm4cSOrV6/+xzqJiYm0bt0agOTkZNatW+exekrzYFE9YGOR6U1Ap+IaikhDIBH44eRLOzEREdD/8ir0v7wemZkw4bFMxoyPZGd+NGc/fD7dH5/JmaflctuziVQ/vVlFl2eM8bTjHElXlKJD4M6cOZPvv/+e3377jfDwcLp27VrsfeQhISGHvwcGBlbsKZcTNAiYoqoFxS0UkWHAMIC4uDhmzpxZph+SnZ1d4rpn9ITve8LqleH8OCmAD2Z1ZcYcGHcGDIr9isHXbSPqvETwkntaS9NnX2N99g8n0ufo6GiysrLKt6AS7N27l6ysLPbv309+fv7herZu3UpkZCQFBQXMnz+f33//nf3795OVlYWqkp2dTXZ2NoWFhRQUFJCVlcWBAwc4cODAMfuUm5t7Qv8eShPo6UD9ItPx7nnFGQTcfKwNqeprwGsA7du317KOB3wiYwl37QrXXQ/vFMCrT2Xx+evb+eSv8/jssUL6v/I9t44IocOo7hBQuW/4sTGj/YP1+fiWL19+3Efmy1tkZCRnnXUWp59+OmFhYcTFxR2u59JLL+Wdd96hY8eONGvWjM6dOxMeHk5kZCQiQkREBAABAQEEBgYSGRlJSEgIeXl5x+xTaGgo7dqV/pJkaQJ9LtBERBJxBfkg4LKjG4lIc6Aa8Fupf3oFCgyEm+6J5KZ7Itm8Jpe7L9vER7Mv4P37grnwsZ8YebfQ7f4zveaI3RjjjEmTJhU7PyQkhK+//rrYZYfOk8fGxrJkyZLDR+QjRozwaG0lHpaqaj4wHJgOLAcmq+pSERknIr2LNB0EpKiqerTCclD3lFDe/70x6VsDubHHar7O7sK5Y87iPzX/x+5PU50uzxhjyqRU5xlUdZqqNlXVRqr6iHveGFWdWqTNg6r6j3vUK7OacQG89F0T5v2eT/8O63h7Z28a9G3P2KaT2DtvldPlGWPMCancJ44rSHKnICbPSeCnGQdpVCeHcasvo2GHmjx25pcUZjp7AcYYY0rLAr2Is86twp/ptfj6wz3EV9/Pvb9eTIvY7cx89FenSzPGmBJZoB9FBHoOimHB9nqMuXoTGwvq0v2+TgxpOIuMJducLs8YY47JAv0YAgPhoTfiSd8SyMXN03h/w9nUahXHD3d9BZX/uq8xxg9ZoJegWlwVPl3SjOsHusYb6/7fXlxV/wdy1m93uDJjTGV36N7zzZs3069fv2LbdO3alXnz5nnk51mgl0JgILySEsO2LYUM6bCc99K70b3xev584WenSzPGeIG6desyZcqUcv85FugnoFbtAN6d04KU8ZtYpY3peGsnnusyhfwsz43FYIypvEaNGsWECRMOTz/44IM8/PDDdO/endNOO41WrVrxxRdf/GO9devWceqppwKQk5PD0KFDadGiBZdeemmlHsvFLwwY0YDzLs/lgnZbuP3nftweBVt+XUvt00v/dm5jzMlxYPRcBg4cyO23387NN7tGOJk8eTLTp0/n1ltvJSoqih07dtC5c2d69+59zHeCvvzyy4SHh7N8+XIWLVrEaaed5rH67Qi9jKrVCWXWugYM/9d6AE45I44/nvnR4aqMMeWpXbt2bN++nc2bN7Nw4UKqVatG7dq1uffee2ndujU9evQgPT2dbduOfUfcrFmzGDhwIACtW7c+PJSuJ9gR+kkIDYXnPm9Ijze2M+j6KM69sw1PfvsZ1/2vNxIU6HR5xvg0p0bP7d+/P1OmTGHr1q0MHDiQDz74gIyMDObPn09wcDAJCQnFDptbEewI/SQFBECf62qxaJFQK+oA139zKeNbvAEZGU6XZowpBwMHDiQlJYUpU6bQv39/MjMzqVWrFsHBwaSmprJ+/frjrn/22Wfz8ccfA7BkyRIWLVrksdos0D2kyakh/Lk5jgtO3cQ9acO4oP4yVn/iuR1ljKkcWrZsSVZWFvXq1aNOnTpcfvnlzJs3j1atWvHuu+/SvHnz465/4403kp2dTYsWLRgzZgzJyckeq81OuXhQ1arw7ox47r1+B298fg5N+8GHt/7GoOdOd7o0Y4wHLV68+PD32NhYfvut+FHDs7OzAddLopcsWQJAWFgYb7/9drmM625H6B5WqxZM/CyWr1NcDyJd+Xwy7/X9zJ4uNcaUOwv0ctJzYAwb0w5QM2wfV33ah1c7vYHut/vVjTHlxwK9HMU3CuHPtTGc22gDN8y9loCqYaydu8Ppsozxal7wDh2PKEs/LdDLWa04YfrKBMJD8gE4pWMsuUv/crgqY7xTaGgoO3fu9PlQV1V27txJaGjoCa1nF0UrQGAgZOwKompV13RS6yDeeWkZXa5PcrYwY7xMfHw8mzZtIsPLbwvOzc0tMaxDQ0OJj48/oe1aoFeQ8HA4cACefyCDkU825OwbYFLaHwwe77nHfo3xdcHBwSQmev8QGzNnzqRdu3Ye366dcqlAVarAiCdq8sOUXQAMfaolU2743uGqjDG+wgLdAd36Vmftkn1IgND/1R70TVpmtzUaY06aBbpDElpWZetW12hsny5PYmL3D6Gw0OGqjDHezALdQTE1g8naqzSI3M11qZcxvPn3kJfndFnGGC9lge6wiEhh9soYACasPp97m3+K7tvvcFXGGG9kgV4J1K4j5OXB1Weu4LE1A+nXcA75O/Y4XZYxxstYoFcSQUEw8afmjBu4lE93dmV0i8/RbfYiamNM6VmgVyIicN+klgw9L52ndgwlvE4Uj9yz1+myjDFeolSBLiI9RWSliKSJyKhjtBkgIstEZKmITPJsmf4jIABen1aPO/pvIldDuf/JKPYt3+B0WcYYL1BioItIIDABuBBIAgaLSNJRbZoAo4EzVbUlcHs51Oo3goLgqZQjj/wmtz7IvqU7HazIGOMNSnOE3hFIU9U1qnoQSAH6HNXmOmCCqu4GUFU7+XuSAgLg4EG4ecB20vITuHh4X5ZOtUG9jDHHJiWNWiYi/YCeqnqte3oI0ElVhxdp8zmwCjgTCAQeVNVvitnWMGAYQFxcXHJKSkqZis7OziYiIqJM63qjOVMKuGdCdwC+efp9Qk47sQF7vJW/7WewPvuLk+lzt27d5qtq+2IXqupxP0A/YGKR6SHAi0e1+RL4DAgGEoGNQMzxtpucnKxllZqaWuZ1vVFhoeqA85apa3wA1R9eXuF0SRXC3/azqvXZX5xMn4F5eoxcLc0pl3SgfpHpePe8ojYBU1U1T1XX4jpab1KqXzemRCJw/aht3HWN6970c29sxsZP5zpclTGmsilNoM8FmohIoohUAQYBU49q8znQFUBEYoGmwBoP1un3AgLgqYkxvP+c6+Jog74dmP+Khbox5ogSA11V84HhwHRgOTBZVZeKyDgR6e1uNh3YKSLLgFRgpKrabRnl4LJbanDLNfsA6HxjW2Y9NcfhiowxlUWp7kNX1Wmq2lRVG6nqI+55Y1R1qvu7quqdqpqkqq1UtWxXO02JROD5iVVZM28XNYIyOWdkRz4f+6fTZRljKgF7UtRLJSZX58XXQgC4dFw75jz/u8MVGWOcZoHuxfoOjeQ/l+UCcPFtp5D+wUxnCzLGOMoC3YuJwJsfhPLbN5nsojrxV3Rl8au/Ol2WMcYhFug+oPMF0bzy3xwAWt9wBqve/NnhiowxTrBA9xHX3hHJ+Addd780v+YMZjwxz+GKjDEVzQLdh4wYW5WU1/aiBNBjVHveu3ux0yUZYyqQBbqPGXhdFF+85xpD/crxrZg6boHDFRljKooFug/qfUUUH72+l1DJpc/Ytjx/0wqnSzLGVAALdB814NoonnosH4DbXm7Ony/bferG+DoLdB928z0RrJ69i+qBe+h8Uzs+GL3E6ZKMMeXIAt3HNe5YnWWLCmgZuoYRj9dg7xepTpdkjCknFuh+IC6pBve9VI+t1CH6km58Onah0yUZY8qBBbqf6PufKFJec9390ndcG9a894vDFRljPM0C3Y8MvC6KO290PVHa6MozWfW+Db1rjC+xQPczT78Uxr23uZ4oPWNII9Z9bC/JMMZXWKD7oUeercqKnzLIJIoBg4Q939qRujG+wALdTzU7qyYvj9/H3ML2DLgoG51toW6Mt7NA92PXjohh5PV7+a7gXNqdEUbmj/bmI2O8mQW6n3v0xSieG7uLhYWtiOnajrSpy5wuyRhTRhbofi4oCG59sDoP3rYbgCZ9ksj8danDVRljysIC3QAw9tlqvP3ENgBizmxJ5mwb0MsYb2OBbg67cmQc3TrtByDpjGh+/XC9wxUZY06EBbo5TARm/BbOnUN3sbmwDmde1pDZUzY4XZYxppQs0M3fiMDTb1Xn3z1cwwTcflkGe/5c63BVxpjSsEA3xfrkuygeGLaN3/OSqXZaIum/b3S6JGNMCSzQzTHd+UQcHU91DRMQf3p9Vvyw2eGKjDHHY4FujikmBmYvrsqNfbcD0KJ7XdLnWqgbU1mVKtBFpKeIrBSRNBEZVczyoSKSISIL3J9rPV+qccpLU2ox7BLXLY2JHWPRdAt1YyqjEgNdRAKBCcCFQBIwWESSimn6kaq2dX8merhO47Cn3o0DII8qDGv5M3tWbnO4ImPM0UpzhN4RSFPVNap6EEgB+pRvWaayiYyEnBzo3HIvEzMHUK15HNuWZDhdljGmCFHV4zcQ6Qf0VNVr3dNDgE6qOrxIm6HAY0AGsAq4Q1X/cVuEiAwDhgHExcUlp6SklKno7OxsIiIiyrSut6osfc7MDOLKy9qzd38ofap+zcgPDpIXHV0uP6uy9LkiWZ/9w8n0uVu3bvNVtX2xC1X1uB+gHzCxyPQQ4MWj2tQAQtzfrwd+KGm7ycnJWlapqallXtdbVaY+5+erhofmK6jeFvu+ZqzaVS4/pzL1uaJYn/3DyfQZmKfHyNXSnHJJB+oXmY53zyv6S2Gnqh5wT04Ekkv3u8Z4o8BA2Lo9kB7tdvDcjsup2bQa21dnOl2WMX6vNIE+F2giIokiUgUYBEwt2kBE6hSZ7A0s91yJpjKKjISpv8Qenk5KUgp3W6gb46QSA11V84HhwHRcQT1ZVZeKyDgR6e1udquILBWRhcCtwNDyKthUHmFhsGYNBAQoO/NjGNHiKw5s2+N0Wcb4raDSNFLVacC0o+aNKfJ9NDDas6UZb5CYCLt3C//uksEziy5jQZN5fLe2MYE1YpwuzRi/Y0+KmpMWFQVfz6tJ99YZpGa1p1vCWvIy7EjdmIpmgW48IjgY/vd7TWpFH+Cn7HZc1fx3dNdup8syxq9YoBuPCQuDbXtCuH/AKj7c1ZNbmn8Huy3UjakoFujG4x6c1JR/n76FCRkDuLnZd3akbkwFsUA3HhcYCO/PcN3J+lLGAFrUzeTnaXsdrsoY32eBbspFWBiMcd8HtfJAAl16RbFv4y5nizLGx1mgm3IzdixsLDKiT0SD6kx8Ntu5gozxcRboptwEBEB8POwpcgfjdXdE8Me3O5wryhgfZoFuyl10NEyeDDf+axMAT/ad/fdDd2OMR1igmwrRvz9M+CKe6lF5fJTdi1fbvgxpaU6XZYxPsUA3FUYElq8OpnWT/dyw61Gubj0PXbrM6bKM8RkW6KZC1aoFL0wMB+CtnEG0aB1Mwdw/HK7KGN9ggW4q3NlnQ0EBXHTOPlYWNqF95yDWfTLf6bKM8XoW6MYRAQHwzpSqACwobE1iv2TeH73U4aqM8W4W6MYxsbGgCp++4RoaYMjjLakZfYAMe/e0MWVigW4cd+nV1ZjyVhYAO/aG8Notix2uyBjvZIFuKoW+QyNJeXM/APd/1Ip7L17ocEXGeB8LdFNpDPxPOHvS9wHw2FdtWDx+jcMVGeNdLNBNpRJdtyq/ph4A4NZpV/NOv/+5TrQbY0pkgW4qnc7nhHBej0IAhn7yLzrW3kBOdoHDVRlT+Vmgm0pHBL79LoD/ffEj58SnMXd7Q8YkfwUHDjhdmjGVmgW6qbQiopTUDY1pU3c7T63qzTOnvgGZmU6XZUylZYFuKjUR+C2tFg1qZHNn2k0MO+V7CtO3OF2WMZWSBbqp9MLC4LtfI7ioQwav7+rLGadsZc88G6nRmKNZoBuv0LQpfDm7Jg/fsInZB9tRrUNjXr9vrdNlGVOpWKAbryECoyfEE1stH4Bhjyby+q32VKkxh5Qq0EWkp4isFJE0ERl1nHZ9RURFpL3nSjTmiIAA2LYjiKEDXU+VDnuhFW8M/h4ttHvVjSkx0EUkEJgAXAgkAYNFJKmYdpHAbcBsTxdpTFEBAfDGpHC+nJJL9eAsrk3pwcc934C8PKdLM8ZRpTlC7wikqeoaVT0IpAB9imn3f8ATQK4H6zOmWAEB0KtvKH9tdQ3BO/C7a4mP3MOaBXsdrswY54iW8Fi1iPQDeqrqte7pIUAnVR1epM1pwH2q2ldEZgIjVHVeMdsaBgwDiIuLS05JSSlT0dnZ2URERJRpXW9lfT62995ryIfv1iMnvwr1Ajfz0NjFNOoSUgEVep7tZ/9wMn3u1q3bfFUt/rS2qh73A/QDJhaZHgK8WGQ6AJgJJLinZwLtS9pucnKyllVqamqZ1/VW1ueSndd+p7oGflFdP2VO+RRVzmw/+4eT6TMwT4+Rq6U55ZIO1C8yHe+ed0gkcCowU0TWAZ2BqXZh1FS0b2ZX566rXS/LaNivA/PHfeVwRcZUrNIE+lygiYgkikgVYBAw9dBCVc1U1VhVTVDVBOB3oLcWc8rFmPIUEADjJ1bj/G6ui6Ptx/ZiaJs/yNlX6HBlxlSMEgNdVfOB4cB0YDkwWVWXisg4Eeld3gUacyJEYPoPwbzzhute9XcWnUZ4RAC6b7/DlRlT/oJK00hVpwHTjpo35hhtu558WcacnCuvDmJXpnLHnQJAVJSyecVWIpvUdrgyY8qPPSlqfNbtdwgHD0KL+L1kF1bloXafwy+/OF2WMeXGAt34tOBgmLcyij5dM3l63w1c22Uld3b9g9Wr7MlS43ss0I3PCw+HD76Mpm/vg7yhV/PMj6fRte1uCjKznS7NGI+yQDd+oWpVmPJFFW4Z7joy35xTnaCYCMaP3O5wZcZ4jgW68SvPvyDMmnVk+u6najF+yCLnCjLGgyzQjd/p0sX1POnE8bsAuPv91vw++Dkb3Mt4PQt047euGVGdjz90hfjpKbchVYKZM22Hw1UZU3YW6Mav9RsUTKtWR6Y79Ypl3Uc2ArTxThboxu8tWgSbN0NAgOuC6dmD6vBW3y8pOFjgcGXGnBgLdGOAOnWgoED47vN9bKQBV396MUEhgXz25i6nSzOm1CzQjSmiR5+qjLjryENH/76mOg9fscLBiowpPQt0Y47yxJPC1q1Hph/4oDkisGGFDfBlKjcLdGOOEhAAcXHwww/Qru2RoXcbtghn6tOrKbTReE0lZYFuzDF06wbz/whgy5Yj8/qMaEJ02AHyD9gFU1P5WKAbcxwiULs27NgB/774IADZB0MIDg3k/Wd3UGC5bioRC3RjSqFGDfjkf1WY9aMSEuxK8SF3xBIUBHfcbiM3msrBAt2YE9DlbGHt+kCuvDSLWsGuWxqffU7IXLGlhDWNKX8W6MacoDp14J1PI9mWG8N1nRcDENOiDkPOWsvBA3a0bpxjgW5MWQUE8OqvrXhp7DYA3v8lkZBQ4ZfPMxwuzPgrC3RjToII3PhgHDO+PXJ19KxLayICL79kR+umYlmgG+MB554XSE4OvDDmyNH5TTcLG1PTHKzK+BsLdGM8JDQUhj9Uk8kphUSEuG5xbHBuYxZe/xKak+twdcYfWKAb42H9BwaQlVvl8OiNbV+7iZiIPLZ+/JPDlRlfZ4FuTDmZNUsOf99bGEmdAV0YkTQNttt7TE35sEA3ppyceabrVXeqcPmgfACeXn4REleLwZ3+QgtsUBjjWRboxlSA9z8M4tdfj0ynzGlEcFAh017Z4FxRxudYoBtTQU4/HQoKIDdHOb3RdgoIoteNDbi9/c/8/K0NzWtOXqkCXUR6ishKEUkTkVHFLL9BRBaLyAIR+VlEkjxfqjHeLyAA18NHq2tx+/WuEH9u/ll0vyCQL0f+6Do/Y0wZlRjoIhIITAAuBJKAwcUE9iRVbaWqbYEngf96vFJjfIgIPPNKOPn5sOCdhRwkhH89dQ6v993LxunLnC7PeKnSHKF3BNJUdY2qHgRSgD5FG6jq3iKTVQE7zDCmFAIDoc2Vbfj6S9eTppN296FVz7oMajyPBam7Ha7OeBvREv7EE5F+QE9VvdY9PQTopKrDj2p3M3AnUAU4V1VXF7OtYcAwgLi4uOSUlJQyFZ2dnU1ERESZ1vVW1mf/sOiXg9x2//mHp9+84Bka3NSCwKhQB6sqX/64n0+mz926dZuvqu2LXaiqx/0A/YCJRaaHAC8ep/1lwDslbTc5OVnLKjU1tczreivrs39ITU3VL75QbdMsR4/c9Kj6za1fqeblOV1eufDX/VxWwDw9Rq6W5pRLOlC/yHS8e96xpACXlGK7xphi9O4NC1aE8tln0KyB68Jpz+cvQoKD+HjkbPLz7IymKV5pAn0u0EREEkWkCjAImFq0gYg0KTLZC/jH6RZjzIm55BL4c0U4V111JMAHPNWJ4CrC1+OXOFiZqaxKDHRVzQeGA9OB5cBkVV0qIuNEpLe72XARWSoiC3CdR7+q3Co2xo+EhcHbbwuqcN/oI0+WXnT3qXSutoLXxqaTl+dggaZSKdV96Ko6TVWbqmojVX3EPW+Mqk51f79NVVuqaltV7aaqS8uzaGP80cOPBlBYCDdf70rw2Xuac/24egxuMo/5X211uDpTGdiTosZ4ERF48ZVg7r4bruh/AIBP1ren/cW1qRG2jzEjc9i7t4SNGJ9lgW6MF3riCXhvcgizZsE5nXKpFZrJrtyq/N9TYYy/9Ffy9uY4XaJxgAW6MV6sSxeY+Xsoaduj6dYhG4CHfziDKtFhPNZ3Hnm5BTaagB+xQDfGB0RGwg9zIpgy5ci8ez9tT5WwQB4YtMrGiPETFujG+JC+fV3ZvXCB0qWF6/2mj0xuSv3Q7fz2398s2H2cBboxPqh1G2HWspq895brxRrpB2tyxl2nIwHCZV03s2e3BbsvskA3xoddflUQK1fCtk35XNdlOQAf/liXatWFHm0zyM2xYPclFujG+DARaNoUatarwmuzWvDwQwU0r70HgBkLaxIWLgzvtdaGE/ARFujG+JH7xgSyfEsMejCP8QPmAjBhWiK1wvZywwVr2LvH3nPqzSzQjfFHwcGM+KgDOVmuc9nEhA0AAAu7SURBVOy7C6J59dtTOK/OEu65eCnp6/MdLtCUhQW6MX4sNCKIDRtgw5p8Hh24kDm5rXnyq5bEJwRxVqPNrFli7zr1Jhboxvi5+vWhfmIQo1PasD+7kFMbusYO+GVNXRq1Cqdn4zR2rtrJ4sUOF2pKZIFujDksrGoAC9dEMXr0kXnT/2pMbLMatG4NF3bdz6JFztVnjs8C3RjzNwEB8OijrmeQ0tOhdmwebaptoAmr+ObHcNq0gfq1D3LhhZCZ6XS1pigLdGPMMdWtC1syglmwqwGTv4k+PH/Ttip88w3ExEBWZqGdjqkkLNCNMaXS9oI41q6FKe/sY/Gdbx2eHxUTQOvW8O3UXAerM2CBbow5AQkJ0PfKqpz69H/Ynp5Hw9jsw8su6BNKj4TVjL1jL3v2OFejP7NAN8aUSc26wazLiCBrr3J1r20AzFjfhHHPRlGtGtx/dTo5Nix7hbJAN8aclIhI4Y0v49i7F36avOXw/Efeqkd4ODzQZxF7Mw6Qa2dkyp0FujHGIyIj4az+dVCF32fsOzz/4amtia4VQlgYPP/QbjtqL0cW6MYYj+t0blVUYfyTfx/067YHqxEeDikPLLWx2cuBBboxptyMGCmoQn4+pH64laCAAgAGP9ySxJB0osMO8PN3kQ5X6Tss0I0x5S4wELoOqk1eQSATXzoIwLq8ePbmhvDAo8kkRu5g5isrWLhAyctzuFgvZoFujKlQ19xYhT17YMUKqBPrDvfsWLrd2Jy27YQqVWDwvw9YsJeBBboxpsJFR0OzZrA5owqvvz6X1P9l06P5xsPLUz4LITZ8H+/d+SfTptpQvqVlgW6McVTjxvvoenEE3y2vT14ezHl/FW1qprM3vypXPtOOXn2CGNBsAQ/euI2NG0venj+zQDfGVBpBQdDh8qb8ua0eH7535Mj841VteeiVOBo0gDcvn8Hin/ZQaC9X+odSBbqI9BSRlSKSJiKjill+p4gsE5FFIjJDRBp6vlRjjL8QgUFXBKEKO3bAo/cdGWLgmkndaX12DIGBMLp/GjOm59sdkG4lBrqIBAITgAuBJGCwiCQd1exPoL2qtgamAE96ulBjjH+qUQNGPxyBKvz1F9w5ZPvhZY9PaUyPnkEEBEBgoJLv56fbS3OE3hFIU9U1qnoQSAH6FG2gqqmqeuhdVb8D8Z4t0xhj4JRT4Ol3a6EKhQfyePWmhYeXFRYKwcHwQv9ZFGzf6WCVzhEt4W8VEekH9FTVa93TQ4BOqjr8GO1fBLaq6sPFLBsGDAOIi4tLTklJKVPR2dnZRERElGldb2V99g/W5xM3b1411iwO5OV3T/3b/I5Ri+jVYyOtBkcRWEWIiqo8h+8n0+du3brNV9X2xS5U1eN+gH7AxCLTQ4AXj9H2ClxH6CElbTc5OVnLKjU1tczreivrs3+wPp+cDRtUWzbar65xBf7+efHedD140GM/6qScTJ+BeXqMXC3NKZd0oH6R6Xj3vL8RkR7AfUBvVT1Q2t82xhjjKfXrw5K0MAoK4N57Cv62bPijdalSBc5pnM6cr3f65IXU0gT6XKCJiCSKSBVgEDC1aAMRaQe8iivMtxezDWOMqTABAfDI44Guc+2FsOHPnUSHuY4zZ/1Vj04X1aBh2HYSa2Yx7KoDLFvmcMEeUmKgq2o+MByYDiwHJqvqUhEZJyK93c3GAxHAxyKyQESmHmNzxhhToUSgftsabN4RQno6LPlsNR3rbmTjgVqs2xHJ6++G0LIlPHX5H6xdnF3yBiuxoNI0UtVpwLSj5o0p8r2Hh+syxhiPCg93fepe0oTZlwCqLP5oGTNeTeOOmX0YOek0Rk6Cqxt+z/m9w9h9SjLnXBBKixZOV156pQp0Y4zxOSK0GtSSVoNa0uevQj5/dh3PvhPDm+t78OYLR5ol1cvkmQlVSEoOI76S35Btj/4bY/xeYqMA7njhFNZlVufVlwvp3y2D8+qvAGBZejQXXBJG/fow8sLF/PxVZqW9oGqBbowxbiIw7IYAJv9Qk283NEfzCxjac+vh5U9904ouF0cTEAA1I3MYNyKTLVtg377jbLQCWaAbY8yxBAby1te1UYWFC5QHh20+vGhHdhhjn46mbl1oVX83L927iTmznT10t0A3xphSaN1GGPtqXfLyID0dvn9rI09emEqHqstYu7saNz8WT6fOQtf41bw7ahlPP1lAVlbF1miBbowxJyAoCOrWhe5D6zNyWjfmZCfxyRt7uKnrMppW3cSP6U246okkRtwTSFQU3HR+GtOm7Ccnp/xrs0A3xpiT9O+rY5iQmsTK7Hgy1u3jll5/HV728neN6dU/nPBwGNB2FdNeTyfvYPnUYYFujDEeFNuwKs9/2YjCQli8oIAVH8zn1NgtAHy8sCm9htXj27F7yuVn233oxhhTDkTg1DaB0CaZxZdBRgZMeWUHm39dx/n9yueJVAt0Y4ypADVrwo0PxAKxzJxZPoFup1yMMcZHWKAbY4yPsEA3xhgfYYFujDE+wgLdGGN8hAW6Mcb4CAt0Y4zxERboxhjjI0QdGqldRDKA9WVcPRbY4cFyvIH12T9Yn/3DyfS5oarWLG6BY4F+MkRknqq2d7qOimR99g/WZ/9QXn22Uy7GGOMjLNCNMcZHeGugv+Z0AQ6wPvsH67N/KJc+e+U5dGOMMf/krUfoxhhjjmKBbowxPsKrAl1EeorIShFJE5FRTtfjKSJSX0RSRWSZiCwVkdvc86uLyHcistr932ru+SIiz7v/PywSkdOc7UHZiUigiPwpIl+6pxNFZLa7bx+JSBX3/BD3dJp7eYKTdZeViMSIyBQRWSEiy0XkdF/fzyJyh/vf9RIR+VBEQn1tP4vImyKyXUSWFJl3wvtVRK5yt18tIledaB1eE+giEghMAC4EkoDBIpLkbFUekw/cpapJQGfgZnffRgEzVLUJMMM9Da7/B03cn2HAyxVfssfcBiwvMv0E8IyqNgZ2A9e4518D7HbPf8bdzhs9B3yjqs2BNrj67rP7WUTqAbcC7VX1VCAQGITv7ee3gZ5HzTuh/Soi1YGxQCegIzD20C+BUlNVr/gApwPTi0yPBkY7XVc59fUL4DxgJVDHPa8OsNL9/VVgcJH2h9t50weId/9DPxf4EhBcT88FHb3PgenA6e7vQe524nQfTrC/0cDao+v25f0M1AM2AtXd++1L4AJf3M9AArCkrPsVGAy8WmT+39qV5uM1R+gc+YdxyCb3PJ/i/hOzHTAbiFPVLe5FW4E493df+X/xLHA3UOiergHsUdV893TRfh3us3t5pru9N0kEMoC33KeZJopIVXx4P6tqOvAUsAHYgmu/zce39/MhJ7pfT3p/e1Og+zwRiQA+AW5X1b1Fl6nrV7bP3GMqIhcD21V1vtO1VKAg4DTgZVVtB+zjyJ/hgE/u52pAH1y/zOoCVfnnqQmfV1H71ZsCPR2oX2Q63j3PJ4hIMK4w/0BVP3XP3iYiddzL6wDb3fN94f/FmUBvEVkHpOA67fIcECMiQe42Rft1uM/u5dHAzoos2AM2AZtUdbZ7egqugPfl/dwDWKuqGaqaB3yKa9/78n4+5ET360nvb28K9LlAE/fV8Sq4LqxMdbgmjxARAd4Alqvqf4ssmgocutJ9Fa5z64fmX+m+Wt4ZyCzyp51XUNXRqhqvqgm49uUPqno5kAr0czc7us+H/l/0c7f3qiNZVd0KbBSRZu5Z3YFl+PB+xnWqpbOIhLv/nR/qs8/u5yJOdL9OB84XkWruv2zOd88rPacvJJzgRYeLgFXAX8B9TtfjwX6dhevPsUXAAvfnIlznDmcAq4Hvgeru9oLrjp+/gMW47iBwvB8n0f+uwJfu76cAc4A04GMgxD0/1D2d5l5+itN1l7GvbYF57n39OVDN1/cz8BCwAlgCvAeE+Np+Bj7EdY0gD9dfYteUZb8CV7v7ngb850TrsEf/jTHGR3jTKRdjjDHHYYFujDE+wgLdGGN8hAW6Mcb4CAt0Y4zxERboxhjjIyzQjTHGR/w/6fqQI+alGRIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 4...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71485 | Valid Loss: 0.71275 | Time: 0.48 seconds\n",
            "Epoch: 2 | Train Loss: 0.71431 | Valid Loss: 0.71492 | Time: 0.46 seconds\n",
            "Epoch: 3 | Train Loss: 0.71378 | Valid Loss: 0.71389 | Time: 0.45 seconds\n",
            "Epoch: 4 | Train Loss: 0.71329 | Valid Loss: 0.71369 | Time: 0.46 seconds\n",
            "Epoch: 5 | Train Loss: 0.71281 | Valid Loss: 0.71351 | Time: 0.45 seconds\n",
            "Epoch: 6 | Train Loss: 0.71235 | Valid Loss: 0.71306 | Time: 0.45 seconds\n",
            "Epoch: 7 | Train Loss: 0.71190 | Valid Loss: 0.71303 | Time: 0.45 seconds\n",
            "Epoch: 8 | Train Loss: 0.71147 | Valid Loss: 0.71234 | Time: 0.49 seconds\n",
            "Epoch: 9 | Train Loss: 0.71105 | Valid Loss: 0.71143 | Time: 0.47 seconds\n",
            "Epoch: 10 | Train Loss: 0.71064 | Valid Loss: 0.71134 | Time: 0.46 seconds\n",
            "Epoch: 11 | Train Loss: 0.71026 | Valid Loss: 0.71111 | Time: 0.45 seconds\n",
            "Epoch: 12 | Train Loss: 0.70988 | Valid Loss: 0.71050 | Time: 0.46 seconds\n",
            "Epoch: 13 | Train Loss: 0.70951 | Valid Loss: 0.71075 | Time: 0.46 seconds\n",
            "Epoch: 14 | Train Loss: 0.70913 | Valid Loss: 0.70970 | Time: 0.46 seconds\n",
            "Epoch: 15 | Train Loss: 0.70878 | Valid Loss: 0.70902 | Time: 0.45 seconds\n",
            "Epoch: 16 | Train Loss: 0.70841 | Valid Loss: 0.70932 | Time: 0.45 seconds\n",
            "Epoch: 17 | Train Loss: 0.70807 | Valid Loss: 0.70884 | Time: 0.46 seconds\n",
            "Epoch: 18 | Train Loss: 0.70773 | Valid Loss: 0.70811 | Time: 0.47 seconds\n",
            "Epoch: 19 | Train Loss: 0.70739 | Valid Loss: 0.70765 | Time: 0.48 seconds\n",
            "Epoch: 20 | Train Loss: 0.70706 | Valid Loss: 0.70813 | Time: 0.46 seconds\n",
            "Epoch: 21 | Train Loss: 0.70674 | Valid Loss: 0.70702 | Time: 0.47 seconds\n",
            "Epoch: 22 | Train Loss: 0.70641 | Valid Loss: 0.70643 | Time: 0.47 seconds\n",
            "Epoch: 23 | Train Loss: 0.70609 | Valid Loss: 0.70630 | Time: 0.46 seconds\n",
            "Epoch: 24 | Train Loss: 0.70575 | Valid Loss: 0.70632 | Time: 0.45 seconds\n",
            "Epoch: 25 | Train Loss: 0.70545 | Valid Loss: 0.70595 | Time: 0.46 seconds\n",
            "Epoch: 26 | Train Loss: 0.70513 | Valid Loss: 0.70594 | Time: 0.46 seconds\n",
            "Epoch: 27 | Train Loss: 0.70482 | Valid Loss: 0.70540 | Time: 0.45 seconds\n",
            "Epoch: 28 | Train Loss: 0.70451 | Valid Loss: 0.70514 | Time: 0.46 seconds\n",
            "Epoch: 29 | Train Loss: 0.70419 | Valid Loss: 0.70493 | Time: 0.45 seconds\n",
            "Epoch: 30 | Train Loss: 0.70386 | Valid Loss: 0.70496 | Time: 0.46 seconds\n",
            "Epoch: 31 | Train Loss: 0.70355 | Valid Loss: 0.70426 | Time: 0.46 seconds\n",
            "Epoch: 32 | Train Loss: 0.70324 | Valid Loss: 0.70409 | Time: 0.46 seconds\n",
            "Epoch: 33 | Train Loss: 0.70292 | Valid Loss: 0.70379 | Time: 0.45 seconds\n",
            "Epoch: 34 | Train Loss: 0.70261 | Valid Loss: 0.70324 | Time: 0.47 seconds\n",
            "Epoch: 35 | Train Loss: 0.70230 | Valid Loss: 0.70268 | Time: 0.47 seconds\n",
            "Epoch: 36 | Train Loss: 0.70198 | Valid Loss: 0.70262 | Time: 0.45 seconds\n",
            "Epoch: 37 | Train Loss: 0.70164 | Valid Loss: 0.70257 | Time: 0.46 seconds\n",
            "Epoch: 38 | Train Loss: 0.70132 | Valid Loss: 0.70193 | Time: 0.45 seconds\n",
            "Epoch: 39 | Train Loss: 0.70100 | Valid Loss: 0.70165 | Time: 0.46 seconds\n",
            "Epoch: 40 | Train Loss: 0.70067 | Valid Loss: 0.70171 | Time: 0.45 seconds\n",
            "Epoch: 41 | Train Loss: 0.70034 | Valid Loss: 0.70085 | Time: 0.47 seconds\n",
            "Epoch: 42 | Train Loss: 0.70000 | Valid Loss: 0.70047 | Time: 0.47 seconds\n",
            "Epoch: 43 | Train Loss: 0.69966 | Valid Loss: 0.70030 | Time: 0.47 seconds\n",
            "Epoch: 44 | Train Loss: 0.69933 | Valid Loss: 0.70030 | Time: 0.46 seconds\n",
            "Epoch: 45 | Train Loss: 0.69898 | Valid Loss: 0.69991 | Time: 0.46 seconds\n",
            "Epoch: 46 | Train Loss: 0.69864 | Valid Loss: 0.69907 | Time: 0.46 seconds\n",
            "Epoch: 47 | Train Loss: 0.69829 | Valid Loss: 0.69919 | Time: 0.48 seconds\n",
            "Epoch: 48 | Train Loss: 0.69794 | Valid Loss: 0.69836 | Time: 0.46 seconds\n",
            "Epoch: 49 | Train Loss: 0.69758 | Valid Loss: 0.69892 | Time: 0.45 seconds\n",
            "Epoch: 50 | Train Loss: 0.69723 | Valid Loss: 0.69813 | Time: 0.48 seconds\n",
            "Epoch: 51 | Train Loss: 0.69687 | Valid Loss: 0.69802 | Time: 0.47 seconds\n",
            "Epoch: 52 | Train Loss: 0.69650 | Valid Loss: 0.69693 | Time: 0.49 seconds\n",
            "Epoch: 53 | Train Loss: 0.69612 | Valid Loss: 0.69696 | Time: 0.45 seconds\n",
            "Epoch: 54 | Train Loss: 0.69575 | Valid Loss: 0.69631 | Time: 0.47 seconds\n",
            "Epoch: 55 | Train Loss: 0.69536 | Valid Loss: 0.69608 | Time: 0.46 seconds\n",
            "Epoch: 56 | Train Loss: 0.69498 | Valid Loss: 0.69507 | Time: 0.45 seconds\n",
            "Epoch: 57 | Train Loss: 0.69459 | Valid Loss: 0.69523 | Time: 0.45 seconds\n",
            "Epoch: 58 | Train Loss: 0.69420 | Valid Loss: 0.69484 | Time: 0.46 seconds\n",
            "Epoch: 59 | Train Loss: 0.69381 | Valid Loss: 0.69493 | Time: 0.45 seconds\n",
            "Epoch: 60 | Train Loss: 0.69341 | Valid Loss: 0.69451 | Time: 0.44 seconds\n",
            "Epoch: 61 | Train Loss: 0.69299 | Valid Loss: 0.69381 | Time: 0.46 seconds\n",
            "Epoch: 62 | Train Loss: 0.69260 | Valid Loss: 0.69393 | Time: 0.46 seconds\n",
            "Epoch: 63 | Train Loss: 0.69218 | Valid Loss: 0.69250 | Time: 0.46 seconds\n",
            "Epoch: 64 | Train Loss: 0.69177 | Valid Loss: 0.69246 | Time: 0.45 seconds\n",
            "Epoch: 65 | Train Loss: 0.69135 | Valid Loss: 0.69213 | Time: 0.47 seconds\n",
            "Epoch: 66 | Train Loss: 0.69091 | Valid Loss: 0.69196 | Time: 0.46 seconds\n",
            "Epoch: 67 | Train Loss: 0.69049 | Valid Loss: 0.69180 | Time: 0.46 seconds\n",
            "Epoch: 68 | Train Loss: 0.69006 | Valid Loss: 0.69133 | Time: 0.48 seconds\n",
            "Epoch: 69 | Train Loss: 0.68960 | Valid Loss: 0.69036 | Time: 0.48 seconds\n",
            "Epoch: 70 | Train Loss: 0.68916 | Valid Loss: 0.69048 | Time: 0.46 seconds\n",
            "Epoch: 71 | Train Loss: 0.68872 | Valid Loss: 0.68947 | Time: 0.46 seconds\n",
            "Epoch: 72 | Train Loss: 0.68828 | Valid Loss: 0.68886 | Time: 0.45 seconds\n",
            "Epoch: 73 | Train Loss: 0.68781 | Valid Loss: 0.68887 | Time: 0.43 seconds\n",
            "Epoch: 74 | Train Loss: 0.68735 | Valid Loss: 0.68844 | Time: 0.46 seconds\n",
            "Epoch: 75 | Train Loss: 0.68689 | Valid Loss: 0.68837 | Time: 0.46 seconds\n",
            "Epoch: 76 | Train Loss: 0.68643 | Valid Loss: 0.68697 | Time: 0.48 seconds\n",
            "Epoch: 77 | Train Loss: 0.68595 | Valid Loss: 0.68665 | Time: 0.46 seconds\n",
            "Epoch: 78 | Train Loss: 0.68549 | Valid Loss: 0.68616 | Time: 0.46 seconds\n",
            "Epoch: 79 | Train Loss: 0.68500 | Valid Loss: 0.68558 | Time: 0.46 seconds\n",
            "Epoch: 80 | Train Loss: 0.68451 | Valid Loss: 0.68512 | Time: 0.45 seconds\n",
            "Epoch: 81 | Train Loss: 0.68403 | Valid Loss: 0.68468 | Time: 0.47 seconds\n",
            "Epoch: 82 | Train Loss: 0.68354 | Valid Loss: 0.68399 | Time: 0.47 seconds\n",
            "Epoch: 83 | Train Loss: 0.68304 | Valid Loss: 0.68372 | Time: 0.45 seconds\n",
            "Epoch: 84 | Train Loss: 0.68254 | Valid Loss: 0.68356 | Time: 0.44 seconds\n",
            "Epoch: 85 | Train Loss: 0.68204 | Valid Loss: 0.68301 | Time: 0.45 seconds\n",
            "Epoch: 86 | Train Loss: 0.68152 | Valid Loss: 0.68234 | Time: 0.46 seconds\n",
            "Epoch: 87 | Train Loss: 0.68102 | Valid Loss: 0.68194 | Time: 0.47 seconds\n",
            "Epoch: 88 | Train Loss: 0.68052 | Valid Loss: 0.68140 | Time: 0.45 seconds\n",
            "Epoch: 89 | Train Loss: 0.67998 | Valid Loss: 0.68050 | Time: 0.47 seconds\n",
            "Epoch: 90 | Train Loss: 0.67946 | Valid Loss: 0.68087 | Time: 0.46 seconds\n",
            "Epoch: 91 | Train Loss: 0.67894 | Valid Loss: 0.67965 | Time: 0.45 seconds\n",
            "Epoch: 92 | Train Loss: 0.67841 | Valid Loss: 0.67944 | Time: 0.48 seconds\n",
            "Epoch: 93 | Train Loss: 0.67788 | Valid Loss: 0.67854 | Time: 0.45 seconds\n",
            "Epoch: 94 | Train Loss: 0.67733 | Valid Loss: 0.67830 | Time: 0.48 seconds\n",
            "Epoch: 95 | Train Loss: 0.67680 | Valid Loss: 0.67707 | Time: 0.45 seconds\n",
            "Epoch: 96 | Train Loss: 0.67625 | Valid Loss: 0.67689 | Time: 0.49 seconds\n",
            "Epoch: 97 | Train Loss: 0.67570 | Valid Loss: 0.67702 | Time: 0.44 seconds\n",
            "Epoch: 98 | Train Loss: 0.67514 | Valid Loss: 0.67654 | Time: 0.46 seconds\n",
            "Epoch: 99 | Train Loss: 0.67457 | Valid Loss: 0.67590 | Time: 0.47 seconds\n",
            "Epoch: 100 | Train Loss: 0.67401 | Valid Loss: 0.67474 | Time: 0.47 seconds\n",
            "Epoch: 101 | Train Loss: 0.67343 | Valid Loss: 0.67442 | Time: 0.48 seconds\n",
            "Epoch: 102 | Train Loss: 0.67288 | Valid Loss: 0.67397 | Time: 0.47 seconds\n",
            "Epoch: 103 | Train Loss: 0.67230 | Valid Loss: 0.67328 | Time: 0.45 seconds\n",
            "Epoch: 104 | Train Loss: 0.67171 | Valid Loss: 0.67280 | Time: 0.47 seconds\n",
            "Epoch: 105 | Train Loss: 0.67113 | Valid Loss: 0.67243 | Time: 0.47 seconds\n",
            "Epoch: 106 | Train Loss: 0.67055 | Valid Loss: 0.67204 | Time: 0.46 seconds\n",
            "Epoch: 107 | Train Loss: 0.66997 | Valid Loss: 0.67156 | Time: 0.48 seconds\n",
            "Epoch: 108 | Train Loss: 0.66936 | Valid Loss: 0.67036 | Time: 0.45 seconds\n",
            "Epoch: 109 | Train Loss: 0.66878 | Valid Loss: 0.66924 | Time: 0.48 seconds\n",
            "Epoch: 110 | Train Loss: 0.66818 | Valid Loss: 0.66919 | Time: 0.46 seconds\n",
            "Epoch: 111 | Train Loss: 0.66756 | Valid Loss: 0.66870 | Time: 0.46 seconds\n",
            "Epoch: 112 | Train Loss: 0.66695 | Valid Loss: 0.66840 | Time: 0.47 seconds\n",
            "Epoch: 113 | Train Loss: 0.66635 | Valid Loss: 0.66737 | Time: 0.47 seconds\n",
            "Epoch: 114 | Train Loss: 0.66572 | Valid Loss: 0.66695 | Time: 0.47 seconds\n",
            "Epoch: 115 | Train Loss: 0.66511 | Valid Loss: 0.66649 | Time: 0.45 seconds\n",
            "Epoch: 116 | Train Loss: 0.66447 | Valid Loss: 0.66604 | Time: 0.47 seconds\n",
            "Epoch: 117 | Train Loss: 0.66383 | Valid Loss: 0.66497 | Time: 0.46 seconds\n",
            "Epoch: 118 | Train Loss: 0.66321 | Valid Loss: 0.66499 | Time: 0.46 seconds\n",
            "Epoch: 119 | Train Loss: 0.66259 | Valid Loss: 0.66325 | Time: 0.46 seconds\n",
            "Epoch: 120 | Train Loss: 0.66194 | Valid Loss: 0.66403 | Time: 0.46 seconds\n",
            "Epoch: 121 | Train Loss: 0.66130 | Valid Loss: 0.66296 | Time: 0.45 seconds\n",
            "Epoch: 122 | Train Loss: 0.66065 | Valid Loss: 0.66088 | Time: 0.48 seconds\n",
            "Epoch: 123 | Train Loss: 0.65999 | Valid Loss: 0.66215 | Time: 0.45 seconds\n",
            "Epoch: 124 | Train Loss: 0.65935 | Valid Loss: 0.66005 | Time: 0.47 seconds\n",
            "Epoch: 125 | Train Loss: 0.65869 | Valid Loss: 0.65970 | Time: 0.46 seconds\n",
            "Epoch: 126 | Train Loss: 0.65804 | Valid Loss: 0.65974 | Time: 0.45 seconds\n",
            "Epoch: 127 | Train Loss: 0.65737 | Valid Loss: 0.65801 | Time: 0.48 seconds\n",
            "Epoch: 128 | Train Loss: 0.65670 | Valid Loss: 0.65823 | Time: 0.45 seconds\n",
            "Epoch: 129 | Train Loss: 0.65605 | Valid Loss: 0.65648 | Time: 0.46 seconds\n",
            "Epoch: 130 | Train Loss: 0.65536 | Valid Loss: 0.65679 | Time: 0.45 seconds\n",
            "Epoch: 131 | Train Loss: 0.65469 | Valid Loss: 0.65530 | Time: 0.48 seconds\n",
            "Epoch: 132 | Train Loss: 0.65401 | Valid Loss: 0.65503 | Time: 0.48 seconds\n",
            "Epoch: 133 | Train Loss: 0.65333 | Valid Loss: 0.65486 | Time: 0.47 seconds\n",
            "Epoch: 134 | Train Loss: 0.65263 | Valid Loss: 0.65445 | Time: 0.46 seconds\n",
            "Epoch: 135 | Train Loss: 0.65195 | Valid Loss: 0.65296 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65126 | Valid Loss: 0.65289 | Time: 0.47 seconds\n",
            "Epoch: 137 | Train Loss: 0.65056 | Valid Loss: 0.65211 | Time: 0.48 seconds\n",
            "Epoch: 138 | Train Loss: 0.64987 | Valid Loss: 0.65158 | Time: 0.46 seconds\n",
            "Epoch: 139 | Train Loss: 0.64917 | Valid Loss: 0.65077 | Time: 0.47 seconds\n",
            "Epoch: 140 | Train Loss: 0.64847 | Valid Loss: 0.64907 | Time: 0.47 seconds\n",
            "Epoch: 141 | Train Loss: 0.64777 | Valid Loss: 0.64936 | Time: 0.47 seconds\n",
            "Epoch: 142 | Train Loss: 0.64705 | Valid Loss: 0.64880 | Time: 0.47 seconds\n",
            "Epoch: 143 | Train Loss: 0.64635 | Valid Loss: 0.64700 | Time: 0.47 seconds\n",
            "Epoch: 144 | Train Loss: 0.64561 | Valid Loss: 0.64781 | Time: 0.47 seconds\n",
            "Epoch: 145 | Train Loss: 0.64490 | Valid Loss: 0.64551 | Time: 0.45 seconds\n",
            "Epoch: 146 | Train Loss: 0.64418 | Valid Loss: 0.64507 | Time: 0.48 seconds\n",
            "Epoch: 147 | Train Loss: 0.64346 | Valid Loss: 0.64403 | Time: 0.48 seconds\n",
            "Epoch: 148 | Train Loss: 0.64274 | Valid Loss: 0.64385 | Time: 0.47 seconds\n",
            "Epoch: 149 | Train Loss: 0.64201 | Valid Loss: 0.64268 | Time: 0.47 seconds\n",
            "Epoch: 150 | Train Loss: 0.64127 | Valid Loss: 0.64328 | Time: 0.48 seconds\n",
            "Epoch: 151 | Train Loss: 0.64054 | Valid Loss: 0.64192 | Time: 0.47 seconds\n",
            "Epoch: 152 | Train Loss: 0.63981 | Valid Loss: 0.64110 | Time: 0.45 seconds\n",
            "Epoch: 153 | Train Loss: 0.63906 | Valid Loss: 0.64018 | Time: 0.49 seconds\n",
            "Epoch: 154 | Train Loss: 0.63833 | Valid Loss: 0.63967 | Time: 0.46 seconds\n",
            "Epoch: 155 | Train Loss: 0.63759 | Valid Loss: 0.63819 | Time: 0.47 seconds\n",
            "Epoch: 156 | Train Loss: 0.63684 | Valid Loss: 0.63815 | Time: 0.47 seconds\n",
            "Epoch: 157 | Train Loss: 0.63609 | Valid Loss: 0.63703 | Time: 0.47 seconds\n",
            "Epoch: 158 | Train Loss: 0.63535 | Valid Loss: 0.63593 | Time: 0.46 seconds\n",
            "Epoch: 159 | Train Loss: 0.63459 | Valid Loss: 0.63743 | Time: 0.45 seconds\n",
            "Epoch: 160 | Train Loss: 0.63383 | Valid Loss: 0.63463 | Time: 0.46 seconds\n",
            "Epoch: 161 | Train Loss: 0.63308 | Valid Loss: 0.63331 | Time: 0.48 seconds\n",
            "Epoch: 162 | Train Loss: 0.63233 | Valid Loss: 0.63274 | Time: 0.45 seconds\n",
            "Epoch: 163 | Train Loss: 0.63156 | Valid Loss: 0.63334 | Time: 0.45 seconds\n",
            "Epoch: 164 | Train Loss: 0.63081 | Valid Loss: 0.63287 | Time: 0.47 seconds\n",
            "Epoch: 165 | Train Loss: 0.63004 | Valid Loss: 0.63171 | Time: 0.46 seconds\n",
            "Epoch: 166 | Train Loss: 0.62926 | Valid Loss: 0.63042 | Time: 0.47 seconds\n",
            "Epoch: 167 | Train Loss: 0.62849 | Valid Loss: 0.63065 | Time: 0.46 seconds\n",
            "Epoch: 168 | Train Loss: 0.62773 | Valid Loss: 0.62784 | Time: 0.47 seconds\n",
            "Epoch: 169 | Train Loss: 0.62696 | Valid Loss: 0.62868 | Time: 0.47 seconds\n",
            "Epoch: 170 | Train Loss: 0.62618 | Valid Loss: 0.62797 | Time: 0.46 seconds\n",
            "Epoch: 171 | Train Loss: 0.62540 | Valid Loss: 0.62739 | Time: 0.46 seconds\n",
            "Epoch: 172 | Train Loss: 0.62463 | Valid Loss: 0.62594 | Time: 0.48 seconds\n",
            "Epoch: 173 | Train Loss: 0.62385 | Valid Loss: 0.62490 | Time: 0.47 seconds\n",
            "Epoch: 174 | Train Loss: 0.62307 | Valid Loss: 0.62541 | Time: 0.45 seconds\n",
            "Epoch: 175 | Train Loss: 0.62229 | Valid Loss: 0.62233 | Time: 0.46 seconds\n",
            "Epoch: 176 | Train Loss: 0.62149 | Valid Loss: 0.62129 | Time: 0.46 seconds\n",
            "Epoch: 177 | Train Loss: 0.62071 | Valid Loss: 0.62150 | Time: 0.47 seconds\n",
            "Epoch: 178 | Train Loss: 0.61993 | Valid Loss: 0.62249 | Time: 0.46 seconds\n",
            "Epoch: 179 | Train Loss: 0.61912 | Valid Loss: 0.62212 | Time: 0.45 seconds\n",
            "Epoch: 180 | Train Loss: 0.61834 | Valid Loss: 0.61841 | Time: 0.45 seconds\n",
            "Epoch: 181 | Train Loss: 0.61755 | Valid Loss: 0.61902 | Time: 0.46 seconds\n",
            "Epoch: 182 | Train Loss: 0.61674 | Valid Loss: 0.61884 | Time: 0.46 seconds\n",
            "Epoch: 183 | Train Loss: 0.61595 | Valid Loss: 0.61778 | Time: 0.47 seconds\n",
            "Epoch: 184 | Train Loss: 0.61515 | Valid Loss: 0.61540 | Time: 0.46 seconds\n",
            "Epoch: 185 | Train Loss: 0.61436 | Valid Loss: 0.61707 | Time: 0.45 seconds\n",
            "Epoch: 186 | Train Loss: 0.61355 | Valid Loss: 0.61401 | Time: 0.47 seconds\n",
            "Epoch: 187 | Train Loss: 0.61274 | Valid Loss: 0.61350 | Time: 0.47 seconds\n",
            "Epoch: 188 | Train Loss: 0.61195 | Valid Loss: 0.61374 | Time: 0.47 seconds\n",
            "Epoch: 189 | Train Loss: 0.61114 | Valid Loss: 0.61354 | Time: 0.45 seconds\n",
            "Epoch: 190 | Train Loss: 0.61035 | Valid Loss: 0.61218 | Time: 0.48 seconds\n",
            "Epoch: 191 | Train Loss: 0.60953 | Valid Loss: 0.61176 | Time: 0.46 seconds\n",
            "Epoch: 192 | Train Loss: 0.60871 | Valid Loss: 0.61018 | Time: 0.46 seconds\n",
            "Epoch: 193 | Train Loss: 0.60790 | Valid Loss: 0.60875 | Time: 0.46 seconds\n",
            "Epoch: 194 | Train Loss: 0.60709 | Valid Loss: 0.60896 | Time: 0.47 seconds\n",
            "Epoch: 195 | Train Loss: 0.60628 | Valid Loss: 0.60868 | Time: 0.47 seconds\n",
            "Epoch: 196 | Train Loss: 0.60547 | Valid Loss: 0.60884 | Time: 0.45 seconds\n",
            "Epoch: 197 | Train Loss: 0.60465 | Valid Loss: 0.60611 | Time: 0.47 seconds\n",
            "Epoch: 198 | Train Loss: 0.60383 | Valid Loss: 0.60651 | Time: 0.45 seconds\n",
            "Epoch: 199 | Train Loss: 0.60301 | Valid Loss: 0.60556 | Time: 0.49 seconds\n",
            "Epoch: 200 | Train Loss: 0.60220 | Valid Loss: 0.60373 | Time: 0.45 seconds\n",
            "Epoch: 201 | Train Loss: 0.60138 | Valid Loss: 0.60317 | Time: 0.47 seconds\n",
            "Epoch: 202 | Train Loss: 0.60057 | Valid Loss: 0.60178 | Time: 0.46 seconds\n",
            "Epoch: 203 | Train Loss: 0.59973 | Valid Loss: 0.60129 | Time: 0.47 seconds\n",
            "Epoch: 204 | Train Loss: 0.59891 | Valid Loss: 0.59932 | Time: 0.49 seconds\n",
            "Epoch: 205 | Train Loss: 0.59809 | Valid Loss: 0.59990 | Time: 0.46 seconds\n",
            "Epoch: 206 | Train Loss: 0.59726 | Valid Loss: 0.59948 | Time: 0.45 seconds\n",
            "Epoch: 207 | Train Loss: 0.59644 | Valid Loss: 0.59719 | Time: 0.47 seconds\n",
            "Epoch: 208 | Train Loss: 0.59558 | Valid Loss: 0.59777 | Time: 0.46 seconds\n",
            "Epoch: 209 | Train Loss: 0.59478 | Valid Loss: 0.59596 | Time: 0.47 seconds\n",
            "Epoch: 210 | Train Loss: 0.59395 | Valid Loss: 0.59586 | Time: 0.47 seconds\n",
            "Epoch: 211 | Train Loss: 0.59312 | Valid Loss: 0.59484 | Time: 0.48 seconds\n",
            "Epoch: 212 | Train Loss: 0.59229 | Valid Loss: 0.59323 | Time: 0.50 seconds\n",
            "Epoch: 213 | Train Loss: 0.59144 | Valid Loss: 0.59308 | Time: 0.46 seconds\n",
            "Epoch: 214 | Train Loss: 0.59062 | Valid Loss: 0.59276 | Time: 0.47 seconds\n",
            "Epoch: 215 | Train Loss: 0.58978 | Valid Loss: 0.59151 | Time: 0.47 seconds\n",
            "Epoch: 216 | Train Loss: 0.58894 | Valid Loss: 0.59167 | Time: 0.46 seconds\n",
            "Epoch: 217 | Train Loss: 0.58811 | Valid Loss: 0.59052 | Time: 0.47 seconds\n",
            "Epoch: 218 | Train Loss: 0.58726 | Valid Loss: 0.58725 | Time: 0.47 seconds\n",
            "Epoch: 219 | Train Loss: 0.58643 | Valid Loss: 0.58869 | Time: 0.45 seconds\n",
            "Epoch: 220 | Train Loss: 0.58560 | Valid Loss: 0.58745 | Time: 0.47 seconds\n",
            "Epoch: 221 | Train Loss: 0.58475 | Valid Loss: 0.58560 | Time: 0.48 seconds\n",
            "Epoch: 222 | Train Loss: 0.58391 | Valid Loss: 0.58539 | Time: 0.45 seconds\n",
            "Epoch: 223 | Train Loss: 0.58305 | Valid Loss: 0.58603 | Time: 0.47 seconds\n",
            "Epoch: 224 | Train Loss: 0.58222 | Valid Loss: 0.58366 | Time: 0.48 seconds\n",
            "Epoch: 225 | Train Loss: 0.58137 | Valid Loss: 0.58315 | Time: 0.47 seconds\n",
            "Epoch: 226 | Train Loss: 0.58053 | Valid Loss: 0.58388 | Time: 0.45 seconds\n",
            "Epoch: 227 | Train Loss: 0.57967 | Valid Loss: 0.58065 | Time: 0.47 seconds\n",
            "Epoch: 228 | Train Loss: 0.57885 | Valid Loss: 0.58081 | Time: 0.46 seconds\n",
            "Epoch: 229 | Train Loss: 0.57799 | Valid Loss: 0.58041 | Time: 0.48 seconds\n",
            "Epoch: 230 | Train Loss: 0.57714 | Valid Loss: 0.57969 | Time: 0.46 seconds\n",
            "Epoch: 231 | Train Loss: 0.57629 | Valid Loss: 0.57814 | Time: 0.47 seconds\n",
            "Epoch: 232 | Train Loss: 0.57545 | Valid Loss: 0.57646 | Time: 0.46 seconds\n",
            "Epoch: 233 | Train Loss: 0.57459 | Valid Loss: 0.57683 | Time: 0.48 seconds\n",
            "Epoch: 234 | Train Loss: 0.57374 | Valid Loss: 0.57585 | Time: 0.47 seconds\n",
            "Epoch: 235 | Train Loss: 0.57289 | Valid Loss: 0.57463 | Time: 0.46 seconds\n",
            "Epoch: 236 | Train Loss: 0.57204 | Valid Loss: 0.57400 | Time: 0.47 seconds\n",
            "Epoch: 237 | Train Loss: 0.57117 | Valid Loss: 0.57168 | Time: 0.48 seconds\n",
            "Epoch: 238 | Train Loss: 0.57033 | Valid Loss: 0.57172 | Time: 0.47 seconds\n",
            "Epoch: 239 | Train Loss: 0.56948 | Valid Loss: 0.57036 | Time: 0.46 seconds\n",
            "Epoch: 240 | Train Loss: 0.56862 | Valid Loss: 0.57053 | Time: 0.45 seconds\n",
            "Epoch: 241 | Train Loss: 0.56776 | Valid Loss: 0.57077 | Time: 0.45 seconds\n",
            "Epoch: 242 | Train Loss: 0.56690 | Valid Loss: 0.56715 | Time: 0.47 seconds\n",
            "Epoch: 243 | Train Loss: 0.56605 | Valid Loss: 0.56825 | Time: 0.45 seconds\n",
            "Epoch: 244 | Train Loss: 0.56519 | Valid Loss: 0.56662 | Time: 0.47 seconds\n",
            "Epoch: 245 | Train Loss: 0.56433 | Valid Loss: 0.56642 | Time: 0.47 seconds\n",
            "Epoch: 246 | Train Loss: 0.56347 | Valid Loss: 0.56621 | Time: 0.45 seconds\n",
            "Epoch: 247 | Train Loss: 0.56260 | Valid Loss: 0.56497 | Time: 0.47 seconds\n",
            "Epoch: 248 | Train Loss: 0.56176 | Valid Loss: 0.56234 | Time: 0.45 seconds\n",
            "Epoch: 249 | Train Loss: 0.56088 | Valid Loss: 0.56162 | Time: 0.47 seconds\n",
            "Epoch: 250 | Train Loss: 0.56001 | Valid Loss: 0.56316 | Time: 0.46 seconds\n",
            "Epoch: 251 | Train Loss: 0.55916 | Valid Loss: 0.56112 | Time: 0.46 seconds\n",
            "Epoch: 252 | Train Loss: 0.55831 | Valid Loss: 0.56029 | Time: 0.45 seconds\n",
            "Epoch: 253 | Train Loss: 0.55744 | Valid Loss: 0.55805 | Time: 0.47 seconds\n",
            "Epoch: 254 | Train Loss: 0.55658 | Valid Loss: 0.55887 | Time: 0.45 seconds\n",
            "Epoch: 255 | Train Loss: 0.55571 | Valid Loss: 0.55809 | Time: 0.45 seconds\n",
            "Epoch: 256 | Train Loss: 0.55484 | Valid Loss: 0.55886 | Time: 0.45 seconds\n",
            "Epoch: 257 | Train Loss: 0.55398 | Valid Loss: 0.55661 | Time: 0.46 seconds\n",
            "Epoch: 258 | Train Loss: 0.55310 | Valid Loss: 0.55447 | Time: 0.45 seconds\n",
            "Epoch: 259 | Train Loss: 0.55225 | Valid Loss: 0.55409 | Time: 0.45 seconds\n",
            "Epoch: 260 | Train Loss: 0.55137 | Valid Loss: 0.55388 | Time: 0.47 seconds\n",
            "Epoch: 261 | Train Loss: 0.55051 | Valid Loss: 0.55049 | Time: 0.47 seconds\n",
            "Epoch: 262 | Train Loss: 0.54963 | Valid Loss: 0.55096 | Time: 0.46 seconds\n",
            "Epoch: 263 | Train Loss: 0.54879 | Valid Loss: 0.55157 | Time: 0.45 seconds\n",
            "Epoch: 264 | Train Loss: 0.54790 | Valid Loss: 0.54964 | Time: 0.47 seconds\n",
            "Epoch: 265 | Train Loss: 0.54704 | Valid Loss: 0.54992 | Time: 0.47 seconds\n",
            "Epoch: 266 | Train Loss: 0.54618 | Valid Loss: 0.54549 | Time: 0.47 seconds\n",
            "Epoch: 267 | Train Loss: 0.54530 | Valid Loss: 0.54657 | Time: 0.47 seconds\n",
            "Epoch: 268 | Train Loss: 0.54443 | Valid Loss: 0.54556 | Time: 0.45 seconds\n",
            "Epoch: 269 | Train Loss: 0.54356 | Valid Loss: 0.54619 | Time: 0.45 seconds\n",
            "Epoch: 270 | Train Loss: 0.54270 | Valid Loss: 0.54518 | Time: 0.45 seconds\n",
            "Epoch: 271 | Train Loss: 0.54182 | Valid Loss: 0.54428 | Time: 0.46 seconds\n",
            "Epoch: 272 | Train Loss: 0.54097 | Valid Loss: 0.54331 | Time: 0.46 seconds\n",
            "Epoch: 273 | Train Loss: 0.54008 | Valid Loss: 0.54419 | Time: 0.45 seconds\n",
            "Epoch: 274 | Train Loss: 0.53921 | Valid Loss: 0.54140 | Time: 0.46 seconds\n",
            "Epoch: 275 | Train Loss: 0.53834 | Valid Loss: 0.53894 | Time: 0.48 seconds\n",
            "Epoch: 276 | Train Loss: 0.53747 | Valid Loss: 0.54013 | Time: 0.47 seconds\n",
            "Epoch: 277 | Train Loss: 0.53661 | Valid Loss: 0.53933 | Time: 0.45 seconds\n",
            "Epoch: 278 | Train Loss: 0.53572 | Valid Loss: 0.53927 | Time: 0.45 seconds\n",
            "Epoch: 279 | Train Loss: 0.53484 | Valid Loss: 0.53739 | Time: 0.46 seconds\n",
            "Epoch: 280 | Train Loss: 0.53399 | Valid Loss: 0.53471 | Time: 0.48 seconds\n",
            "Epoch: 281 | Train Loss: 0.53310 | Valid Loss: 0.53395 | Time: 0.46 seconds\n",
            "Epoch: 282 | Train Loss: 0.53222 | Valid Loss: 0.53446 | Time: 0.45 seconds\n",
            "Epoch: 283 | Train Loss: 0.53137 | Valid Loss: 0.53486 | Time: 0.44 seconds\n",
            "Epoch: 284 | Train Loss: 0.53048 | Valid Loss: 0.53524 | Time: 0.47 seconds\n",
            "Epoch: 285 | Train Loss: 0.52961 | Valid Loss: 0.53227 | Time: 0.47 seconds\n",
            "Epoch: 286 | Train Loss: 0.52875 | Valid Loss: 0.53031 | Time: 0.46 seconds\n",
            "Epoch: 287 | Train Loss: 0.52787 | Valid Loss: 0.52892 | Time: 0.46 seconds\n",
            "Epoch: 288 | Train Loss: 0.52700 | Valid Loss: 0.53146 | Time: 0.45 seconds\n",
            "Epoch: 289 | Train Loss: 0.52613 | Valid Loss: 0.52703 | Time: 0.48 seconds\n",
            "Epoch: 290 | Train Loss: 0.52525 | Valid Loss: 0.52979 | Time: 0.46 seconds\n",
            "Epoch: 291 | Train Loss: 0.52437 | Valid Loss: 0.52756 | Time: 0.45 seconds\n",
            "Epoch: 292 | Train Loss: 0.52350 | Valid Loss: 0.52645 | Time: 0.48 seconds\n",
            "Epoch: 293 | Train Loss: 0.52263 | Valid Loss: 0.52415 | Time: 0.46 seconds\n",
            "Epoch: 294 | Train Loss: 0.52174 | Valid Loss: 0.52332 | Time: 0.46 seconds\n",
            "Epoch: 295 | Train Loss: 0.52088 | Valid Loss: 0.52173 | Time: 0.47 seconds\n",
            "Epoch: 296 | Train Loss: 0.52001 | Valid Loss: 0.52289 | Time: 0.45 seconds\n",
            "Epoch: 297 | Train Loss: 0.51914 | Valid Loss: 0.52112 | Time: 0.48 seconds\n",
            "Epoch: 298 | Train Loss: 0.51825 | Valid Loss: 0.51997 | Time: 0.47 seconds\n",
            "Epoch: 299 | Train Loss: 0.51740 | Valid Loss: 0.51910 | Time: 0.46 seconds\n",
            "Epoch: 300 | Train Loss: 0.51652 | Valid Loss: 0.51788 | Time: 0.48 seconds\n",
            "Epoch: 301 | Train Loss: 0.51564 | Valid Loss: 0.51690 | Time: 0.47 seconds\n",
            "Epoch: 302 | Train Loss: 0.51479 | Valid Loss: 0.51625 | Time: 0.47 seconds\n",
            "Epoch: 303 | Train Loss: 0.51390 | Valid Loss: 0.51610 | Time: 0.45 seconds\n",
            "Epoch: 304 | Train Loss: 0.51301 | Valid Loss: 0.51479 | Time: 0.46 seconds\n",
            "Epoch: 305 | Train Loss: 0.51215 | Valid Loss: 0.51420 | Time: 0.47 seconds\n",
            "Epoch: 306 | Train Loss: 0.51127 | Valid Loss: 0.51466 | Time: 0.46 seconds\n",
            "Epoch: 307 | Train Loss: 0.51041 | Valid Loss: 0.51520 | Time: 0.45 seconds\n",
            "Epoch: 308 | Train Loss: 0.50953 | Valid Loss: 0.51130 | Time: 0.48 seconds\n",
            "Epoch: 309 | Train Loss: 0.50866 | Valid Loss: 0.50925 | Time: 0.46 seconds\n",
            "Epoch: 310 | Train Loss: 0.50778 | Valid Loss: 0.51117 | Time: 0.48 seconds\n",
            "Epoch: 311 | Train Loss: 0.50692 | Valid Loss: 0.50881 | Time: 0.47 seconds\n",
            "Epoch: 312 | Train Loss: 0.50604 | Valid Loss: 0.50940 | Time: 0.45 seconds\n",
            "Epoch: 313 | Train Loss: 0.50519 | Valid Loss: 0.50620 | Time: 0.47 seconds\n",
            "Epoch: 314 | Train Loss: 0.50430 | Valid Loss: 0.50663 | Time: 0.47 seconds\n",
            "Epoch: 315 | Train Loss: 0.50343 | Valid Loss: 0.50311 | Time: 0.48 seconds\n",
            "Epoch: 316 | Train Loss: 0.50257 | Valid Loss: 0.50562 | Time: 0.46 seconds\n",
            "Epoch: 317 | Train Loss: 0.50171 | Valid Loss: 0.50267 | Time: 0.47 seconds\n",
            "Epoch: 318 | Train Loss: 0.50083 | Valid Loss: 0.50322 | Time: 0.45 seconds\n",
            "Epoch: 319 | Train Loss: 0.49998 | Valid Loss: 0.50185 | Time: 0.46 seconds\n",
            "Epoch: 320 | Train Loss: 0.49909 | Valid Loss: 0.50346 | Time: 0.47 seconds\n",
            "Epoch: 321 | Train Loss: 0.49822 | Valid Loss: 0.50141 | Time: 0.49 seconds\n",
            "Epoch: 322 | Train Loss: 0.49737 | Valid Loss: 0.49859 | Time: 0.47 seconds\n",
            "Epoch: 323 | Train Loss: 0.49649 | Valid Loss: 0.50010 | Time: 0.46 seconds\n",
            "Epoch: 324 | Train Loss: 0.49562 | Valid Loss: 0.49793 | Time: 0.46 seconds\n",
            "Epoch: 325 | Train Loss: 0.49476 | Valid Loss: 0.49888 | Time: 0.45 seconds\n",
            "Epoch: 326 | Train Loss: 0.49389 | Valid Loss: 0.49642 | Time: 0.48 seconds\n",
            "Epoch: 327 | Train Loss: 0.49302 | Valid Loss: 0.49518 | Time: 0.47 seconds\n",
            "Epoch: 328 | Train Loss: 0.49218 | Valid Loss: 0.49372 | Time: 0.46 seconds\n",
            "Epoch: 329 | Train Loss: 0.49130 | Valid Loss: 0.49382 | Time: 0.46 seconds\n",
            "Epoch: 330 | Train Loss: 0.49042 | Valid Loss: 0.49097 | Time: 0.47 seconds\n",
            "Epoch: 331 | Train Loss: 0.48958 | Valid Loss: 0.48988 | Time: 0.45 seconds\n",
            "Epoch: 332 | Train Loss: 0.48870 | Valid Loss: 0.49116 | Time: 0.46 seconds\n",
            "Epoch: 333 | Train Loss: 0.48786 | Valid Loss: 0.48920 | Time: 0.47 seconds\n",
            "Epoch: 334 | Train Loss: 0.48700 | Valid Loss: 0.48987 | Time: 0.47 seconds\n",
            "Epoch: 335 | Train Loss: 0.48614 | Valid Loss: 0.48724 | Time: 0.46 seconds\n",
            "Epoch: 336 | Train Loss: 0.48528 | Valid Loss: 0.48807 | Time: 0.45 seconds\n",
            "Epoch: 337 | Train Loss: 0.48441 | Valid Loss: 0.48590 | Time: 0.49 seconds\n",
            "Epoch: 338 | Train Loss: 0.48354 | Valid Loss: 0.48868 | Time: 0.46 seconds\n",
            "Epoch: 339 | Train Loss: 0.48269 | Valid Loss: 0.48564 | Time: 0.47 seconds\n",
            "Epoch: 340 | Train Loss: 0.48182 | Valid Loss: 0.48559 | Time: 0.45 seconds\n",
            "Epoch: 341 | Train Loss: 0.48097 | Valid Loss: 0.48278 | Time: 0.49 seconds\n",
            "Epoch: 342 | Train Loss: 0.48011 | Valid Loss: 0.48099 | Time: 0.45 seconds\n",
            "Epoch: 343 | Train Loss: 0.47927 | Valid Loss: 0.48209 | Time: 0.45 seconds\n",
            "Epoch: 344 | Train Loss: 0.47837 | Valid Loss: 0.48190 | Time: 0.45 seconds\n",
            "Epoch: 345 | Train Loss: 0.47754 | Valid Loss: 0.47923 | Time: 0.50 seconds\n",
            "Epoch: 346 | Train Loss: 0.47671 | Valid Loss: 0.47783 | Time: 0.47 seconds\n",
            "Epoch: 347 | Train Loss: 0.47585 | Valid Loss: 0.47998 | Time: 0.45 seconds\n",
            "Epoch: 348 | Train Loss: 0.47500 | Valid Loss: 0.47876 | Time: 0.47 seconds\n",
            "Epoch: 349 | Train Loss: 0.47416 | Valid Loss: 0.47527 | Time: 0.46 seconds\n",
            "Epoch: 350 | Train Loss: 0.47327 | Valid Loss: 0.47608 | Time: 0.47 seconds\n",
            "Epoch: 351 | Train Loss: 0.47242 | Valid Loss: 0.47535 | Time: 0.46 seconds\n",
            "Epoch: 352 | Train Loss: 0.47160 | Valid Loss: 0.47269 | Time: 0.48 seconds\n",
            "Epoch: 353 | Train Loss: 0.47073 | Valid Loss: 0.47378 | Time: 0.45 seconds\n",
            "Epoch: 354 | Train Loss: 0.46992 | Valid Loss: 0.47327 | Time: 0.45 seconds\n",
            "Epoch: 355 | Train Loss: 0.46904 | Valid Loss: 0.47198 | Time: 0.46 seconds\n",
            "Epoch: 356 | Train Loss: 0.46822 | Valid Loss: 0.47132 | Time: 0.49 seconds\n",
            "Epoch: 357 | Train Loss: 0.46736 | Valid Loss: 0.46988 | Time: 0.45 seconds\n",
            "Epoch: 358 | Train Loss: 0.46653 | Valid Loss: 0.46899 | Time: 0.46 seconds\n",
            "Epoch: 359 | Train Loss: 0.46566 | Valid Loss: 0.46855 | Time: 0.47 seconds\n",
            "Epoch: 360 | Train Loss: 0.46485 | Valid Loss: 0.46707 | Time: 0.46 seconds\n",
            "Epoch: 361 | Train Loss: 0.46400 | Valid Loss: 0.46594 | Time: 0.47 seconds\n",
            "Epoch: 362 | Train Loss: 0.46319 | Valid Loss: 0.46608 | Time: 0.44 seconds\n",
            "Epoch: 363 | Train Loss: 0.46231 | Valid Loss: 0.46609 | Time: 0.47 seconds\n",
            "Epoch: 364 | Train Loss: 0.46149 | Valid Loss: 0.46416 | Time: 0.45 seconds\n",
            "Epoch: 365 | Train Loss: 0.46067 | Valid Loss: 0.46410 | Time: 0.47 seconds\n",
            "Epoch: 366 | Train Loss: 0.45985 | Valid Loss: 0.46232 | Time: 0.47 seconds\n",
            "Epoch: 367 | Train Loss: 0.45897 | Valid Loss: 0.46304 | Time: 0.48 seconds\n",
            "Epoch: 368 | Train Loss: 0.45814 | Valid Loss: 0.46221 | Time: 0.47 seconds\n",
            "Epoch: 369 | Train Loss: 0.45731 | Valid Loss: 0.45915 | Time: 0.46 seconds\n",
            "Epoch: 370 | Train Loss: 0.45650 | Valid Loss: 0.45875 | Time: 0.46 seconds\n",
            "Epoch: 371 | Train Loss: 0.45564 | Valid Loss: 0.45766 | Time: 0.46 seconds\n",
            "Epoch: 372 | Train Loss: 0.45483 | Valid Loss: 0.45657 | Time: 0.48 seconds\n",
            "Epoch: 373 | Train Loss: 0.45401 | Valid Loss: 0.45523 | Time: 0.46 seconds\n",
            "Epoch: 374 | Train Loss: 0.45316 | Valid Loss: 0.45553 | Time: 0.47 seconds\n",
            "Epoch: 375 | Train Loss: 0.45232 | Valid Loss: 0.45384 | Time: 0.46 seconds\n",
            "Epoch: 376 | Train Loss: 0.45152 | Valid Loss: 0.45576 | Time: 0.48 seconds\n",
            "Epoch: 377 | Train Loss: 0.45072 | Valid Loss: 0.45415 | Time: 0.46 seconds\n",
            "Epoch: 378 | Train Loss: 0.44986 | Valid Loss: 0.45284 | Time: 0.46 seconds\n",
            "Epoch: 379 | Train Loss: 0.44906 | Valid Loss: 0.45262 | Time: 0.46 seconds\n",
            "Epoch: 380 | Train Loss: 0.44823 | Valid Loss: 0.44948 | Time: 0.47 seconds\n",
            "Epoch: 381 | Train Loss: 0.44740 | Valid Loss: 0.45093 | Time: 0.45 seconds\n",
            "Epoch: 382 | Train Loss: 0.44661 | Valid Loss: 0.45037 | Time: 0.46 seconds\n",
            "Epoch: 383 | Train Loss: 0.44576 | Valid Loss: 0.44710 | Time: 0.46 seconds\n",
            "Epoch: 384 | Train Loss: 0.44499 | Valid Loss: 0.44885 | Time: 0.46 seconds\n",
            "Epoch: 385 | Train Loss: 0.44413 | Valid Loss: 0.44650 | Time: 0.47 seconds\n",
            "Epoch: 386 | Train Loss: 0.44334 | Valid Loss: 0.44407 | Time: 0.46 seconds\n",
            "Epoch: 387 | Train Loss: 0.44254 | Valid Loss: 0.44649 | Time: 0.46 seconds\n",
            "Epoch: 388 | Train Loss: 0.44172 | Valid Loss: 0.44463 | Time: 0.44 seconds\n",
            "Epoch: 389 | Train Loss: 0.44091 | Valid Loss: 0.44506 | Time: 0.47 seconds\n",
            "Epoch: 390 | Train Loss: 0.44008 | Valid Loss: 0.44128 | Time: 0.47 seconds\n",
            "Epoch: 391 | Train Loss: 0.43930 | Valid Loss: 0.44255 | Time: 0.46 seconds\n",
            "Epoch: 392 | Train Loss: 0.43850 | Valid Loss: 0.44292 | Time: 0.44 seconds\n",
            "Epoch: 393 | Train Loss: 0.43765 | Valid Loss: 0.43981 | Time: 0.46 seconds\n",
            "Epoch: 394 | Train Loss: 0.43688 | Valid Loss: 0.44019 | Time: 0.46 seconds\n",
            "Epoch: 395 | Train Loss: 0.43607 | Valid Loss: 0.44011 | Time: 0.45 seconds\n",
            "Epoch: 396 | Train Loss: 0.43528 | Valid Loss: 0.43923 | Time: 0.47 seconds\n",
            "Epoch: 397 | Train Loss: 0.43449 | Valid Loss: 0.43926 | Time: 0.45 seconds\n",
            "Epoch: 398 | Train Loss: 0.43369 | Valid Loss: 0.43614 | Time: 0.46 seconds\n",
            "Epoch: 399 | Train Loss: 0.43290 | Valid Loss: 0.43507 | Time: 0.45 seconds\n",
            "Epoch: 400 | Train Loss: 0.43209 | Valid Loss: 0.43657 | Time: 0.47 seconds\n",
            "Epoch: 401 | Train Loss: 0.43131 | Valid Loss: 0.43518 | Time: 0.44 seconds\n",
            "Epoch: 402 | Train Loss: 0.43051 | Valid Loss: 0.43430 | Time: 0.45 seconds\n",
            "Epoch: 403 | Train Loss: 0.42971 | Valid Loss: 0.43104 | Time: 0.47 seconds\n",
            "Epoch: 404 | Train Loss: 0.42892 | Valid Loss: 0.43243 | Time: 0.45 seconds\n",
            "Epoch: 405 | Train Loss: 0.42815 | Valid Loss: 0.43092 | Time: 0.46 seconds\n",
            "Epoch: 406 | Train Loss: 0.42736 | Valid Loss: 0.43045 | Time: 0.49 seconds\n",
            "Epoch: 407 | Train Loss: 0.42657 | Valid Loss: 0.42826 | Time: 0.47 seconds\n",
            "Epoch: 408 | Train Loss: 0.42577 | Valid Loss: 0.42984 | Time: 0.46 seconds\n",
            "Epoch: 409 | Train Loss: 0.42500 | Valid Loss: 0.42741 | Time: 0.48 seconds\n",
            "Epoch: 410 | Train Loss: 0.42423 | Valid Loss: 0.42676 | Time: 0.48 seconds\n",
            "Epoch: 411 | Train Loss: 0.42347 | Valid Loss: 0.42736 | Time: 0.46 seconds\n",
            "Epoch: 412 | Train Loss: 0.42266 | Valid Loss: 0.42464 | Time: 0.45 seconds\n",
            "Epoch: 413 | Train Loss: 0.42192 | Valid Loss: 0.42495 | Time: 0.45 seconds\n",
            "Epoch: 414 | Train Loss: 0.42111 | Valid Loss: 0.42269 | Time: 0.47 seconds\n",
            "Epoch: 415 | Train Loss: 0.42034 | Valid Loss: 0.42328 | Time: 0.47 seconds\n",
            "Epoch: 416 | Train Loss: 0.41958 | Valid Loss: 0.42118 | Time: 0.47 seconds\n",
            "Epoch: 417 | Train Loss: 0.41883 | Valid Loss: 0.42273 | Time: 0.45 seconds\n",
            "Epoch: 418 | Train Loss: 0.41803 | Valid Loss: 0.41969 | Time: 0.47 seconds\n",
            "Epoch: 419 | Train Loss: 0.41727 | Valid Loss: 0.41787 | Time: 0.47 seconds\n",
            "Epoch: 420 | Train Loss: 0.41654 | Valid Loss: 0.41866 | Time: 0.47 seconds\n",
            "Epoch: 421 | Train Loss: 0.41572 | Valid Loss: 0.41877 | Time: 0.46 seconds\n",
            "Epoch: 422 | Train Loss: 0.41498 | Valid Loss: 0.41623 | Time: 0.46 seconds\n",
            "Epoch: 423 | Train Loss: 0.41419 | Valid Loss: 0.41485 | Time: 0.45 seconds\n",
            "Epoch: 424 | Train Loss: 0.41348 | Valid Loss: 0.41560 | Time: 0.44 seconds\n",
            "Epoch: 425 | Train Loss: 0.41272 | Valid Loss: 0.41620 | Time: 0.45 seconds\n",
            "Epoch: 426 | Train Loss: 0.41192 | Valid Loss: 0.41436 | Time: 0.45 seconds\n",
            "Epoch: 427 | Train Loss: 0.41118 | Valid Loss: 0.41236 | Time: 0.46 seconds\n",
            "Epoch: 428 | Train Loss: 0.41040 | Valid Loss: 0.41198 | Time: 0.46 seconds\n",
            "Epoch: 429 | Train Loss: 0.40969 | Valid Loss: 0.41134 | Time: 0.46 seconds\n",
            "Epoch: 430 | Train Loss: 0.40893 | Valid Loss: 0.40933 | Time: 0.46 seconds\n",
            "Epoch: 431 | Train Loss: 0.40814 | Valid Loss: 0.41256 | Time: 0.48 seconds\n",
            "Epoch: 432 | Train Loss: 0.40743 | Valid Loss: 0.41037 | Time: 0.45 seconds\n",
            "Epoch: 433 | Train Loss: 0.40666 | Valid Loss: 0.40876 | Time: 0.46 seconds\n",
            "Epoch: 434 | Train Loss: 0.40597 | Valid Loss: 0.40838 | Time: 0.45 seconds\n",
            "Epoch: 435 | Train Loss: 0.40519 | Valid Loss: 0.40882 | Time: 0.46 seconds\n",
            "Epoch: 436 | Train Loss: 0.40443 | Valid Loss: 0.40625 | Time: 0.46 seconds\n",
            "Epoch: 437 | Train Loss: 0.40373 | Valid Loss: 0.40728 | Time: 0.46 seconds\n",
            "Epoch: 438 | Train Loss: 0.40295 | Valid Loss: 0.40607 | Time: 0.46 seconds\n",
            "Epoch: 439 | Train Loss: 0.40222 | Valid Loss: 0.40411 | Time: 0.45 seconds\n",
            "Epoch: 440 | Train Loss: 0.40148 | Valid Loss: 0.40411 | Time: 0.45 seconds\n",
            "Epoch: 441 | Train Loss: 0.40076 | Valid Loss: 0.40594 | Time: 0.46 seconds\n",
            "Epoch: 442 | Train Loss: 0.40004 | Valid Loss: 0.40248 | Time: 0.48 seconds\n",
            "Epoch: 443 | Train Loss: 0.39933 | Valid Loss: 0.40173 | Time: 0.46 seconds\n",
            "Epoch: 444 | Train Loss: 0.39857 | Valid Loss: 0.40202 | Time: 0.44 seconds\n",
            "Epoch: 445 | Train Loss: 0.39783 | Valid Loss: 0.40104 | Time: 0.46 seconds\n",
            "Epoch: 446 | Train Loss: 0.39713 | Valid Loss: 0.39911 | Time: 0.46 seconds\n",
            "Epoch: 447 | Train Loss: 0.39641 | Valid Loss: 0.39978 | Time: 0.47 seconds\n",
            "Epoch: 448 | Train Loss: 0.39567 | Valid Loss: 0.39806 | Time: 0.46 seconds\n",
            "Epoch: 449 | Train Loss: 0.39497 | Valid Loss: 0.39754 | Time: 0.46 seconds\n",
            "Epoch: 450 | Train Loss: 0.39426 | Valid Loss: 0.39677 | Time: 0.46 seconds\n",
            "Epoch: 451 | Train Loss: 0.39354 | Valid Loss: 0.39788 | Time: 0.47 seconds\n",
            "Epoch: 452 | Train Loss: 0.39281 | Valid Loss: 0.39474 | Time: 0.46 seconds\n",
            "Epoch: 453 | Train Loss: 0.39208 | Valid Loss: 0.39334 | Time: 0.47 seconds\n",
            "Epoch: 454 | Train Loss: 0.39142 | Valid Loss: 0.39490 | Time: 0.45 seconds\n",
            "Epoch: 455 | Train Loss: 0.39068 | Valid Loss: 0.39257 | Time: 0.48 seconds\n",
            "Epoch: 456 | Train Loss: 0.38994 | Valid Loss: 0.39332 | Time: 0.47 seconds\n",
            "Epoch: 457 | Train Loss: 0.38927 | Valid Loss: 0.39318 | Time: 0.48 seconds\n",
            "Epoch: 458 | Train Loss: 0.38855 | Valid Loss: 0.39131 | Time: 0.46 seconds\n",
            "Epoch: 459 | Train Loss: 0.38782 | Valid Loss: 0.38909 | Time: 0.46 seconds\n",
            "Epoch: 460 | Train Loss: 0.38715 | Valid Loss: 0.39024 | Time: 0.45 seconds\n",
            "Epoch: 461 | Train Loss: 0.38645 | Valid Loss: 0.38702 | Time: 0.45 seconds\n",
            "Epoch: 462 | Train Loss: 0.38574 | Valid Loss: 0.38902 | Time: 0.48 seconds\n",
            "Epoch: 463 | Train Loss: 0.38502 | Valid Loss: 0.38848 | Time: 0.44 seconds\n",
            "Epoch: 464 | Train Loss: 0.38435 | Valid Loss: 0.39000 | Time: 0.45 seconds\n",
            "Epoch: 465 | Train Loss: 0.38363 | Valid Loss: 0.38604 | Time: 0.47 seconds\n",
            "Epoch: 466 | Train Loss: 0.38299 | Valid Loss: 0.38851 | Time: 0.45 seconds\n",
            "Epoch: 467 | Train Loss: 0.38227 | Valid Loss: 0.38418 | Time: 0.49 seconds\n",
            "Epoch: 468 | Train Loss: 0.38158 | Valid Loss: 0.38401 | Time: 0.45 seconds\n",
            "Epoch: 469 | Train Loss: 0.38091 | Valid Loss: 0.38263 | Time: 0.46 seconds\n",
            "Epoch: 470 | Train Loss: 0.38017 | Valid Loss: 0.38361 | Time: 0.46 seconds\n",
            "Epoch: 471 | Train Loss: 0.37948 | Valid Loss: 0.38076 | Time: 0.49 seconds\n",
            "Epoch: 472 | Train Loss: 0.37881 | Valid Loss: 0.38014 | Time: 0.45 seconds\n",
            "Epoch: 473 | Train Loss: 0.37815 | Valid Loss: 0.38157 | Time: 0.45 seconds\n",
            "Epoch: 474 | Train Loss: 0.37750 | Valid Loss: 0.37871 | Time: 0.46 seconds\n",
            "Epoch: 475 | Train Loss: 0.37681 | Valid Loss: 0.38139 | Time: 0.47 seconds\n",
            "Epoch: 476 | Train Loss: 0.37611 | Valid Loss: 0.38058 | Time: 0.44 seconds\n",
            "Epoch: 477 | Train Loss: 0.37543 | Valid Loss: 0.37697 | Time: 0.44 seconds\n",
            "Epoch: 478 | Train Loss: 0.37477 | Valid Loss: 0.37877 | Time: 0.45 seconds\n",
            "Epoch: 479 | Train Loss: 0.37407 | Valid Loss: 0.37583 | Time: 0.45 seconds\n",
            "Epoch: 480 | Train Loss: 0.37348 | Valid Loss: 0.37578 | Time: 0.46 seconds\n",
            "Epoch: 481 | Train Loss: 0.37278 | Valid Loss: 0.37571 | Time: 0.46 seconds\n",
            "Epoch: 482 | Train Loss: 0.37212 | Valid Loss: 0.37609 | Time: 0.45 seconds\n",
            "Epoch: 483 | Train Loss: 0.37144 | Valid Loss: 0.37496 | Time: 0.45 seconds\n",
            "Epoch: 484 | Train Loss: 0.37077 | Valid Loss: 0.37489 | Time: 0.46 seconds\n",
            "Epoch: 485 | Train Loss: 0.37014 | Valid Loss: 0.37261 | Time: 0.45 seconds\n",
            "Epoch: 486 | Train Loss: 0.36950 | Valid Loss: 0.37060 | Time: 0.48 seconds\n",
            "Epoch: 487 | Train Loss: 0.36882 | Valid Loss: 0.37031 | Time: 0.46 seconds\n",
            "Epoch: 488 | Train Loss: 0.36819 | Valid Loss: 0.37241 | Time: 0.46 seconds\n",
            "Epoch: 489 | Train Loss: 0.36753 | Valid Loss: 0.37040 | Time: 0.45 seconds\n",
            "Epoch: 490 | Train Loss: 0.36682 | Valid Loss: 0.36853 | Time: 0.46 seconds\n",
            "Epoch: 491 | Train Loss: 0.36617 | Valid Loss: 0.36923 | Time: 0.46 seconds\n",
            "Epoch: 492 | Train Loss: 0.36553 | Valid Loss: 0.36995 | Time: 0.46 seconds\n",
            "Epoch: 493 | Train Loss: 0.36489 | Valid Loss: 0.36871 | Time: 0.45 seconds\n",
            "Epoch: 494 | Train Loss: 0.36422 | Valid Loss: 0.36840 | Time: 0.45 seconds\n",
            "Epoch: 495 | Train Loss: 0.36358 | Valid Loss: 0.36611 | Time: 0.47 seconds\n",
            "Epoch: 496 | Train Loss: 0.36300 | Valid Loss: 0.36649 | Time: 0.45 seconds\n",
            "Epoch: 497 | Train Loss: 0.36234 | Valid Loss: 0.36626 | Time: 0.44 seconds\n",
            "Epoch: 498 | Train Loss: 0.36167 | Valid Loss: 0.36442 | Time: 0.47 seconds\n",
            "Epoch: 499 | Train Loss: 0.36101 | Valid Loss: 0.36592 | Time: 0.44 seconds\n",
            "Epoch: 500 | Train Loss: 0.36038 | Valid Loss: 0.36405 | Time: 0.47 seconds\n",
            "Epoch: 501 | Train Loss: 0.35977 | Valid Loss: 0.36255 | Time: 0.45 seconds\n",
            "Epoch: 502 | Train Loss: 0.35914 | Valid Loss: 0.36318 | Time: 0.47 seconds\n",
            "Epoch: 503 | Train Loss: 0.35850 | Valid Loss: 0.36025 | Time: 0.47 seconds\n",
            "Epoch: 504 | Train Loss: 0.35788 | Valid Loss: 0.35926 | Time: 0.46 seconds\n",
            "Epoch: 505 | Train Loss: 0.35724 | Valid Loss: 0.35784 | Time: 0.46 seconds\n",
            "Epoch: 506 | Train Loss: 0.35662 | Valid Loss: 0.35974 | Time: 0.45 seconds\n",
            "Epoch: 507 | Train Loss: 0.35598 | Valid Loss: 0.35823 | Time: 0.45 seconds\n",
            "Epoch: 508 | Train Loss: 0.35533 | Valid Loss: 0.35734 | Time: 0.46 seconds\n",
            "Epoch: 509 | Train Loss: 0.35474 | Valid Loss: 0.35756 | Time: 0.46 seconds\n",
            "Epoch: 510 | Train Loss: 0.35410 | Valid Loss: 0.35541 | Time: 0.46 seconds\n",
            "Epoch: 511 | Train Loss: 0.35348 | Valid Loss: 0.35551 | Time: 0.46 seconds\n",
            "Epoch: 512 | Train Loss: 0.35287 | Valid Loss: 0.35824 | Time: 0.45 seconds\n",
            "Epoch: 513 | Train Loss: 0.35226 | Valid Loss: 0.35487 | Time: 0.46 seconds\n",
            "Epoch: 514 | Train Loss: 0.35162 | Valid Loss: 0.35451 | Time: 0.46 seconds\n",
            "Epoch: 515 | Train Loss: 0.35102 | Valid Loss: 0.35268 | Time: 0.48 seconds\n",
            "Epoch: 516 | Train Loss: 0.35041 | Valid Loss: 0.35294 | Time: 0.44 seconds\n",
            "Epoch: 517 | Train Loss: 0.34981 | Valid Loss: 0.35245 | Time: 0.46 seconds\n",
            "Epoch: 518 | Train Loss: 0.34917 | Valid Loss: 0.35341 | Time: 0.46 seconds\n",
            "Epoch: 519 | Train Loss: 0.34859 | Valid Loss: 0.35100 | Time: 0.45 seconds\n",
            "Epoch: 520 | Train Loss: 0.34797 | Valid Loss: 0.35000 | Time: 0.48 seconds\n",
            "Epoch: 521 | Train Loss: 0.34736 | Valid Loss: 0.35134 | Time: 0.46 seconds\n",
            "Epoch: 522 | Train Loss: 0.34678 | Valid Loss: 0.34813 | Time: 0.47 seconds\n",
            "Epoch: 523 | Train Loss: 0.34616 | Valid Loss: 0.34989 | Time: 0.45 seconds\n",
            "Epoch: 524 | Train Loss: 0.34561 | Valid Loss: 0.34825 | Time: 0.45 seconds\n",
            "Epoch: 525 | Train Loss: 0.34501 | Valid Loss: 0.34747 | Time: 0.45 seconds\n",
            "Epoch: 526 | Train Loss: 0.34442 | Valid Loss: 0.34492 | Time: 0.48 seconds\n",
            "Epoch: 527 | Train Loss: 0.34378 | Valid Loss: 0.34747 | Time: 0.46 seconds\n",
            "Epoch: 528 | Train Loss: 0.34318 | Valid Loss: 0.34416 | Time: 0.46 seconds\n",
            "Epoch: 529 | Train Loss: 0.34258 | Valid Loss: 0.34501 | Time: 0.46 seconds\n",
            "Epoch: 530 | Train Loss: 0.34200 | Valid Loss: 0.34337 | Time: 0.45 seconds\n",
            "Epoch: 531 | Train Loss: 0.34143 | Valid Loss: 0.34249 | Time: 0.48 seconds\n",
            "Epoch: 532 | Train Loss: 0.34084 | Valid Loss: 0.34290 | Time: 0.46 seconds\n",
            "Epoch: 533 | Train Loss: 0.34024 | Valid Loss: 0.34162 | Time: 0.46 seconds\n",
            "Epoch: 534 | Train Loss: 0.33965 | Valid Loss: 0.34297 | Time: 0.46 seconds\n",
            "Epoch: 535 | Train Loss: 0.33907 | Valid Loss: 0.34225 | Time: 0.45 seconds\n",
            "Epoch: 536 | Train Loss: 0.33849 | Valid Loss: 0.34316 | Time: 0.47 seconds\n",
            "Epoch: 537 | Train Loss: 0.33795 | Valid Loss: 0.34049 | Time: 0.47 seconds\n",
            "Epoch: 538 | Train Loss: 0.33728 | Valid Loss: 0.34082 | Time: 0.45 seconds\n",
            "Epoch: 539 | Train Loss: 0.33675 | Valid Loss: 0.34029 | Time: 0.47 seconds\n",
            "Epoch: 540 | Train Loss: 0.33616 | Valid Loss: 0.33957 | Time: 0.48 seconds\n",
            "Epoch: 541 | Train Loss: 0.33563 | Valid Loss: 0.33853 | Time: 0.46 seconds\n",
            "Epoch: 542 | Train Loss: 0.33502 | Valid Loss: 0.33819 | Time: 0.49 seconds\n",
            "Epoch: 543 | Train Loss: 0.33447 | Valid Loss: 0.33644 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33389 | Valid Loss: 0.33816 | Time: 0.46 seconds\n",
            "Epoch: 545 | Train Loss: 0.33330 | Valid Loss: 0.33650 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33279 | Valid Loss: 0.33607 | Time: 0.47 seconds\n",
            "Epoch: 547 | Train Loss: 0.33221 | Valid Loss: 0.33524 | Time: 0.46 seconds\n",
            "Epoch: 548 | Train Loss: 0.33165 | Valid Loss: 0.33352 | Time: 0.46 seconds\n",
            "Epoch: 549 | Train Loss: 0.33107 | Valid Loss: 0.33629 | Time: 0.47 seconds\n",
            "Epoch: 550 | Train Loss: 0.33050 | Valid Loss: 0.33345 | Time: 0.47 seconds\n",
            "Epoch: 551 | Train Loss: 0.32993 | Valid Loss: 0.33241 | Time: 0.46 seconds\n",
            "Epoch: 552 | Train Loss: 0.32940 | Valid Loss: 0.33186 | Time: 0.46 seconds\n",
            "Epoch: 553 | Train Loss: 0.32882 | Valid Loss: 0.33170 | Time: 0.47 seconds\n",
            "Epoch: 554 | Train Loss: 0.32826 | Valid Loss: 0.33400 | Time: 0.48 seconds\n",
            "Epoch: 555 | Train Loss: 0.32767 | Valid Loss: 0.33224 | Time: 0.45 seconds\n",
            "Epoch: 556 | Train Loss: 0.32712 | Valid Loss: 0.33083 | Time: 0.46 seconds\n",
            "Epoch: 557 | Train Loss: 0.32658 | Valid Loss: 0.32844 | Time: 0.47 seconds\n",
            "Epoch: 558 | Train Loss: 0.32602 | Valid Loss: 0.32866 | Time: 0.47 seconds\n",
            "Epoch: 559 | Train Loss: 0.32545 | Valid Loss: 0.32882 | Time: 0.46 seconds\n",
            "Epoch: 560 | Train Loss: 0.32489 | Valid Loss: 0.32674 | Time: 0.47 seconds\n",
            "Epoch: 561 | Train Loss: 0.32439 | Valid Loss: 0.32583 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32384 | Valid Loss: 0.32586 | Time: 0.45 seconds\n",
            "Epoch: 563 | Train Loss: 0.32331 | Valid Loss: 0.32758 | Time: 0.46 seconds\n",
            "Epoch: 564 | Train Loss: 0.32276 | Valid Loss: 0.32487 | Time: 0.46 seconds\n",
            "Epoch: 565 | Train Loss: 0.32220 | Valid Loss: 0.32304 | Time: 0.46 seconds\n",
            "Epoch: 566 | Train Loss: 0.32168 | Valid Loss: 0.32412 | Time: 0.46 seconds\n",
            "Epoch: 567 | Train Loss: 0.32110 | Valid Loss: 0.32345 | Time: 0.47 seconds\n",
            "Epoch: 568 | Train Loss: 0.32058 | Valid Loss: 0.32300 | Time: 0.47 seconds\n",
            "Epoch: 569 | Train Loss: 0.32004 | Valid Loss: 0.32234 | Time: 0.45 seconds\n",
            "Epoch: 570 | Train Loss: 0.31949 | Valid Loss: 0.32152 | Time: 0.47 seconds\n",
            "Epoch: 571 | Train Loss: 0.31895 | Valid Loss: 0.32186 | Time: 0.45 seconds\n",
            "Epoch: 572 | Train Loss: 0.31842 | Valid Loss: 0.32096 | Time: 0.47 seconds\n",
            "Epoch: 573 | Train Loss: 0.31788 | Valid Loss: 0.31969 | Time: 0.46 seconds\n",
            "Epoch: 574 | Train Loss: 0.31740 | Valid Loss: 0.31926 | Time: 0.46 seconds\n",
            "Epoch: 575 | Train Loss: 0.31687 | Valid Loss: 0.31782 | Time: 0.46 seconds\n",
            "Epoch: 576 | Train Loss: 0.31631 | Valid Loss: 0.32047 | Time: 0.45 seconds\n",
            "Epoch: 577 | Train Loss: 0.31579 | Valid Loss: 0.31801 | Time: 0.45 seconds\n",
            "Epoch: 578 | Train Loss: 0.31528 | Valid Loss: 0.31740 | Time: 0.45 seconds\n",
            "Epoch: 579 | Train Loss: 0.31472 | Valid Loss: 0.31627 | Time: 0.46 seconds\n",
            "Epoch: 580 | Train Loss: 0.31420 | Valid Loss: 0.31673 | Time: 0.44 seconds\n",
            "Epoch: 581 | Train Loss: 0.31366 | Valid Loss: 0.31732 | Time: 0.45 seconds\n",
            "Epoch: 582 | Train Loss: 0.31313 | Valid Loss: 0.31782 | Time: 0.44 seconds\n",
            "Epoch: 583 | Train Loss: 0.31266 | Valid Loss: 0.31515 | Time: 0.45 seconds\n",
            "Epoch: 584 | Train Loss: 0.31211 | Valid Loss: 0.31453 | Time: 0.47 seconds\n",
            "Epoch: 585 | Train Loss: 0.31162 | Valid Loss: 0.31662 | Time: 0.45 seconds\n",
            "Epoch: 586 | Train Loss: 0.31107 | Valid Loss: 0.31418 | Time: 0.47 seconds\n",
            "Epoch: 587 | Train Loss: 0.31056 | Valid Loss: 0.31157 | Time: 0.46 seconds\n",
            "Epoch: 588 | Train Loss: 0.31009 | Valid Loss: 0.31387 | Time: 0.46 seconds\n",
            "Epoch: 589 | Train Loss: 0.30953 | Valid Loss: 0.31093 | Time: 0.44 seconds\n",
            "Epoch: 590 | Train Loss: 0.30899 | Valid Loss: 0.31215 | Time: 0.46 seconds\n",
            "Epoch: 591 | Train Loss: 0.30850 | Valid Loss: 0.31177 | Time: 0.46 seconds\n",
            "Epoch: 592 | Train Loss: 0.30802 | Valid Loss: 0.31174 | Time: 0.45 seconds\n",
            "Epoch: 593 | Train Loss: 0.30748 | Valid Loss: 0.30797 | Time: 0.47 seconds\n",
            "Epoch: 594 | Train Loss: 0.30698 | Valid Loss: 0.31235 | Time: 0.45 seconds\n",
            "Epoch: 595 | Train Loss: 0.30645 | Valid Loss: 0.30958 | Time: 0.46 seconds\n",
            "Epoch: 596 | Train Loss: 0.30594 | Valid Loss: 0.31001 | Time: 0.47 seconds\n",
            "Epoch: 597 | Train Loss: 0.30543 | Valid Loss: 0.30877 | Time: 0.46 seconds\n",
            "Epoch: 598 | Train Loss: 0.30497 | Valid Loss: 0.30803 | Time: 0.44 seconds\n",
            "Epoch: 599 | Train Loss: 0.30445 | Valid Loss: 0.30606 | Time: 0.48 seconds\n",
            "Epoch: 600 | Train Loss: 0.30394 | Valid Loss: 0.30441 | Time: 0.46 seconds\n",
            "Epoch: 601 | Train Loss: 0.30347 | Valid Loss: 0.30521 | Time: 0.46 seconds\n",
            "Epoch: 602 | Train Loss: 0.30293 | Valid Loss: 0.30829 | Time: 0.45 seconds\n",
            "Epoch: 603 | Train Loss: 0.30245 | Valid Loss: 0.30466 | Time: 0.44 seconds\n",
            "Epoch: 604 | Train Loss: 0.30191 | Valid Loss: 0.30351 | Time: 0.45 seconds\n",
            "Epoch: 605 | Train Loss: 0.30150 | Valid Loss: 0.30373 | Time: 0.43 seconds\n",
            "Epoch: 606 | Train Loss: 0.30094 | Valid Loss: 0.30466 | Time: 0.48 seconds\n",
            "Epoch: 607 | Train Loss: 0.30045 | Valid Loss: 0.30308 | Time: 0.48 seconds\n",
            "Epoch: 608 | Train Loss: 0.29996 | Valid Loss: 0.30270 | Time: 0.47 seconds\n",
            "Epoch: 609 | Train Loss: 0.29947 | Valid Loss: 0.30071 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29902 | Valid Loss: 0.30191 | Time: 0.47 seconds\n",
            "Epoch: 611 | Train Loss: 0.29850 | Valid Loss: 0.30204 | Time: 0.45 seconds\n",
            "Epoch: 612 | Train Loss: 0.29801 | Valid Loss: 0.30169 | Time: 0.46 seconds\n",
            "Epoch: 613 | Train Loss: 0.29752 | Valid Loss: 0.30162 | Time: 0.45 seconds\n",
            "Epoch: 614 | Train Loss: 0.29702 | Valid Loss: 0.29578 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29654 | Valid Loss: 0.29790 | Time: 0.45 seconds\n",
            "Epoch: 616 | Train Loss: 0.29604 | Valid Loss: 0.29607 | Time: 0.47 seconds\n",
            "Epoch: 617 | Train Loss: 0.29558 | Valid Loss: 0.29891 | Time: 0.45 seconds\n",
            "Epoch: 618 | Train Loss: 0.29512 | Valid Loss: 0.29764 | Time: 0.45 seconds\n",
            "Epoch: 619 | Train Loss: 0.29460 | Valid Loss: 0.29696 | Time: 0.45 seconds\n",
            "Epoch: 620 | Train Loss: 0.29413 | Valid Loss: 0.29650 | Time: 0.44 seconds\n",
            "Epoch: 621 | Train Loss: 0.29364 | Valid Loss: 0.29493 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29315 | Valid Loss: 0.29524 | Time: 0.44 seconds\n",
            "Epoch: 623 | Train Loss: 0.29269 | Valid Loss: 0.29333 | Time: 0.46 seconds\n",
            "Epoch: 624 | Train Loss: 0.29216 | Valid Loss: 0.29492 | Time: 0.46 seconds\n",
            "Epoch: 625 | Train Loss: 0.29172 | Valid Loss: 0.29436 | Time: 0.47 seconds\n",
            "Epoch: 626 | Train Loss: 0.29130 | Valid Loss: 0.29425 | Time: 0.47 seconds\n",
            "Epoch: 627 | Train Loss: 0.29077 | Valid Loss: 0.29353 | Time: 0.45 seconds\n",
            "Epoch: 628 | Train Loss: 0.29032 | Valid Loss: 0.29210 | Time: 0.46 seconds\n",
            "Epoch: 629 | Train Loss: 0.28984 | Valid Loss: 0.29156 | Time: 0.45 seconds\n",
            "Epoch: 630 | Train Loss: 0.28944 | Valid Loss: 0.29408 | Time: 0.46 seconds\n",
            "Epoch: 631 | Train Loss: 0.28892 | Valid Loss: 0.29228 | Time: 0.45 seconds\n",
            "Epoch: 632 | Train Loss: 0.28844 | Valid Loss: 0.29078 | Time: 0.46 seconds\n",
            "Epoch: 633 | Train Loss: 0.28796 | Valid Loss: 0.29067 | Time: 0.47 seconds\n",
            "Epoch: 634 | Train Loss: 0.28748 | Valid Loss: 0.28863 | Time: 0.45 seconds\n",
            "Epoch: 635 | Train Loss: 0.28703 | Valid Loss: 0.29033 | Time: 0.45 seconds\n",
            "Epoch: 636 | Train Loss: 0.28655 | Valid Loss: 0.28854 | Time: 0.45 seconds\n",
            "Epoch: 637 | Train Loss: 0.28609 | Valid Loss: 0.29101 | Time: 0.46 seconds\n",
            "Epoch: 638 | Train Loss: 0.28563 | Valid Loss: 0.28687 | Time: 0.46 seconds\n",
            "Epoch: 639 | Train Loss: 0.28517 | Valid Loss: 0.28741 | Time: 0.45 seconds\n",
            "Epoch: 640 | Train Loss: 0.28472 | Valid Loss: 0.28714 | Time: 0.45 seconds\n",
            "Epoch: 641 | Train Loss: 0.28424 | Valid Loss: 0.28617 | Time: 0.46 seconds\n",
            "Epoch: 642 | Train Loss: 0.28379 | Valid Loss: 0.28592 | Time: 0.45 seconds\n",
            "Epoch: 643 | Train Loss: 0.28329 | Valid Loss: 0.28775 | Time: 0.46 seconds\n",
            "Epoch: 644 | Train Loss: 0.28285 | Valid Loss: 0.28599 | Time: 0.46 seconds\n",
            "Epoch: 645 | Train Loss: 0.28241 | Valid Loss: 0.28406 | Time: 0.46 seconds\n",
            "Epoch: 646 | Train Loss: 0.28193 | Valid Loss: 0.28567 | Time: 0.45 seconds\n",
            "Epoch: 647 | Train Loss: 0.28149 | Valid Loss: 0.28434 | Time: 0.44 seconds\n",
            "Epoch: 648 | Train Loss: 0.28106 | Valid Loss: 0.28363 | Time: 0.47 seconds\n",
            "Epoch: 649 | Train Loss: 0.28060 | Valid Loss: 0.28312 | Time: 0.45 seconds\n",
            "Epoch: 650 | Train Loss: 0.28013 | Valid Loss: 0.28255 | Time: 0.46 seconds\n",
            "Epoch: 651 | Train Loss: 0.27968 | Valid Loss: 0.28599 | Time: 0.46 seconds\n",
            "Epoch: 652 | Train Loss: 0.27920 | Valid Loss: 0.28356 | Time: 0.44 seconds\n",
            "Epoch: 653 | Train Loss: 0.27877 | Valid Loss: 0.28269 | Time: 0.45 seconds\n",
            "Epoch: 654 | Train Loss: 0.27833 | Valid Loss: 0.28230 | Time: 0.45 seconds\n",
            "Epoch: 655 | Train Loss: 0.27788 | Valid Loss: 0.27909 | Time: 0.46 seconds\n",
            "Epoch: 656 | Train Loss: 0.27744 | Valid Loss: 0.28000 | Time: 0.44 seconds\n",
            "Epoch: 657 | Train Loss: 0.27698 | Valid Loss: 0.27999 | Time: 0.46 seconds\n",
            "Epoch: 658 | Train Loss: 0.27652 | Valid Loss: 0.27849 | Time: 0.45 seconds\n",
            "Epoch: 659 | Train Loss: 0.27609 | Valid Loss: 0.27755 | Time: 0.46 seconds\n",
            "Epoch: 660 | Train Loss: 0.27562 | Valid Loss: 0.27956 | Time: 0.45 seconds\n",
            "Epoch: 661 | Train Loss: 0.27516 | Valid Loss: 0.27842 | Time: 0.46 seconds\n",
            "Epoch: 662 | Train Loss: 0.27477 | Valid Loss: 0.28016 | Time: 0.44 seconds\n",
            "Epoch: 663 | Train Loss: 0.27430 | Valid Loss: 0.27704 | Time: 0.46 seconds\n",
            "Epoch: 664 | Train Loss: 0.27385 | Valid Loss: 0.27543 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27339 | Valid Loss: 0.27419 | Time: 0.46 seconds\n",
            "Epoch: 666 | Train Loss: 0.27299 | Valid Loss: 0.27561 | Time: 0.47 seconds\n",
            "Epoch: 667 | Train Loss: 0.27251 | Valid Loss: 0.27382 | Time: 0.49 seconds\n",
            "Epoch: 668 | Train Loss: 0.27212 | Valid Loss: 0.27526 | Time: 0.46 seconds\n",
            "Epoch: 669 | Train Loss: 0.27164 | Valid Loss: 0.27389 | Time: 0.45 seconds\n",
            "Epoch: 670 | Train Loss: 0.27124 | Valid Loss: 0.27324 | Time: 0.47 seconds\n",
            "Epoch: 671 | Train Loss: 0.27078 | Valid Loss: 0.27287 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27035 | Valid Loss: 0.27309 | Time: 0.45 seconds\n",
            "Epoch: 673 | Train Loss: 0.26989 | Valid Loss: 0.27182 | Time: 0.47 seconds\n",
            "Epoch: 674 | Train Loss: 0.26949 | Valid Loss: 0.27199 | Time: 0.44 seconds\n",
            "Epoch: 675 | Train Loss: 0.26908 | Valid Loss: 0.27058 | Time: 0.46 seconds\n",
            "Epoch: 676 | Train Loss: 0.26861 | Valid Loss: 0.27065 | Time: 0.44 seconds\n",
            "Epoch: 677 | Train Loss: 0.26816 | Valid Loss: 0.27100 | Time: 0.46 seconds\n",
            "Epoch: 678 | Train Loss: 0.26774 | Valid Loss: 0.26779 | Time: 0.46 seconds\n",
            "Epoch: 679 | Train Loss: 0.26731 | Valid Loss: 0.27156 | Time: 0.46 seconds\n",
            "Epoch: 680 | Train Loss: 0.26689 | Valid Loss: 0.26917 | Time: 0.44 seconds\n",
            "Epoch: 681 | Train Loss: 0.26646 | Valid Loss: 0.26913 | Time: 0.46 seconds\n",
            "Epoch: 682 | Train Loss: 0.26601 | Valid Loss: 0.26805 | Time: 0.45 seconds\n",
            "Epoch: 683 | Train Loss: 0.26560 | Valid Loss: 0.26860 | Time: 0.45 seconds\n",
            "Epoch: 684 | Train Loss: 0.26521 | Valid Loss: 0.26866 | Time: 0.45 seconds\n",
            "Epoch: 685 | Train Loss: 0.26475 | Valid Loss: 0.26834 | Time: 0.45 seconds\n",
            "Epoch: 686 | Train Loss: 0.26431 | Valid Loss: 0.26891 | Time: 0.45 seconds\n",
            "Epoch: 687 | Train Loss: 0.26392 | Valid Loss: 0.26756 | Time: 0.46 seconds\n",
            "Epoch: 688 | Train Loss: 0.26352 | Valid Loss: 0.26635 | Time: 0.46 seconds\n",
            "Epoch: 689 | Train Loss: 0.26307 | Valid Loss: 0.26473 | Time: 0.45 seconds\n",
            "Epoch: 690 | Train Loss: 0.26266 | Valid Loss: 0.26627 | Time: 0.47 seconds\n",
            "Epoch: 691 | Train Loss: 0.26221 | Valid Loss: 0.26492 | Time: 0.44 seconds\n",
            "Epoch: 692 | Train Loss: 0.26181 | Valid Loss: 0.26503 | Time: 0.44 seconds\n",
            "Epoch: 693 | Train Loss: 0.26138 | Valid Loss: 0.26524 | Time: 0.45 seconds\n",
            "Epoch: 694 | Train Loss: 0.26092 | Valid Loss: 0.26153 | Time: 0.47 seconds\n",
            "Epoch: 695 | Train Loss: 0.26057 | Valid Loss: 0.26204 | Time: 0.45 seconds\n",
            "Epoch: 696 | Train Loss: 0.26011 | Valid Loss: 0.26311 | Time: 0.45 seconds\n",
            "Epoch: 697 | Train Loss: 0.25972 | Valid Loss: 0.26172 | Time: 0.45 seconds\n",
            "Epoch: 698 | Train Loss: 0.25928 | Valid Loss: 0.26457 | Time: 0.45 seconds\n",
            "Epoch: 699 | Train Loss: 0.25889 | Valid Loss: 0.25969 | Time: 0.46 seconds\n",
            "Epoch: 700 | Train Loss: 0.25844 | Valid Loss: 0.25995 | Time: 0.44 seconds\n",
            "Epoch: 701 | Train Loss: 0.25811 | Valid Loss: 0.26015 | Time: 0.44 seconds\n",
            "Epoch: 702 | Train Loss: 0.25763 | Valid Loss: 0.26099 | Time: 0.45 seconds\n",
            "Epoch: 703 | Train Loss: 0.25725 | Valid Loss: 0.25925 | Time: 0.46 seconds\n",
            "Epoch: 704 | Train Loss: 0.25682 | Valid Loss: 0.25954 | Time: 0.45 seconds\n",
            "Epoch: 705 | Train Loss: 0.25642 | Valid Loss: 0.25827 | Time: 0.44 seconds\n",
            "Epoch: 706 | Train Loss: 0.25601 | Valid Loss: 0.25803 | Time: 0.46 seconds\n",
            "Epoch: 707 | Train Loss: 0.25555 | Valid Loss: 0.25991 | Time: 0.45 seconds\n",
            "Epoch: 708 | Train Loss: 0.25517 | Valid Loss: 0.25714 | Time: 0.46 seconds\n",
            "Epoch: 709 | Train Loss: 0.25474 | Valid Loss: 0.25808 | Time: 0.43 seconds\n",
            "Epoch: 710 | Train Loss: 0.25438 | Valid Loss: 0.25733 | Time: 0.44 seconds\n",
            "Epoch: 711 | Train Loss: 0.25394 | Valid Loss: 0.25752 | Time: 0.45 seconds\n",
            "Epoch: 712 | Train Loss: 0.25355 | Valid Loss: 0.25732 | Time: 0.44 seconds\n",
            "Epoch: 713 | Train Loss: 0.25315 | Valid Loss: 0.25693 | Time: 0.46 seconds\n",
            "Epoch: 714 | Train Loss: 0.25275 | Valid Loss: 0.25642 | Time: 0.44 seconds\n",
            "Epoch: 715 | Train Loss: 0.25230 | Valid Loss: 0.25438 | Time: 0.46 seconds\n",
            "Epoch: 716 | Train Loss: 0.25193 | Valid Loss: 0.25474 | Time: 0.44 seconds\n",
            "Epoch: 717 | Train Loss: 0.25154 | Valid Loss: 0.25504 | Time: 0.48 seconds\n",
            "Epoch: 718 | Train Loss: 0.25112 | Valid Loss: 0.25181 | Time: 0.45 seconds\n",
            "Epoch: 719 | Train Loss: 0.25075 | Valid Loss: 0.25206 | Time: 0.45 seconds\n",
            "Epoch: 720 | Train Loss: 0.25036 | Valid Loss: 0.25129 | Time: 0.46 seconds\n",
            "Epoch: 721 | Train Loss: 0.24993 | Valid Loss: 0.25174 | Time: 0.45 seconds\n",
            "Epoch: 722 | Train Loss: 0.24956 | Valid Loss: 0.25135 | Time: 0.48 seconds\n",
            "Epoch: 723 | Train Loss: 0.24913 | Valid Loss: 0.24983 | Time: 0.48 seconds\n",
            "Epoch: 724 | Train Loss: 0.24873 | Valid Loss: 0.25039 | Time: 0.46 seconds\n",
            "Epoch: 725 | Train Loss: 0.24833 | Valid Loss: 0.25044 | Time: 0.45 seconds\n",
            "Epoch: 726 | Train Loss: 0.24790 | Valid Loss: 0.24987 | Time: 0.45 seconds\n",
            "Epoch: 727 | Train Loss: 0.24751 | Valid Loss: 0.25171 | Time: 0.45 seconds\n",
            "Epoch: 728 | Train Loss: 0.24714 | Valid Loss: 0.24986 | Time: 0.45 seconds\n",
            "Epoch: 729 | Train Loss: 0.24672 | Valid Loss: 0.24995 | Time: 0.46 seconds\n",
            "Epoch: 730 | Train Loss: 0.24637 | Valid Loss: 0.24883 | Time: 0.45 seconds\n",
            "Epoch: 731 | Train Loss: 0.24594 | Valid Loss: 0.24852 | Time: 0.47 seconds\n",
            "Epoch: 732 | Train Loss: 0.24557 | Valid Loss: 0.24753 | Time: 0.45 seconds\n",
            "Epoch: 733 | Train Loss: 0.24518 | Valid Loss: 0.24771 | Time: 0.46 seconds\n",
            "Epoch: 734 | Train Loss: 0.24479 | Valid Loss: 0.24706 | Time: 0.45 seconds\n",
            "Epoch: 735 | Train Loss: 0.24444 | Valid Loss: 0.24686 | Time: 0.48 seconds\n",
            "Epoch: 736 | Train Loss: 0.24402 | Valid Loss: 0.24519 | Time: 0.46 seconds\n",
            "Epoch: 737 | Train Loss: 0.24363 | Valid Loss: 0.24542 | Time: 0.46 seconds\n",
            "Epoch: 738 | Train Loss: 0.24320 | Valid Loss: 0.24780 | Time: 0.44 seconds\n",
            "Epoch: 739 | Train Loss: 0.24282 | Valid Loss: 0.24495 | Time: 0.46 seconds\n",
            "Epoch: 740 | Train Loss: 0.24246 | Valid Loss: 0.24593 | Time: 0.47 seconds\n",
            "Epoch: 741 | Train Loss: 0.24210 | Valid Loss: 0.24395 | Time: 0.46 seconds\n",
            "Epoch: 742 | Train Loss: 0.24170 | Valid Loss: 0.24465 | Time: 0.47 seconds\n",
            "Epoch: 743 | Train Loss: 0.24133 | Valid Loss: 0.24491 | Time: 0.45 seconds\n",
            "Epoch: 744 | Train Loss: 0.24094 | Valid Loss: 0.24394 | Time: 0.47 seconds\n",
            "Epoch: 745 | Train Loss: 0.24055 | Valid Loss: 0.24353 | Time: 0.49 seconds\n",
            "Epoch: 746 | Train Loss: 0.24015 | Valid Loss: 0.24243 | Time: 0.47 seconds\n",
            "Epoch: 747 | Train Loss: 0.23978 | Valid Loss: 0.24140 | Time: 0.45 seconds\n",
            "Epoch: 748 | Train Loss: 0.23942 | Valid Loss: 0.24432 | Time: 0.47 seconds\n",
            "Epoch: 749 | Train Loss: 0.23899 | Valid Loss: 0.24145 | Time: 0.45 seconds\n",
            "Epoch: 750 | Train Loss: 0.23862 | Valid Loss: 0.24122 | Time: 0.47 seconds\n",
            "Epoch: 751 | Train Loss: 0.23826 | Valid Loss: 0.24010 | Time: 0.47 seconds\n",
            "Epoch: 752 | Train Loss: 0.23789 | Valid Loss: 0.23987 | Time: 0.46 seconds\n",
            "Epoch: 753 | Train Loss: 0.23746 | Valid Loss: 0.23981 | Time: 0.46 seconds\n",
            "Epoch: 754 | Train Loss: 0.23709 | Valid Loss: 0.23828 | Time: 0.46 seconds\n",
            "Epoch: 755 | Train Loss: 0.23671 | Valid Loss: 0.23855 | Time: 0.47 seconds\n",
            "Epoch: 756 | Train Loss: 0.23638 | Valid Loss: 0.23947 | Time: 0.45 seconds\n",
            "Epoch: 757 | Train Loss: 0.23598 | Valid Loss: 0.23703 | Time: 0.46 seconds\n",
            "Epoch: 758 | Train Loss: 0.23562 | Valid Loss: 0.24015 | Time: 0.44 seconds\n",
            "Epoch: 759 | Train Loss: 0.23524 | Valid Loss: 0.23698 | Time: 0.47 seconds\n",
            "Epoch: 760 | Train Loss: 0.23488 | Valid Loss: 0.23776 | Time: 0.45 seconds\n",
            "Epoch: 761 | Train Loss: 0.23446 | Valid Loss: 0.23747 | Time: 0.45 seconds\n",
            "Epoch: 762 | Train Loss: 0.23410 | Valid Loss: 0.23615 | Time: 0.46 seconds\n",
            "Epoch: 763 | Train Loss: 0.23375 | Valid Loss: 0.23628 | Time: 0.45 seconds\n",
            "Epoch: 764 | Train Loss: 0.23335 | Valid Loss: 0.23561 | Time: 0.46 seconds\n",
            "Epoch: 765 | Train Loss: 0.23299 | Valid Loss: 0.23361 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23266 | Valid Loss: 0.23477 | Time: 0.45 seconds\n",
            "Epoch: 767 | Train Loss: 0.23226 | Valid Loss: 0.23464 | Time: 0.45 seconds\n",
            "Epoch: 768 | Train Loss: 0.23188 | Valid Loss: 0.23544 | Time: 0.46 seconds\n",
            "Epoch: 769 | Train Loss: 0.23152 | Valid Loss: 0.23324 | Time: 0.48 seconds\n",
            "Epoch: 770 | Train Loss: 0.23115 | Valid Loss: 0.23271 | Time: 0.49 seconds\n",
            "Epoch: 771 | Train Loss: 0.23079 | Valid Loss: 0.23276 | Time: 0.45 seconds\n",
            "Epoch: 772 | Train Loss: 0.23040 | Valid Loss: 0.23302 | Time: 0.45 seconds\n",
            "Epoch: 773 | Train Loss: 0.23002 | Valid Loss: 0.23304 | Time: 0.46 seconds\n",
            "Epoch: 774 | Train Loss: 0.22970 | Valid Loss: 0.23180 | Time: 0.46 seconds\n",
            "Epoch: 775 | Train Loss: 0.22934 | Valid Loss: 0.23105 | Time: 0.47 seconds\n",
            "Epoch: 776 | Train Loss: 0.22895 | Valid Loss: 0.22915 | Time: 0.46 seconds\n",
            "Epoch: 777 | Train Loss: 0.22860 | Valid Loss: 0.23103 | Time: 0.45 seconds\n",
            "Epoch: 778 | Train Loss: 0.22821 | Valid Loss: 0.22955 | Time: 0.46 seconds\n",
            "Epoch: 779 | Train Loss: 0.22788 | Valid Loss: 0.23016 | Time: 0.45 seconds\n",
            "Epoch: 780 | Train Loss: 0.22749 | Valid Loss: 0.23024 | Time: 0.47 seconds\n",
            "Epoch: 781 | Train Loss: 0.22713 | Valid Loss: 0.23044 | Time: 0.45 seconds\n",
            "Epoch: 782 | Train Loss: 0.22677 | Valid Loss: 0.22972 | Time: 0.45 seconds\n",
            "Epoch: 783 | Train Loss: 0.22642 | Valid Loss: 0.22890 | Time: 0.46 seconds\n",
            "Epoch: 784 | Train Loss: 0.22605 | Valid Loss: 0.22824 | Time: 0.46 seconds\n",
            "Epoch: 785 | Train Loss: 0.22566 | Valid Loss: 0.22850 | Time: 0.46 seconds\n",
            "Epoch: 786 | Train Loss: 0.22535 | Valid Loss: 0.22801 | Time: 0.47 seconds\n",
            "Epoch: 787 | Train Loss: 0.22498 | Valid Loss: 0.22701 | Time: 0.46 seconds\n",
            "Epoch: 788 | Train Loss: 0.22463 | Valid Loss: 0.22642 | Time: 0.46 seconds\n",
            "Epoch: 789 | Train Loss: 0.22424 | Valid Loss: 0.22466 | Time: 0.46 seconds\n",
            "Epoch: 790 | Train Loss: 0.22393 | Valid Loss: 0.22575 | Time: 0.46 seconds\n",
            "Epoch: 791 | Train Loss: 0.22356 | Valid Loss: 0.22728 | Time: 0.45 seconds\n",
            "Epoch: 792 | Train Loss: 0.22319 | Valid Loss: 0.22477 | Time: 0.44 seconds\n",
            "Epoch: 793 | Train Loss: 0.22287 | Valid Loss: 0.22398 | Time: 0.46 seconds\n",
            "Epoch: 794 | Train Loss: 0.22246 | Valid Loss: 0.22416 | Time: 0.45 seconds\n",
            "Epoch: 795 | Train Loss: 0.22216 | Valid Loss: 0.22550 | Time: 0.48 seconds\n",
            "Epoch: 796 | Train Loss: 0.22185 | Valid Loss: 0.22455 | Time: 0.45 seconds\n",
            "Epoch: 797 | Train Loss: 0.22142 | Valid Loss: 0.22386 | Time: 0.46 seconds\n",
            "Epoch: 798 | Train Loss: 0.22105 | Valid Loss: 0.22290 | Time: 0.48 seconds\n",
            "Epoch: 799 | Train Loss: 0.22078 | Valid Loss: 0.22283 | Time: 0.49 seconds\n",
            "Epoch: 800 | Train Loss: 0.22041 | Valid Loss: 0.22327 | Time: 0.46 seconds\n",
            "Epoch: 801 | Train Loss: 0.22008 | Valid Loss: 0.22431 | Time: 0.45 seconds\n",
            "Epoch: 802 | Train Loss: 0.21967 | Valid Loss: 0.22201 | Time: 0.46 seconds\n",
            "Epoch: 803 | Train Loss: 0.21936 | Valid Loss: 0.22197 | Time: 0.45 seconds\n",
            "Epoch: 804 | Train Loss: 0.21899 | Valid Loss: 0.22101 | Time: 0.48 seconds\n",
            "Epoch: 805 | Train Loss: 0.21867 | Valid Loss: 0.21955 | Time: 0.45 seconds\n",
            "Epoch: 806 | Train Loss: 0.21831 | Valid Loss: 0.22154 | Time: 0.47 seconds\n",
            "Epoch: 807 | Train Loss: 0.21798 | Valid Loss: 0.22064 | Time: 0.44 seconds\n",
            "Epoch: 808 | Train Loss: 0.21762 | Valid Loss: 0.22031 | Time: 0.46 seconds\n",
            "Epoch: 809 | Train Loss: 0.21726 | Valid Loss: 0.22205 | Time: 0.48 seconds\n",
            "Epoch: 810 | Train Loss: 0.21692 | Valid Loss: 0.21825 | Time: 0.47 seconds\n",
            "Epoch: 811 | Train Loss: 0.21659 | Valid Loss: 0.21921 | Time: 0.45 seconds\n",
            "Epoch: 812 | Train Loss: 0.21622 | Valid Loss: 0.21636 | Time: 0.47 seconds\n",
            "Epoch: 813 | Train Loss: 0.21592 | Valid Loss: 0.21757 | Time: 0.45 seconds\n",
            "Epoch: 814 | Train Loss: 0.21557 | Valid Loss: 0.21834 | Time: 0.46 seconds\n",
            "Epoch: 815 | Train Loss: 0.21520 | Valid Loss: 0.21748 | Time: 0.46 seconds\n",
            "Epoch: 816 | Train Loss: 0.21483 | Valid Loss: 0.21767 | Time: 0.46 seconds\n",
            "Epoch: 817 | Train Loss: 0.21455 | Valid Loss: 0.21771 | Time: 0.46 seconds\n",
            "Epoch: 818 | Train Loss: 0.21420 | Valid Loss: 0.21479 | Time: 0.46 seconds\n",
            "Epoch: 819 | Train Loss: 0.21389 | Valid Loss: 0.21566 | Time: 0.48 seconds\n",
            "Epoch: 820 | Train Loss: 0.21351 | Valid Loss: 0.21555 | Time: 0.45 seconds\n",
            "Epoch: 821 | Train Loss: 0.21320 | Valid Loss: 0.21505 | Time: 0.46 seconds\n",
            "Epoch: 822 | Train Loss: 0.21283 | Valid Loss: 0.21585 | Time: 0.45 seconds\n",
            "Epoch: 823 | Train Loss: 0.21253 | Valid Loss: 0.21376 | Time: 0.46 seconds\n",
            "Epoch: 824 | Train Loss: 0.21217 | Valid Loss: 0.21465 | Time: 0.46 seconds\n",
            "Epoch: 825 | Train Loss: 0.21186 | Valid Loss: 0.21526 | Time: 0.45 seconds\n",
            "Epoch: 826 | Train Loss: 0.21152 | Valid Loss: 0.21392 | Time: 0.45 seconds\n",
            "Epoch: 827 | Train Loss: 0.21116 | Valid Loss: 0.21367 | Time: 0.47 seconds\n",
            "Epoch: 828 | Train Loss: 0.21082 | Valid Loss: 0.21289 | Time: 0.47 seconds\n",
            "Epoch: 829 | Train Loss: 0.21050 | Valid Loss: 0.21254 | Time: 0.46 seconds\n",
            "Epoch: 830 | Train Loss: 0.21015 | Valid Loss: 0.21106 | Time: 0.46 seconds\n",
            "Epoch: 831 | Train Loss: 0.20983 | Valid Loss: 0.21186 | Time: 0.46 seconds\n",
            "Epoch: 832 | Train Loss: 0.20951 | Valid Loss: 0.21292 | Time: 0.45 seconds\n",
            "Epoch: 833 | Train Loss: 0.20913 | Valid Loss: 0.21169 | Time: 0.44 seconds\n",
            "Epoch: 834 | Train Loss: 0.20879 | Valid Loss: 0.21142 | Time: 0.44 seconds\n",
            "Epoch: 835 | Train Loss: 0.20851 | Valid Loss: 0.21044 | Time: 0.48 seconds\n",
            "Epoch: 836 | Train Loss: 0.20816 | Valid Loss: 0.21112 | Time: 0.46 seconds\n",
            "Epoch: 837 | Train Loss: 0.20784 | Valid Loss: 0.20994 | Time: 0.47 seconds\n",
            "Epoch: 838 | Train Loss: 0.20753 | Valid Loss: 0.21040 | Time: 0.46 seconds\n",
            "Epoch: 839 | Train Loss: 0.20720 | Valid Loss: 0.21003 | Time: 0.45 seconds\n",
            "Epoch: 840 | Train Loss: 0.20683 | Valid Loss: 0.20951 | Time: 0.46 seconds\n",
            "Epoch: 841 | Train Loss: 0.20654 | Valid Loss: 0.20712 | Time: 0.46 seconds\n",
            "Epoch: 842 | Train Loss: 0.20616 | Valid Loss: 0.20866 | Time: 0.45 seconds\n",
            "Epoch: 843 | Train Loss: 0.20587 | Valid Loss: 0.20781 | Time: 0.46 seconds\n",
            "Epoch: 844 | Train Loss: 0.20558 | Valid Loss: 0.20943 | Time: 0.45 seconds\n",
            "Epoch: 845 | Train Loss: 0.20522 | Valid Loss: 0.20708 | Time: 0.47 seconds\n",
            "Epoch: 846 | Train Loss: 0.20487 | Valid Loss: 0.20679 | Time: 0.47 seconds\n",
            "Epoch: 847 | Train Loss: 0.20458 | Valid Loss: 0.20713 | Time: 0.46 seconds\n",
            "Epoch: 848 | Train Loss: 0.20425 | Valid Loss: 0.20698 | Time: 0.47 seconds\n",
            "Epoch: 849 | Train Loss: 0.20392 | Valid Loss: 0.20555 | Time: 0.46 seconds\n",
            "Epoch: 850 | Train Loss: 0.20360 | Valid Loss: 0.20643 | Time: 0.46 seconds\n",
            "Epoch: 851 | Train Loss: 0.20323 | Valid Loss: 0.20585 | Time: 0.46 seconds\n",
            "Epoch: 852 | Train Loss: 0.20296 | Valid Loss: 0.20650 | Time: 0.46 seconds\n",
            "Epoch: 853 | Train Loss: 0.20263 | Valid Loss: 0.20305 | Time: 0.47 seconds\n",
            "Epoch: 854 | Train Loss: 0.20232 | Valid Loss: 0.20305 | Time: 0.49 seconds\n",
            "Epoch: 855 | Train Loss: 0.20201 | Valid Loss: 0.20326 | Time: 0.47 seconds\n",
            "Epoch: 856 | Train Loss: 0.20171 | Valid Loss: 0.20339 | Time: 0.46 seconds\n",
            "Epoch: 857 | Train Loss: 0.20133 | Valid Loss: 0.20437 | Time: 0.47 seconds\n",
            "Epoch: 858 | Train Loss: 0.20102 | Valid Loss: 0.20415 | Time: 0.45 seconds\n",
            "Epoch: 859 | Train Loss: 0.20071 | Valid Loss: 0.20183 | Time: 0.46 seconds\n",
            "Epoch: 860 | Train Loss: 0.20041 | Valid Loss: 0.20226 | Time: 0.46 seconds\n",
            "Epoch: 861 | Train Loss: 0.20013 | Valid Loss: 0.20353 | Time: 0.47 seconds\n",
            "Epoch: 862 | Train Loss: 0.19979 | Valid Loss: 0.20318 | Time: 0.45 seconds\n",
            "Epoch: 863 | Train Loss: 0.19943 | Valid Loss: 0.20218 | Time: 0.46 seconds\n",
            "Epoch: 864 | Train Loss: 0.19914 | Valid Loss: 0.20152 | Time: 0.46 seconds\n",
            "Epoch: 865 | Train Loss: 0.19882 | Valid Loss: 0.19948 | Time: 0.47 seconds\n",
            "Epoch: 866 | Train Loss: 0.19855 | Valid Loss: 0.20181 | Time: 0.45 seconds\n",
            "Epoch: 867 | Train Loss: 0.19819 | Valid Loss: 0.20000 | Time: 0.45 seconds\n",
            "Epoch: 868 | Train Loss: 0.19791 | Valid Loss: 0.19890 | Time: 0.47 seconds\n",
            "Epoch: 869 | Train Loss: 0.19760 | Valid Loss: 0.19836 | Time: 0.46 seconds\n",
            "Epoch: 870 | Train Loss: 0.19728 | Valid Loss: 0.19957 | Time: 0.47 seconds\n",
            "Epoch: 871 | Train Loss: 0.19695 | Valid Loss: 0.19827 | Time: 0.47 seconds\n",
            "Epoch: 872 | Train Loss: 0.19666 | Valid Loss: 0.19711 | Time: 0.48 seconds\n",
            "Epoch: 873 | Train Loss: 0.19635 | Valid Loss: 0.19893 | Time: 0.46 seconds\n",
            "Epoch: 874 | Train Loss: 0.19604 | Valid Loss: 0.19735 | Time: 0.47 seconds\n",
            "Epoch: 875 | Train Loss: 0.19574 | Valid Loss: 0.19719 | Time: 0.47 seconds\n",
            "Epoch: 876 | Train Loss: 0.19541 | Valid Loss: 0.19783 | Time: 0.48 seconds\n",
            "Epoch: 877 | Train Loss: 0.19509 | Valid Loss: 0.19671 | Time: 0.47 seconds\n",
            "Epoch: 878 | Train Loss: 0.19480 | Valid Loss: 0.19808 | Time: 0.47 seconds\n",
            "Epoch: 879 | Train Loss: 0.19445 | Valid Loss: 0.19707 | Time: 0.47 seconds\n",
            "Epoch: 880 | Train Loss: 0.19416 | Valid Loss: 0.19648 | Time: 0.48 seconds\n",
            "Epoch: 881 | Train Loss: 0.19384 | Valid Loss: 0.19605 | Time: 0.46 seconds\n",
            "Epoch: 882 | Train Loss: 0.19355 | Valid Loss: 0.19662 | Time: 0.47 seconds\n",
            "Epoch: 883 | Train Loss: 0.19329 | Valid Loss: 0.19569 | Time: 0.47 seconds\n",
            "Epoch: 884 | Train Loss: 0.19299 | Valid Loss: 0.19480 | Time: 0.48 seconds\n",
            "Epoch: 885 | Train Loss: 0.19269 | Valid Loss: 0.19516 | Time: 0.48 seconds\n",
            "Epoch: 886 | Train Loss: 0.19236 | Valid Loss: 0.19470 | Time: 0.47 seconds\n",
            "Epoch: 887 | Train Loss: 0.19204 | Valid Loss: 0.19377 | Time: 0.48 seconds\n",
            "Epoch: 888 | Train Loss: 0.19176 | Valid Loss: 0.19294 | Time: 0.46 seconds\n",
            "Epoch: 889 | Train Loss: 0.19147 | Valid Loss: 0.19530 | Time: 0.48 seconds\n",
            "Epoch: 890 | Train Loss: 0.19117 | Valid Loss: 0.19287 | Time: 0.48 seconds\n",
            "Epoch: 891 | Train Loss: 0.19082 | Valid Loss: 0.19333 | Time: 0.46 seconds\n",
            "Epoch: 892 | Train Loss: 0.19054 | Valid Loss: 0.19180 | Time: 0.46 seconds\n",
            "Epoch: 893 | Train Loss: 0.19024 | Valid Loss: 0.19207 | Time: 0.46 seconds\n",
            "Epoch: 894 | Train Loss: 0.18997 | Valid Loss: 0.19346 | Time: 0.48 seconds\n",
            "Epoch: 895 | Train Loss: 0.18966 | Valid Loss: 0.19180 | Time: 0.47 seconds\n",
            "Epoch: 896 | Train Loss: 0.18940 | Valid Loss: 0.19128 | Time: 0.47 seconds\n",
            "Epoch: 897 | Train Loss: 0.18907 | Valid Loss: 0.19164 | Time: 0.46 seconds\n",
            "Epoch: 898 | Train Loss: 0.18875 | Valid Loss: 0.19151 | Time: 0.47 seconds\n",
            "Epoch: 899 | Train Loss: 0.18845 | Valid Loss: 0.19178 | Time: 0.47 seconds\n",
            "Epoch: 900 | Train Loss: 0.18816 | Valid Loss: 0.19061 | Time: 0.47 seconds\n",
            "Epoch: 901 | Train Loss: 0.18787 | Valid Loss: 0.18929 | Time: 0.45 seconds\n",
            "Epoch: 902 | Train Loss: 0.18755 | Valid Loss: 0.19081 | Time: 0.46 seconds\n",
            "Epoch: 903 | Train Loss: 0.18724 | Valid Loss: 0.18791 | Time: 0.49 seconds\n",
            "Epoch: 904 | Train Loss: 0.18695 | Valid Loss: 0.18975 | Time: 0.46 seconds\n",
            "Epoch: 905 | Train Loss: 0.18669 | Valid Loss: 0.18836 | Time: 0.45 seconds\n",
            "Epoch: 906 | Train Loss: 0.18639 | Valid Loss: 0.18949 | Time: 0.45 seconds\n",
            "Epoch: 907 | Train Loss: 0.18607 | Valid Loss: 0.18675 | Time: 0.46 seconds\n",
            "Epoch: 908 | Train Loss: 0.18580 | Valid Loss: 0.18750 | Time: 0.47 seconds\n",
            "Epoch: 909 | Train Loss: 0.18552 | Valid Loss: 0.18622 | Time: 0.47 seconds\n",
            "Epoch: 910 | Train Loss: 0.18521 | Valid Loss: 0.18694 | Time: 0.45 seconds\n",
            "Epoch: 911 | Train Loss: 0.18494 | Valid Loss: 0.18910 | Time: 0.46 seconds\n",
            "Epoch: 912 | Train Loss: 0.18465 | Valid Loss: 0.18701 | Time: 0.45 seconds\n",
            "Epoch: 913 | Train Loss: 0.18435 | Valid Loss: 0.18525 | Time: 0.46 seconds\n",
            "Epoch: 914 | Train Loss: 0.18408 | Valid Loss: 0.18648 | Time: 0.46 seconds\n",
            "Epoch: 915 | Train Loss: 0.18375 | Valid Loss: 0.18647 | Time: 0.46 seconds\n",
            "Epoch: 916 | Train Loss: 0.18348 | Valid Loss: 0.18440 | Time: 0.46 seconds\n",
            "Epoch: 917 | Train Loss: 0.18321 | Valid Loss: 0.18532 | Time: 0.48 seconds\n",
            "Epoch: 918 | Train Loss: 0.18290 | Valid Loss: 0.18549 | Time: 0.47 seconds\n",
            "Epoch: 919 | Train Loss: 0.18262 | Valid Loss: 0.18460 | Time: 0.59 seconds\n",
            "Epoch: 920 | Train Loss: 0.18233 | Valid Loss: 0.18344 | Time: 0.57 seconds\n",
            "Epoch: 921 | Train Loss: 0.18206 | Valid Loss: 0.18445 | Time: 0.45 seconds\n",
            "Epoch: 922 | Train Loss: 0.18175 | Valid Loss: 0.18415 | Time: 0.48 seconds\n",
            "Epoch: 923 | Train Loss: 0.18145 | Valid Loss: 0.18252 | Time: 0.47 seconds\n",
            "Epoch: 924 | Train Loss: 0.18117 | Valid Loss: 0.18272 | Time: 0.47 seconds\n",
            "Epoch: 925 | Train Loss: 0.18088 | Valid Loss: 0.18166 | Time: 0.47 seconds\n",
            "Epoch: 926 | Train Loss: 0.18059 | Valid Loss: 0.18233 | Time: 0.48 seconds\n",
            "Epoch: 927 | Train Loss: 0.18034 | Valid Loss: 0.18230 | Time: 0.47 seconds\n",
            "Epoch: 928 | Train Loss: 0.18007 | Valid Loss: 0.18345 | Time: 0.48 seconds\n",
            "Epoch: 929 | Train Loss: 0.17979 | Valid Loss: 0.18188 | Time: 0.47 seconds\n",
            "Epoch: 930 | Train Loss: 0.17948 | Valid Loss: 0.18174 | Time: 0.46 seconds\n",
            "Epoch: 931 | Train Loss: 0.17920 | Valid Loss: 0.18107 | Time: 0.46 seconds\n",
            "Epoch: 932 | Train Loss: 0.17893 | Valid Loss: 0.18062 | Time: 0.49 seconds\n",
            "Epoch: 933 | Train Loss: 0.17864 | Valid Loss: 0.18139 | Time: 0.46 seconds\n",
            "Epoch: 934 | Train Loss: 0.17836 | Valid Loss: 0.18076 | Time: 0.48 seconds\n",
            "Epoch: 935 | Train Loss: 0.17808 | Valid Loss: 0.18043 | Time: 0.47 seconds\n",
            "Epoch: 936 | Train Loss: 0.17783 | Valid Loss: 0.18037 | Time: 0.46 seconds\n",
            "Epoch: 937 | Train Loss: 0.17755 | Valid Loss: 0.17930 | Time: 0.48 seconds\n",
            "Epoch: 938 | Train Loss: 0.17722 | Valid Loss: 0.17834 | Time: 0.48 seconds\n",
            "Epoch: 939 | Train Loss: 0.17694 | Valid Loss: 0.17824 | Time: 0.48 seconds\n",
            "Epoch: 940 | Train Loss: 0.17669 | Valid Loss: 0.17976 | Time: 0.46 seconds\n",
            "Epoch: 941 | Train Loss: 0.17639 | Valid Loss: 0.17811 | Time: 0.47 seconds\n",
            "Epoch: 942 | Train Loss: 0.17610 | Valid Loss: 0.18005 | Time: 0.46 seconds\n",
            "Epoch: 943 | Train Loss: 0.17588 | Valid Loss: 0.17817 | Time: 0.48 seconds\n",
            "Epoch: 944 | Train Loss: 0.17558 | Valid Loss: 0.17627 | Time: 0.47 seconds\n",
            "Epoch: 945 | Train Loss: 0.17529 | Valid Loss: 0.17854 | Time: 0.47 seconds\n",
            "Epoch: 946 | Train Loss: 0.17504 | Valid Loss: 0.17703 | Time: 0.45 seconds\n",
            "Epoch: 947 | Train Loss: 0.17476 | Valid Loss: 0.17591 | Time: 0.47 seconds\n",
            "Epoch: 948 | Train Loss: 0.17449 | Valid Loss: 0.17684 | Time: 0.46 seconds\n",
            "Epoch: 949 | Train Loss: 0.17422 | Valid Loss: 0.17705 | Time: 0.46 seconds\n",
            "Epoch: 950 | Train Loss: 0.17395 | Valid Loss: 0.17529 | Time: 0.48 seconds\n",
            "Epoch: 951 | Train Loss: 0.17369 | Valid Loss: 0.17609 | Time: 0.47 seconds\n",
            "Epoch: 952 | Train Loss: 0.17341 | Valid Loss: 0.17562 | Time: 0.47 seconds\n",
            "Epoch: 953 | Train Loss: 0.17311 | Valid Loss: 0.17606 | Time: 0.46 seconds\n",
            "Epoch: 954 | Train Loss: 0.17287 | Valid Loss: 0.17537 | Time: 0.47 seconds\n",
            "Epoch: 955 | Train Loss: 0.17260 | Valid Loss: 0.17552 | Time: 0.45 seconds\n",
            "Epoch: 956 | Train Loss: 0.17232 | Valid Loss: 0.17548 | Time: 0.47 seconds\n",
            "Epoch: 957 | Train Loss: 0.17205 | Valid Loss: 0.17388 | Time: 0.48 seconds\n",
            "Epoch: 958 | Train Loss: 0.17175 | Valid Loss: 0.17470 | Time: 0.47 seconds\n",
            "Epoch: 959 | Train Loss: 0.17150 | Valid Loss: 0.17213 | Time: 0.46 seconds\n",
            "Epoch: 960 | Train Loss: 0.17126 | Valid Loss: 0.17285 | Time: 0.46 seconds\n",
            "Epoch: 961 | Train Loss: 0.17096 | Valid Loss: 0.17396 | Time: 0.48 seconds\n",
            "Epoch: 962 | Train Loss: 0.17072 | Valid Loss: 0.17403 | Time: 0.46 seconds\n",
            "Epoch: 963 | Train Loss: 0.17045 | Valid Loss: 0.17213 | Time: 0.46 seconds\n",
            "Epoch: 964 | Train Loss: 0.17018 | Valid Loss: 0.17242 | Time: 0.45 seconds\n",
            "Epoch: 965 | Train Loss: 0.16992 | Valid Loss: 0.17181 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16964 | Valid Loss: 0.17192 | Time: 0.46 seconds\n",
            "Epoch: 967 | Train Loss: 0.16938 | Valid Loss: 0.17077 | Time: 0.48 seconds\n",
            "Epoch: 968 | Train Loss: 0.16909 | Valid Loss: 0.16963 | Time: 0.46 seconds\n",
            "Epoch: 969 | Train Loss: 0.16883 | Valid Loss: 0.17063 | Time: 0.47 seconds\n",
            "Epoch: 970 | Train Loss: 0.16857 | Valid Loss: 0.17185 | Time: 0.46 seconds\n",
            "Epoch: 971 | Train Loss: 0.16832 | Valid Loss: 0.17003 | Time: 0.46 seconds\n",
            "Epoch: 972 | Train Loss: 0.16804 | Valid Loss: 0.16978 | Time: 0.48 seconds\n",
            "Epoch: 973 | Train Loss: 0.16779 | Valid Loss: 0.17000 | Time: 0.45 seconds\n",
            "Epoch: 974 | Train Loss: 0.16751 | Valid Loss: 0.16892 | Time: 0.47 seconds\n",
            "Epoch: 975 | Train Loss: 0.16729 | Valid Loss: 0.16910 | Time: 0.47 seconds\n",
            "Epoch: 976 | Train Loss: 0.16701 | Valid Loss: 0.16970 | Time: 0.47 seconds\n",
            "Epoch: 977 | Train Loss: 0.16676 | Valid Loss: 0.16848 | Time: 0.47 seconds\n",
            "Epoch: 978 | Train Loss: 0.16649 | Valid Loss: 0.16871 | Time: 0.47 seconds\n",
            "Epoch: 979 | Train Loss: 0.16627 | Valid Loss: 0.16760 | Time: 0.47 seconds\n",
            "Epoch: 980 | Train Loss: 0.16598 | Valid Loss: 0.16724 | Time: 0.48 seconds\n",
            "Epoch: 981 | Train Loss: 0.16573 | Valid Loss: 0.16864 | Time: 0.45 seconds\n",
            "Epoch: 982 | Train Loss: 0.16545 | Valid Loss: 0.16656 | Time: 0.49 seconds\n",
            "Epoch: 983 | Train Loss: 0.16518 | Valid Loss: 0.16644 | Time: 0.46 seconds\n",
            "Epoch: 984 | Train Loss: 0.16492 | Valid Loss: 0.16628 | Time: 0.48 seconds\n",
            "Epoch: 985 | Train Loss: 0.16467 | Valid Loss: 0.16614 | Time: 0.46 seconds\n",
            "Epoch: 986 | Train Loss: 0.16443 | Valid Loss: 0.16598 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16418 | Valid Loss: 0.16792 | Time: 0.47 seconds\n",
            "Epoch: 988 | Train Loss: 0.16392 | Valid Loss: 0.16701 | Time: 0.48 seconds\n",
            "Epoch: 989 | Train Loss: 0.16367 | Valid Loss: 0.16575 | Time: 0.49 seconds\n",
            "Epoch: 990 | Train Loss: 0.16342 | Valid Loss: 0.16540 | Time: 0.47 seconds\n",
            "Epoch: 991 | Train Loss: 0.16316 | Valid Loss: 0.16416 | Time: 0.50 seconds\n",
            "Epoch: 992 | Train Loss: 0.16290 | Valid Loss: 0.16508 | Time: 0.47 seconds\n",
            "Epoch: 993 | Train Loss: 0.16261 | Valid Loss: 0.16487 | Time: 0.47 seconds\n",
            "Epoch: 994 | Train Loss: 0.16239 | Valid Loss: 0.16356 | Time: 0.46 seconds\n",
            "Epoch: 995 | Train Loss: 0.16215 | Valid Loss: 0.16488 | Time: 0.47 seconds\n",
            "Epoch: 996 | Train Loss: 0.16188 | Valid Loss: 0.16367 | Time: 0.48 seconds\n",
            "Epoch: 997 | Train Loss: 0.16165 | Valid Loss: 0.16345 | Time: 0.49 seconds\n",
            "Epoch: 998 | Train Loss: 0.16137 | Valid Loss: 0.16341 | Time: 0.47 seconds\n",
            "Epoch: 999 | Train Loss: 0.16113 | Valid Loss: 0.16312 | Time: 0.46 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16089 | Valid Loss: 0.16322 | Time: 0.47 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 999\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.71 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 4]: 32.20404\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 5...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71488 | Valid Loss: 0.71144 | Time: 0.49 seconds\n",
            "Epoch: 2 | Train Loss: 0.71432 | Valid Loss: 0.71334 | Time: 0.45 seconds\n",
            "Epoch: 3 | Train Loss: 0.71380 | Valid Loss: 0.71344 | Time: 0.49 seconds\n",
            "Epoch: 4 | Train Loss: 0.71331 | Valid Loss: 0.71315 | Time: 0.47 seconds\n",
            "Epoch: 5 | Train Loss: 0.71283 | Valid Loss: 0.71267 | Time: 0.47 seconds\n",
            "Epoch: 6 | Train Loss: 0.71236 | Valid Loss: 0.71178 | Time: 0.47 seconds\n",
            "Epoch: 7 | Train Loss: 0.71191 | Valid Loss: 0.71179 | Time: 0.45 seconds\n",
            "Epoch: 8 | Train Loss: 0.71149 | Valid Loss: 0.71168 | Time: 0.47 seconds\n",
            "Epoch: 9 | Train Loss: 0.71107 | Valid Loss: 0.71077 | Time: 0.46 seconds\n",
            "Epoch: 10 | Train Loss: 0.71066 | Valid Loss: 0.71019 | Time: 0.46 seconds\n",
            "Epoch: 11 | Train Loss: 0.71026 | Valid Loss: 0.71019 | Time: 0.47 seconds\n",
            "Epoch: 12 | Train Loss: 0.70988 | Valid Loss: 0.71012 | Time: 0.49 seconds\n",
            "Epoch: 13 | Train Loss: 0.70951 | Valid Loss: 0.71000 | Time: 0.48 seconds\n",
            "Epoch: 14 | Train Loss: 0.70915 | Valid Loss: 0.70858 | Time: 0.47 seconds\n",
            "Epoch: 15 | Train Loss: 0.70879 | Valid Loss: 0.70857 | Time: 0.46 seconds\n",
            "Epoch: 16 | Train Loss: 0.70843 | Valid Loss: 0.70856 | Time: 0.48 seconds\n",
            "Epoch: 17 | Train Loss: 0.70808 | Valid Loss: 0.70809 | Time: 0.46 seconds\n",
            "Epoch: 18 | Train Loss: 0.70774 | Valid Loss: 0.70772 | Time: 0.47 seconds\n",
            "Epoch: 19 | Train Loss: 0.70741 | Valid Loss: 0.70736 | Time: 0.47 seconds\n",
            "Epoch: 20 | Train Loss: 0.70708 | Valid Loss: 0.70723 | Time: 0.46 seconds\n",
            "Epoch: 21 | Train Loss: 0.70677 | Valid Loss: 0.70680 | Time: 0.47 seconds\n",
            "Epoch: 22 | Train Loss: 0.70643 | Valid Loss: 0.70608 | Time: 0.48 seconds\n",
            "Epoch: 23 | Train Loss: 0.70610 | Valid Loss: 0.70605 | Time: 0.48 seconds\n",
            "Epoch: 24 | Train Loss: 0.70577 | Valid Loss: 0.70609 | Time: 0.47 seconds\n",
            "Epoch: 25 | Train Loss: 0.70545 | Valid Loss: 0.70588 | Time: 0.48 seconds\n",
            "Epoch: 26 | Train Loss: 0.70516 | Valid Loss: 0.70482 | Time: 0.48 seconds\n",
            "Epoch: 27 | Train Loss: 0.70483 | Valid Loss: 0.70476 | Time: 0.47 seconds\n",
            "Epoch: 28 | Train Loss: 0.70451 | Valid Loss: 0.70453 | Time: 0.48 seconds\n",
            "Epoch: 29 | Train Loss: 0.70420 | Valid Loss: 0.70391 | Time: 0.49 seconds\n",
            "Epoch: 30 | Train Loss: 0.70389 | Valid Loss: 0.70360 | Time: 0.48 seconds\n",
            "Epoch: 31 | Train Loss: 0.70357 | Valid Loss: 0.70306 | Time: 0.49 seconds\n",
            "Epoch: 32 | Train Loss: 0.70326 | Valid Loss: 0.70268 | Time: 0.46 seconds\n",
            "Epoch: 33 | Train Loss: 0.70294 | Valid Loss: 0.70267 | Time: 0.47 seconds\n",
            "Epoch: 34 | Train Loss: 0.70262 | Valid Loss: 0.70263 | Time: 0.47 seconds\n",
            "Epoch: 35 | Train Loss: 0.70231 | Valid Loss: 0.70172 | Time: 0.47 seconds\n",
            "Epoch: 36 | Train Loss: 0.70198 | Valid Loss: 0.70186 | Time: 0.47 seconds\n",
            "Epoch: 37 | Train Loss: 0.70167 | Valid Loss: 0.70113 | Time: 0.46 seconds\n",
            "Epoch: 38 | Train Loss: 0.70135 | Valid Loss: 0.70083 | Time: 0.47 seconds\n",
            "Epoch: 39 | Train Loss: 0.70102 | Valid Loss: 0.70109 | Time: 0.45 seconds\n",
            "Epoch: 40 | Train Loss: 0.70069 | Valid Loss: 0.70038 | Time: 0.47 seconds\n",
            "Epoch: 41 | Train Loss: 0.70037 | Valid Loss: 0.69994 | Time: 0.50 seconds\n",
            "Epoch: 42 | Train Loss: 0.70003 | Valid Loss: 0.69975 | Time: 0.49 seconds\n",
            "Epoch: 43 | Train Loss: 0.69969 | Valid Loss: 0.69964 | Time: 0.47 seconds\n",
            "Epoch: 44 | Train Loss: 0.69935 | Valid Loss: 0.69958 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69901 | Valid Loss: 0.69900 | Time: 0.49 seconds\n",
            "Epoch: 46 | Train Loss: 0.69865 | Valid Loss: 0.69854 | Time: 0.48 seconds\n",
            "Epoch: 47 | Train Loss: 0.69831 | Valid Loss: 0.69833 | Time: 0.46 seconds\n",
            "Epoch: 48 | Train Loss: 0.69795 | Valid Loss: 0.69767 | Time: 0.47 seconds\n",
            "Epoch: 49 | Train Loss: 0.69761 | Valid Loss: 0.69729 | Time: 0.46 seconds\n",
            "Epoch: 50 | Train Loss: 0.69724 | Valid Loss: 0.69668 | Time: 0.46 seconds\n",
            "Epoch: 51 | Train Loss: 0.69688 | Valid Loss: 0.69656 | Time: 0.48 seconds\n",
            "Epoch: 52 | Train Loss: 0.69653 | Valid Loss: 0.69672 | Time: 0.46 seconds\n",
            "Epoch: 53 | Train Loss: 0.69614 | Valid Loss: 0.69618 | Time: 0.47 seconds\n",
            "Epoch: 54 | Train Loss: 0.69577 | Valid Loss: 0.69504 | Time: 0.49 seconds\n",
            "Epoch: 55 | Train Loss: 0.69537 | Valid Loss: 0.69515 | Time: 0.46 seconds\n",
            "Epoch: 56 | Train Loss: 0.69501 | Valid Loss: 0.69421 | Time: 0.46 seconds\n",
            "Epoch: 57 | Train Loss: 0.69462 | Valid Loss: 0.69413 | Time: 0.48 seconds\n",
            "Epoch: 58 | Train Loss: 0.69422 | Valid Loss: 0.69360 | Time: 0.46 seconds\n",
            "Epoch: 59 | Train Loss: 0.69382 | Valid Loss: 0.69381 | Time: 0.48 seconds\n",
            "Epoch: 60 | Train Loss: 0.69342 | Valid Loss: 0.69389 | Time: 0.45 seconds\n",
            "Epoch: 61 | Train Loss: 0.69301 | Valid Loss: 0.69287 | Time: 0.47 seconds\n",
            "Epoch: 62 | Train Loss: 0.69261 | Valid Loss: 0.69308 | Time: 0.46 seconds\n",
            "Epoch: 63 | Train Loss: 0.69217 | Valid Loss: 0.69252 | Time: 0.46 seconds\n",
            "Epoch: 64 | Train Loss: 0.69177 | Valid Loss: 0.69136 | Time: 0.49 seconds\n",
            "Epoch: 65 | Train Loss: 0.69135 | Valid Loss: 0.69095 | Time: 0.46 seconds\n",
            "Epoch: 66 | Train Loss: 0.69095 | Valid Loss: 0.69036 | Time: 0.47 seconds\n",
            "Epoch: 67 | Train Loss: 0.69049 | Valid Loss: 0.69048 | Time: 0.45 seconds\n",
            "Epoch: 68 | Train Loss: 0.69007 | Valid Loss: 0.68986 | Time: 0.48 seconds\n",
            "Epoch: 69 | Train Loss: 0.68963 | Valid Loss: 0.68955 | Time: 0.46 seconds\n",
            "Epoch: 70 | Train Loss: 0.68918 | Valid Loss: 0.68904 | Time: 0.48 seconds\n",
            "Epoch: 71 | Train Loss: 0.68874 | Valid Loss: 0.68873 | Time: 0.46 seconds\n",
            "Epoch: 72 | Train Loss: 0.68828 | Valid Loss: 0.68780 | Time: 0.47 seconds\n",
            "Epoch: 73 | Train Loss: 0.68784 | Valid Loss: 0.68742 | Time: 0.47 seconds\n",
            "Epoch: 74 | Train Loss: 0.68737 | Valid Loss: 0.68749 | Time: 0.47 seconds\n",
            "Epoch: 75 | Train Loss: 0.68690 | Valid Loss: 0.68656 | Time: 0.46 seconds\n",
            "Epoch: 76 | Train Loss: 0.68644 | Valid Loss: 0.68635 | Time: 0.46 seconds\n",
            "Epoch: 77 | Train Loss: 0.68596 | Valid Loss: 0.68544 | Time: 0.47 seconds\n",
            "Epoch: 78 | Train Loss: 0.68550 | Valid Loss: 0.68508 | Time: 0.45 seconds\n",
            "Epoch: 79 | Train Loss: 0.68502 | Valid Loss: 0.68428 | Time: 0.48 seconds\n",
            "Epoch: 80 | Train Loss: 0.68453 | Valid Loss: 0.68425 | Time: 0.46 seconds\n",
            "Epoch: 81 | Train Loss: 0.68405 | Valid Loss: 0.68371 | Time: 0.48 seconds\n",
            "Epoch: 82 | Train Loss: 0.68355 | Valid Loss: 0.68290 | Time: 0.47 seconds\n",
            "Epoch: 83 | Train Loss: 0.68306 | Valid Loss: 0.68310 | Time: 0.47 seconds\n",
            "Epoch: 84 | Train Loss: 0.68257 | Valid Loss: 0.68209 | Time: 0.47 seconds\n",
            "Epoch: 85 | Train Loss: 0.68206 | Valid Loss: 0.68186 | Time: 0.46 seconds\n",
            "Epoch: 86 | Train Loss: 0.68155 | Valid Loss: 0.68098 | Time: 0.46 seconds\n",
            "Epoch: 87 | Train Loss: 0.68104 | Valid Loss: 0.68042 | Time: 0.47 seconds\n",
            "Epoch: 88 | Train Loss: 0.68052 | Valid Loss: 0.67995 | Time: 0.46 seconds\n",
            "Epoch: 89 | Train Loss: 0.68000 | Valid Loss: 0.67931 | Time: 0.47 seconds\n",
            "Epoch: 90 | Train Loss: 0.67948 | Valid Loss: 0.67969 | Time: 0.46 seconds\n",
            "Epoch: 91 | Train Loss: 0.67895 | Valid Loss: 0.67864 | Time: 0.46 seconds\n",
            "Epoch: 92 | Train Loss: 0.67842 | Valid Loss: 0.67792 | Time: 0.47 seconds\n",
            "Epoch: 93 | Train Loss: 0.67788 | Valid Loss: 0.67689 | Time: 0.47 seconds\n",
            "Epoch: 94 | Train Loss: 0.67735 | Valid Loss: 0.67650 | Time: 0.47 seconds\n",
            "Epoch: 95 | Train Loss: 0.67680 | Valid Loss: 0.67618 | Time: 0.46 seconds\n",
            "Epoch: 96 | Train Loss: 0.67625 | Valid Loss: 0.67660 | Time: 0.47 seconds\n",
            "Epoch: 97 | Train Loss: 0.67571 | Valid Loss: 0.67585 | Time: 0.46 seconds\n",
            "Epoch: 98 | Train Loss: 0.67515 | Valid Loss: 0.67528 | Time: 0.48 seconds\n",
            "Epoch: 99 | Train Loss: 0.67458 | Valid Loss: 0.67447 | Time: 0.46 seconds\n",
            "Epoch: 100 | Train Loss: 0.67402 | Valid Loss: 0.67369 | Time: 0.46 seconds\n",
            "Epoch: 101 | Train Loss: 0.67346 | Valid Loss: 0.67336 | Time: 0.47 seconds\n",
            "Epoch: 102 | Train Loss: 0.67289 | Valid Loss: 0.67292 | Time: 0.48 seconds\n",
            "Epoch: 103 | Train Loss: 0.67232 | Valid Loss: 0.67216 | Time: 0.46 seconds\n",
            "Epoch: 104 | Train Loss: 0.67173 | Valid Loss: 0.67161 | Time: 0.48 seconds\n",
            "Epoch: 105 | Train Loss: 0.67116 | Valid Loss: 0.67104 | Time: 0.47 seconds\n",
            "Epoch: 106 | Train Loss: 0.67056 | Valid Loss: 0.66991 | Time: 0.46 seconds\n",
            "Epoch: 107 | Train Loss: 0.66996 | Valid Loss: 0.66914 | Time: 0.48 seconds\n",
            "Epoch: 108 | Train Loss: 0.66938 | Valid Loss: 0.66876 | Time: 0.47 seconds\n",
            "Epoch: 109 | Train Loss: 0.66878 | Valid Loss: 0.66846 | Time: 0.48 seconds\n",
            "Epoch: 110 | Train Loss: 0.66817 | Valid Loss: 0.66820 | Time: 0.46 seconds\n",
            "Epoch: 111 | Train Loss: 0.66756 | Valid Loss: 0.66620 | Time: 0.48 seconds\n",
            "Epoch: 112 | Train Loss: 0.66696 | Valid Loss: 0.66658 | Time: 0.47 seconds\n",
            "Epoch: 113 | Train Loss: 0.66635 | Valid Loss: 0.66549 | Time: 0.50 seconds\n",
            "Epoch: 114 | Train Loss: 0.66573 | Valid Loss: 0.66424 | Time: 0.47 seconds\n",
            "Epoch: 115 | Train Loss: 0.66511 | Valid Loss: 0.66524 | Time: 0.45 seconds\n",
            "Epoch: 116 | Train Loss: 0.66449 | Valid Loss: 0.66430 | Time: 0.47 seconds\n",
            "Epoch: 117 | Train Loss: 0.66386 | Valid Loss: 0.66382 | Time: 0.48 seconds\n",
            "Epoch: 118 | Train Loss: 0.66323 | Valid Loss: 0.66220 | Time: 0.49 seconds\n",
            "Epoch: 119 | Train Loss: 0.66259 | Valid Loss: 0.66200 | Time: 0.46 seconds\n",
            "Epoch: 120 | Train Loss: 0.66195 | Valid Loss: 0.66100 | Time: 0.47 seconds\n",
            "Epoch: 121 | Train Loss: 0.66132 | Valid Loss: 0.66063 | Time: 0.47 seconds\n",
            "Epoch: 122 | Train Loss: 0.66065 | Valid Loss: 0.65965 | Time: 0.47 seconds\n",
            "Epoch: 123 | Train Loss: 0.66002 | Valid Loss: 0.66006 | Time: 0.44 seconds\n",
            "Epoch: 124 | Train Loss: 0.65937 | Valid Loss: 0.65869 | Time: 0.48 seconds\n",
            "Epoch: 125 | Train Loss: 0.65870 | Valid Loss: 0.65802 | Time: 0.46 seconds\n",
            "Epoch: 126 | Train Loss: 0.65804 | Valid Loss: 0.65728 | Time: 0.48 seconds\n",
            "Epoch: 127 | Train Loss: 0.65738 | Valid Loss: 0.65621 | Time: 0.46 seconds\n",
            "Epoch: 128 | Train Loss: 0.65671 | Valid Loss: 0.65621 | Time: 0.46 seconds\n",
            "Epoch: 129 | Train Loss: 0.65604 | Valid Loss: 0.65467 | Time: 0.47 seconds\n",
            "Epoch: 130 | Train Loss: 0.65537 | Valid Loss: 0.65471 | Time: 0.47 seconds\n",
            "Epoch: 131 | Train Loss: 0.65469 | Valid Loss: 0.65379 | Time: 0.48 seconds\n",
            "Epoch: 132 | Train Loss: 0.65402 | Valid Loss: 0.65343 | Time: 0.46 seconds\n",
            "Epoch: 133 | Train Loss: 0.65333 | Valid Loss: 0.65232 | Time: 0.47 seconds\n",
            "Epoch: 134 | Train Loss: 0.65264 | Valid Loss: 0.65169 | Time: 0.48 seconds\n",
            "Epoch: 135 | Train Loss: 0.65196 | Valid Loss: 0.65148 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65126 | Valid Loss: 0.65121 | Time: 0.48 seconds\n",
            "Epoch: 137 | Train Loss: 0.65057 | Valid Loss: 0.64910 | Time: 0.47 seconds\n",
            "Epoch: 138 | Train Loss: 0.64987 | Valid Loss: 0.64859 | Time: 0.46 seconds\n",
            "Epoch: 139 | Train Loss: 0.64917 | Valid Loss: 0.64859 | Time: 0.48 seconds\n",
            "Epoch: 140 | Train Loss: 0.64847 | Valid Loss: 0.64756 | Time: 0.45 seconds\n",
            "Epoch: 141 | Train Loss: 0.64777 | Valid Loss: 0.64662 | Time: 0.47 seconds\n",
            "Epoch: 142 | Train Loss: 0.64704 | Valid Loss: 0.64658 | Time: 0.47 seconds\n",
            "Epoch: 143 | Train Loss: 0.64634 | Valid Loss: 0.64556 | Time: 0.46 seconds\n",
            "Epoch: 144 | Train Loss: 0.64562 | Valid Loss: 0.64436 | Time: 0.47 seconds\n",
            "Epoch: 145 | Train Loss: 0.64492 | Valid Loss: 0.64380 | Time: 0.46 seconds\n",
            "Epoch: 146 | Train Loss: 0.64419 | Valid Loss: 0.64375 | Time: 0.48 seconds\n",
            "Epoch: 147 | Train Loss: 0.64347 | Valid Loss: 0.64244 | Time: 0.47 seconds\n",
            "Epoch: 148 | Train Loss: 0.64274 | Valid Loss: 0.64251 | Time: 0.46 seconds\n",
            "Epoch: 149 | Train Loss: 0.64202 | Valid Loss: 0.64311 | Time: 0.45 seconds\n",
            "Epoch: 150 | Train Loss: 0.64127 | Valid Loss: 0.63958 | Time: 0.48 seconds\n",
            "Epoch: 151 | Train Loss: 0.64055 | Valid Loss: 0.63937 | Time: 0.46 seconds\n",
            "Epoch: 152 | Train Loss: 0.63983 | Valid Loss: 0.63919 | Time: 0.46 seconds\n",
            "Epoch: 153 | Train Loss: 0.63908 | Valid Loss: 0.63758 | Time: 0.47 seconds\n",
            "Epoch: 154 | Train Loss: 0.63834 | Valid Loss: 0.63825 | Time: 0.47 seconds\n",
            "Epoch: 155 | Train Loss: 0.63760 | Valid Loss: 0.63637 | Time: 0.48 seconds\n",
            "Epoch: 156 | Train Loss: 0.63685 | Valid Loss: 0.63641 | Time: 0.46 seconds\n",
            "Epoch: 157 | Train Loss: 0.63610 | Valid Loss: 0.63422 | Time: 0.47 seconds\n",
            "Epoch: 158 | Train Loss: 0.63535 | Valid Loss: 0.63382 | Time: 0.48 seconds\n",
            "Epoch: 159 | Train Loss: 0.63460 | Valid Loss: 0.63308 | Time: 0.47 seconds\n",
            "Epoch: 160 | Train Loss: 0.63385 | Valid Loss: 0.63392 | Time: 0.47 seconds\n",
            "Epoch: 161 | Train Loss: 0.63309 | Valid Loss: 0.63249 | Time: 0.47 seconds\n",
            "Epoch: 162 | Train Loss: 0.63233 | Valid Loss: 0.63111 | Time: 0.46 seconds\n",
            "Epoch: 163 | Train Loss: 0.63157 | Valid Loss: 0.63092 | Time: 0.46 seconds\n",
            "Epoch: 164 | Train Loss: 0.63080 | Valid Loss: 0.62953 | Time: 0.46 seconds\n",
            "Epoch: 165 | Train Loss: 0.63004 | Valid Loss: 0.63054 | Time: 0.46 seconds\n",
            "Epoch: 166 | Train Loss: 0.62928 | Valid Loss: 0.62877 | Time: 0.46 seconds\n",
            "Epoch: 167 | Train Loss: 0.62850 | Valid Loss: 0.62760 | Time: 0.47 seconds\n",
            "Epoch: 168 | Train Loss: 0.62774 | Valid Loss: 0.62692 | Time: 0.48 seconds\n",
            "Epoch: 169 | Train Loss: 0.62696 | Valid Loss: 0.62608 | Time: 0.46 seconds\n",
            "Epoch: 170 | Train Loss: 0.62619 | Valid Loss: 0.62621 | Time: 0.46 seconds\n",
            "Epoch: 171 | Train Loss: 0.62540 | Valid Loss: 0.62467 | Time: 0.49 seconds\n",
            "Epoch: 172 | Train Loss: 0.62463 | Valid Loss: 0.62346 | Time: 0.47 seconds\n",
            "Epoch: 173 | Train Loss: 0.62385 | Valid Loss: 0.62278 | Time: 0.47 seconds\n",
            "Epoch: 174 | Train Loss: 0.62307 | Valid Loss: 0.62273 | Time: 0.47 seconds\n",
            "Epoch: 175 | Train Loss: 0.62228 | Valid Loss: 0.62121 | Time: 0.46 seconds\n",
            "Epoch: 176 | Train Loss: 0.62150 | Valid Loss: 0.61996 | Time: 0.48 seconds\n",
            "Epoch: 177 | Train Loss: 0.62070 | Valid Loss: 0.61940 | Time: 0.46 seconds\n",
            "Epoch: 178 | Train Loss: 0.61992 | Valid Loss: 0.61816 | Time: 0.46 seconds\n",
            "Epoch: 179 | Train Loss: 0.61913 | Valid Loss: 0.61788 | Time: 0.47 seconds\n",
            "Epoch: 180 | Train Loss: 0.61833 | Valid Loss: 0.61776 | Time: 0.47 seconds\n",
            "Epoch: 181 | Train Loss: 0.61755 | Valid Loss: 0.61599 | Time: 0.48 seconds\n",
            "Epoch: 182 | Train Loss: 0.61676 | Valid Loss: 0.61657 | Time: 0.46 seconds\n",
            "Epoch: 183 | Train Loss: 0.61595 | Valid Loss: 0.61467 | Time: 0.49 seconds\n",
            "Epoch: 184 | Train Loss: 0.61515 | Valid Loss: 0.61304 | Time: 0.46 seconds\n",
            "Epoch: 185 | Train Loss: 0.61434 | Valid Loss: 0.61435 | Time: 0.48 seconds\n",
            "Epoch: 186 | Train Loss: 0.61356 | Valid Loss: 0.61247 | Time: 0.47 seconds\n",
            "Epoch: 187 | Train Loss: 0.61275 | Valid Loss: 0.61184 | Time: 0.47 seconds\n",
            "Epoch: 188 | Train Loss: 0.61195 | Valid Loss: 0.61116 | Time: 0.47 seconds\n",
            "Epoch: 189 | Train Loss: 0.61114 | Valid Loss: 0.60987 | Time: 0.50 seconds\n",
            "Epoch: 190 | Train Loss: 0.61033 | Valid Loss: 0.61002 | Time: 0.46 seconds\n",
            "Epoch: 191 | Train Loss: 0.60952 | Valid Loss: 0.60836 | Time: 0.48 seconds\n",
            "Epoch: 192 | Train Loss: 0.60872 | Valid Loss: 0.60839 | Time: 0.46 seconds\n",
            "Epoch: 193 | Train Loss: 0.60791 | Valid Loss: 0.60836 | Time: 0.45 seconds\n",
            "Epoch: 194 | Train Loss: 0.60709 | Valid Loss: 0.60573 | Time: 0.47 seconds\n",
            "Epoch: 195 | Train Loss: 0.60628 | Valid Loss: 0.60481 | Time: 0.48 seconds\n",
            "Epoch: 196 | Train Loss: 0.60546 | Valid Loss: 0.60423 | Time: 0.47 seconds\n",
            "Epoch: 197 | Train Loss: 0.60464 | Valid Loss: 0.60308 | Time: 0.46 seconds\n",
            "Epoch: 198 | Train Loss: 0.60383 | Valid Loss: 0.60122 | Time: 0.47 seconds\n",
            "Epoch: 199 | Train Loss: 0.60302 | Valid Loss: 0.60293 | Time: 0.45 seconds\n",
            "Epoch: 200 | Train Loss: 0.60220 | Valid Loss: 0.60090 | Time: 0.49 seconds\n",
            "Epoch: 201 | Train Loss: 0.60138 | Valid Loss: 0.59982 | Time: 0.47 seconds\n",
            "Epoch: 202 | Train Loss: 0.60055 | Valid Loss: 0.59997 | Time: 0.46 seconds\n",
            "Epoch: 203 | Train Loss: 0.59973 | Valid Loss: 0.59837 | Time: 0.47 seconds\n",
            "Epoch: 204 | Train Loss: 0.59890 | Valid Loss: 0.59652 | Time: 0.48 seconds\n",
            "Epoch: 205 | Train Loss: 0.59807 | Valid Loss: 0.59634 | Time: 0.47 seconds\n",
            "Epoch: 206 | Train Loss: 0.59726 | Valid Loss: 0.59630 | Time: 0.46 seconds\n",
            "Epoch: 207 | Train Loss: 0.59642 | Valid Loss: 0.59659 | Time: 0.48 seconds\n",
            "Epoch: 208 | Train Loss: 0.59560 | Valid Loss: 0.59514 | Time: 0.47 seconds\n",
            "Epoch: 209 | Train Loss: 0.59477 | Valid Loss: 0.59311 | Time: 0.48 seconds\n",
            "Epoch: 210 | Train Loss: 0.59394 | Valid Loss: 0.59205 | Time: 0.46 seconds\n",
            "Epoch: 211 | Train Loss: 0.59311 | Valid Loss: 0.59212 | Time: 0.47 seconds\n",
            "Epoch: 212 | Train Loss: 0.59228 | Valid Loss: 0.59070 | Time: 0.46 seconds\n",
            "Epoch: 213 | Train Loss: 0.59143 | Valid Loss: 0.59182 | Time: 0.48 seconds\n",
            "Epoch: 214 | Train Loss: 0.59060 | Valid Loss: 0.58846 | Time: 0.46 seconds\n",
            "Epoch: 215 | Train Loss: 0.58977 | Valid Loss: 0.58860 | Time: 0.47 seconds\n",
            "Epoch: 216 | Train Loss: 0.58893 | Valid Loss: 0.58822 | Time: 0.48 seconds\n",
            "Epoch: 217 | Train Loss: 0.58810 | Valid Loss: 0.58711 | Time: 0.47 seconds\n",
            "Epoch: 218 | Train Loss: 0.58726 | Valid Loss: 0.58553 | Time: 0.46 seconds\n",
            "Epoch: 219 | Train Loss: 0.58642 | Valid Loss: 0.58410 | Time: 0.46 seconds\n",
            "Epoch: 220 | Train Loss: 0.58557 | Valid Loss: 0.58486 | Time: 0.46 seconds\n",
            "Epoch: 221 | Train Loss: 0.58473 | Valid Loss: 0.58303 | Time: 0.45 seconds\n",
            "Epoch: 222 | Train Loss: 0.58390 | Valid Loss: 0.58173 | Time: 0.49 seconds\n",
            "Epoch: 223 | Train Loss: 0.58306 | Valid Loss: 0.58170 | Time: 0.46 seconds\n",
            "Epoch: 224 | Train Loss: 0.58221 | Valid Loss: 0.57907 | Time: 0.47 seconds\n",
            "Epoch: 225 | Train Loss: 0.58137 | Valid Loss: 0.57972 | Time: 0.45 seconds\n",
            "Epoch: 226 | Train Loss: 0.58052 | Valid Loss: 0.57818 | Time: 0.47 seconds\n",
            "Epoch: 227 | Train Loss: 0.57967 | Valid Loss: 0.57756 | Time: 0.47 seconds\n",
            "Epoch: 228 | Train Loss: 0.57882 | Valid Loss: 0.57662 | Time: 0.48 seconds\n",
            "Epoch: 229 | Train Loss: 0.57798 | Valid Loss: 0.57780 | Time: 0.45 seconds\n",
            "Epoch: 230 | Train Loss: 0.57712 | Valid Loss: 0.57440 | Time: 0.47 seconds\n",
            "Epoch: 231 | Train Loss: 0.57628 | Valid Loss: 0.57494 | Time: 0.48 seconds\n",
            "Epoch: 232 | Train Loss: 0.57543 | Valid Loss: 0.57317 | Time: 0.48 seconds\n",
            "Epoch: 233 | Train Loss: 0.57457 | Valid Loss: 0.57322 | Time: 0.46 seconds\n",
            "Epoch: 234 | Train Loss: 0.57374 | Valid Loss: 0.57253 | Time: 0.47 seconds\n",
            "Epoch: 235 | Train Loss: 0.57286 | Valid Loss: 0.57148 | Time: 0.48 seconds\n",
            "Epoch: 236 | Train Loss: 0.57203 | Valid Loss: 0.57133 | Time: 0.46 seconds\n",
            "Epoch: 237 | Train Loss: 0.57117 | Valid Loss: 0.56972 | Time: 0.48 seconds\n",
            "Epoch: 238 | Train Loss: 0.57032 | Valid Loss: 0.56886 | Time: 0.47 seconds\n",
            "Epoch: 239 | Train Loss: 0.56946 | Valid Loss: 0.56876 | Time: 0.47 seconds\n",
            "Epoch: 240 | Train Loss: 0.56860 | Valid Loss: 0.56865 | Time: 0.46 seconds\n",
            "Epoch: 241 | Train Loss: 0.56774 | Valid Loss: 0.56759 | Time: 0.47 seconds\n",
            "Epoch: 242 | Train Loss: 0.56690 | Valid Loss: 0.56495 | Time: 0.47 seconds\n",
            "Epoch: 243 | Train Loss: 0.56602 | Valid Loss: 0.56337 | Time: 0.46 seconds\n",
            "Epoch: 244 | Train Loss: 0.56517 | Valid Loss: 0.56358 | Time: 0.46 seconds\n",
            "Epoch: 245 | Train Loss: 0.56431 | Valid Loss: 0.56350 | Time: 0.45 seconds\n",
            "Epoch: 246 | Train Loss: 0.56345 | Valid Loss: 0.56200 | Time: 0.47 seconds\n",
            "Epoch: 247 | Train Loss: 0.56260 | Valid Loss: 0.56156 | Time: 0.48 seconds\n",
            "Epoch: 248 | Train Loss: 0.56173 | Valid Loss: 0.56079 | Time: 0.46 seconds\n",
            "Epoch: 249 | Train Loss: 0.56087 | Valid Loss: 0.55971 | Time: 0.48 seconds\n",
            "Epoch: 250 | Train Loss: 0.56001 | Valid Loss: 0.55847 | Time: 0.49 seconds\n",
            "Epoch: 251 | Train Loss: 0.55915 | Valid Loss: 0.55498 | Time: 0.47 seconds\n",
            "Epoch: 252 | Train Loss: 0.55828 | Valid Loss: 0.55857 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55741 | Valid Loss: 0.55479 | Time: 0.46 seconds\n",
            "Epoch: 254 | Train Loss: 0.55656 | Valid Loss: 0.55570 | Time: 0.46 seconds\n",
            "Epoch: 255 | Train Loss: 0.55569 | Valid Loss: 0.55344 | Time: 0.47 seconds\n",
            "Epoch: 256 | Train Loss: 0.55482 | Valid Loss: 0.55468 | Time: 0.45 seconds\n",
            "Epoch: 257 | Train Loss: 0.55396 | Valid Loss: 0.55252 | Time: 0.46 seconds\n",
            "Epoch: 258 | Train Loss: 0.55309 | Valid Loss: 0.55080 | Time: 0.45 seconds\n",
            "Epoch: 259 | Train Loss: 0.55222 | Valid Loss: 0.55169 | Time: 0.46 seconds\n",
            "Epoch: 260 | Train Loss: 0.55135 | Valid Loss: 0.54924 | Time: 0.47 seconds\n",
            "Epoch: 261 | Train Loss: 0.55049 | Valid Loss: 0.54921 | Time: 0.46 seconds\n",
            "Epoch: 262 | Train Loss: 0.54963 | Valid Loss: 0.54711 | Time: 0.45 seconds\n",
            "Epoch: 263 | Train Loss: 0.54875 | Valid Loss: 0.54691 | Time: 0.47 seconds\n",
            "Epoch: 264 | Train Loss: 0.54788 | Valid Loss: 0.54619 | Time: 0.47 seconds\n",
            "Epoch: 265 | Train Loss: 0.54703 | Valid Loss: 0.54631 | Time: 0.46 seconds\n",
            "Epoch: 266 | Train Loss: 0.54616 | Valid Loss: 0.54490 | Time: 0.45 seconds\n",
            "Epoch: 267 | Train Loss: 0.54528 | Valid Loss: 0.54430 | Time: 0.45 seconds\n",
            "Epoch: 268 | Train Loss: 0.54441 | Valid Loss: 0.54082 | Time: 0.47 seconds\n",
            "Epoch: 269 | Train Loss: 0.54354 | Valid Loss: 0.54293 | Time: 0.47 seconds\n",
            "Epoch: 270 | Train Loss: 0.54266 | Valid Loss: 0.54258 | Time: 0.46 seconds\n",
            "Epoch: 271 | Train Loss: 0.54180 | Valid Loss: 0.53983 | Time: 0.46 seconds\n",
            "Epoch: 272 | Train Loss: 0.54094 | Valid Loss: 0.53996 | Time: 0.47 seconds\n",
            "Epoch: 273 | Train Loss: 0.54006 | Valid Loss: 0.53926 | Time: 0.46 seconds\n",
            "Epoch: 274 | Train Loss: 0.53917 | Valid Loss: 0.53661 | Time: 0.48 seconds\n",
            "Epoch: 275 | Train Loss: 0.53831 | Valid Loss: 0.53654 | Time: 0.46 seconds\n",
            "Epoch: 276 | Train Loss: 0.53744 | Valid Loss: 0.53705 | Time: 0.46 seconds\n",
            "Epoch: 277 | Train Loss: 0.53657 | Valid Loss: 0.53416 | Time: 0.46 seconds\n",
            "Epoch: 278 | Train Loss: 0.53570 | Valid Loss: 0.53456 | Time: 0.47 seconds\n",
            "Epoch: 279 | Train Loss: 0.53483 | Valid Loss: 0.53210 | Time: 0.47 seconds\n",
            "Epoch: 280 | Train Loss: 0.53396 | Valid Loss: 0.53281 | Time: 0.46 seconds\n",
            "Epoch: 281 | Train Loss: 0.53307 | Valid Loss: 0.53194 | Time: 0.47 seconds\n",
            "Epoch: 282 | Train Loss: 0.53221 | Valid Loss: 0.53269 | Time: 0.46 seconds\n",
            "Epoch: 283 | Train Loss: 0.53131 | Valid Loss: 0.52862 | Time: 0.48 seconds\n",
            "Epoch: 284 | Train Loss: 0.53045 | Valid Loss: 0.52737 | Time: 0.46 seconds\n",
            "Epoch: 285 | Train Loss: 0.52957 | Valid Loss: 0.52828 | Time: 0.46 seconds\n",
            "Epoch: 286 | Train Loss: 0.52871 | Valid Loss: 0.52749 | Time: 0.45 seconds\n",
            "Epoch: 287 | Train Loss: 0.52783 | Valid Loss: 0.52616 | Time: 0.47 seconds\n",
            "Epoch: 288 | Train Loss: 0.52697 | Valid Loss: 0.52445 | Time: 0.48 seconds\n",
            "Epoch: 289 | Train Loss: 0.52608 | Valid Loss: 0.52445 | Time: 0.46 seconds\n",
            "Epoch: 290 | Train Loss: 0.52520 | Valid Loss: 0.52462 | Time: 0.45 seconds\n",
            "Epoch: 291 | Train Loss: 0.52435 | Valid Loss: 0.52311 | Time: 0.46 seconds\n",
            "Epoch: 292 | Train Loss: 0.52346 | Valid Loss: 0.52372 | Time: 0.46 seconds\n",
            "Epoch: 293 | Train Loss: 0.52259 | Valid Loss: 0.52065 | Time: 0.47 seconds\n",
            "Epoch: 294 | Train Loss: 0.52172 | Valid Loss: 0.51853 | Time: 0.47 seconds\n",
            "Epoch: 295 | Train Loss: 0.52084 | Valid Loss: 0.52001 | Time: 0.45 seconds\n",
            "Epoch: 296 | Train Loss: 0.51998 | Valid Loss: 0.51784 | Time: 0.46 seconds\n",
            "Epoch: 297 | Train Loss: 0.51909 | Valid Loss: 0.51666 | Time: 0.46 seconds\n",
            "Epoch: 298 | Train Loss: 0.51820 | Valid Loss: 0.51704 | Time: 0.47 seconds\n",
            "Epoch: 299 | Train Loss: 0.51737 | Valid Loss: 0.51531 | Time: 0.46 seconds\n",
            "Epoch: 300 | Train Loss: 0.51646 | Valid Loss: 0.51617 | Time: 0.46 seconds\n",
            "Epoch: 301 | Train Loss: 0.51560 | Valid Loss: 0.51378 | Time: 0.46 seconds\n",
            "Epoch: 302 | Train Loss: 0.51474 | Valid Loss: 0.51362 | Time: 0.47 seconds\n",
            "Epoch: 303 | Train Loss: 0.51384 | Valid Loss: 0.51259 | Time: 0.47 seconds\n",
            "Epoch: 304 | Train Loss: 0.51298 | Valid Loss: 0.51020 | Time: 0.47 seconds\n",
            "Epoch: 305 | Train Loss: 0.51209 | Valid Loss: 0.51130 | Time: 0.46 seconds\n",
            "Epoch: 306 | Train Loss: 0.51124 | Valid Loss: 0.50858 | Time: 0.46 seconds\n",
            "Epoch: 307 | Train Loss: 0.51038 | Valid Loss: 0.50782 | Time: 0.47 seconds\n",
            "Epoch: 308 | Train Loss: 0.50951 | Valid Loss: 0.50818 | Time: 0.46 seconds\n",
            "Epoch: 309 | Train Loss: 0.50862 | Valid Loss: 0.50628 | Time: 0.48 seconds\n",
            "Epoch: 310 | Train Loss: 0.50775 | Valid Loss: 0.50510 | Time: 0.48 seconds\n",
            "Epoch: 311 | Train Loss: 0.50689 | Valid Loss: 0.50696 | Time: 0.47 seconds\n",
            "Epoch: 312 | Train Loss: 0.50602 | Valid Loss: 0.50320 | Time: 0.45 seconds\n",
            "Epoch: 313 | Train Loss: 0.50514 | Valid Loss: 0.50402 | Time: 0.47 seconds\n",
            "Epoch: 314 | Train Loss: 0.50426 | Valid Loss: 0.50167 | Time: 0.46 seconds\n",
            "Epoch: 315 | Train Loss: 0.50340 | Valid Loss: 0.50320 | Time: 0.46 seconds\n",
            "Epoch: 316 | Train Loss: 0.50250 | Valid Loss: 0.49865 | Time: 0.47 seconds\n",
            "Epoch: 317 | Train Loss: 0.50166 | Valid Loss: 0.50020 | Time: 0.45 seconds\n",
            "Epoch: 318 | Train Loss: 0.50080 | Valid Loss: 0.49983 | Time: 0.47 seconds\n",
            "Epoch: 319 | Train Loss: 0.49992 | Valid Loss: 0.49808 | Time: 0.47 seconds\n",
            "Epoch: 320 | Train Loss: 0.49906 | Valid Loss: 0.49766 | Time: 0.47 seconds\n",
            "Epoch: 321 | Train Loss: 0.49819 | Valid Loss: 0.49587 | Time: 0.47 seconds\n",
            "Epoch: 322 | Train Loss: 0.49732 | Valid Loss: 0.49499 | Time: 0.47 seconds\n",
            "Epoch: 323 | Train Loss: 0.49645 | Valid Loss: 0.49106 | Time: 0.48 seconds\n",
            "Epoch: 324 | Train Loss: 0.49558 | Valid Loss: 0.49362 | Time: 0.47 seconds\n",
            "Epoch: 325 | Train Loss: 0.49470 | Valid Loss: 0.49181 | Time: 0.47 seconds\n",
            "Epoch: 326 | Train Loss: 0.49384 | Valid Loss: 0.49208 | Time: 0.48 seconds\n",
            "Epoch: 327 | Train Loss: 0.49298 | Valid Loss: 0.48949 | Time: 0.48 seconds\n",
            "Epoch: 328 | Train Loss: 0.49212 | Valid Loss: 0.49054 | Time: 0.48 seconds\n",
            "Epoch: 329 | Train Loss: 0.49125 | Valid Loss: 0.48740 | Time: 0.49 seconds\n",
            "Epoch: 330 | Train Loss: 0.49038 | Valid Loss: 0.48686 | Time: 0.47 seconds\n",
            "Epoch: 331 | Train Loss: 0.48955 | Valid Loss: 0.48810 | Time: 0.48 seconds\n",
            "Epoch: 332 | Train Loss: 0.48867 | Valid Loss: 0.48432 | Time: 0.50 seconds\n",
            "Epoch: 333 | Train Loss: 0.48779 | Valid Loss: 0.48529 | Time: 0.48 seconds\n",
            "Epoch: 334 | Train Loss: 0.48696 | Valid Loss: 0.48607 | Time: 0.45 seconds\n",
            "Epoch: 335 | Train Loss: 0.48608 | Valid Loss: 0.48493 | Time: 0.47 seconds\n",
            "Epoch: 336 | Train Loss: 0.48522 | Valid Loss: 0.48474 | Time: 0.47 seconds\n",
            "Epoch: 337 | Train Loss: 0.48437 | Valid Loss: 0.48151 | Time: 0.48 seconds\n",
            "Epoch: 338 | Train Loss: 0.48348 | Valid Loss: 0.48181 | Time: 0.47 seconds\n",
            "Epoch: 339 | Train Loss: 0.48264 | Valid Loss: 0.48162 | Time: 0.47 seconds\n",
            "Epoch: 340 | Train Loss: 0.48178 | Valid Loss: 0.48143 | Time: 0.46 seconds\n",
            "Epoch: 341 | Train Loss: 0.48093 | Valid Loss: 0.47799 | Time: 0.49 seconds\n",
            "Epoch: 342 | Train Loss: 0.48008 | Valid Loss: 0.47670 | Time: 0.47 seconds\n",
            "Epoch: 343 | Train Loss: 0.47922 | Valid Loss: 0.47580 | Time: 0.48 seconds\n",
            "Epoch: 344 | Train Loss: 0.47834 | Valid Loss: 0.47597 | Time: 0.47 seconds\n",
            "Epoch: 345 | Train Loss: 0.47750 | Valid Loss: 0.47436 | Time: 0.47 seconds\n",
            "Epoch: 346 | Train Loss: 0.47665 | Valid Loss: 0.47586 | Time: 0.47 seconds\n",
            "Epoch: 347 | Train Loss: 0.47580 | Valid Loss: 0.47378 | Time: 0.47 seconds\n",
            "Epoch: 348 | Train Loss: 0.47496 | Valid Loss: 0.47183 | Time: 0.47 seconds\n",
            "Epoch: 349 | Train Loss: 0.47410 | Valid Loss: 0.47252 | Time: 0.45 seconds\n",
            "Epoch: 350 | Train Loss: 0.47326 | Valid Loss: 0.47151 | Time: 0.49 seconds\n",
            "Epoch: 351 | Train Loss: 0.47239 | Valid Loss: 0.46993 | Time: 0.46 seconds\n",
            "Epoch: 352 | Train Loss: 0.47155 | Valid Loss: 0.46765 | Time: 0.48 seconds\n",
            "Epoch: 353 | Train Loss: 0.47071 | Valid Loss: 0.46949 | Time: 0.46 seconds\n",
            "Epoch: 354 | Train Loss: 0.46986 | Valid Loss: 0.46745 | Time: 0.48 seconds\n",
            "Epoch: 355 | Train Loss: 0.46900 | Valid Loss: 0.46760 | Time: 0.48 seconds\n",
            "Epoch: 356 | Train Loss: 0.46816 | Valid Loss: 0.46523 | Time: 0.48 seconds\n",
            "Epoch: 357 | Train Loss: 0.46732 | Valid Loss: 0.46668 | Time: 0.48 seconds\n",
            "Epoch: 358 | Train Loss: 0.46648 | Valid Loss: 0.46288 | Time: 0.46 seconds\n",
            "Epoch: 359 | Train Loss: 0.46563 | Valid Loss: 0.46234 | Time: 0.48 seconds\n",
            "Epoch: 360 | Train Loss: 0.46477 | Valid Loss: 0.46263 | Time: 0.46 seconds\n",
            "Epoch: 361 | Train Loss: 0.46395 | Valid Loss: 0.46093 | Time: 0.49 seconds\n",
            "Epoch: 362 | Train Loss: 0.46312 | Valid Loss: 0.46124 | Time: 0.46 seconds\n",
            "Epoch: 363 | Train Loss: 0.46225 | Valid Loss: 0.45927 | Time: 0.47 seconds\n",
            "Epoch: 364 | Train Loss: 0.46143 | Valid Loss: 0.46088 | Time: 0.46 seconds\n",
            "Epoch: 365 | Train Loss: 0.46060 | Valid Loss: 0.45664 | Time: 0.48 seconds\n",
            "Epoch: 366 | Train Loss: 0.45975 | Valid Loss: 0.45746 | Time: 0.47 seconds\n",
            "Epoch: 367 | Train Loss: 0.45893 | Valid Loss: 0.45890 | Time: 0.47 seconds\n",
            "Epoch: 368 | Train Loss: 0.45809 | Valid Loss: 0.45704 | Time: 0.45 seconds\n",
            "Epoch: 369 | Train Loss: 0.45726 | Valid Loss: 0.45525 | Time: 0.46 seconds\n",
            "Epoch: 370 | Train Loss: 0.45643 | Valid Loss: 0.45268 | Time: 0.48 seconds\n",
            "Epoch: 371 | Train Loss: 0.45560 | Valid Loss: 0.45303 | Time: 0.48 seconds\n",
            "Epoch: 372 | Train Loss: 0.45475 | Valid Loss: 0.45243 | Time: 0.48 seconds\n",
            "Epoch: 373 | Train Loss: 0.45394 | Valid Loss: 0.45139 | Time: 0.46 seconds\n",
            "Epoch: 374 | Train Loss: 0.45313 | Valid Loss: 0.45062 | Time: 0.47 seconds\n",
            "Epoch: 375 | Train Loss: 0.45227 | Valid Loss: 0.44990 | Time: 0.49 seconds\n",
            "Epoch: 376 | Train Loss: 0.45145 | Valid Loss: 0.44910 | Time: 0.46 seconds\n",
            "Epoch: 377 | Train Loss: 0.45064 | Valid Loss: 0.45001 | Time: 0.45 seconds\n",
            "Epoch: 378 | Train Loss: 0.44981 | Valid Loss: 0.44665 | Time: 0.47 seconds\n",
            "Epoch: 379 | Train Loss: 0.44900 | Valid Loss: 0.44406 | Time: 0.46 seconds\n",
            "Epoch: 380 | Train Loss: 0.44817 | Valid Loss: 0.44733 | Time: 0.46 seconds\n",
            "Epoch: 381 | Train Loss: 0.44737 | Valid Loss: 0.44512 | Time: 0.44 seconds\n",
            "Epoch: 382 | Train Loss: 0.44655 | Valid Loss: 0.44400 | Time: 0.47 seconds\n",
            "Epoch: 383 | Train Loss: 0.44573 | Valid Loss: 0.44350 | Time: 0.47 seconds\n",
            "Epoch: 384 | Train Loss: 0.44494 | Valid Loss: 0.44350 | Time: 0.46 seconds\n",
            "Epoch: 385 | Train Loss: 0.44411 | Valid Loss: 0.44139 | Time: 0.49 seconds\n",
            "Epoch: 386 | Train Loss: 0.44328 | Valid Loss: 0.44197 | Time: 0.47 seconds\n",
            "Epoch: 387 | Train Loss: 0.44247 | Valid Loss: 0.44133 | Time: 0.49 seconds\n",
            "Epoch: 388 | Train Loss: 0.44167 | Valid Loss: 0.43947 | Time: 0.46 seconds\n",
            "Epoch: 389 | Train Loss: 0.44085 | Valid Loss: 0.43933 | Time: 0.48 seconds\n",
            "Epoch: 390 | Train Loss: 0.44002 | Valid Loss: 0.43983 | Time: 0.45 seconds\n",
            "Epoch: 391 | Train Loss: 0.43923 | Valid Loss: 0.43761 | Time: 0.48 seconds\n",
            "Epoch: 392 | Train Loss: 0.43843 | Valid Loss: 0.43655 | Time: 0.47 seconds\n",
            "Epoch: 393 | Train Loss: 0.43762 | Valid Loss: 0.43554 | Time: 0.47 seconds\n",
            "Epoch: 394 | Train Loss: 0.43682 | Valid Loss: 0.43448 | Time: 0.47 seconds\n",
            "Epoch: 395 | Train Loss: 0.43601 | Valid Loss: 0.43412 | Time: 0.46 seconds\n",
            "Epoch: 396 | Train Loss: 0.43523 | Valid Loss: 0.43021 | Time: 0.47 seconds\n",
            "Epoch: 397 | Train Loss: 0.43441 | Valid Loss: 0.43150 | Time: 0.49 seconds\n",
            "Epoch: 398 | Train Loss: 0.43363 | Valid Loss: 0.43320 | Time: 0.48 seconds\n",
            "Epoch: 399 | Train Loss: 0.43280 | Valid Loss: 0.43029 | Time: 0.47 seconds\n",
            "Epoch: 400 | Train Loss: 0.43204 | Valid Loss: 0.43066 | Time: 0.47 seconds\n",
            "Epoch: 401 | Train Loss: 0.43122 | Valid Loss: 0.42807 | Time: 0.45 seconds\n",
            "Epoch: 402 | Train Loss: 0.43045 | Valid Loss: 0.42821 | Time: 0.48 seconds\n",
            "Epoch: 403 | Train Loss: 0.42966 | Valid Loss: 0.42790 | Time: 0.47 seconds\n",
            "Epoch: 404 | Train Loss: 0.42887 | Valid Loss: 0.42442 | Time: 0.48 seconds\n",
            "Epoch: 405 | Train Loss: 0.42807 | Valid Loss: 0.42645 | Time: 0.45 seconds\n",
            "Epoch: 406 | Train Loss: 0.42728 | Valid Loss: 0.42287 | Time: 0.47 seconds\n",
            "Epoch: 407 | Train Loss: 0.42651 | Valid Loss: 0.42380 | Time: 0.46 seconds\n",
            "Epoch: 408 | Train Loss: 0.42568 | Valid Loss: 0.42317 | Time: 0.47 seconds\n",
            "Epoch: 409 | Train Loss: 0.42493 | Valid Loss: 0.42318 | Time: 0.47 seconds\n",
            "Epoch: 410 | Train Loss: 0.42416 | Valid Loss: 0.41788 | Time: 0.48 seconds\n",
            "Epoch: 411 | Train Loss: 0.42335 | Valid Loss: 0.42382 | Time: 0.48 seconds\n",
            "Epoch: 412 | Train Loss: 0.42262 | Valid Loss: 0.41965 | Time: 0.46 seconds\n",
            "Epoch: 413 | Train Loss: 0.42182 | Valid Loss: 0.42046 | Time: 0.46 seconds\n",
            "Epoch: 414 | Train Loss: 0.42105 | Valid Loss: 0.41787 | Time: 0.47 seconds\n",
            "Epoch: 415 | Train Loss: 0.42030 | Valid Loss: 0.41726 | Time: 0.47 seconds\n",
            "Epoch: 416 | Train Loss: 0.41950 | Valid Loss: 0.41943 | Time: 0.46 seconds\n",
            "Epoch: 417 | Train Loss: 0.41870 | Valid Loss: 0.41676 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41797 | Valid Loss: 0.41505 | Time: 0.47 seconds\n",
            "Epoch: 419 | Train Loss: 0.41717 | Valid Loss: 0.41524 | Time: 0.48 seconds\n",
            "Epoch: 420 | Train Loss: 0.41644 | Valid Loss: 0.41430 | Time: 0.47 seconds\n",
            "Epoch: 421 | Train Loss: 0.41564 | Valid Loss: 0.41437 | Time: 0.46 seconds\n",
            "Epoch: 422 | Train Loss: 0.41490 | Valid Loss: 0.41269 | Time: 0.47 seconds\n",
            "Epoch: 423 | Train Loss: 0.41411 | Valid Loss: 0.41158 | Time: 0.48 seconds\n",
            "Epoch: 424 | Train Loss: 0.41335 | Valid Loss: 0.41131 | Time: 0.48 seconds\n",
            "Epoch: 425 | Train Loss: 0.41261 | Valid Loss: 0.41097 | Time: 0.46 seconds\n",
            "Epoch: 426 | Train Loss: 0.41186 | Valid Loss: 0.40693 | Time: 0.47 seconds\n",
            "Epoch: 427 | Train Loss: 0.41112 | Valid Loss: 0.40904 | Time: 0.45 seconds\n",
            "Epoch: 428 | Train Loss: 0.41032 | Valid Loss: 0.40807 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40962 | Valid Loss: 0.40829 | Time: 0.46 seconds\n",
            "Epoch: 430 | Train Loss: 0.40885 | Valid Loss: 0.40472 | Time: 0.48 seconds\n",
            "Epoch: 431 | Train Loss: 0.40808 | Valid Loss: 0.40552 | Time: 0.46 seconds\n",
            "Epoch: 432 | Train Loss: 0.40735 | Valid Loss: 0.40455 | Time: 0.47 seconds\n",
            "Epoch: 433 | Train Loss: 0.40660 | Valid Loss: 0.40696 | Time: 0.46 seconds\n",
            "Epoch: 434 | Train Loss: 0.40586 | Valid Loss: 0.40325 | Time: 0.47 seconds\n",
            "Epoch: 435 | Train Loss: 0.40511 | Valid Loss: 0.40266 | Time: 0.47 seconds\n",
            "Epoch: 436 | Train Loss: 0.40439 | Valid Loss: 0.40173 | Time: 0.50 seconds\n",
            "Epoch: 437 | Train Loss: 0.40362 | Valid Loss: 0.40130 | Time: 0.48 seconds\n",
            "Epoch: 438 | Train Loss: 0.40286 | Valid Loss: 0.39856 | Time: 0.48 seconds\n",
            "Epoch: 439 | Train Loss: 0.40217 | Valid Loss: 0.40146 | Time: 0.50 seconds\n",
            "Epoch: 440 | Train Loss: 0.40141 | Valid Loss: 0.39680 | Time: 0.47 seconds\n",
            "Epoch: 441 | Train Loss: 0.40068 | Valid Loss: 0.40022 | Time: 0.47 seconds\n",
            "Epoch: 442 | Train Loss: 0.39996 | Valid Loss: 0.39866 | Time: 0.46 seconds\n",
            "Epoch: 443 | Train Loss: 0.39922 | Valid Loss: 0.39756 | Time: 0.75 seconds\n",
            "Epoch: 444 | Train Loss: 0.39849 | Valid Loss: 0.39843 | Time: 0.49 seconds\n",
            "Epoch: 445 | Train Loss: 0.39775 | Valid Loss: 0.39439 | Time: 0.57 seconds\n",
            "Epoch: 446 | Train Loss: 0.39706 | Valid Loss: 0.39585 | Time: 0.50 seconds\n",
            "Epoch: 447 | Train Loss: 0.39632 | Valid Loss: 0.39511 | Time: 0.48 seconds\n",
            "Epoch: 448 | Train Loss: 0.39560 | Valid Loss: 0.39069 | Time: 0.49 seconds\n",
            "Epoch: 449 | Train Loss: 0.39491 | Valid Loss: 0.39552 | Time: 0.48 seconds\n",
            "Epoch: 450 | Train Loss: 0.39416 | Valid Loss: 0.39168 | Time: 0.47 seconds\n",
            "Epoch: 451 | Train Loss: 0.39346 | Valid Loss: 0.39248 | Time: 0.47 seconds\n",
            "Epoch: 452 | Train Loss: 0.39275 | Valid Loss: 0.38860 | Time: 0.46 seconds\n",
            "Epoch: 453 | Train Loss: 0.39205 | Valid Loss: 0.39053 | Time: 0.48 seconds\n",
            "Epoch: 454 | Train Loss: 0.39130 | Valid Loss: 0.39053 | Time: 0.47 seconds\n",
            "Epoch: 455 | Train Loss: 0.39060 | Valid Loss: 0.38847 | Time: 0.48 seconds\n",
            "Epoch: 456 | Train Loss: 0.38988 | Valid Loss: 0.38819 | Time: 0.46 seconds\n",
            "Epoch: 457 | Train Loss: 0.38919 | Valid Loss: 0.38929 | Time: 0.47 seconds\n",
            "Epoch: 458 | Train Loss: 0.38846 | Valid Loss: 0.38618 | Time: 0.48 seconds\n",
            "Epoch: 459 | Train Loss: 0.38779 | Valid Loss: 0.38560 | Time: 0.47 seconds\n",
            "Epoch: 460 | Train Loss: 0.38708 | Valid Loss: 0.38637 | Time: 0.46 seconds\n",
            "Epoch: 461 | Train Loss: 0.38635 | Valid Loss: 0.38411 | Time: 0.47 seconds\n",
            "Epoch: 462 | Train Loss: 0.38570 | Valid Loss: 0.38545 | Time: 0.48 seconds\n",
            "Epoch: 463 | Train Loss: 0.38494 | Valid Loss: 0.38402 | Time: 0.47 seconds\n",
            "Epoch: 464 | Train Loss: 0.38430 | Valid Loss: 0.38485 | Time: 0.47 seconds\n",
            "Epoch: 465 | Train Loss: 0.38358 | Valid Loss: 0.38216 | Time: 0.46 seconds\n",
            "Epoch: 466 | Train Loss: 0.38286 | Valid Loss: 0.38076 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38218 | Valid Loss: 0.37855 | Time: 0.47 seconds\n",
            "Epoch: 468 | Train Loss: 0.38150 | Valid Loss: 0.37999 | Time: 0.47 seconds\n",
            "Epoch: 469 | Train Loss: 0.38084 | Valid Loss: 0.37980 | Time: 0.45 seconds\n",
            "Epoch: 470 | Train Loss: 0.38012 | Valid Loss: 0.37577 | Time: 0.50 seconds\n",
            "Epoch: 471 | Train Loss: 0.37945 | Valid Loss: 0.37413 | Time: 0.46 seconds\n",
            "Epoch: 472 | Train Loss: 0.37877 | Valid Loss: 0.37496 | Time: 0.46 seconds\n",
            "Epoch: 473 | Train Loss: 0.37808 | Valid Loss: 0.37557 | Time: 0.48 seconds\n",
            "Epoch: 474 | Train Loss: 0.37740 | Valid Loss: 0.37437 | Time: 0.47 seconds\n",
            "Epoch: 475 | Train Loss: 0.37671 | Valid Loss: 0.37614 | Time: 0.48 seconds\n",
            "Epoch: 476 | Train Loss: 0.37604 | Valid Loss: 0.37193 | Time: 0.46 seconds\n",
            "Epoch: 477 | Train Loss: 0.37539 | Valid Loss: 0.37288 | Time: 0.48 seconds\n",
            "Epoch: 478 | Train Loss: 0.37468 | Valid Loss: 0.37243 | Time: 0.47 seconds\n",
            "Epoch: 479 | Train Loss: 0.37403 | Valid Loss: 0.37180 | Time: 0.49 seconds\n",
            "Epoch: 480 | Train Loss: 0.37338 | Valid Loss: 0.37042 | Time: 0.47 seconds\n",
            "Epoch: 481 | Train Loss: 0.37271 | Valid Loss: 0.37073 | Time: 0.46 seconds\n",
            "Epoch: 482 | Train Loss: 0.37200 | Valid Loss: 0.37155 | Time: 0.45 seconds\n",
            "Epoch: 483 | Train Loss: 0.37133 | Valid Loss: 0.36966 | Time: 0.50 seconds\n",
            "Epoch: 484 | Train Loss: 0.37072 | Valid Loss: 0.36690 | Time: 0.47 seconds\n",
            "Epoch: 485 | Train Loss: 0.37004 | Valid Loss: 0.36890 | Time: 0.47 seconds\n",
            "Epoch: 486 | Train Loss: 0.36936 | Valid Loss: 0.36809 | Time: 0.46 seconds\n",
            "Epoch: 487 | Train Loss: 0.36871 | Valid Loss: 0.36733 | Time: 0.47 seconds\n",
            "Epoch: 488 | Train Loss: 0.36804 | Valid Loss: 0.36370 | Time: 0.48 seconds\n",
            "Epoch: 489 | Train Loss: 0.36740 | Valid Loss: 0.36649 | Time: 0.47 seconds\n",
            "Epoch: 490 | Train Loss: 0.36674 | Valid Loss: 0.36552 | Time: 0.49 seconds\n",
            "Epoch: 491 | Train Loss: 0.36610 | Valid Loss: 0.36354 | Time: 0.47 seconds\n",
            "Epoch: 492 | Train Loss: 0.36544 | Valid Loss: 0.36540 | Time: 0.47 seconds\n",
            "Epoch: 493 | Train Loss: 0.36478 | Valid Loss: 0.36418 | Time: 0.46 seconds\n",
            "Epoch: 494 | Train Loss: 0.36413 | Valid Loss: 0.36512 | Time: 0.46 seconds\n",
            "Epoch: 495 | Train Loss: 0.36353 | Valid Loss: 0.36318 | Time: 0.47 seconds\n",
            "Epoch: 496 | Train Loss: 0.36288 | Valid Loss: 0.35840 | Time: 0.46 seconds\n",
            "Epoch: 497 | Train Loss: 0.36224 | Valid Loss: 0.35840 | Time: 0.45 seconds\n",
            "Epoch: 498 | Train Loss: 0.36156 | Valid Loss: 0.35871 | Time: 0.47 seconds\n",
            "Epoch: 499 | Train Loss: 0.36093 | Valid Loss: 0.35820 | Time: 0.46 seconds\n",
            "Epoch: 500 | Train Loss: 0.36027 | Valid Loss: 0.35820 | Time: 0.45 seconds\n",
            "Epoch: 501 | Train Loss: 0.35967 | Valid Loss: 0.35871 | Time: 0.46 seconds\n",
            "Epoch: 502 | Train Loss: 0.35905 | Valid Loss: 0.35812 | Time: 0.48 seconds\n",
            "Epoch: 503 | Train Loss: 0.35843 | Valid Loss: 0.35671 | Time: 0.47 seconds\n",
            "Epoch: 504 | Train Loss: 0.35776 | Valid Loss: 0.35319 | Time: 0.47 seconds\n",
            "Epoch: 505 | Train Loss: 0.35711 | Valid Loss: 0.35510 | Time: 0.46 seconds\n",
            "Epoch: 506 | Train Loss: 0.35653 | Valid Loss: 0.35558 | Time: 0.45 seconds\n",
            "Epoch: 507 | Train Loss: 0.35592 | Valid Loss: 0.35458 | Time: 0.46 seconds\n",
            "Epoch: 508 | Train Loss: 0.35526 | Valid Loss: 0.35505 | Time: 0.48 seconds\n",
            "Epoch: 509 | Train Loss: 0.35463 | Valid Loss: 0.35049 | Time: 0.46 seconds\n",
            "Epoch: 510 | Train Loss: 0.35404 | Valid Loss: 0.35224 | Time: 0.46 seconds\n",
            "Epoch: 511 | Train Loss: 0.35340 | Valid Loss: 0.35251 | Time: 0.46 seconds\n",
            "Epoch: 512 | Train Loss: 0.35281 | Valid Loss: 0.34865 | Time: 0.47 seconds\n",
            "Epoch: 513 | Train Loss: 0.35215 | Valid Loss: 0.35093 | Time: 0.47 seconds\n",
            "Epoch: 514 | Train Loss: 0.35154 | Valid Loss: 0.35012 | Time: 0.47 seconds\n",
            "Epoch: 515 | Train Loss: 0.35092 | Valid Loss: 0.34723 | Time: 0.47 seconds\n",
            "Epoch: 516 | Train Loss: 0.35036 | Valid Loss: 0.34639 | Time: 0.49 seconds\n",
            "Epoch: 517 | Train Loss: 0.34971 | Valid Loss: 0.34760 | Time: 0.46 seconds\n",
            "Epoch: 518 | Train Loss: 0.34912 | Valid Loss: 0.34925 | Time: 0.48 seconds\n",
            "Epoch: 519 | Train Loss: 0.34849 | Valid Loss: 0.34566 | Time: 0.47 seconds\n",
            "Epoch: 520 | Train Loss: 0.34789 | Valid Loss: 0.34663 | Time: 0.47 seconds\n",
            "Epoch: 521 | Train Loss: 0.34724 | Valid Loss: 0.34378 | Time: 0.46 seconds\n",
            "Epoch: 522 | Train Loss: 0.34667 | Valid Loss: 0.34358 | Time: 0.49 seconds\n",
            "Epoch: 523 | Train Loss: 0.34609 | Valid Loss: 0.34263 | Time: 0.49 seconds\n",
            "Epoch: 524 | Train Loss: 0.34547 | Valid Loss: 0.34207 | Time: 0.47 seconds\n",
            "Epoch: 525 | Train Loss: 0.34488 | Valid Loss: 0.34297 | Time: 0.46 seconds\n",
            "Epoch: 526 | Train Loss: 0.34428 | Valid Loss: 0.34057 | Time: 0.47 seconds\n",
            "Epoch: 527 | Train Loss: 0.34372 | Valid Loss: 0.34076 | Time: 0.47 seconds\n",
            "Epoch: 528 | Train Loss: 0.34310 | Valid Loss: 0.34072 | Time: 0.46 seconds\n",
            "Epoch: 529 | Train Loss: 0.34256 | Valid Loss: 0.33958 | Time: 0.47 seconds\n",
            "Epoch: 530 | Train Loss: 0.34190 | Valid Loss: 0.34138 | Time: 0.45 seconds\n",
            "Epoch: 531 | Train Loss: 0.34132 | Valid Loss: 0.33790 | Time: 0.47 seconds\n",
            "Epoch: 532 | Train Loss: 0.34074 | Valid Loss: 0.33663 | Time: 0.47 seconds\n",
            "Epoch: 533 | Train Loss: 0.34015 | Valid Loss: 0.33729 | Time: 0.49 seconds\n",
            "Epoch: 534 | Train Loss: 0.33959 | Valid Loss: 0.33801 | Time: 0.46 seconds\n",
            "Epoch: 535 | Train Loss: 0.33895 | Valid Loss: 0.33676 | Time: 0.46 seconds\n",
            "Epoch: 536 | Train Loss: 0.33841 | Valid Loss: 0.33807 | Time: 0.46 seconds\n",
            "Epoch: 537 | Train Loss: 0.33780 | Valid Loss: 0.33573 | Time: 0.46 seconds\n",
            "Epoch: 538 | Train Loss: 0.33717 | Valid Loss: 0.33382 | Time: 0.50 seconds\n",
            "Epoch: 539 | Train Loss: 0.33666 | Valid Loss: 0.33509 | Time: 0.46 seconds\n",
            "Epoch: 540 | Train Loss: 0.33608 | Valid Loss: 0.33680 | Time: 0.47 seconds\n",
            "Epoch: 541 | Train Loss: 0.33551 | Valid Loss: 0.33323 | Time: 0.47 seconds\n",
            "Epoch: 542 | Train Loss: 0.33497 | Valid Loss: 0.33105 | Time: 0.47 seconds\n",
            "Epoch: 543 | Train Loss: 0.33437 | Valid Loss: 0.33253 | Time: 0.50 seconds\n",
            "Epoch: 544 | Train Loss: 0.33381 | Valid Loss: 0.32977 | Time: 0.47 seconds\n",
            "Epoch: 545 | Train Loss: 0.33322 | Valid Loss: 0.32942 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33265 | Valid Loss: 0.32983 | Time: 0.47 seconds\n",
            "Epoch: 547 | Train Loss: 0.33207 | Valid Loss: 0.33069 | Time: 0.45 seconds\n",
            "Epoch: 548 | Train Loss: 0.33155 | Valid Loss: 0.32854 | Time: 0.49 seconds\n",
            "Epoch: 549 | Train Loss: 0.33094 | Valid Loss: 0.32845 | Time: 0.46 seconds\n",
            "Epoch: 550 | Train Loss: 0.33037 | Valid Loss: 0.32800 | Time: 0.50 seconds\n",
            "Epoch: 551 | Train Loss: 0.32981 | Valid Loss: 0.32813 | Time: 0.46 seconds\n",
            "Epoch: 552 | Train Loss: 0.32926 | Valid Loss: 0.32545 | Time: 0.47 seconds\n",
            "Epoch: 553 | Train Loss: 0.32871 | Valid Loss: 0.32716 | Time: 0.46 seconds\n",
            "Epoch: 554 | Train Loss: 0.32816 | Valid Loss: 0.32353 | Time: 0.48 seconds\n",
            "Epoch: 555 | Train Loss: 0.32763 | Valid Loss: 0.32628 | Time: 0.47 seconds\n",
            "Epoch: 556 | Train Loss: 0.32706 | Valid Loss: 0.32596 | Time: 0.46 seconds\n",
            "Epoch: 557 | Train Loss: 0.32648 | Valid Loss: 0.32282 | Time: 0.47 seconds\n",
            "Epoch: 558 | Train Loss: 0.32594 | Valid Loss: 0.32499 | Time: 0.47 seconds\n",
            "Epoch: 559 | Train Loss: 0.32541 | Valid Loss: 0.32394 | Time: 0.47 seconds\n",
            "Epoch: 560 | Train Loss: 0.32481 | Valid Loss: 0.31984 | Time: 0.49 seconds\n",
            "Epoch: 561 | Train Loss: 0.32428 | Valid Loss: 0.32181 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32377 | Valid Loss: 0.32165 | Time: 0.47 seconds\n",
            "Epoch: 563 | Train Loss: 0.32320 | Valid Loss: 0.32132 | Time: 0.47 seconds\n",
            "Epoch: 564 | Train Loss: 0.32267 | Valid Loss: 0.31980 | Time: 0.47 seconds\n",
            "Epoch: 565 | Train Loss: 0.32209 | Valid Loss: 0.32145 | Time: 0.46 seconds\n",
            "Epoch: 566 | Train Loss: 0.32156 | Valid Loss: 0.31975 | Time: 0.50 seconds\n",
            "Epoch: 567 | Train Loss: 0.32104 | Valid Loss: 0.31944 | Time: 0.47 seconds\n",
            "Epoch: 568 | Train Loss: 0.32047 | Valid Loss: 0.31626 | Time: 0.48 seconds\n",
            "Epoch: 569 | Train Loss: 0.31988 | Valid Loss: 0.31928 | Time: 0.45 seconds\n",
            "Epoch: 570 | Train Loss: 0.31941 | Valid Loss: 0.31833 | Time: 0.46 seconds\n",
            "Epoch: 571 | Train Loss: 0.31888 | Valid Loss: 0.31641 | Time: 0.49 seconds\n",
            "Epoch: 572 | Train Loss: 0.31833 | Valid Loss: 0.31446 | Time: 0.49 seconds\n",
            "Epoch: 573 | Train Loss: 0.31778 | Valid Loss: 0.31352 | Time: 0.48 seconds\n",
            "Epoch: 574 | Train Loss: 0.31729 | Valid Loss: 0.31648 | Time: 0.47 seconds\n",
            "Epoch: 575 | Train Loss: 0.31677 | Valid Loss: 0.31459 | Time: 0.47 seconds\n",
            "Epoch: 576 | Train Loss: 0.31622 | Valid Loss: 0.31514 | Time: 0.47 seconds\n",
            "Epoch: 577 | Train Loss: 0.31569 | Valid Loss: 0.31482 | Time: 0.46 seconds\n",
            "Epoch: 578 | Train Loss: 0.31514 | Valid Loss: 0.31058 | Time: 0.48 seconds\n",
            "Epoch: 579 | Train Loss: 0.31462 | Valid Loss: 0.31273 | Time: 0.45 seconds\n",
            "Epoch: 580 | Train Loss: 0.31412 | Valid Loss: 0.31358 | Time: 0.48 seconds\n",
            "Epoch: 581 | Train Loss: 0.31360 | Valid Loss: 0.31185 | Time: 0.47 seconds\n",
            "Epoch: 582 | Train Loss: 0.31311 | Valid Loss: 0.30998 | Time: 0.46 seconds\n",
            "Epoch: 583 | Train Loss: 0.31256 | Valid Loss: 0.30978 | Time: 0.47 seconds\n",
            "Epoch: 584 | Train Loss: 0.31205 | Valid Loss: 0.30935 | Time: 0.47 seconds\n",
            "Epoch: 585 | Train Loss: 0.31151 | Valid Loss: 0.31049 | Time: 0.46 seconds\n",
            "Epoch: 586 | Train Loss: 0.31098 | Valid Loss: 0.30721 | Time: 0.46 seconds\n",
            "Epoch: 587 | Train Loss: 0.31047 | Valid Loss: 0.30910 | Time: 0.46 seconds\n",
            "Epoch: 588 | Train Loss: 0.30996 | Valid Loss: 0.30781 | Time: 0.47 seconds\n",
            "Epoch: 589 | Train Loss: 0.30944 | Valid Loss: 0.30743 | Time: 0.47 seconds\n",
            "Epoch: 590 | Train Loss: 0.30896 | Valid Loss: 0.30664 | Time: 0.48 seconds\n",
            "Epoch: 591 | Train Loss: 0.30841 | Valid Loss: 0.30553 | Time: 0.46 seconds\n",
            "Epoch: 592 | Train Loss: 0.30794 | Valid Loss: 0.30516 | Time: 0.47 seconds\n",
            "Epoch: 593 | Train Loss: 0.30737 | Valid Loss: 0.30653 | Time: 0.45 seconds\n",
            "Epoch: 594 | Train Loss: 0.30692 | Valid Loss: 0.30532 | Time: 0.47 seconds\n",
            "Epoch: 595 | Train Loss: 0.30637 | Valid Loss: 0.30610 | Time: 0.45 seconds\n",
            "Epoch: 596 | Train Loss: 0.30587 | Valid Loss: 0.30444 | Time: 0.47 seconds\n",
            "Epoch: 597 | Train Loss: 0.30535 | Valid Loss: 0.30313 | Time: 0.47 seconds\n",
            "Epoch: 598 | Train Loss: 0.30490 | Valid Loss: 0.30225 | Time: 0.48 seconds\n",
            "Epoch: 599 | Train Loss: 0.30436 | Valid Loss: 0.30049 | Time: 0.48 seconds\n",
            "Epoch: 600 | Train Loss: 0.30387 | Valid Loss: 0.30284 | Time: 0.47 seconds\n",
            "Epoch: 601 | Train Loss: 0.30335 | Valid Loss: 0.30104 | Time: 0.45 seconds\n",
            "Epoch: 602 | Train Loss: 0.30287 | Valid Loss: 0.30079 | Time: 0.46 seconds\n",
            "Epoch: 603 | Train Loss: 0.30239 | Valid Loss: 0.30021 | Time: 0.48 seconds\n",
            "Epoch: 604 | Train Loss: 0.30189 | Valid Loss: 0.29973 | Time: 0.46 seconds\n",
            "Epoch: 605 | Train Loss: 0.30138 | Valid Loss: 0.29992 | Time: 0.47 seconds\n",
            "Epoch: 606 | Train Loss: 0.30087 | Valid Loss: 0.30127 | Time: 0.45 seconds\n",
            "Epoch: 607 | Train Loss: 0.30036 | Valid Loss: 0.29874 | Time: 0.46 seconds\n",
            "Epoch: 608 | Train Loss: 0.29989 | Valid Loss: 0.29927 | Time: 0.46 seconds\n",
            "Epoch: 609 | Train Loss: 0.29937 | Valid Loss: 0.29738 | Time: 0.49 seconds\n",
            "Epoch: 610 | Train Loss: 0.29889 | Valid Loss: 0.29654 | Time: 0.47 seconds\n",
            "Epoch: 611 | Train Loss: 0.29840 | Valid Loss: 0.29507 | Time: 0.48 seconds\n",
            "Epoch: 612 | Train Loss: 0.29795 | Valid Loss: 0.29533 | Time: 0.46 seconds\n",
            "Epoch: 613 | Train Loss: 0.29740 | Valid Loss: 0.29573 | Time: 0.48 seconds\n",
            "Epoch: 614 | Train Loss: 0.29695 | Valid Loss: 0.29603 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29643 | Valid Loss: 0.29444 | Time: 0.46 seconds\n",
            "Epoch: 616 | Train Loss: 0.29599 | Valid Loss: 0.29372 | Time: 0.47 seconds\n",
            "Epoch: 617 | Train Loss: 0.29552 | Valid Loss: 0.29246 | Time: 0.48 seconds\n",
            "Epoch: 618 | Train Loss: 0.29498 | Valid Loss: 0.29413 | Time: 0.47 seconds\n",
            "Epoch: 619 | Train Loss: 0.29452 | Valid Loss: 0.29394 | Time: 0.45 seconds\n",
            "Epoch: 620 | Train Loss: 0.29407 | Valid Loss: 0.29189 | Time: 0.47 seconds\n",
            "Epoch: 621 | Train Loss: 0.29361 | Valid Loss: 0.29280 | Time: 0.45 seconds\n",
            "Epoch: 622 | Train Loss: 0.29307 | Valid Loss: 0.29079 | Time: 0.47 seconds\n",
            "Epoch: 623 | Train Loss: 0.29260 | Valid Loss: 0.29124 | Time: 0.46 seconds\n",
            "Epoch: 624 | Train Loss: 0.29214 | Valid Loss: 0.29069 | Time: 0.48 seconds\n",
            "Epoch: 625 | Train Loss: 0.29166 | Valid Loss: 0.28963 | Time: 0.46 seconds\n",
            "Epoch: 626 | Train Loss: 0.29119 | Valid Loss: 0.28885 | Time: 0.47 seconds\n",
            "Epoch: 627 | Train Loss: 0.29070 | Valid Loss: 0.28678 | Time: 0.47 seconds\n",
            "Epoch: 628 | Train Loss: 0.29020 | Valid Loss: 0.28771 | Time: 0.47 seconds\n",
            "Epoch: 629 | Train Loss: 0.28974 | Valid Loss: 0.28874 | Time: 0.46 seconds\n",
            "Epoch: 630 | Train Loss: 0.28929 | Valid Loss: 0.28615 | Time: 0.48 seconds\n",
            "Epoch: 631 | Train Loss: 0.28878 | Valid Loss: 0.28552 | Time: 0.48 seconds\n",
            "Epoch: 632 | Train Loss: 0.28833 | Valid Loss: 0.28651 | Time: 0.48 seconds\n",
            "Epoch: 633 | Train Loss: 0.28786 | Valid Loss: 0.28731 | Time: 0.46 seconds\n",
            "Epoch: 634 | Train Loss: 0.28741 | Valid Loss: 0.28381 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28694 | Valid Loss: 0.28579 | Time: 0.47 seconds\n",
            "Epoch: 636 | Train Loss: 0.28646 | Valid Loss: 0.28493 | Time: 0.47 seconds\n",
            "Epoch: 637 | Train Loss: 0.28601 | Valid Loss: 0.28403 | Time: 0.46 seconds\n",
            "Epoch: 638 | Train Loss: 0.28553 | Valid Loss: 0.28355 | Time: 0.46 seconds\n",
            "Epoch: 639 | Train Loss: 0.28512 | Valid Loss: 0.28106 | Time: 0.47 seconds\n",
            "Epoch: 640 | Train Loss: 0.28456 | Valid Loss: 0.28442 | Time: 0.46 seconds\n",
            "Epoch: 641 | Train Loss: 0.28416 | Valid Loss: 0.28387 | Time: 0.46 seconds\n",
            "Epoch: 642 | Train Loss: 0.28368 | Valid Loss: 0.28322 | Time: 0.46 seconds\n",
            "Epoch: 643 | Train Loss: 0.28323 | Valid Loss: 0.28286 | Time: 0.46 seconds\n",
            "Epoch: 644 | Train Loss: 0.28278 | Valid Loss: 0.27891 | Time: 0.47 seconds\n",
            "Epoch: 645 | Train Loss: 0.28234 | Valid Loss: 0.28001 | Time: 0.45 seconds\n",
            "Epoch: 646 | Train Loss: 0.28184 | Valid Loss: 0.27817 | Time: 0.47 seconds\n",
            "Epoch: 647 | Train Loss: 0.28140 | Valid Loss: 0.27929 | Time: 0.46 seconds\n",
            "Epoch: 648 | Train Loss: 0.28097 | Valid Loss: 0.27839 | Time: 0.46 seconds\n",
            "Epoch: 649 | Train Loss: 0.28049 | Valid Loss: 0.27903 | Time: 0.46 seconds\n",
            "Epoch: 650 | Train Loss: 0.28004 | Valid Loss: 0.27842 | Time: 0.45 seconds\n",
            "Epoch: 651 | Train Loss: 0.27958 | Valid Loss: 0.27781 | Time: 0.49 seconds\n",
            "Epoch: 652 | Train Loss: 0.27909 | Valid Loss: 0.27706 | Time: 0.47 seconds\n",
            "Epoch: 653 | Train Loss: 0.27870 | Valid Loss: 0.27717 | Time: 0.47 seconds\n",
            "Epoch: 654 | Train Loss: 0.27822 | Valid Loss: 0.27699 | Time: 0.46 seconds\n",
            "Epoch: 655 | Train Loss: 0.27779 | Valid Loss: 0.27628 | Time: 0.47 seconds\n",
            "Epoch: 656 | Train Loss: 0.27736 | Valid Loss: 0.27597 | Time: 0.47 seconds\n",
            "Epoch: 657 | Train Loss: 0.27689 | Valid Loss: 0.27432 | Time: 0.47 seconds\n",
            "Epoch: 658 | Train Loss: 0.27646 | Valid Loss: 0.27591 | Time: 0.45 seconds\n",
            "Epoch: 659 | Train Loss: 0.27599 | Valid Loss: 0.27503 | Time: 0.46 seconds\n",
            "Epoch: 660 | Train Loss: 0.27554 | Valid Loss: 0.27309 | Time: 0.47 seconds\n",
            "Epoch: 661 | Train Loss: 0.27513 | Valid Loss: 0.27342 | Time: 0.46 seconds\n",
            "Epoch: 662 | Train Loss: 0.27467 | Valid Loss: 0.27397 | Time: 0.46 seconds\n",
            "Epoch: 663 | Train Loss: 0.27420 | Valid Loss: 0.27363 | Time: 0.45 seconds\n",
            "Epoch: 664 | Train Loss: 0.27382 | Valid Loss: 0.27287 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27334 | Valid Loss: 0.27095 | Time: 0.47 seconds\n",
            "Epoch: 666 | Train Loss: 0.27289 | Valid Loss: 0.27007 | Time: 0.47 seconds\n",
            "Epoch: 667 | Train Loss: 0.27243 | Valid Loss: 0.27017 | Time: 0.48 seconds\n",
            "Epoch: 668 | Train Loss: 0.27205 | Valid Loss: 0.27227 | Time: 0.47 seconds\n",
            "Epoch: 669 | Train Loss: 0.27159 | Valid Loss: 0.26900 | Time: 0.46 seconds\n",
            "Epoch: 670 | Train Loss: 0.27111 | Valid Loss: 0.26857 | Time: 0.48 seconds\n",
            "Epoch: 671 | Train Loss: 0.27071 | Valid Loss: 0.26763 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27028 | Valid Loss: 0.27120 | Time: 0.47 seconds\n",
            "Epoch: 673 | Train Loss: 0.26982 | Valid Loss: 0.26947 | Time: 0.45 seconds\n",
            "Epoch: 674 | Train Loss: 0.26939 | Valid Loss: 0.26707 | Time: 0.46 seconds\n",
            "Epoch: 675 | Train Loss: 0.26898 | Valid Loss: 0.26620 | Time: 0.48 seconds\n",
            "Epoch: 676 | Train Loss: 0.26854 | Valid Loss: 0.26746 | Time: 0.48 seconds\n",
            "Epoch: 677 | Train Loss: 0.26809 | Valid Loss: 0.26612 | Time: 0.48 seconds\n",
            "Epoch: 678 | Train Loss: 0.26767 | Valid Loss: 0.26687 | Time: 0.46 seconds\n",
            "Epoch: 679 | Train Loss: 0.26722 | Valid Loss: 0.26682 | Time: 0.47 seconds\n",
            "Epoch: 680 | Train Loss: 0.26680 | Valid Loss: 0.26461 | Time: 0.46 seconds\n",
            "Epoch: 681 | Train Loss: 0.26636 | Valid Loss: 0.26559 | Time: 0.46 seconds\n",
            "Epoch: 682 | Train Loss: 0.26591 | Valid Loss: 0.26236 | Time: 0.48 seconds\n",
            "Epoch: 683 | Train Loss: 0.26555 | Valid Loss: 0.26516 | Time: 0.49 seconds\n",
            "Epoch: 684 | Train Loss: 0.26506 | Valid Loss: 0.26287 | Time: 0.47 seconds\n",
            "Epoch: 685 | Train Loss: 0.26471 | Valid Loss: 0.26271 | Time: 0.47 seconds\n",
            "Epoch: 686 | Train Loss: 0.26427 | Valid Loss: 0.26209 | Time: 0.48 seconds\n",
            "Epoch: 687 | Train Loss: 0.26383 | Valid Loss: 0.26292 | Time: 0.48 seconds\n",
            "Epoch: 688 | Train Loss: 0.26340 | Valid Loss: 0.26125 | Time: 0.46 seconds\n",
            "Epoch: 689 | Train Loss: 0.26296 | Valid Loss: 0.26162 | Time: 0.47 seconds\n",
            "Epoch: 690 | Train Loss: 0.26255 | Valid Loss: 0.26109 | Time: 0.46 seconds\n",
            "Epoch: 691 | Train Loss: 0.26214 | Valid Loss: 0.26162 | Time: 0.46 seconds\n",
            "Epoch: 692 | Train Loss: 0.26173 | Valid Loss: 0.26009 | Time: 0.46 seconds\n",
            "Epoch: 693 | Train Loss: 0.26128 | Valid Loss: 0.26014 | Time: 0.45 seconds\n",
            "Epoch: 694 | Train Loss: 0.26088 | Valid Loss: 0.25919 | Time: 0.47 seconds\n",
            "Epoch: 695 | Train Loss: 0.26047 | Valid Loss: 0.25905 | Time: 0.48 seconds\n",
            "Epoch: 696 | Train Loss: 0.26005 | Valid Loss: 0.25828 | Time: 0.47 seconds\n",
            "Epoch: 697 | Train Loss: 0.25965 | Valid Loss: 0.25627 | Time: 0.47 seconds\n",
            "Epoch: 698 | Train Loss: 0.25921 | Valid Loss: 0.25841 | Time: 0.48 seconds\n",
            "Epoch: 699 | Train Loss: 0.25877 | Valid Loss: 0.25625 | Time: 0.47 seconds\n",
            "Epoch: 700 | Train Loss: 0.25836 | Valid Loss: 0.25664 | Time: 0.48 seconds\n",
            "Epoch: 701 | Train Loss: 0.25800 | Valid Loss: 0.25579 | Time: 0.46 seconds\n",
            "Epoch: 702 | Train Loss: 0.25755 | Valid Loss: 0.25597 | Time: 0.45 seconds\n",
            "Epoch: 703 | Train Loss: 0.25718 | Valid Loss: 0.25538 | Time: 0.48 seconds\n",
            "Epoch: 704 | Train Loss: 0.25674 | Valid Loss: 0.25462 | Time: 0.47 seconds\n",
            "Epoch: 705 | Train Loss: 0.25634 | Valid Loss: 0.25495 | Time: 0.46 seconds\n",
            "Epoch: 706 | Train Loss: 0.25590 | Valid Loss: 0.25436 | Time: 0.46 seconds\n",
            "Epoch: 707 | Train Loss: 0.25550 | Valid Loss: 0.25442 | Time: 0.48 seconds\n",
            "Epoch: 708 | Train Loss: 0.25507 | Valid Loss: 0.25330 | Time: 0.48 seconds\n",
            "Epoch: 709 | Train Loss: 0.25468 | Valid Loss: 0.25291 | Time: 0.48 seconds\n",
            "Epoch: 710 | Train Loss: 0.25428 | Valid Loss: 0.25213 | Time: 0.49 seconds\n",
            "Epoch: 711 | Train Loss: 0.25385 | Valid Loss: 0.25192 | Time: 0.48 seconds\n",
            "Epoch: 712 | Train Loss: 0.25346 | Valid Loss: 0.25200 | Time: 0.47 seconds\n",
            "Epoch: 713 | Train Loss: 0.25307 | Valid Loss: 0.25210 | Time: 0.47 seconds\n",
            "Epoch: 714 | Train Loss: 0.25269 | Valid Loss: 0.25281 | Time: 0.45 seconds\n",
            "Epoch: 715 | Train Loss: 0.25224 | Valid Loss: 0.25299 | Time: 0.47 seconds\n",
            "Epoch: 716 | Train Loss: 0.25185 | Valid Loss: 0.24920 | Time: 0.49 seconds\n",
            "Epoch: 717 | Train Loss: 0.25142 | Valid Loss: 0.24941 | Time: 0.46 seconds\n",
            "Epoch: 718 | Train Loss: 0.25103 | Valid Loss: 0.24961 | Time: 0.46 seconds\n",
            "Epoch: 719 | Train Loss: 0.25067 | Valid Loss: 0.24980 | Time: 0.45 seconds\n",
            "Epoch: 720 | Train Loss: 0.25021 | Valid Loss: 0.24859 | Time: 0.47 seconds\n",
            "Epoch: 721 | Train Loss: 0.24981 | Valid Loss: 0.24673 | Time: 0.46 seconds\n",
            "Epoch: 722 | Train Loss: 0.24947 | Valid Loss: 0.24793 | Time: 0.47 seconds\n",
            "Epoch: 723 | Train Loss: 0.24905 | Valid Loss: 0.24585 | Time: 0.47 seconds\n",
            "Epoch: 724 | Train Loss: 0.24864 | Valid Loss: 0.24750 | Time: 0.48 seconds\n",
            "Epoch: 725 | Train Loss: 0.24825 | Valid Loss: 0.24654 | Time: 0.45 seconds\n",
            "Epoch: 726 | Train Loss: 0.24783 | Valid Loss: 0.24637 | Time: 0.47 seconds\n",
            "Epoch: 727 | Train Loss: 0.24747 | Valid Loss: 0.24508 | Time: 0.45 seconds\n",
            "Epoch: 728 | Train Loss: 0.24704 | Valid Loss: 0.24623 | Time: 0.46 seconds\n",
            "Epoch: 729 | Train Loss: 0.24665 | Valid Loss: 0.24560 | Time: 0.49 seconds\n",
            "Epoch: 730 | Train Loss: 0.24630 | Valid Loss: 0.24291 | Time: 0.47 seconds\n",
            "Epoch: 731 | Train Loss: 0.24584 | Valid Loss: 0.24334 | Time: 0.49 seconds\n",
            "Epoch: 732 | Train Loss: 0.24548 | Valid Loss: 0.24533 | Time: 0.47 seconds\n",
            "Epoch: 733 | Train Loss: 0.24509 | Valid Loss: 0.24260 | Time: 0.48 seconds\n",
            "Epoch: 734 | Train Loss: 0.24472 | Valid Loss: 0.24317 | Time: 0.47 seconds\n",
            "Epoch: 735 | Train Loss: 0.24433 | Valid Loss: 0.24278 | Time: 0.48 seconds\n",
            "Epoch: 736 | Train Loss: 0.24394 | Valid Loss: 0.24078 | Time: 0.46 seconds\n",
            "Epoch: 737 | Train Loss: 0.24357 | Valid Loss: 0.24099 | Time: 0.48 seconds\n",
            "Epoch: 738 | Train Loss: 0.24315 | Valid Loss: 0.24355 | Time: 0.46 seconds\n",
            "Epoch: 739 | Train Loss: 0.24277 | Valid Loss: 0.24129 | Time: 0.47 seconds\n",
            "Epoch: 740 | Train Loss: 0.24239 | Valid Loss: 0.23966 | Time: 0.45 seconds\n",
            "Epoch: 741 | Train Loss: 0.24198 | Valid Loss: 0.24194 | Time: 0.47 seconds\n",
            "Epoch: 742 | Train Loss: 0.24164 | Valid Loss: 0.23983 | Time: 0.47 seconds\n",
            "Epoch: 743 | Train Loss: 0.24120 | Valid Loss: 0.24115 | Time: 0.46 seconds\n",
            "Epoch: 744 | Train Loss: 0.24085 | Valid Loss: 0.23927 | Time: 0.48 seconds\n",
            "Epoch: 745 | Train Loss: 0.24045 | Valid Loss: 0.24108 | Time: 0.46 seconds\n",
            "Epoch: 746 | Train Loss: 0.24007 | Valid Loss: 0.23759 | Time: 0.48 seconds\n",
            "Epoch: 747 | Train Loss: 0.23968 | Valid Loss: 0.23714 | Time: 0.46 seconds\n",
            "Epoch: 748 | Train Loss: 0.23930 | Valid Loss: 0.23702 | Time: 0.47 seconds\n",
            "Epoch: 749 | Train Loss: 0.23896 | Valid Loss: 0.23745 | Time: 0.45 seconds\n",
            "Epoch: 750 | Train Loss: 0.23855 | Valid Loss: 0.23744 | Time: 0.47 seconds\n",
            "Epoch: 751 | Train Loss: 0.23819 | Valid Loss: 0.23684 | Time: 0.46 seconds\n",
            "Epoch: 752 | Train Loss: 0.23780 | Valid Loss: 0.23496 | Time: 0.46 seconds\n",
            "Epoch: 753 | Train Loss: 0.23743 | Valid Loss: 0.23760 | Time: 0.47 seconds\n",
            "Epoch: 754 | Train Loss: 0.23701 | Valid Loss: 0.23604 | Time: 0.45 seconds\n",
            "Epoch: 755 | Train Loss: 0.23664 | Valid Loss: 0.23516 | Time: 0.45 seconds\n",
            "Epoch: 756 | Train Loss: 0.23626 | Valid Loss: 0.23481 | Time: 0.47 seconds\n",
            "Epoch: 757 | Train Loss: 0.23588 | Valid Loss: 0.23516 | Time: 0.46 seconds\n",
            "Epoch: 758 | Train Loss: 0.23554 | Valid Loss: 0.23425 | Time: 0.46 seconds\n",
            "Epoch: 759 | Train Loss: 0.23518 | Valid Loss: 0.23361 | Time: 0.48 seconds\n",
            "Epoch: 760 | Train Loss: 0.23475 | Valid Loss: 0.23441 | Time: 0.47 seconds\n",
            "Epoch: 761 | Train Loss: 0.23442 | Valid Loss: 0.23380 | Time: 0.46 seconds\n",
            "Epoch: 762 | Train Loss: 0.23404 | Valid Loss: 0.23286 | Time: 0.46 seconds\n",
            "Epoch: 763 | Train Loss: 0.23366 | Valid Loss: 0.23196 | Time: 0.46 seconds\n",
            "Epoch: 764 | Train Loss: 0.23330 | Valid Loss: 0.23210 | Time: 0.47 seconds\n",
            "Epoch: 765 | Train Loss: 0.23293 | Valid Loss: 0.23046 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23255 | Valid Loss: 0.23206 | Time: 0.46 seconds\n",
            "Epoch: 767 | Train Loss: 0.23215 | Valid Loss: 0.22992 | Time: 0.46 seconds\n",
            "Epoch: 768 | Train Loss: 0.23180 | Valid Loss: 0.22978 | Time: 0.48 seconds\n",
            "Epoch: 769 | Train Loss: 0.23142 | Valid Loss: 0.23032 | Time: 0.46 seconds\n",
            "Epoch: 770 | Train Loss: 0.23107 | Valid Loss: 0.22851 | Time: 0.46 seconds\n",
            "Epoch: 771 | Train Loss: 0.23071 | Valid Loss: 0.22922 | Time: 0.44 seconds\n",
            "Epoch: 772 | Train Loss: 0.23032 | Valid Loss: 0.22913 | Time: 0.47 seconds\n",
            "Epoch: 773 | Train Loss: 0.22999 | Valid Loss: 0.22847 | Time: 0.46 seconds\n",
            "Epoch: 774 | Train Loss: 0.22958 | Valid Loss: 0.22792 | Time: 0.48 seconds\n",
            "Epoch: 775 | Train Loss: 0.22925 | Valid Loss: 0.22901 | Time: 0.45 seconds\n",
            "Epoch: 776 | Train Loss: 0.22884 | Valid Loss: 0.22645 | Time: 0.48 seconds\n",
            "Epoch: 777 | Train Loss: 0.22853 | Valid Loss: 0.22655 | Time: 0.46 seconds\n",
            "Epoch: 778 | Train Loss: 0.22817 | Valid Loss: 0.22657 | Time: 0.46 seconds\n",
            "Epoch: 779 | Train Loss: 0.22776 | Valid Loss: 0.22687 | Time: 0.46 seconds\n",
            "Epoch: 780 | Train Loss: 0.22741 | Valid Loss: 0.22498 | Time: 0.46 seconds\n",
            "Epoch: 781 | Train Loss: 0.22706 | Valid Loss: 0.22799 | Time: 0.48 seconds\n",
            "Epoch: 782 | Train Loss: 0.22673 | Valid Loss: 0.22561 | Time: 0.46 seconds\n",
            "Epoch: 783 | Train Loss: 0.22635 | Valid Loss: 0.22390 | Time: 0.49 seconds\n",
            "Epoch: 784 | Train Loss: 0.22596 | Valid Loss: 0.22474 | Time: 0.45 seconds\n",
            "Epoch: 785 | Train Loss: 0.22561 | Valid Loss: 0.22234 | Time: 0.47 seconds\n",
            "Epoch: 786 | Train Loss: 0.22525 | Valid Loss: 0.22385 | Time: 0.45 seconds\n",
            "Epoch: 787 | Train Loss: 0.22486 | Valid Loss: 0.22426 | Time: 0.44 seconds\n",
            "Epoch: 788 | Train Loss: 0.22455 | Valid Loss: 0.22576 | Time: 0.48 seconds\n",
            "Epoch: 789 | Train Loss: 0.22419 | Valid Loss: 0.22248 | Time: 0.45 seconds\n",
            "Epoch: 790 | Train Loss: 0.22389 | Valid Loss: 0.22352 | Time: 0.48 seconds\n",
            "Epoch: 791 | Train Loss: 0.22346 | Valid Loss: 0.22329 | Time: 0.45 seconds\n",
            "Epoch: 792 | Train Loss: 0.22313 | Valid Loss: 0.22228 | Time: 0.48 seconds\n",
            "Epoch: 793 | Train Loss: 0.22275 | Valid Loss: 0.22177 | Time: 0.47 seconds\n",
            "Epoch: 794 | Train Loss: 0.22239 | Valid Loss: 0.22183 | Time: 0.46 seconds\n",
            "Epoch: 795 | Train Loss: 0.22208 | Valid Loss: 0.21945 | Time: 0.46 seconds\n",
            "Epoch: 796 | Train Loss: 0.22171 | Valid Loss: 0.22031 | Time: 0.46 seconds\n",
            "Epoch: 797 | Train Loss: 0.22137 | Valid Loss: 0.22015 | Time: 0.46 seconds\n",
            "Epoch: 798 | Train Loss: 0.22100 | Valid Loss: 0.21950 | Time: 0.46 seconds\n",
            "Epoch: 799 | Train Loss: 0.22067 | Valid Loss: 0.21929 | Time: 0.48 seconds\n",
            "Epoch: 800 | Train Loss: 0.22031 | Valid Loss: 0.22088 | Time: 0.45 seconds\n",
            "Epoch: 801 | Train Loss: 0.22001 | Valid Loss: 0.21742 | Time: 0.49 seconds\n",
            "Epoch: 802 | Train Loss: 0.21959 | Valid Loss: 0.21728 | Time: 0.47 seconds\n",
            "Epoch: 803 | Train Loss: 0.21928 | Valid Loss: 0.21772 | Time: 0.48 seconds\n",
            "Epoch: 804 | Train Loss: 0.21891 | Valid Loss: 0.21800 | Time: 0.45 seconds\n",
            "Epoch: 805 | Train Loss: 0.21856 | Valid Loss: 0.21805 | Time: 0.46 seconds\n",
            "Epoch: 806 | Train Loss: 0.21824 | Valid Loss: 0.21720 | Time: 0.46 seconds\n",
            "Epoch: 807 | Train Loss: 0.21786 | Valid Loss: 0.21764 | Time: 0.47 seconds\n",
            "Epoch: 808 | Train Loss: 0.21753 | Valid Loss: 0.21486 | Time: 0.46 seconds\n",
            "Epoch: 809 | Train Loss: 0.21721 | Valid Loss: 0.21530 | Time: 0.46 seconds\n",
            "Epoch: 810 | Train Loss: 0.21684 | Valid Loss: 0.21448 | Time: 0.46 seconds\n",
            "Epoch: 811 | Train Loss: 0.21648 | Valid Loss: 0.21608 | Time: 0.45 seconds\n",
            "Epoch: 812 | Train Loss: 0.21613 | Valid Loss: 0.21487 | Time: 0.49 seconds\n",
            "Epoch: 813 | Train Loss: 0.21584 | Valid Loss: 0.21406 | Time: 0.49 seconds\n",
            "Epoch: 814 | Train Loss: 0.21547 | Valid Loss: 0.21473 | Time: 0.47 seconds\n",
            "Epoch: 815 | Train Loss: 0.21514 | Valid Loss: 0.21529 | Time: 0.45 seconds\n",
            "Epoch: 816 | Train Loss: 0.21477 | Valid Loss: 0.21320 | Time: 0.46 seconds\n",
            "Epoch: 817 | Train Loss: 0.21447 | Valid Loss: 0.21491 | Time: 0.45 seconds\n",
            "Epoch: 818 | Train Loss: 0.21408 | Valid Loss: 0.21401 | Time: 0.47 seconds\n",
            "Epoch: 819 | Train Loss: 0.21377 | Valid Loss: 0.21290 | Time: 0.47 seconds\n",
            "Epoch: 820 | Train Loss: 0.21343 | Valid Loss: 0.21213 | Time: 0.47 seconds\n",
            "Epoch: 821 | Train Loss: 0.21309 | Valid Loss: 0.21128 | Time: 0.46 seconds\n",
            "Epoch: 822 | Train Loss: 0.21275 | Valid Loss: 0.21082 | Time: 0.47 seconds\n",
            "Epoch: 823 | Train Loss: 0.21240 | Valid Loss: 0.21153 | Time: 0.49 seconds\n",
            "Epoch: 824 | Train Loss: 0.21210 | Valid Loss: 0.21089 | Time: 0.45 seconds\n",
            "Epoch: 825 | Train Loss: 0.21174 | Valid Loss: 0.21009 | Time: 0.47 seconds\n",
            "Epoch: 826 | Train Loss: 0.21141 | Valid Loss: 0.21048 | Time: 0.47 seconds\n",
            "Epoch: 827 | Train Loss: 0.21108 | Valid Loss: 0.21019 | Time: 0.48 seconds\n",
            "Epoch: 828 | Train Loss: 0.21074 | Valid Loss: 0.20922 | Time: 0.47 seconds\n",
            "Epoch: 829 | Train Loss: 0.21040 | Valid Loss: 0.20915 | Time: 0.48 seconds\n",
            "Epoch: 830 | Train Loss: 0.21007 | Valid Loss: 0.20879 | Time: 0.49 seconds\n",
            "Epoch: 831 | Train Loss: 0.20973 | Valid Loss: 0.20835 | Time: 0.50 seconds\n",
            "Epoch: 832 | Train Loss: 0.20945 | Valid Loss: 0.20783 | Time: 0.47 seconds\n",
            "Epoch: 833 | Train Loss: 0.20906 | Valid Loss: 0.20713 | Time: 0.47 seconds\n",
            "Epoch: 834 | Train Loss: 0.20876 | Valid Loss: 0.20794 | Time: 0.45 seconds\n",
            "Epoch: 835 | Train Loss: 0.20846 | Valid Loss: 0.20677 | Time: 0.47 seconds\n",
            "Epoch: 836 | Train Loss: 0.20806 | Valid Loss: 0.20692 | Time: 0.47 seconds\n",
            "Epoch: 837 | Train Loss: 0.20776 | Valid Loss: 0.20721 | Time: 0.49 seconds\n",
            "Epoch: 838 | Train Loss: 0.20743 | Valid Loss: 0.20649 | Time: 0.47 seconds\n",
            "Epoch: 839 | Train Loss: 0.20709 | Valid Loss: 0.20593 | Time: 0.46 seconds\n",
            "Epoch: 840 | Train Loss: 0.20677 | Valid Loss: 0.20595 | Time: 0.47 seconds\n",
            "Epoch: 841 | Train Loss: 0.20645 | Valid Loss: 0.20551 | Time: 0.47 seconds\n",
            "Epoch: 842 | Train Loss: 0.20613 | Valid Loss: 0.20513 | Time: 0.49 seconds\n",
            "Epoch: 843 | Train Loss: 0.20578 | Valid Loss: 0.20607 | Time: 0.45 seconds\n",
            "Epoch: 844 | Train Loss: 0.20546 | Valid Loss: 0.20429 | Time: 0.48 seconds\n",
            "Epoch: 845 | Train Loss: 0.20514 | Valid Loss: 0.20493 | Time: 0.46 seconds\n",
            "Epoch: 846 | Train Loss: 0.20481 | Valid Loss: 0.20286 | Time: 0.48 seconds\n",
            "Epoch: 847 | Train Loss: 0.20450 | Valid Loss: 0.20297 | Time: 0.46 seconds\n",
            "Epoch: 848 | Train Loss: 0.20419 | Valid Loss: 0.20342 | Time: 0.46 seconds\n",
            "Epoch: 849 | Train Loss: 0.20386 | Valid Loss: 0.20313 | Time: 0.47 seconds\n",
            "Epoch: 850 | Train Loss: 0.20352 | Valid Loss: 0.20196 | Time: 0.46 seconds\n",
            "Epoch: 851 | Train Loss: 0.20324 | Valid Loss: 0.20263 | Time: 0.48 seconds\n",
            "Epoch: 852 | Train Loss: 0.20293 | Valid Loss: 0.20167 | Time: 0.46 seconds\n",
            "Epoch: 853 | Train Loss: 0.20261 | Valid Loss: 0.20132 | Time: 0.47 seconds\n",
            "Epoch: 854 | Train Loss: 0.20223 | Valid Loss: 0.20029 | Time: 0.46 seconds\n",
            "Epoch: 855 | Train Loss: 0.20195 | Valid Loss: 0.20049 | Time: 0.48 seconds\n",
            "Epoch: 856 | Train Loss: 0.20159 | Valid Loss: 0.20069 | Time: 0.45 seconds\n",
            "Epoch: 857 | Train Loss: 0.20126 | Valid Loss: 0.20054 | Time: 0.49 seconds\n",
            "Epoch: 858 | Train Loss: 0.20098 | Valid Loss: 0.19951 | Time: 0.47 seconds\n",
            "Epoch: 859 | Train Loss: 0.20066 | Valid Loss: 0.20048 | Time: 0.46 seconds\n",
            "Epoch: 860 | Train Loss: 0.20031 | Valid Loss: 0.19967 | Time: 0.47 seconds\n",
            "Epoch: 861 | Train Loss: 0.19998 | Valid Loss: 0.19828 | Time: 0.48 seconds\n",
            "Epoch: 862 | Train Loss: 0.19969 | Valid Loss: 0.19860 | Time: 0.46 seconds\n",
            "Epoch: 863 | Train Loss: 0.19940 | Valid Loss: 0.19870 | Time: 0.46 seconds\n",
            "Epoch: 864 | Train Loss: 0.19907 | Valid Loss: 0.19980 | Time: 0.46 seconds\n",
            "Epoch: 865 | Train Loss: 0.19875 | Valid Loss: 0.19608 | Time: 0.49 seconds\n",
            "Epoch: 866 | Train Loss: 0.19843 | Valid Loss: 0.19771 | Time: 0.48 seconds\n",
            "Epoch: 867 | Train Loss: 0.19814 | Valid Loss: 0.19735 | Time: 0.45 seconds\n",
            "Epoch: 868 | Train Loss: 0.19783 | Valid Loss: 0.19833 | Time: 0.46 seconds\n",
            "Epoch: 869 | Train Loss: 0.19753 | Valid Loss: 0.19469 | Time: 0.48 seconds\n",
            "Epoch: 870 | Train Loss: 0.19718 | Valid Loss: 0.19732 | Time: 0.47 seconds\n",
            "Epoch: 871 | Train Loss: 0.19687 | Valid Loss: 0.19709 | Time: 0.46 seconds\n",
            "Epoch: 872 | Train Loss: 0.19654 | Valid Loss: 0.19580 | Time: 0.48 seconds\n",
            "Epoch: 873 | Train Loss: 0.19627 | Valid Loss: 0.19511 | Time: 0.46 seconds\n",
            "Epoch: 874 | Train Loss: 0.19591 | Valid Loss: 0.19519 | Time: 0.49 seconds\n",
            "Epoch: 875 | Train Loss: 0.19568 | Valid Loss: 0.19567 | Time: 0.45 seconds\n",
            "Epoch: 876 | Train Loss: 0.19535 | Valid Loss: 0.19316 | Time: 0.47 seconds\n",
            "Epoch: 877 | Train Loss: 0.19505 | Valid Loss: 0.19276 | Time: 0.48 seconds\n",
            "Epoch: 878 | Train Loss: 0.19473 | Valid Loss: 0.19315 | Time: 0.46 seconds\n",
            "Epoch: 879 | Train Loss: 0.19440 | Valid Loss: 0.19414 | Time: 0.47 seconds\n",
            "Epoch: 880 | Train Loss: 0.19411 | Valid Loss: 0.19212 | Time: 0.46 seconds\n",
            "Epoch: 881 | Train Loss: 0.19380 | Valid Loss: 0.19201 | Time: 0.47 seconds\n",
            "Epoch: 882 | Train Loss: 0.19350 | Valid Loss: 0.19280 | Time: 0.45 seconds\n",
            "Epoch: 883 | Train Loss: 0.19316 | Valid Loss: 0.19147 | Time: 0.48 seconds\n",
            "Epoch: 884 | Train Loss: 0.19290 | Valid Loss: 0.19129 | Time: 0.46 seconds\n",
            "Epoch: 885 | Train Loss: 0.19256 | Valid Loss: 0.19245 | Time: 0.47 seconds\n",
            "Epoch: 886 | Train Loss: 0.19229 | Valid Loss: 0.19250 | Time: 0.46 seconds\n",
            "Epoch: 887 | Train Loss: 0.19195 | Valid Loss: 0.19126 | Time: 0.51 seconds\n",
            "Epoch: 888 | Train Loss: 0.19165 | Valid Loss: 0.18993 | Time: 0.45 seconds\n",
            "Epoch: 889 | Train Loss: 0.19137 | Valid Loss: 0.19057 | Time: 0.45 seconds\n",
            "Epoch: 890 | Train Loss: 0.19108 | Valid Loss: 0.18917 | Time: 0.47 seconds\n",
            "Epoch: 891 | Train Loss: 0.19080 | Valid Loss: 0.18959 | Time: 0.45 seconds\n",
            "Epoch: 892 | Train Loss: 0.19042 | Valid Loss: 0.18898 | Time: 0.47 seconds\n",
            "Epoch: 893 | Train Loss: 0.19017 | Valid Loss: 0.18943 | Time: 0.46 seconds\n",
            "Epoch: 894 | Train Loss: 0.18986 | Valid Loss: 0.18797 | Time: 0.46 seconds\n",
            "Epoch: 895 | Train Loss: 0.18958 | Valid Loss: 0.18826 | Time: 0.45 seconds\n",
            "Epoch: 896 | Train Loss: 0.18928 | Valid Loss: 0.18852 | Time: 0.45 seconds\n",
            "Epoch: 897 | Train Loss: 0.18896 | Valid Loss: 0.18693 | Time: 0.46 seconds\n",
            "Epoch: 898 | Train Loss: 0.18865 | Valid Loss: 0.18674 | Time: 0.47 seconds\n",
            "Epoch: 899 | Train Loss: 0.18838 | Valid Loss: 0.18748 | Time: 0.48 seconds\n",
            "Epoch: 900 | Train Loss: 0.18809 | Valid Loss: 0.18824 | Time: 0.47 seconds\n",
            "Epoch: 901 | Train Loss: 0.18780 | Valid Loss: 0.18495 | Time: 0.49 seconds\n",
            "Epoch: 902 | Train Loss: 0.18746 | Valid Loss: 0.18643 | Time: 0.47 seconds\n",
            "Epoch: 903 | Train Loss: 0.18720 | Valid Loss: 0.18486 | Time: 0.48 seconds\n",
            "Epoch: 904 | Train Loss: 0.18689 | Valid Loss: 0.18766 | Time: 0.47 seconds\n",
            "Epoch: 905 | Train Loss: 0.18660 | Valid Loss: 0.18408 | Time: 0.47 seconds\n",
            "Epoch: 906 | Train Loss: 0.18629 | Valid Loss: 0.18634 | Time: 0.48 seconds\n",
            "Epoch: 907 | Train Loss: 0.18599 | Valid Loss: 0.18634 | Time: 0.49 seconds\n",
            "Epoch: 908 | Train Loss: 0.18572 | Valid Loss: 0.18429 | Time: 0.45 seconds\n",
            "Epoch: 909 | Train Loss: 0.18546 | Valid Loss: 0.18552 | Time: 0.49 seconds\n",
            "Epoch: 910 | Train Loss: 0.18512 | Valid Loss: 0.18473 | Time: 0.46 seconds\n",
            "Epoch: 911 | Train Loss: 0.18485 | Valid Loss: 0.18424 | Time: 0.47 seconds\n",
            "Epoch: 912 | Train Loss: 0.18455 | Valid Loss: 0.18405 | Time: 0.46 seconds\n",
            "Epoch: 913 | Train Loss: 0.18430 | Valid Loss: 0.18309 | Time: 0.48 seconds\n",
            "Epoch: 914 | Train Loss: 0.18397 | Valid Loss: 0.18386 | Time: 0.47 seconds\n",
            "Epoch: 915 | Train Loss: 0.18371 | Valid Loss: 0.18249 | Time: 0.47 seconds\n",
            "Epoch: 916 | Train Loss: 0.18343 | Valid Loss: 0.18300 | Time: 0.48 seconds\n",
            "Epoch: 917 | Train Loss: 0.18309 | Valid Loss: 0.18075 | Time: 0.46 seconds\n",
            "Epoch: 918 | Train Loss: 0.18285 | Valid Loss: 0.18147 | Time: 0.46 seconds\n",
            "Epoch: 919 | Train Loss: 0.18253 | Valid Loss: 0.18236 | Time: 0.47 seconds\n",
            "Epoch: 920 | Train Loss: 0.18225 | Valid Loss: 0.17983 | Time: 0.49 seconds\n",
            "Epoch: 921 | Train Loss: 0.18199 | Valid Loss: 0.18219 | Time: 0.46 seconds\n",
            "Epoch: 922 | Train Loss: 0.18167 | Valid Loss: 0.17971 | Time: 0.47 seconds\n",
            "Epoch: 923 | Train Loss: 0.18140 | Valid Loss: 0.18089 | Time: 0.47 seconds\n",
            "Epoch: 924 | Train Loss: 0.18111 | Valid Loss: 0.18088 | Time: 0.47 seconds\n",
            "Epoch: 925 | Train Loss: 0.18084 | Valid Loss: 0.17871 | Time: 0.47 seconds\n",
            "Epoch: 926 | Train Loss: 0.18056 | Valid Loss: 0.17927 | Time: 0.45 seconds\n",
            "Epoch: 927 | Train Loss: 0.18025 | Valid Loss: 0.17895 | Time: 0.49 seconds\n",
            "Epoch: 928 | Train Loss: 0.17998 | Valid Loss: 0.18006 | Time: 0.46 seconds\n",
            "Epoch: 929 | Train Loss: 0.17968 | Valid Loss: 0.17875 | Time: 0.47 seconds\n",
            "Epoch: 930 | Train Loss: 0.17939 | Valid Loss: 0.17830 | Time: 0.47 seconds\n",
            "Epoch: 931 | Train Loss: 0.17913 | Valid Loss: 0.17812 | Time: 0.47 seconds\n",
            "Epoch: 932 | Train Loss: 0.17886 | Valid Loss: 0.17845 | Time: 0.46 seconds\n",
            "Epoch: 933 | Train Loss: 0.17855 | Valid Loss: 0.17891 | Time: 0.47 seconds\n",
            "Epoch: 934 | Train Loss: 0.17828 | Valid Loss: 0.17812 | Time: 0.47 seconds\n",
            "Epoch: 935 | Train Loss: 0.17804 | Valid Loss: 0.17736 | Time: 0.48 seconds\n",
            "Epoch: 936 | Train Loss: 0.17775 | Valid Loss: 0.17722 | Time: 0.46 seconds\n",
            "Epoch: 937 | Train Loss: 0.17748 | Valid Loss: 0.17739 | Time: 0.46 seconds\n",
            "Epoch: 938 | Train Loss: 0.17718 | Valid Loss: 0.17718 | Time: 0.47 seconds\n",
            "Epoch: 939 | Train Loss: 0.17690 | Valid Loss: 0.17636 | Time: 0.48 seconds\n",
            "Epoch: 940 | Train Loss: 0.17662 | Valid Loss: 0.17513 | Time: 0.47 seconds\n",
            "Epoch: 941 | Train Loss: 0.17633 | Valid Loss: 0.17515 | Time: 0.46 seconds\n",
            "Epoch: 942 | Train Loss: 0.17610 | Valid Loss: 0.17550 | Time: 0.46 seconds\n",
            "Epoch: 943 | Train Loss: 0.17580 | Valid Loss: 0.17641 | Time: 0.45 seconds\n",
            "Epoch: 944 | Train Loss: 0.17552 | Valid Loss: 0.17594 | Time: 0.47 seconds\n",
            "Epoch: 945 | Train Loss: 0.17522 | Valid Loss: 0.17390 | Time: 0.47 seconds\n",
            "Epoch: 946 | Train Loss: 0.17492 | Valid Loss: 0.17499 | Time: 0.47 seconds\n",
            "Epoch: 947 | Train Loss: 0.17469 | Valid Loss: 0.17281 | Time: 0.46 seconds\n",
            "Epoch: 948 | Train Loss: 0.17442 | Valid Loss: 0.17210 | Time: 0.47 seconds\n",
            "Epoch: 949 | Train Loss: 0.17415 | Valid Loss: 0.17327 | Time: 0.46 seconds\n",
            "Epoch: 950 | Train Loss: 0.17386 | Valid Loss: 0.17457 | Time: 0.48 seconds\n",
            "Epoch: 951 | Train Loss: 0.17361 | Valid Loss: 0.17220 | Time: 0.46 seconds\n",
            "Epoch: 952 | Train Loss: 0.17333 | Valid Loss: 0.17185 | Time: 0.47 seconds\n",
            "Epoch: 953 | Train Loss: 0.17307 | Valid Loss: 0.17222 | Time: 0.47 seconds\n",
            "Epoch: 954 | Train Loss: 0.17282 | Valid Loss: 0.17250 | Time: 0.46 seconds\n",
            "Epoch: 955 | Train Loss: 0.17251 | Valid Loss: 0.17186 | Time: 0.47 seconds\n",
            "Epoch: 956 | Train Loss: 0.17225 | Valid Loss: 0.17167 | Time: 0.46 seconds\n",
            "Epoch: 957 | Train Loss: 0.17198 | Valid Loss: 0.17091 | Time: 0.47 seconds\n",
            "Epoch: 958 | Train Loss: 0.17170 | Valid Loss: 0.17121 | Time: 0.45 seconds\n",
            "Epoch: 959 | Train Loss: 0.17147 | Valid Loss: 0.17190 | Time: 0.48 seconds\n",
            "Epoch: 960 | Train Loss: 0.17116 | Valid Loss: 0.17007 | Time: 0.47 seconds\n",
            "Epoch: 961 | Train Loss: 0.17089 | Valid Loss: 0.16937 | Time: 0.47 seconds\n",
            "Epoch: 962 | Train Loss: 0.17061 | Valid Loss: 0.16903 | Time: 0.47 seconds\n",
            "Epoch: 963 | Train Loss: 0.17034 | Valid Loss: 0.17076 | Time: 0.48 seconds\n",
            "Epoch: 964 | Train Loss: 0.17009 | Valid Loss: 0.16939 | Time: 0.46 seconds\n",
            "Epoch: 965 | Train Loss: 0.16986 | Valid Loss: 0.16966 | Time: 0.46 seconds\n",
            "Epoch: 966 | Train Loss: 0.16958 | Valid Loss: 0.16849 | Time: 0.48 seconds\n",
            "Epoch: 967 | Train Loss: 0.16931 | Valid Loss: 0.16798 | Time: 0.46 seconds\n",
            "Epoch: 968 | Train Loss: 0.16904 | Valid Loss: 0.16820 | Time: 0.47 seconds\n",
            "Epoch: 969 | Train Loss: 0.16876 | Valid Loss: 0.16794 | Time: 0.47 seconds\n",
            "Epoch: 970 | Train Loss: 0.16855 | Valid Loss: 0.16731 | Time: 0.47 seconds\n",
            "Epoch: 971 | Train Loss: 0.16826 | Valid Loss: 0.16731 | Time: 0.47 seconds\n",
            "Epoch: 972 | Train Loss: 0.16798 | Valid Loss: 0.16745 | Time: 0.48 seconds\n",
            "Epoch: 973 | Train Loss: 0.16771 | Valid Loss: 0.16695 | Time: 0.47 seconds\n",
            "Epoch: 974 | Train Loss: 0.16744 | Valid Loss: 0.16621 | Time: 0.47 seconds\n",
            "Epoch: 975 | Train Loss: 0.16719 | Valid Loss: 0.16731 | Time: 0.45 seconds\n",
            "Epoch: 976 | Train Loss: 0.16695 | Valid Loss: 0.16744 | Time: 0.45 seconds\n",
            "Epoch: 977 | Train Loss: 0.16669 | Valid Loss: 0.16524 | Time: 0.48 seconds\n",
            "Epoch: 978 | Train Loss: 0.16644 | Valid Loss: 0.16513 | Time: 0.46 seconds\n",
            "Epoch: 979 | Train Loss: 0.16618 | Valid Loss: 0.16572 | Time: 0.46 seconds\n",
            "Epoch: 980 | Train Loss: 0.16590 | Valid Loss: 0.16557 | Time: 0.46 seconds\n",
            "Epoch: 981 | Train Loss: 0.16565 | Valid Loss: 0.16539 | Time: 0.47 seconds\n",
            "Epoch: 982 | Train Loss: 0.16539 | Valid Loss: 0.16534 | Time: 0.45 seconds\n",
            "Epoch: 983 | Train Loss: 0.16516 | Valid Loss: 0.16487 | Time: 0.49 seconds\n",
            "Epoch: 984 | Train Loss: 0.16490 | Valid Loss: 0.16313 | Time: 0.46 seconds\n",
            "Epoch: 985 | Train Loss: 0.16459 | Valid Loss: 0.16527 | Time: 0.47 seconds\n",
            "Epoch: 986 | Train Loss: 0.16436 | Valid Loss: 0.16218 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16411 | Valid Loss: 0.16438 | Time: 0.47 seconds\n",
            "Epoch: 988 | Train Loss: 0.16384 | Valid Loss: 0.16280 | Time: 0.46 seconds\n",
            "Epoch: 989 | Train Loss: 0.16358 | Valid Loss: 0.16334 | Time: 0.47 seconds\n",
            "Epoch: 990 | Train Loss: 0.16335 | Valid Loss: 0.16227 | Time: 0.46 seconds\n",
            "Epoch: 991 | Train Loss: 0.16307 | Valid Loss: 0.16290 | Time: 0.45 seconds\n",
            "Epoch: 992 | Train Loss: 0.16281 | Valid Loss: 0.16244 | Time: 0.46 seconds\n",
            "Epoch: 993 | Train Loss: 0.16257 | Valid Loss: 0.16216 | Time: 0.48 seconds\n",
            "Epoch: 994 | Train Loss: 0.16231 | Valid Loss: 0.16107 | Time: 0.47 seconds\n",
            "Epoch: 995 | Train Loss: 0.16205 | Valid Loss: 0.16201 | Time: 0.46 seconds\n",
            "Epoch: 996 | Train Loss: 0.16183 | Valid Loss: 0.16104 | Time: 0.48 seconds\n",
            "Epoch: 997 | Train Loss: 0.16155 | Valid Loss: 0.16076 | Time: 0.49 seconds\n",
            "Epoch: 998 | Train Loss: 0.16133 | Valid Loss: 0.16098 | Time: 0.47 seconds\n",
            "Epoch: 999 | Train Loss: 0.16105 | Valid Loss: 0.16116 | Time: 0.46 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16080 | Valid Loss: 0.16205 | Time: 0.47 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 997\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.82 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 5]: 34.59102\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 6...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71486 | Valid Loss: 0.71130 | Time: 0.48 seconds\n",
            "Epoch: 2 | Train Loss: 0.71431 | Valid Loss: 0.71328 | Time: 0.48 seconds\n",
            "Epoch: 3 | Train Loss: 0.71381 | Valid Loss: 0.71301 | Time: 0.46 seconds\n",
            "Epoch: 4 | Train Loss: 0.71329 | Valid Loss: 0.71227 | Time: 0.46 seconds\n",
            "Epoch: 5 | Train Loss: 0.71281 | Valid Loss: 0.71232 | Time: 0.46 seconds\n",
            "Epoch: 6 | Train Loss: 0.71234 | Valid Loss: 0.71144 | Time: 0.47 seconds\n",
            "Epoch: 7 | Train Loss: 0.71191 | Valid Loss: 0.71153 | Time: 0.48 seconds\n",
            "Epoch: 8 | Train Loss: 0.71149 | Valid Loss: 0.71081 | Time: 0.46 seconds\n",
            "Epoch: 9 | Train Loss: 0.71107 | Valid Loss: 0.71075 | Time: 0.47 seconds\n",
            "Epoch: 10 | Train Loss: 0.71065 | Valid Loss: 0.70951 | Time: 0.47 seconds\n",
            "Epoch: 11 | Train Loss: 0.71027 | Valid Loss: 0.70952 | Time: 0.46 seconds\n",
            "Epoch: 12 | Train Loss: 0.70987 | Valid Loss: 0.70829 | Time: 0.48 seconds\n",
            "Epoch: 13 | Train Loss: 0.70950 | Valid Loss: 0.70846 | Time: 0.47 seconds\n",
            "Epoch: 14 | Train Loss: 0.70914 | Valid Loss: 0.70833 | Time: 0.46 seconds\n",
            "Epoch: 15 | Train Loss: 0.70878 | Valid Loss: 0.70775 | Time: 0.49 seconds\n",
            "Epoch: 16 | Train Loss: 0.70842 | Valid Loss: 0.70836 | Time: 0.47 seconds\n",
            "Epoch: 17 | Train Loss: 0.70807 | Valid Loss: 0.70752 | Time: 0.47 seconds\n",
            "Epoch: 18 | Train Loss: 0.70775 | Valid Loss: 0.70689 | Time: 0.47 seconds\n",
            "Epoch: 19 | Train Loss: 0.70740 | Valid Loss: 0.70665 | Time: 0.47 seconds\n",
            "Epoch: 20 | Train Loss: 0.70707 | Valid Loss: 0.70578 | Time: 0.47 seconds\n",
            "Epoch: 21 | Train Loss: 0.70674 | Valid Loss: 0.70613 | Time: 0.47 seconds\n",
            "Epoch: 22 | Train Loss: 0.70641 | Valid Loss: 0.70585 | Time: 0.47 seconds\n",
            "Epoch: 23 | Train Loss: 0.70610 | Valid Loss: 0.70554 | Time: 0.47 seconds\n",
            "Epoch: 24 | Train Loss: 0.70577 | Valid Loss: 0.70496 | Time: 0.48 seconds\n",
            "Epoch: 25 | Train Loss: 0.70546 | Valid Loss: 0.70495 | Time: 0.46 seconds\n",
            "Epoch: 26 | Train Loss: 0.70514 | Valid Loss: 0.70435 | Time: 0.48 seconds\n",
            "Epoch: 27 | Train Loss: 0.70484 | Valid Loss: 0.70382 | Time: 0.46 seconds\n",
            "Epoch: 28 | Train Loss: 0.70451 | Valid Loss: 0.70453 | Time: 0.48 seconds\n",
            "Epoch: 29 | Train Loss: 0.70419 | Valid Loss: 0.70360 | Time: 0.48 seconds\n",
            "Epoch: 30 | Train Loss: 0.70389 | Valid Loss: 0.70374 | Time: 0.46 seconds\n",
            "Epoch: 31 | Train Loss: 0.70356 | Valid Loss: 0.70272 | Time: 0.50 seconds\n",
            "Epoch: 32 | Train Loss: 0.70326 | Valid Loss: 0.70306 | Time: 0.47 seconds\n",
            "Epoch: 33 | Train Loss: 0.70293 | Valid Loss: 0.70271 | Time: 0.47 seconds\n",
            "Epoch: 34 | Train Loss: 0.70262 | Valid Loss: 0.70261 | Time: 0.49 seconds\n",
            "Epoch: 35 | Train Loss: 0.70230 | Valid Loss: 0.70196 | Time: 0.48 seconds\n",
            "Epoch: 36 | Train Loss: 0.70198 | Valid Loss: 0.70122 | Time: 0.47 seconds\n",
            "Epoch: 37 | Train Loss: 0.70165 | Valid Loss: 0.70094 | Time: 0.47 seconds\n",
            "Epoch: 38 | Train Loss: 0.70132 | Valid Loss: 0.70084 | Time: 0.47 seconds\n",
            "Epoch: 39 | Train Loss: 0.70100 | Valid Loss: 0.69981 | Time: 0.48 seconds\n",
            "Epoch: 40 | Train Loss: 0.70067 | Valid Loss: 0.70004 | Time: 0.46 seconds\n",
            "Epoch: 41 | Train Loss: 0.70035 | Valid Loss: 0.69978 | Time: 0.48 seconds\n",
            "Epoch: 42 | Train Loss: 0.70001 | Valid Loss: 0.69913 | Time: 0.47 seconds\n",
            "Epoch: 43 | Train Loss: 0.69967 | Valid Loss: 0.69891 | Time: 0.48 seconds\n",
            "Epoch: 44 | Train Loss: 0.69934 | Valid Loss: 0.69883 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69900 | Valid Loss: 0.69811 | Time: 0.49 seconds\n",
            "Epoch: 46 | Train Loss: 0.69866 | Valid Loss: 0.69804 | Time: 0.47 seconds\n",
            "Epoch: 47 | Train Loss: 0.69830 | Valid Loss: 0.69744 | Time: 0.49 seconds\n",
            "Epoch: 48 | Train Loss: 0.69795 | Valid Loss: 0.69820 | Time: 0.46 seconds\n",
            "Epoch: 49 | Train Loss: 0.69758 | Valid Loss: 0.69710 | Time: 0.48 seconds\n",
            "Epoch: 50 | Train Loss: 0.69722 | Valid Loss: 0.69676 | Time: 0.47 seconds\n",
            "Epoch: 51 | Train Loss: 0.69686 | Valid Loss: 0.69622 | Time: 0.47 seconds\n",
            "Epoch: 52 | Train Loss: 0.69650 | Valid Loss: 0.69579 | Time: 0.48 seconds\n",
            "Epoch: 53 | Train Loss: 0.69612 | Valid Loss: 0.69541 | Time: 0.47 seconds\n",
            "Epoch: 54 | Train Loss: 0.69575 | Valid Loss: 0.69481 | Time: 0.48 seconds\n",
            "Epoch: 55 | Train Loss: 0.69537 | Valid Loss: 0.69426 | Time: 0.46 seconds\n",
            "Epoch: 56 | Train Loss: 0.69498 | Valid Loss: 0.69368 | Time: 0.49 seconds\n",
            "Epoch: 57 | Train Loss: 0.69460 | Valid Loss: 0.69420 | Time: 0.45 seconds\n",
            "Epoch: 58 | Train Loss: 0.69419 | Valid Loss: 0.69345 | Time: 0.48 seconds\n",
            "Epoch: 59 | Train Loss: 0.69380 | Valid Loss: 0.69283 | Time: 0.46 seconds\n",
            "Epoch: 60 | Train Loss: 0.69340 | Valid Loss: 0.69332 | Time: 0.47 seconds\n",
            "Epoch: 61 | Train Loss: 0.69300 | Valid Loss: 0.69257 | Time: 0.47 seconds\n",
            "Epoch: 62 | Train Loss: 0.69259 | Valid Loss: 0.69181 | Time: 0.48 seconds\n",
            "Epoch: 63 | Train Loss: 0.69218 | Valid Loss: 0.69201 | Time: 0.45 seconds\n",
            "Epoch: 64 | Train Loss: 0.69176 | Valid Loss: 0.69119 | Time: 0.48 seconds\n",
            "Epoch: 65 | Train Loss: 0.69134 | Valid Loss: 0.69059 | Time: 0.48 seconds\n",
            "Epoch: 66 | Train Loss: 0.69090 | Valid Loss: 0.69073 | Time: 0.45 seconds\n",
            "Epoch: 67 | Train Loss: 0.69048 | Valid Loss: 0.68997 | Time: 0.49 seconds\n",
            "Epoch: 68 | Train Loss: 0.69004 | Valid Loss: 0.68923 | Time: 0.50 seconds\n",
            "Epoch: 69 | Train Loss: 0.68961 | Valid Loss: 0.68899 | Time: 0.49 seconds\n",
            "Epoch: 70 | Train Loss: 0.68916 | Valid Loss: 0.68861 | Time: 0.48 seconds\n",
            "Epoch: 71 | Train Loss: 0.68872 | Valid Loss: 0.68839 | Time: 0.48 seconds\n",
            "Epoch: 72 | Train Loss: 0.68827 | Valid Loss: 0.68768 | Time: 0.46 seconds\n",
            "Epoch: 73 | Train Loss: 0.68782 | Valid Loss: 0.68674 | Time: 0.49 seconds\n",
            "Epoch: 74 | Train Loss: 0.68735 | Valid Loss: 0.68661 | Time: 0.47 seconds\n",
            "Epoch: 75 | Train Loss: 0.68688 | Valid Loss: 0.68617 | Time: 0.47 seconds\n",
            "Epoch: 76 | Train Loss: 0.68643 | Valid Loss: 0.68599 | Time: 0.48 seconds\n",
            "Epoch: 77 | Train Loss: 0.68596 | Valid Loss: 0.68538 | Time: 0.49 seconds\n",
            "Epoch: 78 | Train Loss: 0.68548 | Valid Loss: 0.68489 | Time: 0.49 seconds\n",
            "Epoch: 79 | Train Loss: 0.68500 | Valid Loss: 0.68475 | Time: 0.51 seconds\n",
            "Epoch: 80 | Train Loss: 0.68450 | Valid Loss: 0.68355 | Time: 0.46 seconds\n",
            "Epoch: 81 | Train Loss: 0.68402 | Valid Loss: 0.68348 | Time: 0.48 seconds\n",
            "Epoch: 82 | Train Loss: 0.68354 | Valid Loss: 0.68279 | Time: 0.47 seconds\n",
            "Epoch: 83 | Train Loss: 0.68305 | Valid Loss: 0.68264 | Time: 0.47 seconds\n",
            "Epoch: 84 | Train Loss: 0.68253 | Valid Loss: 0.68236 | Time: 0.48 seconds\n",
            "Epoch: 85 | Train Loss: 0.68203 | Valid Loss: 0.68084 | Time: 0.47 seconds\n",
            "Epoch: 86 | Train Loss: 0.68152 | Valid Loss: 0.68096 | Time: 0.47 seconds\n",
            "Epoch: 87 | Train Loss: 0.68102 | Valid Loss: 0.67979 | Time: 0.47 seconds\n",
            "Epoch: 88 | Train Loss: 0.68049 | Valid Loss: 0.68023 | Time: 0.47 seconds\n",
            "Epoch: 89 | Train Loss: 0.67998 | Valid Loss: 0.67912 | Time: 0.46 seconds\n",
            "Epoch: 90 | Train Loss: 0.67945 | Valid Loss: 0.67929 | Time: 0.48 seconds\n",
            "Epoch: 91 | Train Loss: 0.67892 | Valid Loss: 0.67865 | Time: 0.47 seconds\n",
            "Epoch: 92 | Train Loss: 0.67840 | Valid Loss: 0.67753 | Time: 0.47 seconds\n",
            "Epoch: 93 | Train Loss: 0.67787 | Valid Loss: 0.67711 | Time: 0.47 seconds\n",
            "Epoch: 94 | Train Loss: 0.67732 | Valid Loss: 0.67675 | Time: 0.48 seconds\n",
            "Epoch: 95 | Train Loss: 0.67676 | Valid Loss: 0.67551 | Time: 0.48 seconds\n",
            "Epoch: 96 | Train Loss: 0.67623 | Valid Loss: 0.67517 | Time: 0.47 seconds\n",
            "Epoch: 97 | Train Loss: 0.67568 | Valid Loss: 0.67516 | Time: 0.47 seconds\n",
            "Epoch: 98 | Train Loss: 0.67512 | Valid Loss: 0.67411 | Time: 0.47 seconds\n",
            "Epoch: 99 | Train Loss: 0.67456 | Valid Loss: 0.67410 | Time: 0.49 seconds\n",
            "Epoch: 100 | Train Loss: 0.67399 | Valid Loss: 0.67294 | Time: 0.47 seconds\n",
            "Epoch: 101 | Train Loss: 0.67344 | Valid Loss: 0.67322 | Time: 0.47 seconds\n",
            "Epoch: 102 | Train Loss: 0.67287 | Valid Loss: 0.67216 | Time: 0.47 seconds\n",
            "Epoch: 103 | Train Loss: 0.67229 | Valid Loss: 0.67075 | Time: 0.47 seconds\n",
            "Epoch: 104 | Train Loss: 0.67171 | Valid Loss: 0.67135 | Time: 0.46 seconds\n",
            "Epoch: 105 | Train Loss: 0.67112 | Valid Loss: 0.66907 | Time: 0.49 seconds\n",
            "Epoch: 106 | Train Loss: 0.67054 | Valid Loss: 0.66898 | Time: 0.46 seconds\n",
            "Epoch: 107 | Train Loss: 0.66995 | Valid Loss: 0.66901 | Time: 0.47 seconds\n",
            "Epoch: 108 | Train Loss: 0.66936 | Valid Loss: 0.66888 | Time: 0.46 seconds\n",
            "Epoch: 109 | Train Loss: 0.66876 | Valid Loss: 0.66754 | Time: 0.47 seconds\n",
            "Epoch: 110 | Train Loss: 0.66815 | Valid Loss: 0.66741 | Time: 0.48 seconds\n",
            "Epoch: 111 | Train Loss: 0.66755 | Valid Loss: 0.66666 | Time: 0.49 seconds\n",
            "Epoch: 112 | Train Loss: 0.66693 | Valid Loss: 0.66600 | Time: 0.48 seconds\n",
            "Epoch: 113 | Train Loss: 0.66632 | Valid Loss: 0.66475 | Time: 0.46 seconds\n",
            "Epoch: 114 | Train Loss: 0.66571 | Valid Loss: 0.66518 | Time: 0.47 seconds\n",
            "Epoch: 115 | Train Loss: 0.66508 | Valid Loss: 0.66359 | Time: 0.49 seconds\n",
            "Epoch: 116 | Train Loss: 0.66446 | Valid Loss: 0.66393 | Time: 0.49 seconds\n",
            "Epoch: 117 | Train Loss: 0.66384 | Valid Loss: 0.66243 | Time: 0.47 seconds\n",
            "Epoch: 118 | Train Loss: 0.66320 | Valid Loss: 0.66193 | Time: 0.48 seconds\n",
            "Epoch: 119 | Train Loss: 0.66257 | Valid Loss: 0.66193 | Time: 0.48 seconds\n",
            "Epoch: 120 | Train Loss: 0.66193 | Valid Loss: 0.66087 | Time: 0.47 seconds\n",
            "Epoch: 121 | Train Loss: 0.66129 | Valid Loss: 0.66000 | Time: 0.46 seconds\n",
            "Epoch: 122 | Train Loss: 0.66063 | Valid Loss: 0.65920 | Time: 0.49 seconds\n",
            "Epoch: 123 | Train Loss: 0.65999 | Valid Loss: 0.65898 | Time: 0.48 seconds\n",
            "Epoch: 124 | Train Loss: 0.65933 | Valid Loss: 0.65804 | Time: 0.48 seconds\n",
            "Epoch: 125 | Train Loss: 0.65868 | Valid Loss: 0.65691 | Time: 0.47 seconds\n",
            "Epoch: 126 | Train Loss: 0.65801 | Valid Loss: 0.65756 | Time: 0.46 seconds\n",
            "Epoch: 127 | Train Loss: 0.65736 | Valid Loss: 0.65599 | Time: 0.49 seconds\n",
            "Epoch: 128 | Train Loss: 0.65669 | Valid Loss: 0.65550 | Time: 0.47 seconds\n",
            "Epoch: 129 | Train Loss: 0.65602 | Valid Loss: 0.65639 | Time: 0.47 seconds\n",
            "Epoch: 130 | Train Loss: 0.65535 | Valid Loss: 0.65536 | Time: 0.47 seconds\n",
            "Epoch: 131 | Train Loss: 0.65468 | Valid Loss: 0.65243 | Time: 0.47 seconds\n",
            "Epoch: 132 | Train Loss: 0.65399 | Valid Loss: 0.65212 | Time: 0.48 seconds\n",
            "Epoch: 133 | Train Loss: 0.65331 | Valid Loss: 0.65167 | Time: 0.49 seconds\n",
            "Epoch: 134 | Train Loss: 0.65262 | Valid Loss: 0.65205 | Time: 0.46 seconds\n",
            "Epoch: 135 | Train Loss: 0.65193 | Valid Loss: 0.65046 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65124 | Valid Loss: 0.65038 | Time: 0.47 seconds\n",
            "Epoch: 137 | Train Loss: 0.65054 | Valid Loss: 0.65003 | Time: 0.47 seconds\n",
            "Epoch: 138 | Train Loss: 0.64984 | Valid Loss: 0.64823 | Time: 0.49 seconds\n",
            "Epoch: 139 | Train Loss: 0.64916 | Valid Loss: 0.64867 | Time: 0.47 seconds\n",
            "Epoch: 140 | Train Loss: 0.64843 | Valid Loss: 0.64572 | Time: 0.48 seconds\n",
            "Epoch: 141 | Train Loss: 0.64774 | Valid Loss: 0.64689 | Time: 0.46 seconds\n",
            "Epoch: 142 | Train Loss: 0.64703 | Valid Loss: 0.64510 | Time: 0.51 seconds\n",
            "Epoch: 143 | Train Loss: 0.64632 | Valid Loss: 0.64485 | Time: 0.47 seconds\n",
            "Epoch: 144 | Train Loss: 0.64561 | Valid Loss: 0.64324 | Time: 0.49 seconds\n",
            "Epoch: 145 | Train Loss: 0.64488 | Valid Loss: 0.64376 | Time: 0.46 seconds\n",
            "Epoch: 146 | Train Loss: 0.64416 | Valid Loss: 0.64374 | Time: 0.47 seconds\n",
            "Epoch: 147 | Train Loss: 0.64344 | Valid Loss: 0.64232 | Time: 0.47 seconds\n",
            "Epoch: 148 | Train Loss: 0.64271 | Valid Loss: 0.64072 | Time: 0.48 seconds\n",
            "Epoch: 149 | Train Loss: 0.64200 | Valid Loss: 0.64012 | Time: 0.47 seconds\n",
            "Epoch: 150 | Train Loss: 0.64126 | Valid Loss: 0.63975 | Time: 0.48 seconds\n",
            "Epoch: 151 | Train Loss: 0.64052 | Valid Loss: 0.63863 | Time: 0.47 seconds\n",
            "Epoch: 152 | Train Loss: 0.63979 | Valid Loss: 0.63900 | Time: 0.47 seconds\n",
            "Epoch: 153 | Train Loss: 0.63906 | Valid Loss: 0.63666 | Time: 0.46 seconds\n",
            "Epoch: 154 | Train Loss: 0.63831 | Valid Loss: 0.63649 | Time: 0.48 seconds\n",
            "Epoch: 155 | Train Loss: 0.63757 | Valid Loss: 0.63592 | Time: 0.46 seconds\n",
            "Epoch: 156 | Train Loss: 0.63681 | Valid Loss: 0.63498 | Time: 0.48 seconds\n",
            "Epoch: 157 | Train Loss: 0.63608 | Valid Loss: 0.63443 | Time: 0.47 seconds\n",
            "Epoch: 158 | Train Loss: 0.63533 | Valid Loss: 0.63391 | Time: 0.46 seconds\n",
            "Epoch: 159 | Train Loss: 0.63457 | Valid Loss: 0.63420 | Time: 0.47 seconds\n",
            "Epoch: 160 | Train Loss: 0.63381 | Valid Loss: 0.63363 | Time: 0.48 seconds\n",
            "Epoch: 161 | Train Loss: 0.63306 | Valid Loss: 0.63164 | Time: 0.48 seconds\n",
            "Epoch: 162 | Train Loss: 0.63231 | Valid Loss: 0.63192 | Time: 0.46 seconds\n",
            "Epoch: 163 | Train Loss: 0.63154 | Valid Loss: 0.63040 | Time: 0.48 seconds\n",
            "Epoch: 164 | Train Loss: 0.63077 | Valid Loss: 0.62909 | Time: 0.47 seconds\n",
            "Epoch: 165 | Train Loss: 0.63001 | Valid Loss: 0.62945 | Time: 0.49 seconds\n",
            "Epoch: 166 | Train Loss: 0.62925 | Valid Loss: 0.62845 | Time: 0.46 seconds\n",
            "Epoch: 167 | Train Loss: 0.62846 | Valid Loss: 0.62742 | Time: 0.48 seconds\n",
            "Epoch: 168 | Train Loss: 0.62771 | Valid Loss: 0.62589 | Time: 0.46 seconds\n",
            "Epoch: 169 | Train Loss: 0.62694 | Valid Loss: 0.62560 | Time: 0.48 seconds\n",
            "Epoch: 170 | Train Loss: 0.62617 | Valid Loss: 0.62441 | Time: 0.47 seconds\n",
            "Epoch: 171 | Train Loss: 0.62538 | Valid Loss: 0.62268 | Time: 0.47 seconds\n",
            "Epoch: 172 | Train Loss: 0.62460 | Valid Loss: 0.62239 | Time: 0.47 seconds\n",
            "Epoch: 173 | Train Loss: 0.62382 | Valid Loss: 0.62251 | Time: 0.46 seconds\n",
            "Epoch: 174 | Train Loss: 0.62304 | Valid Loss: 0.62095 | Time: 0.48 seconds\n",
            "Epoch: 175 | Train Loss: 0.62225 | Valid Loss: 0.62058 | Time: 0.47 seconds\n",
            "Epoch: 176 | Train Loss: 0.62147 | Valid Loss: 0.62145 | Time: 0.47 seconds\n",
            "Epoch: 177 | Train Loss: 0.62068 | Valid Loss: 0.61879 | Time: 0.46 seconds\n",
            "Epoch: 178 | Train Loss: 0.61990 | Valid Loss: 0.61814 | Time: 0.49 seconds\n",
            "Epoch: 179 | Train Loss: 0.61911 | Valid Loss: 0.61773 | Time: 0.48 seconds\n",
            "Epoch: 180 | Train Loss: 0.61830 | Valid Loss: 0.61610 | Time: 0.48 seconds\n",
            "Epoch: 181 | Train Loss: 0.61751 | Valid Loss: 0.61612 | Time: 0.46 seconds\n",
            "Epoch: 182 | Train Loss: 0.61673 | Valid Loss: 0.61594 | Time: 0.48 seconds\n",
            "Epoch: 183 | Train Loss: 0.61592 | Valid Loss: 0.61334 | Time: 0.48 seconds\n",
            "Epoch: 184 | Train Loss: 0.61512 | Valid Loss: 0.61394 | Time: 0.47 seconds\n",
            "Epoch: 185 | Train Loss: 0.61434 | Valid Loss: 0.61231 | Time: 0.48 seconds\n",
            "Epoch: 186 | Train Loss: 0.61353 | Valid Loss: 0.61259 | Time: 0.46 seconds\n",
            "Epoch: 187 | Train Loss: 0.61273 | Valid Loss: 0.61044 | Time: 0.48 seconds\n",
            "Epoch: 188 | Train Loss: 0.61192 | Valid Loss: 0.60966 | Time: 0.47 seconds\n",
            "Epoch: 189 | Train Loss: 0.61111 | Valid Loss: 0.60889 | Time: 0.48 seconds\n",
            "Epoch: 190 | Train Loss: 0.61031 | Valid Loss: 0.60921 | Time: 0.46 seconds\n",
            "Epoch: 191 | Train Loss: 0.60950 | Valid Loss: 0.60811 | Time: 0.47 seconds\n",
            "Epoch: 192 | Train Loss: 0.60869 | Valid Loss: 0.60725 | Time: 0.46 seconds\n",
            "Epoch: 193 | Train Loss: 0.60788 | Valid Loss: 0.60561 | Time: 0.51 seconds\n",
            "Epoch: 194 | Train Loss: 0.60706 | Valid Loss: 0.60449 | Time: 0.48 seconds\n",
            "Epoch: 195 | Train Loss: 0.60625 | Valid Loss: 0.60375 | Time: 0.48 seconds\n",
            "Epoch: 196 | Train Loss: 0.60543 | Valid Loss: 0.60269 | Time: 0.47 seconds\n",
            "Epoch: 197 | Train Loss: 0.60462 | Valid Loss: 0.60206 | Time: 0.48 seconds\n",
            "Epoch: 198 | Train Loss: 0.60381 | Valid Loss: 0.60170 | Time: 0.47 seconds\n",
            "Epoch: 199 | Train Loss: 0.60299 | Valid Loss: 0.60044 | Time: 0.52 seconds\n",
            "Epoch: 200 | Train Loss: 0.60217 | Valid Loss: 0.60177 | Time: 0.46 seconds\n",
            "Epoch: 201 | Train Loss: 0.60135 | Valid Loss: 0.59881 | Time: 0.47 seconds\n",
            "Epoch: 202 | Train Loss: 0.60053 | Valid Loss: 0.59889 | Time: 0.47 seconds\n",
            "Epoch: 203 | Train Loss: 0.59970 | Valid Loss: 0.59858 | Time: 0.48 seconds\n",
            "Epoch: 204 | Train Loss: 0.59887 | Valid Loss: 0.59646 | Time: 0.48 seconds\n",
            "Epoch: 205 | Train Loss: 0.59805 | Valid Loss: 0.59628 | Time: 0.48 seconds\n",
            "Epoch: 206 | Train Loss: 0.59723 | Valid Loss: 0.59567 | Time: 0.50 seconds\n",
            "Epoch: 207 | Train Loss: 0.59639 | Valid Loss: 0.59292 | Time: 0.49 seconds\n",
            "Epoch: 208 | Train Loss: 0.59558 | Valid Loss: 0.59269 | Time: 0.49 seconds\n",
            "Epoch: 209 | Train Loss: 0.59474 | Valid Loss: 0.59179 | Time: 0.49 seconds\n",
            "Epoch: 210 | Train Loss: 0.59391 | Valid Loss: 0.59168 | Time: 0.48 seconds\n",
            "Epoch: 211 | Train Loss: 0.59309 | Valid Loss: 0.59083 | Time: 0.48 seconds\n",
            "Epoch: 212 | Train Loss: 0.59224 | Valid Loss: 0.59195 | Time: 0.48 seconds\n",
            "Epoch: 213 | Train Loss: 0.59141 | Valid Loss: 0.58783 | Time: 0.47 seconds\n",
            "Epoch: 214 | Train Loss: 0.59059 | Valid Loss: 0.58769 | Time: 0.50 seconds\n",
            "Epoch: 215 | Train Loss: 0.58975 | Valid Loss: 0.58800 | Time: 0.46 seconds\n",
            "Epoch: 216 | Train Loss: 0.58892 | Valid Loss: 0.58696 | Time: 0.48 seconds\n",
            "Epoch: 217 | Train Loss: 0.58807 | Valid Loss: 0.58436 | Time: 0.47 seconds\n",
            "Epoch: 218 | Train Loss: 0.58723 | Valid Loss: 0.58496 | Time: 0.47 seconds\n",
            "Epoch: 219 | Train Loss: 0.58639 | Valid Loss: 0.58308 | Time: 0.49 seconds\n",
            "Epoch: 220 | Train Loss: 0.58557 | Valid Loss: 0.58330 | Time: 0.46 seconds\n",
            "Epoch: 221 | Train Loss: 0.58472 | Valid Loss: 0.58109 | Time: 0.47 seconds\n",
            "Epoch: 222 | Train Loss: 0.58388 | Valid Loss: 0.58178 | Time: 0.48 seconds\n",
            "Epoch: 223 | Train Loss: 0.58303 | Valid Loss: 0.58052 | Time: 0.48 seconds\n",
            "Epoch: 224 | Train Loss: 0.58219 | Valid Loss: 0.58142 | Time: 0.47 seconds\n",
            "Epoch: 225 | Train Loss: 0.58135 | Valid Loss: 0.57938 | Time: 0.48 seconds\n",
            "Epoch: 226 | Train Loss: 0.58049 | Valid Loss: 0.57931 | Time: 0.47 seconds\n",
            "Epoch: 227 | Train Loss: 0.57966 | Valid Loss: 0.57715 | Time: 0.48 seconds\n",
            "Epoch: 228 | Train Loss: 0.57880 | Valid Loss: 0.57565 | Time: 0.46 seconds\n",
            "Epoch: 229 | Train Loss: 0.57797 | Valid Loss: 0.57515 | Time: 0.49 seconds\n",
            "Epoch: 230 | Train Loss: 0.57711 | Valid Loss: 0.57464 | Time: 0.47 seconds\n",
            "Epoch: 231 | Train Loss: 0.57625 | Valid Loss: 0.57434 | Time: 0.49 seconds\n",
            "Epoch: 232 | Train Loss: 0.57540 | Valid Loss: 0.57425 | Time: 0.48 seconds\n",
            "Epoch: 233 | Train Loss: 0.57456 | Valid Loss: 0.57319 | Time: 0.47 seconds\n",
            "Epoch: 234 | Train Loss: 0.57371 | Valid Loss: 0.57124 | Time: 0.47 seconds\n",
            "Epoch: 235 | Train Loss: 0.57285 | Valid Loss: 0.56935 | Time: 0.47 seconds\n",
            "Epoch: 236 | Train Loss: 0.57200 | Valid Loss: 0.56951 | Time: 0.47 seconds\n",
            "Epoch: 237 | Train Loss: 0.57114 | Valid Loss: 0.56799 | Time: 0.47 seconds\n",
            "Epoch: 238 | Train Loss: 0.57030 | Valid Loss: 0.56704 | Time: 0.48 seconds\n",
            "Epoch: 239 | Train Loss: 0.56944 | Valid Loss: 0.56647 | Time: 0.46 seconds\n",
            "Epoch: 240 | Train Loss: 0.56857 | Valid Loss: 0.56504 | Time: 0.47 seconds\n",
            "Epoch: 241 | Train Loss: 0.56773 | Valid Loss: 0.56468 | Time: 0.48 seconds\n",
            "Epoch: 242 | Train Loss: 0.56687 | Valid Loss: 0.56466 | Time: 0.49 seconds\n",
            "Epoch: 243 | Train Loss: 0.56600 | Valid Loss: 0.56411 | Time: 0.46 seconds\n",
            "Epoch: 244 | Train Loss: 0.56515 | Valid Loss: 0.56291 | Time: 0.49 seconds\n",
            "Epoch: 245 | Train Loss: 0.56429 | Valid Loss: 0.56209 | Time: 0.47 seconds\n",
            "Epoch: 246 | Train Loss: 0.56343 | Valid Loss: 0.55988 | Time: 0.49 seconds\n",
            "Epoch: 247 | Train Loss: 0.56257 | Valid Loss: 0.55941 | Time: 0.46 seconds\n",
            "Epoch: 248 | Train Loss: 0.56171 | Valid Loss: 0.55851 | Time: 0.49 seconds\n",
            "Epoch: 249 | Train Loss: 0.56085 | Valid Loss: 0.55777 | Time: 0.50 seconds\n",
            "Epoch: 250 | Train Loss: 0.55998 | Valid Loss: 0.55699 | Time: 0.47 seconds\n",
            "Epoch: 251 | Train Loss: 0.55912 | Valid Loss: 0.55563 | Time: 0.48 seconds\n",
            "Epoch: 252 | Train Loss: 0.55826 | Valid Loss: 0.55560 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55740 | Valid Loss: 0.55440 | Time: 0.47 seconds\n",
            "Epoch: 254 | Train Loss: 0.55654 | Valid Loss: 0.55293 | Time: 0.47 seconds\n",
            "Epoch: 255 | Train Loss: 0.55567 | Valid Loss: 0.55389 | Time: 0.48 seconds\n",
            "Epoch: 256 | Train Loss: 0.55482 | Valid Loss: 0.55335 | Time: 0.46 seconds\n",
            "Epoch: 257 | Train Loss: 0.55395 | Valid Loss: 0.55067 | Time: 0.48 seconds\n",
            "Epoch: 258 | Train Loss: 0.55308 | Valid Loss: 0.55133 | Time: 0.47 seconds\n",
            "Epoch: 259 | Train Loss: 0.55221 | Valid Loss: 0.54873 | Time: 0.48 seconds\n",
            "Epoch: 260 | Train Loss: 0.55133 | Valid Loss: 0.54819 | Time: 0.46 seconds\n",
            "Epoch: 261 | Train Loss: 0.55047 | Valid Loss: 0.54706 | Time: 0.47 seconds\n",
            "Epoch: 262 | Train Loss: 0.54961 | Valid Loss: 0.54776 | Time: 0.46 seconds\n",
            "Epoch: 263 | Train Loss: 0.54873 | Valid Loss: 0.54467 | Time: 0.46 seconds\n",
            "Epoch: 264 | Train Loss: 0.54787 | Valid Loss: 0.54465 | Time: 0.48 seconds\n",
            "Epoch: 265 | Train Loss: 0.54699 | Valid Loss: 0.54698 | Time: 0.47 seconds\n",
            "Epoch: 266 | Train Loss: 0.54612 | Valid Loss: 0.54426 | Time: 0.48 seconds\n",
            "Epoch: 267 | Train Loss: 0.54527 | Valid Loss: 0.54249 | Time: 0.47 seconds\n",
            "Epoch: 268 | Train Loss: 0.54438 | Valid Loss: 0.54196 | Time: 0.49 seconds\n",
            "Epoch: 269 | Train Loss: 0.54352 | Valid Loss: 0.54054 | Time: 0.47 seconds\n",
            "Epoch: 270 | Train Loss: 0.54266 | Valid Loss: 0.54057 | Time: 0.48 seconds\n",
            "Epoch: 271 | Train Loss: 0.54178 | Valid Loss: 0.54034 | Time: 0.46 seconds\n",
            "Epoch: 272 | Train Loss: 0.54092 | Valid Loss: 0.53835 | Time: 0.48 seconds\n",
            "Epoch: 273 | Train Loss: 0.54004 | Valid Loss: 0.53820 | Time: 0.47 seconds\n",
            "Epoch: 274 | Train Loss: 0.53917 | Valid Loss: 0.53526 | Time: 0.48 seconds\n",
            "Epoch: 275 | Train Loss: 0.53830 | Valid Loss: 0.53498 | Time: 0.48 seconds\n",
            "Epoch: 276 | Train Loss: 0.53742 | Valid Loss: 0.53452 | Time: 0.47 seconds\n",
            "Epoch: 277 | Train Loss: 0.53656 | Valid Loss: 0.53417 | Time: 0.46 seconds\n",
            "Epoch: 278 | Train Loss: 0.53568 | Valid Loss: 0.53258 | Time: 0.47 seconds\n",
            "Epoch: 279 | Train Loss: 0.53480 | Valid Loss: 0.53102 | Time: 0.49 seconds\n",
            "Epoch: 280 | Train Loss: 0.53394 | Valid Loss: 0.53119 | Time: 0.46 seconds\n",
            "Epoch: 281 | Train Loss: 0.53306 | Valid Loss: 0.53029 | Time: 0.48 seconds\n",
            "Epoch: 282 | Train Loss: 0.53218 | Valid Loss: 0.52883 | Time: 0.46 seconds\n",
            "Epoch: 283 | Train Loss: 0.53130 | Valid Loss: 0.52764 | Time: 0.49 seconds\n",
            "Epoch: 284 | Train Loss: 0.53042 | Valid Loss: 0.52784 | Time: 0.46 seconds\n",
            "Epoch: 285 | Train Loss: 0.52958 | Valid Loss: 0.52558 | Time: 0.48 seconds\n",
            "Epoch: 286 | Train Loss: 0.52869 | Valid Loss: 0.52519 | Time: 0.46 seconds\n",
            "Epoch: 287 | Train Loss: 0.52782 | Valid Loss: 0.52609 | Time: 0.47 seconds\n",
            "Epoch: 288 | Train Loss: 0.52695 | Valid Loss: 0.52382 | Time: 0.48 seconds\n",
            "Epoch: 289 | Train Loss: 0.52609 | Valid Loss: 0.52281 | Time: 0.48 seconds\n",
            "Epoch: 290 | Train Loss: 0.52519 | Valid Loss: 0.52095 | Time: 0.47 seconds\n",
            "Epoch: 291 | Train Loss: 0.52433 | Valid Loss: 0.52177 | Time: 0.46 seconds\n",
            "Epoch: 292 | Train Loss: 0.52346 | Valid Loss: 0.52231 | Time: 0.47 seconds\n",
            "Epoch: 293 | Train Loss: 0.52257 | Valid Loss: 0.52084 | Time: 0.48 seconds\n",
            "Epoch: 294 | Train Loss: 0.52170 | Valid Loss: 0.51908 | Time: 0.48 seconds\n",
            "Epoch: 295 | Train Loss: 0.52083 | Valid Loss: 0.51962 | Time: 0.46 seconds\n",
            "Epoch: 296 | Train Loss: 0.51997 | Valid Loss: 0.51847 | Time: 0.47 seconds\n",
            "Epoch: 297 | Train Loss: 0.51909 | Valid Loss: 0.51742 | Time: 0.47 seconds\n",
            "Epoch: 298 | Train Loss: 0.51821 | Valid Loss: 0.51702 | Time: 0.49 seconds\n",
            "Epoch: 299 | Train Loss: 0.51736 | Valid Loss: 0.51372 | Time: 0.47 seconds\n",
            "Epoch: 300 | Train Loss: 0.51646 | Valid Loss: 0.51378 | Time: 0.47 seconds\n",
            "Epoch: 301 | Train Loss: 0.51559 | Valid Loss: 0.51276 | Time: 0.46 seconds\n",
            "Epoch: 302 | Train Loss: 0.51473 | Valid Loss: 0.51249 | Time: 0.48 seconds\n",
            "Epoch: 303 | Train Loss: 0.51384 | Valid Loss: 0.50982 | Time: 0.49 seconds\n",
            "Epoch: 304 | Train Loss: 0.51297 | Valid Loss: 0.51145 | Time: 0.47 seconds\n",
            "Epoch: 305 | Train Loss: 0.51208 | Valid Loss: 0.51095 | Time: 0.46 seconds\n",
            "Epoch: 306 | Train Loss: 0.51122 | Valid Loss: 0.50897 | Time: 0.46 seconds\n",
            "Epoch: 307 | Train Loss: 0.51036 | Valid Loss: 0.50838 | Time: 0.47 seconds\n",
            "Epoch: 308 | Train Loss: 0.50949 | Valid Loss: 0.50773 | Time: 0.48 seconds\n",
            "Epoch: 309 | Train Loss: 0.50863 | Valid Loss: 0.50540 | Time: 0.48 seconds\n",
            "Epoch: 310 | Train Loss: 0.50774 | Valid Loss: 0.50566 | Time: 0.46 seconds\n",
            "Epoch: 311 | Train Loss: 0.50685 | Valid Loss: 0.50367 | Time: 0.48 seconds\n",
            "Epoch: 312 | Train Loss: 0.50600 | Valid Loss: 0.50361 | Time: 0.48 seconds\n",
            "Epoch: 313 | Train Loss: 0.50514 | Valid Loss: 0.50162 | Time: 0.48 seconds\n",
            "Epoch: 314 | Train Loss: 0.50426 | Valid Loss: 0.50217 | Time: 0.46 seconds\n",
            "Epoch: 315 | Train Loss: 0.50338 | Valid Loss: 0.50165 | Time: 0.47 seconds\n",
            "Epoch: 316 | Train Loss: 0.50252 | Valid Loss: 0.49860 | Time: 0.47 seconds\n",
            "Epoch: 317 | Train Loss: 0.50167 | Valid Loss: 0.49759 | Time: 0.48 seconds\n",
            "Epoch: 318 | Train Loss: 0.50077 | Valid Loss: 0.49760 | Time: 0.46 seconds\n",
            "Epoch: 319 | Train Loss: 0.49991 | Valid Loss: 0.49661 | Time: 0.47 seconds\n",
            "Epoch: 320 | Train Loss: 0.49904 | Valid Loss: 0.49547 | Time: 0.48 seconds\n",
            "Epoch: 321 | Train Loss: 0.49817 | Valid Loss: 0.49466 | Time: 0.49 seconds\n",
            "Epoch: 322 | Train Loss: 0.49732 | Valid Loss: 0.49429 | Time: 0.48 seconds\n",
            "Epoch: 323 | Train Loss: 0.49646 | Valid Loss: 0.49217 | Time: 0.49 seconds\n",
            "Epoch: 324 | Train Loss: 0.49557 | Valid Loss: 0.49240 | Time: 0.47 seconds\n",
            "Epoch: 325 | Train Loss: 0.49472 | Valid Loss: 0.49166 | Time: 0.46 seconds\n",
            "Epoch: 326 | Train Loss: 0.49385 | Valid Loss: 0.49062 | Time: 0.49 seconds\n",
            "Epoch: 327 | Train Loss: 0.49298 | Valid Loss: 0.48949 | Time: 0.46 seconds\n",
            "Epoch: 328 | Train Loss: 0.49213 | Valid Loss: 0.49057 | Time: 0.47 seconds\n",
            "Epoch: 329 | Train Loss: 0.49125 | Valid Loss: 0.48841 | Time: 0.47 seconds\n",
            "Epoch: 330 | Train Loss: 0.49037 | Valid Loss: 0.48643 | Time: 0.48 seconds\n",
            "Epoch: 331 | Train Loss: 0.48951 | Valid Loss: 0.48369 | Time: 0.46 seconds\n",
            "Epoch: 332 | Train Loss: 0.48866 | Valid Loss: 0.48710 | Time: 0.49 seconds\n",
            "Epoch: 333 | Train Loss: 0.48780 | Valid Loss: 0.48422 | Time: 0.46 seconds\n",
            "Epoch: 334 | Train Loss: 0.48696 | Valid Loss: 0.48375 | Time: 0.46 seconds\n",
            "Epoch: 335 | Train Loss: 0.48607 | Valid Loss: 0.48511 | Time: 0.47 seconds\n",
            "Epoch: 336 | Train Loss: 0.48521 | Valid Loss: 0.48311 | Time: 0.47 seconds\n",
            "Epoch: 337 | Train Loss: 0.48436 | Valid Loss: 0.48041 | Time: 0.49 seconds\n",
            "Epoch: 338 | Train Loss: 0.48350 | Valid Loss: 0.48190 | Time: 0.48 seconds\n",
            "Epoch: 339 | Train Loss: 0.48266 | Valid Loss: 0.47952 | Time: 0.47 seconds\n",
            "Epoch: 340 | Train Loss: 0.48178 | Valid Loss: 0.47958 | Time: 0.47 seconds\n",
            "Epoch: 341 | Train Loss: 0.48092 | Valid Loss: 0.47755 | Time: 0.48 seconds\n",
            "Epoch: 342 | Train Loss: 0.48008 | Valid Loss: 0.47629 | Time: 0.46 seconds\n",
            "Epoch: 343 | Train Loss: 0.47921 | Valid Loss: 0.47750 | Time: 0.48 seconds\n",
            "Epoch: 344 | Train Loss: 0.47834 | Valid Loss: 0.47427 | Time: 0.47 seconds\n",
            "Epoch: 345 | Train Loss: 0.47749 | Valid Loss: 0.47412 | Time: 0.49 seconds\n",
            "Epoch: 346 | Train Loss: 0.47665 | Valid Loss: 0.47253 | Time: 0.48 seconds\n",
            "Epoch: 347 | Train Loss: 0.47580 | Valid Loss: 0.47297 | Time: 0.47 seconds\n",
            "Epoch: 348 | Train Loss: 0.47495 | Valid Loss: 0.47326 | Time: 0.47 seconds\n",
            "Epoch: 349 | Train Loss: 0.47408 | Valid Loss: 0.47324 | Time: 0.46 seconds\n",
            "Epoch: 350 | Train Loss: 0.47324 | Valid Loss: 0.46872 | Time: 0.47 seconds\n",
            "Epoch: 351 | Train Loss: 0.47239 | Valid Loss: 0.47004 | Time: 0.48 seconds\n",
            "Epoch: 352 | Train Loss: 0.47154 | Valid Loss: 0.46762 | Time: 0.47 seconds\n",
            "Epoch: 353 | Train Loss: 0.47071 | Valid Loss: 0.46488 | Time: 0.48 seconds\n",
            "Epoch: 354 | Train Loss: 0.46986 | Valid Loss: 0.46671 | Time: 0.48 seconds\n",
            "Epoch: 355 | Train Loss: 0.46898 | Valid Loss: 0.46465 | Time: 0.48 seconds\n",
            "Epoch: 356 | Train Loss: 0.46817 | Valid Loss: 0.46623 | Time: 0.47 seconds\n",
            "Epoch: 357 | Train Loss: 0.46733 | Valid Loss: 0.46403 | Time: 0.47 seconds\n",
            "Epoch: 358 | Train Loss: 0.46647 | Valid Loss: 0.46159 | Time: 0.49 seconds\n",
            "Epoch: 359 | Train Loss: 0.46564 | Valid Loss: 0.46252 | Time: 0.45 seconds\n",
            "Epoch: 360 | Train Loss: 0.46478 | Valid Loss: 0.45865 | Time: 0.49 seconds\n",
            "Epoch: 361 | Train Loss: 0.46394 | Valid Loss: 0.46101 | Time: 0.46 seconds\n",
            "Epoch: 362 | Train Loss: 0.46312 | Valid Loss: 0.46061 | Time: 0.46 seconds\n",
            "Epoch: 363 | Train Loss: 0.46228 | Valid Loss: 0.46176 | Time: 0.48 seconds\n",
            "Epoch: 364 | Train Loss: 0.46145 | Valid Loss: 0.45914 | Time: 0.46 seconds\n",
            "Epoch: 365 | Train Loss: 0.46060 | Valid Loss: 0.45515 | Time: 0.50 seconds\n",
            "Epoch: 366 | Train Loss: 0.45977 | Valid Loss: 0.45623 | Time: 0.46 seconds\n",
            "Epoch: 367 | Train Loss: 0.45893 | Valid Loss: 0.45399 | Time: 0.48 seconds\n",
            "Epoch: 368 | Train Loss: 0.45810 | Valid Loss: 0.45467 | Time: 0.47 seconds\n",
            "Epoch: 369 | Train Loss: 0.45726 | Valid Loss: 0.45327 | Time: 0.48 seconds\n",
            "Epoch: 370 | Train Loss: 0.45640 | Valid Loss: 0.45478 | Time: 0.46 seconds\n",
            "Epoch: 371 | Train Loss: 0.45558 | Valid Loss: 0.45136 | Time: 0.48 seconds\n",
            "Epoch: 372 | Train Loss: 0.45479 | Valid Loss: 0.45126 | Time: 0.47 seconds\n",
            "Epoch: 373 | Train Loss: 0.45395 | Valid Loss: 0.44835 | Time: 0.47 seconds\n",
            "Epoch: 374 | Train Loss: 0.45311 | Valid Loss: 0.44872 | Time: 0.47 seconds\n",
            "Epoch: 375 | Train Loss: 0.45226 | Valid Loss: 0.44923 | Time: 0.48 seconds\n",
            "Epoch: 376 | Train Loss: 0.45147 | Valid Loss: 0.44770 | Time: 0.48 seconds\n",
            "Epoch: 377 | Train Loss: 0.45063 | Valid Loss: 0.44789 | Time: 0.46 seconds\n",
            "Epoch: 378 | Train Loss: 0.44982 | Valid Loss: 0.44755 | Time: 0.47 seconds\n",
            "Epoch: 379 | Train Loss: 0.44897 | Valid Loss: 0.44544 | Time: 0.49 seconds\n",
            "Epoch: 380 | Train Loss: 0.44817 | Valid Loss: 0.44579 | Time: 0.48 seconds\n",
            "Epoch: 381 | Train Loss: 0.44736 | Valid Loss: 0.44392 | Time: 0.47 seconds\n",
            "Epoch: 382 | Train Loss: 0.44653 | Valid Loss: 0.44269 | Time: 0.48 seconds\n",
            "Epoch: 383 | Train Loss: 0.44572 | Valid Loss: 0.44260 | Time: 0.47 seconds\n",
            "Epoch: 384 | Train Loss: 0.44490 | Valid Loss: 0.44365 | Time: 0.48 seconds\n",
            "Epoch: 385 | Train Loss: 0.44408 | Valid Loss: 0.44028 | Time: 0.46 seconds\n",
            "Epoch: 386 | Train Loss: 0.44327 | Valid Loss: 0.43988 | Time: 0.47 seconds\n",
            "Epoch: 387 | Train Loss: 0.44246 | Valid Loss: 0.43834 | Time: 0.46 seconds\n",
            "Epoch: 388 | Train Loss: 0.44167 | Valid Loss: 0.43970 | Time: 0.48 seconds\n",
            "Epoch: 389 | Train Loss: 0.44086 | Valid Loss: 0.43713 | Time: 0.48 seconds\n",
            "Epoch: 390 | Train Loss: 0.44003 | Valid Loss: 0.43634 | Time: 0.46 seconds\n",
            "Epoch: 391 | Train Loss: 0.43924 | Valid Loss: 0.43694 | Time: 0.46 seconds\n",
            "Epoch: 392 | Train Loss: 0.43845 | Valid Loss: 0.43528 | Time: 0.48 seconds\n",
            "Epoch: 393 | Train Loss: 0.43760 | Valid Loss: 0.43497 | Time: 0.48 seconds\n",
            "Epoch: 394 | Train Loss: 0.43680 | Valid Loss: 0.43165 | Time: 0.47 seconds\n",
            "Epoch: 395 | Train Loss: 0.43603 | Valid Loss: 0.43333 | Time: 0.47 seconds\n",
            "Epoch: 396 | Train Loss: 0.43521 | Valid Loss: 0.43087 | Time: 0.47 seconds\n",
            "Epoch: 397 | Train Loss: 0.43440 | Valid Loss: 0.42950 | Time: 0.48 seconds\n",
            "Epoch: 398 | Train Loss: 0.43361 | Valid Loss: 0.43165 | Time: 0.46 seconds\n",
            "Epoch: 399 | Train Loss: 0.43279 | Valid Loss: 0.43057 | Time: 0.47 seconds\n",
            "Epoch: 400 | Train Loss: 0.43201 | Valid Loss: 0.42950 | Time: 0.47 seconds\n",
            "Epoch: 401 | Train Loss: 0.43123 | Valid Loss: 0.42699 | Time: 0.48 seconds\n",
            "Epoch: 402 | Train Loss: 0.43044 | Valid Loss: 0.42737 | Time: 0.48 seconds\n",
            "Epoch: 403 | Train Loss: 0.42964 | Valid Loss: 0.42846 | Time: 0.46 seconds\n",
            "Epoch: 404 | Train Loss: 0.42884 | Valid Loss: 0.42629 | Time: 0.47 seconds\n",
            "Epoch: 405 | Train Loss: 0.42806 | Valid Loss: 0.42528 | Time: 0.46 seconds\n",
            "Epoch: 406 | Train Loss: 0.42729 | Valid Loss: 0.42402 | Time: 0.47 seconds\n",
            "Epoch: 407 | Train Loss: 0.42648 | Valid Loss: 0.42088 | Time: 0.48 seconds\n",
            "Epoch: 408 | Train Loss: 0.42572 | Valid Loss: 0.42322 | Time: 0.47 seconds\n",
            "Epoch: 409 | Train Loss: 0.42497 | Valid Loss: 0.42272 | Time: 0.46 seconds\n",
            "Epoch: 410 | Train Loss: 0.42418 | Valid Loss: 0.42231 | Time: 0.46 seconds\n",
            "Epoch: 411 | Train Loss: 0.42339 | Valid Loss: 0.42026 | Time: 0.46 seconds\n",
            "Epoch: 412 | Train Loss: 0.42261 | Valid Loss: 0.42036 | Time: 0.50 seconds\n",
            "Epoch: 413 | Train Loss: 0.42184 | Valid Loss: 0.41653 | Time: 0.46 seconds\n",
            "Epoch: 414 | Train Loss: 0.42106 | Valid Loss: 0.41693 | Time: 0.47 seconds\n",
            "Epoch: 415 | Train Loss: 0.42028 | Valid Loss: 0.41663 | Time: 0.46 seconds\n",
            "Epoch: 416 | Train Loss: 0.41949 | Valid Loss: 0.41784 | Time: 0.48 seconds\n",
            "Epoch: 417 | Train Loss: 0.41870 | Valid Loss: 0.41618 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41798 | Valid Loss: 0.41565 | Time: 0.46 seconds\n",
            "Epoch: 419 | Train Loss: 0.41720 | Valid Loss: 0.41312 | Time: 0.48 seconds\n",
            "Epoch: 420 | Train Loss: 0.41642 | Valid Loss: 0.41174 | Time: 0.47 seconds\n",
            "Epoch: 421 | Train Loss: 0.41567 | Valid Loss: 0.41080 | Time: 0.49 seconds\n",
            "Epoch: 422 | Train Loss: 0.41490 | Valid Loss: 0.41183 | Time: 0.47 seconds\n",
            "Epoch: 423 | Train Loss: 0.41418 | Valid Loss: 0.40878 | Time: 0.48 seconds\n",
            "Epoch: 424 | Train Loss: 0.41341 | Valid Loss: 0.40854 | Time: 0.49 seconds\n",
            "Epoch: 425 | Train Loss: 0.41263 | Valid Loss: 0.41086 | Time: 0.47 seconds\n",
            "Epoch: 426 | Train Loss: 0.41184 | Valid Loss: 0.41076 | Time: 0.47 seconds\n",
            "Epoch: 427 | Train Loss: 0.41108 | Valid Loss: 0.40761 | Time: 0.49 seconds\n",
            "Epoch: 428 | Train Loss: 0.41040 | Valid Loss: 0.40650 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40959 | Valid Loss: 0.40411 | Time: 0.47 seconds\n",
            "Epoch: 430 | Train Loss: 0.40882 | Valid Loss: 0.40192 | Time: 0.47 seconds\n",
            "Epoch: 431 | Train Loss: 0.40810 | Valid Loss: 0.40575 | Time: 0.48 seconds\n",
            "Epoch: 432 | Train Loss: 0.40736 | Valid Loss: 0.40248 | Time: 0.45 seconds\n",
            "Epoch: 433 | Train Loss: 0.40661 | Valid Loss: 0.40184 | Time: 0.46 seconds\n",
            "Epoch: 434 | Train Loss: 0.40584 | Valid Loss: 0.40374 | Time: 0.47 seconds\n",
            "Epoch: 435 | Train Loss: 0.40512 | Valid Loss: 0.40109 | Time: 0.47 seconds\n",
            "Epoch: 436 | Train Loss: 0.40435 | Valid Loss: 0.40074 | Time: 0.50 seconds\n",
            "Epoch: 437 | Train Loss: 0.40363 | Valid Loss: 0.40010 | Time: 0.47 seconds\n",
            "Epoch: 438 | Train Loss: 0.40288 | Valid Loss: 0.39716 | Time: 0.49 seconds\n",
            "Epoch: 439 | Train Loss: 0.40218 | Valid Loss: 0.39942 | Time: 0.46 seconds\n",
            "Epoch: 440 | Train Loss: 0.40142 | Valid Loss: 0.39807 | Time: 0.47 seconds\n",
            "Epoch: 441 | Train Loss: 0.40072 | Valid Loss: 0.39742 | Time: 0.46 seconds\n",
            "Epoch: 442 | Train Loss: 0.40000 | Valid Loss: 0.39685 | Time: 0.49 seconds\n",
            "Epoch: 443 | Train Loss: 0.39924 | Valid Loss: 0.39461 | Time: 0.46 seconds\n",
            "Epoch: 444 | Train Loss: 0.39853 | Valid Loss: 0.39501 | Time: 0.47 seconds\n",
            "Epoch: 445 | Train Loss: 0.39778 | Valid Loss: 0.39685 | Time: 0.46 seconds\n",
            "Epoch: 446 | Train Loss: 0.39705 | Valid Loss: 0.39127 | Time: 0.47 seconds\n",
            "Epoch: 447 | Train Loss: 0.39634 | Valid Loss: 0.39206 | Time: 0.48 seconds\n",
            "Epoch: 448 | Train Loss: 0.39559 | Valid Loss: 0.39148 | Time: 0.47 seconds\n",
            "Epoch: 449 | Train Loss: 0.39491 | Valid Loss: 0.39111 | Time: 0.48 seconds\n",
            "Epoch: 450 | Train Loss: 0.39416 | Valid Loss: 0.38897 | Time: 0.46 seconds\n",
            "Epoch: 451 | Train Loss: 0.39344 | Valid Loss: 0.38828 | Time: 0.48 seconds\n",
            "Epoch: 452 | Train Loss: 0.39272 | Valid Loss: 0.39187 | Time: 0.46 seconds\n",
            "Epoch: 453 | Train Loss: 0.39203 | Valid Loss: 0.38764 | Time: 0.49 seconds\n",
            "Epoch: 454 | Train Loss: 0.39133 | Valid Loss: 0.38672 | Time: 0.47 seconds\n",
            "Epoch: 455 | Train Loss: 0.39058 | Valid Loss: 0.38516 | Time: 0.48 seconds\n",
            "Epoch: 456 | Train Loss: 0.38991 | Valid Loss: 0.38745 | Time: 0.47 seconds\n",
            "Epoch: 457 | Train Loss: 0.38919 | Valid Loss: 0.38619 | Time: 0.48 seconds\n",
            "Epoch: 458 | Train Loss: 0.38850 | Valid Loss: 0.38522 | Time: 0.46 seconds\n",
            "Epoch: 459 | Train Loss: 0.38782 | Valid Loss: 0.38493 | Time: 0.48 seconds\n",
            "Epoch: 460 | Train Loss: 0.38710 | Valid Loss: 0.38360 | Time: 0.47 seconds\n",
            "Epoch: 461 | Train Loss: 0.38640 | Valid Loss: 0.37966 | Time: 0.48 seconds\n",
            "Epoch: 462 | Train Loss: 0.38568 | Valid Loss: 0.38358 | Time: 0.48 seconds\n",
            "Epoch: 463 | Train Loss: 0.38502 | Valid Loss: 0.38305 | Time: 0.46 seconds\n",
            "Epoch: 464 | Train Loss: 0.38429 | Valid Loss: 0.37946 | Time: 0.47 seconds\n",
            "Epoch: 465 | Train Loss: 0.38359 | Valid Loss: 0.38091 | Time: 0.46 seconds\n",
            "Epoch: 466 | Train Loss: 0.38289 | Valid Loss: 0.38028 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38223 | Valid Loss: 0.37970 | Time: 0.47 seconds\n",
            "Epoch: 468 | Train Loss: 0.38154 | Valid Loss: 0.37882 | Time: 0.48 seconds\n",
            "Epoch: 469 | Train Loss: 0.38085 | Valid Loss: 0.37917 | Time: 0.46 seconds\n",
            "Epoch: 470 | Train Loss: 0.38014 | Valid Loss: 0.37759 | Time: 0.47 seconds\n",
            "Epoch: 471 | Train Loss: 0.37947 | Valid Loss: 0.37476 | Time: 0.46 seconds\n",
            "Epoch: 472 | Train Loss: 0.37878 | Valid Loss: 0.37550 | Time: 0.47 seconds\n",
            "Epoch: 473 | Train Loss: 0.37812 | Valid Loss: 0.37573 | Time: 0.46 seconds\n",
            "Epoch: 474 | Train Loss: 0.37741 | Valid Loss: 0.37342 | Time: 0.46 seconds\n",
            "Epoch: 475 | Train Loss: 0.37675 | Valid Loss: 0.37397 | Time: 0.46 seconds\n",
            "Epoch: 476 | Train Loss: 0.37609 | Valid Loss: 0.37371 | Time: 0.46 seconds\n",
            "Epoch: 477 | Train Loss: 0.37540 | Valid Loss: 0.37567 | Time: 0.47 seconds\n",
            "Epoch: 478 | Train Loss: 0.37473 | Valid Loss: 0.37181 | Time: 0.47 seconds\n",
            "Epoch: 479 | Train Loss: 0.37407 | Valid Loss: 0.37062 | Time: 0.47 seconds\n",
            "Epoch: 480 | Train Loss: 0.37338 | Valid Loss: 0.37037 | Time: 0.47 seconds\n",
            "Epoch: 481 | Train Loss: 0.37270 | Valid Loss: 0.36868 | Time: 0.51 seconds\n",
            "Epoch: 482 | Train Loss: 0.37206 | Valid Loss: 0.37001 | Time: 0.47 seconds\n",
            "Epoch: 483 | Train Loss: 0.37137 | Valid Loss: 0.36716 | Time: 0.48 seconds\n",
            "Epoch: 484 | Train Loss: 0.37071 | Valid Loss: 0.36833 | Time: 0.47 seconds\n",
            "Epoch: 485 | Train Loss: 0.37002 | Valid Loss: 0.36612 | Time: 0.48 seconds\n",
            "Epoch: 486 | Train Loss: 0.36941 | Valid Loss: 0.36427 | Time: 0.49 seconds\n",
            "Epoch: 487 | Train Loss: 0.36876 | Valid Loss: 0.36622 | Time: 0.47 seconds\n",
            "Epoch: 488 | Train Loss: 0.36807 | Valid Loss: 0.36401 | Time: 0.47 seconds\n",
            "Epoch: 489 | Train Loss: 0.36748 | Valid Loss: 0.36353 | Time: 0.47 seconds\n",
            "Epoch: 490 | Train Loss: 0.36679 | Valid Loss: 0.36387 | Time: 0.47 seconds\n",
            "Epoch: 491 | Train Loss: 0.36611 | Valid Loss: 0.36516 | Time: 0.46 seconds\n",
            "Epoch: 492 | Train Loss: 0.36550 | Valid Loss: 0.36051 | Time: 0.47 seconds\n",
            "Epoch: 493 | Train Loss: 0.36486 | Valid Loss: 0.36057 | Time: 0.47 seconds\n",
            "Epoch: 494 | Train Loss: 0.36420 | Valid Loss: 0.36122 | Time: 0.48 seconds\n",
            "Epoch: 495 | Train Loss: 0.36352 | Valid Loss: 0.35857 | Time: 0.47 seconds\n",
            "Epoch: 496 | Train Loss: 0.36290 | Valid Loss: 0.35749 | Time: 0.47 seconds\n",
            "Epoch: 497 | Train Loss: 0.36226 | Valid Loss: 0.35691 | Time: 0.47 seconds\n",
            "Epoch: 498 | Train Loss: 0.36161 | Valid Loss: 0.35381 | Time: 0.48 seconds\n",
            "Epoch: 499 | Train Loss: 0.36096 | Valid Loss: 0.35818 | Time: 0.46 seconds\n",
            "Epoch: 500 | Train Loss: 0.36032 | Valid Loss: 0.35904 | Time: 0.47 seconds\n",
            "Epoch: 501 | Train Loss: 0.35971 | Valid Loss: 0.35581 | Time: 0.49 seconds\n",
            "Epoch: 502 | Train Loss: 0.35910 | Valid Loss: 0.35520 | Time: 0.47 seconds\n",
            "Epoch: 503 | Train Loss: 0.35842 | Valid Loss: 0.35703 | Time: 0.48 seconds\n",
            "Epoch: 504 | Train Loss: 0.35779 | Valid Loss: 0.35306 | Time: 0.48 seconds\n",
            "Epoch: 505 | Train Loss: 0.35721 | Valid Loss: 0.35313 | Time: 0.48 seconds\n",
            "Epoch: 506 | Train Loss: 0.35656 | Valid Loss: 0.35581 | Time: 0.48 seconds\n",
            "Epoch: 507 | Train Loss: 0.35594 | Valid Loss: 0.35203 | Time: 0.47 seconds\n",
            "Epoch: 508 | Train Loss: 0.35530 | Valid Loss: 0.35344 | Time: 0.47 seconds\n",
            "Epoch: 509 | Train Loss: 0.35464 | Valid Loss: 0.35121 | Time: 0.50 seconds\n",
            "Epoch: 510 | Train Loss: 0.35404 | Valid Loss: 0.35000 | Time: 0.49 seconds\n",
            "Epoch: 511 | Train Loss: 0.35347 | Valid Loss: 0.34898 | Time: 0.50 seconds\n",
            "Epoch: 512 | Train Loss: 0.35280 | Valid Loss: 0.35071 | Time: 0.46 seconds\n",
            "Epoch: 513 | Train Loss: 0.35218 | Valid Loss: 0.34748 | Time: 0.48 seconds\n",
            "Epoch: 514 | Train Loss: 0.35161 | Valid Loss: 0.34672 | Time: 0.46 seconds\n",
            "Epoch: 515 | Train Loss: 0.35102 | Valid Loss: 0.34609 | Time: 0.48 seconds\n",
            "Epoch: 516 | Train Loss: 0.35041 | Valid Loss: 0.34724 | Time: 0.47 seconds\n",
            "Epoch: 517 | Train Loss: 0.34976 | Valid Loss: 0.34689 | Time: 0.46 seconds\n",
            "Epoch: 518 | Train Loss: 0.34917 | Valid Loss: 0.34671 | Time: 0.47 seconds\n",
            "Epoch: 519 | Train Loss: 0.34855 | Valid Loss: 0.34453 | Time: 0.47 seconds\n",
            "Epoch: 520 | Train Loss: 0.34792 | Valid Loss: 0.34215 | Time: 0.47 seconds\n",
            "Epoch: 521 | Train Loss: 0.34734 | Valid Loss: 0.34630 | Time: 0.47 seconds\n",
            "Epoch: 522 | Train Loss: 0.34675 | Valid Loss: 0.34263 | Time: 0.47 seconds\n",
            "Epoch: 523 | Train Loss: 0.34612 | Valid Loss: 0.34300 | Time: 0.47 seconds\n",
            "Epoch: 524 | Train Loss: 0.34552 | Valid Loss: 0.34039 | Time: 0.48 seconds\n",
            "Epoch: 525 | Train Loss: 0.34495 | Valid Loss: 0.33994 | Time: 0.47 seconds\n",
            "Epoch: 526 | Train Loss: 0.34432 | Valid Loss: 0.34105 | Time: 0.48 seconds\n",
            "Epoch: 527 | Train Loss: 0.34373 | Valid Loss: 0.34118 | Time: 0.46 seconds\n",
            "Epoch: 528 | Train Loss: 0.34315 | Valid Loss: 0.34097 | Time: 0.47 seconds\n",
            "Epoch: 529 | Train Loss: 0.34254 | Valid Loss: 0.33932 | Time: 0.47 seconds\n",
            "Epoch: 530 | Train Loss: 0.34194 | Valid Loss: 0.33884 | Time: 0.47 seconds\n",
            "Epoch: 531 | Train Loss: 0.34135 | Valid Loss: 0.33697 | Time: 0.47 seconds\n",
            "Epoch: 532 | Train Loss: 0.34079 | Valid Loss: 0.33664 | Time: 0.46 seconds\n",
            "Epoch: 533 | Train Loss: 0.34019 | Valid Loss: 0.33732 | Time: 0.46 seconds\n",
            "Epoch: 534 | Train Loss: 0.33957 | Valid Loss: 0.33759 | Time: 0.47 seconds\n",
            "Epoch: 535 | Train Loss: 0.33902 | Valid Loss: 0.33503 | Time: 0.48 seconds\n",
            "Epoch: 536 | Train Loss: 0.33847 | Valid Loss: 0.33640 | Time: 0.48 seconds\n",
            "Epoch: 537 | Train Loss: 0.33783 | Valid Loss: 0.33533 | Time: 0.48 seconds\n",
            "Epoch: 538 | Train Loss: 0.33730 | Valid Loss: 0.33429 | Time: 0.46 seconds\n",
            "Epoch: 539 | Train Loss: 0.33670 | Valid Loss: 0.33458 | Time: 0.46 seconds\n",
            "Epoch: 540 | Train Loss: 0.33615 | Valid Loss: 0.33395 | Time: 0.47 seconds\n",
            "Epoch: 541 | Train Loss: 0.33557 | Valid Loss: 0.33398 | Time: 0.47 seconds\n",
            "Epoch: 542 | Train Loss: 0.33498 | Valid Loss: 0.33162 | Time: 0.47 seconds\n",
            "Epoch: 543 | Train Loss: 0.33441 | Valid Loss: 0.33060 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33382 | Valid Loss: 0.33149 | Time: 0.47 seconds\n",
            "Epoch: 545 | Train Loss: 0.33323 | Valid Loss: 0.32712 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33266 | Valid Loss: 0.32951 | Time: 0.47 seconds\n",
            "Epoch: 547 | Train Loss: 0.33212 | Valid Loss: 0.32984 | Time: 0.46 seconds\n",
            "Epoch: 548 | Train Loss: 0.33157 | Valid Loss: 0.32756 | Time: 0.47 seconds\n",
            "Epoch: 549 | Train Loss: 0.33099 | Valid Loss: 0.32934 | Time: 0.46 seconds\n",
            "Epoch: 550 | Train Loss: 0.33046 | Valid Loss: 0.32742 | Time: 0.48 seconds\n",
            "Epoch: 551 | Train Loss: 0.32989 | Valid Loss: 0.32720 | Time: 0.47 seconds\n",
            "Epoch: 552 | Train Loss: 0.32928 | Valid Loss: 0.32649 | Time: 0.47 seconds\n",
            "Epoch: 553 | Train Loss: 0.32878 | Valid Loss: 0.32491 | Time: 0.47 seconds\n",
            "Epoch: 554 | Train Loss: 0.32814 | Valid Loss: 0.32477 | Time: 0.47 seconds\n",
            "Epoch: 555 | Train Loss: 0.32761 | Valid Loss: 0.32474 | Time: 0.48 seconds\n",
            "Epoch: 556 | Train Loss: 0.32708 | Valid Loss: 0.32543 | Time: 0.46 seconds\n",
            "Epoch: 557 | Train Loss: 0.32655 | Valid Loss: 0.32168 | Time: 0.48 seconds\n",
            "Epoch: 558 | Train Loss: 0.32601 | Valid Loss: 0.32432 | Time: 0.46 seconds\n",
            "Epoch: 559 | Train Loss: 0.32542 | Valid Loss: 0.32058 | Time: 0.47 seconds\n",
            "Epoch: 560 | Train Loss: 0.32484 | Valid Loss: 0.32004 | Time: 0.47 seconds\n",
            "Epoch: 561 | Train Loss: 0.32430 | Valid Loss: 0.32082 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32378 | Valid Loss: 0.31924 | Time: 0.47 seconds\n",
            "Epoch: 563 | Train Loss: 0.32328 | Valid Loss: 0.32074 | Time: 0.47 seconds\n",
            "Epoch: 564 | Train Loss: 0.32267 | Valid Loss: 0.31876 | Time: 0.47 seconds\n",
            "Epoch: 565 | Train Loss: 0.32217 | Valid Loss: 0.32004 | Time: 0.47 seconds\n",
            "Epoch: 566 | Train Loss: 0.32157 | Valid Loss: 0.31706 | Time: 0.48 seconds\n",
            "Epoch: 567 | Train Loss: 0.32106 | Valid Loss: 0.31779 | Time: 0.47 seconds\n",
            "Epoch: 568 | Train Loss: 0.32052 | Valid Loss: 0.31599 | Time: 0.48 seconds\n",
            "Epoch: 569 | Train Loss: 0.31999 | Valid Loss: 0.31578 | Time: 0.47 seconds\n",
            "Epoch: 570 | Train Loss: 0.31944 | Valid Loss: 0.31567 | Time: 0.49 seconds\n",
            "Epoch: 571 | Train Loss: 0.31894 | Valid Loss: 0.31443 | Time: 0.46 seconds\n",
            "Epoch: 572 | Train Loss: 0.31841 | Valid Loss: 0.31454 | Time: 0.47 seconds\n",
            "Epoch: 573 | Train Loss: 0.31784 | Valid Loss: 0.31417 | Time: 0.48 seconds\n",
            "Epoch: 574 | Train Loss: 0.31733 | Valid Loss: 0.31626 | Time: 0.47 seconds\n",
            "Epoch: 575 | Train Loss: 0.31677 | Valid Loss: 0.31222 | Time: 0.49 seconds\n",
            "Epoch: 576 | Train Loss: 0.31625 | Valid Loss: 0.31563 | Time: 0.48 seconds\n",
            "Epoch: 577 | Train Loss: 0.31573 | Valid Loss: 0.31405 | Time: 0.45 seconds\n",
            "Epoch: 578 | Train Loss: 0.31521 | Valid Loss: 0.31192 | Time: 0.47 seconds\n",
            "Epoch: 579 | Train Loss: 0.31466 | Valid Loss: 0.30943 | Time: 0.46 seconds\n",
            "Epoch: 580 | Train Loss: 0.31413 | Valid Loss: 0.31098 | Time: 0.48 seconds\n",
            "Epoch: 581 | Train Loss: 0.31362 | Valid Loss: 0.30979 | Time: 0.45 seconds\n",
            "Epoch: 582 | Train Loss: 0.31311 | Valid Loss: 0.31075 | Time: 0.46 seconds\n",
            "Epoch: 583 | Train Loss: 0.31259 | Valid Loss: 0.30954 | Time: 0.47 seconds\n",
            "Epoch: 584 | Train Loss: 0.31208 | Valid Loss: 0.30938 | Time: 0.48 seconds\n",
            "Epoch: 585 | Train Loss: 0.31156 | Valid Loss: 0.31044 | Time: 0.48 seconds\n",
            "Epoch: 586 | Train Loss: 0.31104 | Valid Loss: 0.30709 | Time: 0.47 seconds\n",
            "Epoch: 587 | Train Loss: 0.31053 | Valid Loss: 0.30547 | Time: 0.49 seconds\n",
            "Epoch: 588 | Train Loss: 0.31001 | Valid Loss: 0.30385 | Time: 0.48 seconds\n",
            "Epoch: 589 | Train Loss: 0.30947 | Valid Loss: 0.30635 | Time: 0.48 seconds\n",
            "Epoch: 590 | Train Loss: 0.30896 | Valid Loss: 0.30488 | Time: 0.46 seconds\n",
            "Epoch: 591 | Train Loss: 0.30849 | Valid Loss: 0.30268 | Time: 0.47 seconds\n",
            "Epoch: 592 | Train Loss: 0.30793 | Valid Loss: 0.30382 | Time: 0.46 seconds\n",
            "Epoch: 593 | Train Loss: 0.30746 | Valid Loss: 0.30589 | Time: 0.49 seconds\n",
            "Epoch: 594 | Train Loss: 0.30690 | Valid Loss: 0.30158 | Time: 0.47 seconds\n",
            "Epoch: 595 | Train Loss: 0.30644 | Valid Loss: 0.30377 | Time: 0.47 seconds\n",
            "Epoch: 596 | Train Loss: 0.30594 | Valid Loss: 0.30261 | Time: 0.47 seconds\n",
            "Epoch: 597 | Train Loss: 0.30543 | Valid Loss: 0.30106 | Time: 0.47 seconds\n",
            "Epoch: 598 | Train Loss: 0.30487 | Valid Loss: 0.30445 | Time: 0.48 seconds\n",
            "Epoch: 599 | Train Loss: 0.30443 | Valid Loss: 0.30151 | Time: 0.46 seconds\n",
            "Epoch: 600 | Train Loss: 0.30390 | Valid Loss: 0.30176 | Time: 0.49 seconds\n",
            "Epoch: 601 | Train Loss: 0.30342 | Valid Loss: 0.29874 | Time: 0.47 seconds\n",
            "Epoch: 602 | Train Loss: 0.30290 | Valid Loss: 0.30082 | Time: 0.46 seconds\n",
            "Epoch: 603 | Train Loss: 0.30240 | Valid Loss: 0.29885 | Time: 0.46 seconds\n",
            "Epoch: 604 | Train Loss: 0.30190 | Valid Loss: 0.29818 | Time: 0.48 seconds\n",
            "Epoch: 605 | Train Loss: 0.30140 | Valid Loss: 0.30004 | Time: 0.47 seconds\n",
            "Epoch: 606 | Train Loss: 0.30089 | Valid Loss: 0.29780 | Time: 0.48 seconds\n",
            "Epoch: 607 | Train Loss: 0.30041 | Valid Loss: 0.29729 | Time: 0.47 seconds\n",
            "Epoch: 608 | Train Loss: 0.29998 | Valid Loss: 0.29772 | Time: 0.47 seconds\n",
            "Epoch: 609 | Train Loss: 0.29944 | Valid Loss: 0.29664 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29892 | Valid Loss: 0.29563 | Time: 0.49 seconds\n",
            "Epoch: 611 | Train Loss: 0.29848 | Valid Loss: 0.29704 | Time: 0.47 seconds\n",
            "Epoch: 612 | Train Loss: 0.29792 | Valid Loss: 0.29365 | Time: 0.46 seconds\n",
            "Epoch: 613 | Train Loss: 0.29751 | Valid Loss: 0.29438 | Time: 0.47 seconds\n",
            "Epoch: 614 | Train Loss: 0.29698 | Valid Loss: 0.29123 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29654 | Valid Loss: 0.29414 | Time: 0.46 seconds\n",
            "Epoch: 616 | Train Loss: 0.29608 | Valid Loss: 0.29171 | Time: 0.46 seconds\n",
            "Epoch: 617 | Train Loss: 0.29553 | Valid Loss: 0.29316 | Time: 0.46 seconds\n",
            "Epoch: 618 | Train Loss: 0.29505 | Valid Loss: 0.29306 | Time: 0.47 seconds\n",
            "Epoch: 619 | Train Loss: 0.29459 | Valid Loss: 0.28964 | Time: 0.47 seconds\n",
            "Epoch: 620 | Train Loss: 0.29406 | Valid Loss: 0.28910 | Time: 0.47 seconds\n",
            "Epoch: 621 | Train Loss: 0.29360 | Valid Loss: 0.29074 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29309 | Valid Loss: 0.28867 | Time: 0.47 seconds\n",
            "Epoch: 623 | Train Loss: 0.29265 | Valid Loss: 0.29170 | Time: 0.46 seconds\n",
            "Epoch: 624 | Train Loss: 0.29217 | Valid Loss: 0.29016 | Time: 0.47 seconds\n",
            "Epoch: 625 | Train Loss: 0.29168 | Valid Loss: 0.28973 | Time: 0.46 seconds\n",
            "Epoch: 626 | Train Loss: 0.29122 | Valid Loss: 0.28856 | Time: 0.49 seconds\n",
            "Epoch: 627 | Train Loss: 0.29074 | Valid Loss: 0.28684 | Time: 0.47 seconds\n",
            "Epoch: 628 | Train Loss: 0.29025 | Valid Loss: 0.28633 | Time: 0.47 seconds\n",
            "Epoch: 629 | Train Loss: 0.28981 | Valid Loss: 0.28815 | Time: 0.47 seconds\n",
            "Epoch: 630 | Train Loss: 0.28933 | Valid Loss: 0.28677 | Time: 0.46 seconds\n",
            "Epoch: 631 | Train Loss: 0.28883 | Valid Loss: 0.28591 | Time: 0.47 seconds\n",
            "Epoch: 632 | Train Loss: 0.28839 | Valid Loss: 0.28398 | Time: 0.49 seconds\n",
            "Epoch: 633 | Train Loss: 0.28792 | Valid Loss: 0.28561 | Time: 0.46 seconds\n",
            "Epoch: 634 | Train Loss: 0.28747 | Valid Loss: 0.28332 | Time: 0.50 seconds\n",
            "Epoch: 635 | Train Loss: 0.28697 | Valid Loss: 0.28519 | Time: 0.47 seconds\n",
            "Epoch: 636 | Train Loss: 0.28650 | Valid Loss: 0.28502 | Time: 0.46 seconds\n",
            "Epoch: 637 | Train Loss: 0.28603 | Valid Loss: 0.28416 | Time: 0.47 seconds\n",
            "Epoch: 638 | Train Loss: 0.28557 | Valid Loss: 0.28093 | Time: 0.48 seconds\n",
            "Epoch: 639 | Train Loss: 0.28511 | Valid Loss: 0.28198 | Time: 0.48 seconds\n",
            "Epoch: 640 | Train Loss: 0.28466 | Valid Loss: 0.28235 | Time: 0.47 seconds\n",
            "Epoch: 641 | Train Loss: 0.28422 | Valid Loss: 0.28085 | Time: 0.50 seconds\n",
            "Epoch: 642 | Train Loss: 0.28373 | Valid Loss: 0.28132 | Time: 0.48 seconds\n",
            "Epoch: 643 | Train Loss: 0.28327 | Valid Loss: 0.28329 | Time: 0.49 seconds\n",
            "Epoch: 644 | Train Loss: 0.28286 | Valid Loss: 0.27946 | Time: 0.47 seconds\n",
            "Epoch: 645 | Train Loss: 0.28238 | Valid Loss: 0.27991 | Time: 0.47 seconds\n",
            "Epoch: 646 | Train Loss: 0.28189 | Valid Loss: 0.27941 | Time: 0.49 seconds\n",
            "Epoch: 647 | Train Loss: 0.28146 | Valid Loss: 0.27807 | Time: 0.49 seconds\n",
            "Epoch: 648 | Train Loss: 0.28100 | Valid Loss: 0.27744 | Time: 0.47 seconds\n",
            "Epoch: 649 | Train Loss: 0.28057 | Valid Loss: 0.27778 | Time: 0.47 seconds\n",
            "Epoch: 650 | Train Loss: 0.28009 | Valid Loss: 0.27805 | Time: 0.46 seconds\n",
            "Epoch: 651 | Train Loss: 0.27963 | Valid Loss: 0.27740 | Time: 0.49 seconds\n",
            "Epoch: 652 | Train Loss: 0.27922 | Valid Loss: 0.27658 | Time: 0.47 seconds\n",
            "Epoch: 653 | Train Loss: 0.27874 | Valid Loss: 0.27451 | Time: 0.46 seconds\n",
            "Epoch: 654 | Train Loss: 0.27828 | Valid Loss: 0.27589 | Time: 0.47 seconds\n",
            "Epoch: 655 | Train Loss: 0.27780 | Valid Loss: 0.27580 | Time: 0.48 seconds\n",
            "Epoch: 656 | Train Loss: 0.27737 | Valid Loss: 0.27437 | Time: 0.49 seconds\n",
            "Epoch: 657 | Train Loss: 0.27694 | Valid Loss: 0.27276 | Time: 0.46 seconds\n",
            "Epoch: 658 | Train Loss: 0.27649 | Valid Loss: 0.27529 | Time: 0.47 seconds\n",
            "Epoch: 659 | Train Loss: 0.27605 | Valid Loss: 0.27452 | Time: 0.46 seconds\n",
            "Epoch: 660 | Train Loss: 0.27558 | Valid Loss: 0.27152 | Time: 0.47 seconds\n",
            "Epoch: 661 | Train Loss: 0.27517 | Valid Loss: 0.27382 | Time: 0.46 seconds\n",
            "Epoch: 662 | Train Loss: 0.27471 | Valid Loss: 0.27287 | Time: 0.49 seconds\n",
            "Epoch: 663 | Train Loss: 0.27421 | Valid Loss: 0.27230 | Time: 0.46 seconds\n",
            "Epoch: 664 | Train Loss: 0.27383 | Valid Loss: 0.27253 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27341 | Valid Loss: 0.27131 | Time: 0.47 seconds\n",
            "Epoch: 666 | Train Loss: 0.27294 | Valid Loss: 0.27078 | Time: 0.48 seconds\n",
            "Epoch: 667 | Train Loss: 0.27250 | Valid Loss: 0.27084 | Time: 0.47 seconds\n",
            "Epoch: 668 | Train Loss: 0.27210 | Valid Loss: 0.26896 | Time: 0.47 seconds\n",
            "Epoch: 669 | Train Loss: 0.27165 | Valid Loss: 0.26874 | Time: 0.47 seconds\n",
            "Epoch: 670 | Train Loss: 0.27118 | Valid Loss: 0.26805 | Time: 0.47 seconds\n",
            "Epoch: 671 | Train Loss: 0.27076 | Valid Loss: 0.26865 | Time: 0.49 seconds\n",
            "Epoch: 672 | Train Loss: 0.27035 | Valid Loss: 0.26651 | Time: 0.47 seconds\n",
            "Epoch: 673 | Train Loss: 0.26986 | Valid Loss: 0.26974 | Time: 0.47 seconds\n",
            "Epoch: 674 | Train Loss: 0.26944 | Valid Loss: 0.26775 | Time: 0.46 seconds\n",
            "Epoch: 675 | Train Loss: 0.26898 | Valid Loss: 0.26630 | Time: 0.47 seconds\n",
            "Epoch: 676 | Train Loss: 0.26859 | Valid Loss: 0.26443 | Time: 0.47 seconds\n",
            "Epoch: 677 | Train Loss: 0.26810 | Valid Loss: 0.26467 | Time: 0.47 seconds\n",
            "Epoch: 678 | Train Loss: 0.26774 | Valid Loss: 0.26514 | Time: 0.48 seconds\n",
            "Epoch: 679 | Train Loss: 0.26727 | Valid Loss: 0.26334 | Time: 0.47 seconds\n",
            "Epoch: 680 | Train Loss: 0.26685 | Valid Loss: 0.26450 | Time: 0.47 seconds\n",
            "Epoch: 681 | Train Loss: 0.26642 | Valid Loss: 0.26481 | Time: 0.46 seconds\n",
            "Epoch: 682 | Train Loss: 0.26599 | Valid Loss: 0.26158 | Time: 0.48 seconds\n",
            "Epoch: 683 | Train Loss: 0.26556 | Valid Loss: 0.26251 | Time: 0.46 seconds\n",
            "Epoch: 684 | Train Loss: 0.26515 | Valid Loss: 0.26437 | Time: 0.49 seconds\n",
            "Epoch: 685 | Train Loss: 0.26476 | Valid Loss: 0.26279 | Time: 0.46 seconds\n",
            "Epoch: 686 | Train Loss: 0.26428 | Valid Loss: 0.26199 | Time: 0.48 seconds\n",
            "Epoch: 687 | Train Loss: 0.26391 | Valid Loss: 0.25978 | Time: 0.46 seconds\n",
            "Epoch: 688 | Train Loss: 0.26345 | Valid Loss: 0.26080 | Time: 0.47 seconds\n",
            "Epoch: 689 | Train Loss: 0.26300 | Valid Loss: 0.25930 | Time: 0.47 seconds\n",
            "Epoch: 690 | Train Loss: 0.26261 | Valid Loss: 0.25882 | Time: 0.48 seconds\n",
            "Epoch: 691 | Train Loss: 0.26219 | Valid Loss: 0.25957 | Time: 0.49 seconds\n",
            "Epoch: 692 | Train Loss: 0.26174 | Valid Loss: 0.25739 | Time: 0.47 seconds\n",
            "Epoch: 693 | Train Loss: 0.26133 | Valid Loss: 0.25911 | Time: 0.47 seconds\n",
            "Epoch: 694 | Train Loss: 0.26093 | Valid Loss: 0.25836 | Time: 0.46 seconds\n",
            "Epoch: 695 | Train Loss: 0.26051 | Valid Loss: 0.25723 | Time: 0.48 seconds\n",
            "Epoch: 696 | Train Loss: 0.26005 | Valid Loss: 0.25725 | Time: 0.46 seconds\n",
            "Epoch: 697 | Train Loss: 0.25967 | Valid Loss: 0.25652 | Time: 0.47 seconds\n",
            "Epoch: 698 | Train Loss: 0.25926 | Valid Loss: 0.25780 | Time: 0.46 seconds\n",
            "Epoch: 699 | Train Loss: 0.25883 | Valid Loss: 0.25957 | Time: 0.47 seconds\n",
            "Epoch: 700 | Train Loss: 0.25841 | Valid Loss: 0.25433 | Time: 0.48 seconds\n",
            "Epoch: 701 | Train Loss: 0.25801 | Valid Loss: 0.25514 | Time: 0.48 seconds\n",
            "Epoch: 702 | Train Loss: 0.25758 | Valid Loss: 0.25522 | Time: 0.46 seconds\n",
            "Epoch: 703 | Train Loss: 0.25715 | Valid Loss: 0.25544 | Time: 0.47 seconds\n",
            "Epoch: 704 | Train Loss: 0.25676 | Valid Loss: 0.25484 | Time: 0.45 seconds\n",
            "Epoch: 705 | Train Loss: 0.25636 | Valid Loss: 0.25451 | Time: 0.48 seconds\n",
            "Epoch: 706 | Train Loss: 0.25597 | Valid Loss: 0.25406 | Time: 0.47 seconds\n",
            "Epoch: 707 | Train Loss: 0.25556 | Valid Loss: 0.25122 | Time: 0.47 seconds\n",
            "Epoch: 708 | Train Loss: 0.25515 | Valid Loss: 0.25234 | Time: 0.47 seconds\n",
            "Epoch: 709 | Train Loss: 0.25473 | Valid Loss: 0.25171 | Time: 0.47 seconds\n",
            "Epoch: 710 | Train Loss: 0.25430 | Valid Loss: 0.25412 | Time: 0.49 seconds\n",
            "Epoch: 711 | Train Loss: 0.25388 | Valid Loss: 0.24930 | Time: 0.47 seconds\n",
            "Epoch: 712 | Train Loss: 0.25351 | Valid Loss: 0.25130 | Time: 0.47 seconds\n",
            "Epoch: 713 | Train Loss: 0.25309 | Valid Loss: 0.25061 | Time: 0.46 seconds\n",
            "Epoch: 714 | Train Loss: 0.25271 | Valid Loss: 0.24987 | Time: 0.49 seconds\n",
            "Epoch: 715 | Train Loss: 0.25224 | Valid Loss: 0.25095 | Time: 0.46 seconds\n",
            "Epoch: 716 | Train Loss: 0.25186 | Valid Loss: 0.24855 | Time: 0.47 seconds\n",
            "Epoch: 717 | Train Loss: 0.25150 | Valid Loss: 0.24701 | Time: 0.47 seconds\n",
            "Epoch: 718 | Train Loss: 0.25110 | Valid Loss: 0.24741 | Time: 0.48 seconds\n",
            "Epoch: 719 | Train Loss: 0.25068 | Valid Loss: 0.24697 | Time: 0.48 seconds\n",
            "Epoch: 720 | Train Loss: 0.25027 | Valid Loss: 0.24673 | Time: 0.49 seconds\n",
            "Epoch: 721 | Train Loss: 0.24988 | Valid Loss: 0.24626 | Time: 0.47 seconds\n",
            "Epoch: 722 | Train Loss: 0.24951 | Valid Loss: 0.24867 | Time: 0.47 seconds\n",
            "Epoch: 723 | Train Loss: 0.24909 | Valid Loss: 0.24705 | Time: 0.47 seconds\n",
            "Epoch: 724 | Train Loss: 0.24870 | Valid Loss: 0.24616 | Time: 0.47 seconds\n",
            "Epoch: 725 | Train Loss: 0.24831 | Valid Loss: 0.24647 | Time: 0.47 seconds\n",
            "Epoch: 726 | Train Loss: 0.24786 | Valid Loss: 0.24534 | Time: 0.48 seconds\n",
            "Epoch: 727 | Train Loss: 0.24753 | Valid Loss: 0.24536 | Time: 0.47 seconds\n",
            "Epoch: 728 | Train Loss: 0.24711 | Valid Loss: 0.24585 | Time: 0.46 seconds\n",
            "Epoch: 729 | Train Loss: 0.24673 | Valid Loss: 0.24447 | Time: 0.47 seconds\n",
            "Epoch: 730 | Train Loss: 0.24635 | Valid Loss: 0.24555 | Time: 0.46 seconds\n",
            "Epoch: 731 | Train Loss: 0.24592 | Valid Loss: 0.24391 | Time: 0.50 seconds\n",
            "Epoch: 732 | Train Loss: 0.24553 | Valid Loss: 0.24306 | Time: 0.48 seconds\n",
            "Epoch: 733 | Train Loss: 0.24512 | Valid Loss: 0.24348 | Time: 0.46 seconds\n",
            "Epoch: 734 | Train Loss: 0.24476 | Valid Loss: 0.24201 | Time: 0.48 seconds\n",
            "Epoch: 735 | Train Loss: 0.24433 | Valid Loss: 0.24125 | Time: 0.48 seconds\n",
            "Epoch: 736 | Train Loss: 0.24397 | Valid Loss: 0.24195 | Time: 0.47 seconds\n",
            "Epoch: 737 | Train Loss: 0.24359 | Valid Loss: 0.24160 | Time: 0.47 seconds\n",
            "Epoch: 738 | Train Loss: 0.24319 | Valid Loss: 0.24068 | Time: 0.47 seconds\n",
            "Epoch: 739 | Train Loss: 0.24282 | Valid Loss: 0.23907 | Time: 0.46 seconds\n",
            "Epoch: 740 | Train Loss: 0.24244 | Valid Loss: 0.24206 | Time: 0.47 seconds\n",
            "Epoch: 741 | Train Loss: 0.24202 | Valid Loss: 0.24129 | Time: 0.48 seconds\n",
            "Epoch: 742 | Train Loss: 0.24166 | Valid Loss: 0.23698 | Time: 0.48 seconds\n",
            "Epoch: 743 | Train Loss: 0.24126 | Valid Loss: 0.23904 | Time: 0.46 seconds\n",
            "Epoch: 744 | Train Loss: 0.24092 | Valid Loss: 0.23926 | Time: 0.47 seconds\n",
            "Epoch: 745 | Train Loss: 0.24048 | Valid Loss: 0.23876 | Time: 0.49 seconds\n",
            "Epoch: 746 | Train Loss: 0.24014 | Valid Loss: 0.23783 | Time: 0.50 seconds\n",
            "Epoch: 747 | Train Loss: 0.23969 | Valid Loss: 0.23651 | Time: 0.47 seconds\n",
            "Epoch: 748 | Train Loss: 0.23938 | Valid Loss: 0.23567 | Time: 0.48 seconds\n",
            "Epoch: 749 | Train Loss: 0.23897 | Valid Loss: 0.23827 | Time: 0.47 seconds\n",
            "Epoch: 750 | Train Loss: 0.23861 | Valid Loss: 0.23676 | Time: 0.48 seconds\n",
            "Epoch: 751 | Train Loss: 0.23817 | Valid Loss: 0.23464 | Time: 0.47 seconds\n",
            "Epoch: 752 | Train Loss: 0.23785 | Valid Loss: 0.23568 | Time: 0.46 seconds\n",
            "Epoch: 753 | Train Loss: 0.23744 | Valid Loss: 0.23543 | Time: 0.47 seconds\n",
            "Epoch: 754 | Train Loss: 0.23708 | Valid Loss: 0.23455 | Time: 0.48 seconds\n",
            "Epoch: 755 | Train Loss: 0.23669 | Valid Loss: 0.23388 | Time: 0.49 seconds\n",
            "Epoch: 756 | Train Loss: 0.23630 | Valid Loss: 0.23454 | Time: 0.46 seconds\n",
            "Epoch: 757 | Train Loss: 0.23594 | Valid Loss: 0.23282 | Time: 0.48 seconds\n",
            "Epoch: 758 | Train Loss: 0.23556 | Valid Loss: 0.23372 | Time: 0.46 seconds\n",
            "Epoch: 759 | Train Loss: 0.23522 | Valid Loss: 0.23280 | Time: 0.48 seconds\n",
            "Epoch: 760 | Train Loss: 0.23481 | Valid Loss: 0.23245 | Time: 0.48 seconds\n",
            "Epoch: 761 | Train Loss: 0.23446 | Valid Loss: 0.23208 | Time: 0.48 seconds\n",
            "Epoch: 762 | Train Loss: 0.23408 | Valid Loss: 0.23248 | Time: 0.46 seconds\n",
            "Epoch: 763 | Train Loss: 0.23370 | Valid Loss: 0.23128 | Time: 0.49 seconds\n",
            "Epoch: 764 | Train Loss: 0.23333 | Valid Loss: 0.23248 | Time: 0.47 seconds\n",
            "Epoch: 765 | Train Loss: 0.23294 | Valid Loss: 0.23141 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23259 | Valid Loss: 0.23109 | Time: 0.48 seconds\n",
            "Epoch: 767 | Train Loss: 0.23223 | Valid Loss: 0.22987 | Time: 0.48 seconds\n",
            "Epoch: 768 | Train Loss: 0.23183 | Valid Loss: 0.22919 | Time: 0.47 seconds\n",
            "Epoch: 769 | Train Loss: 0.23149 | Valid Loss: 0.22880 | Time: 0.48 seconds\n",
            "Epoch: 770 | Train Loss: 0.23115 | Valid Loss: 0.22841 | Time: 0.48 seconds\n",
            "Epoch: 771 | Train Loss: 0.23075 | Valid Loss: 0.22750 | Time: 0.46 seconds\n",
            "Epoch: 772 | Train Loss: 0.23037 | Valid Loss: 0.22796 | Time: 0.47 seconds\n",
            "Epoch: 773 | Train Loss: 0.23002 | Valid Loss: 0.22753 | Time: 0.46 seconds\n",
            "Epoch: 774 | Train Loss: 0.22966 | Valid Loss: 0.22657 | Time: 0.47 seconds\n",
            "Epoch: 775 | Train Loss: 0.22930 | Valid Loss: 0.22650 | Time: 0.47 seconds\n",
            "Epoch: 776 | Train Loss: 0.22893 | Valid Loss: 0.22765 | Time: 0.48 seconds\n",
            "Epoch: 777 | Train Loss: 0.22855 | Valid Loss: 0.22701 | Time: 0.48 seconds\n",
            "Epoch: 778 | Train Loss: 0.22819 | Valid Loss: 0.22567 | Time: 0.49 seconds\n",
            "Epoch: 779 | Train Loss: 0.22783 | Valid Loss: 0.22608 | Time: 0.47 seconds\n",
            "Epoch: 780 | Train Loss: 0.22749 | Valid Loss: 0.22416 | Time: 0.49 seconds\n",
            "Epoch: 781 | Train Loss: 0.22710 | Valid Loss: 0.22524 | Time: 0.46 seconds\n",
            "Epoch: 782 | Train Loss: 0.22674 | Valid Loss: 0.22594 | Time: 0.46 seconds\n",
            "Epoch: 783 | Train Loss: 0.22639 | Valid Loss: 0.22485 | Time: 0.47 seconds\n",
            "Epoch: 784 | Train Loss: 0.22603 | Valid Loss: 0.22438 | Time: 0.48 seconds\n",
            "Epoch: 785 | Train Loss: 0.22567 | Valid Loss: 0.22413 | Time: 0.47 seconds\n",
            "Epoch: 786 | Train Loss: 0.22533 | Valid Loss: 0.22463 | Time: 0.45 seconds\n",
            "Epoch: 787 | Train Loss: 0.22497 | Valid Loss: 0.22391 | Time: 0.48 seconds\n",
            "Epoch: 788 | Train Loss: 0.22460 | Valid Loss: 0.22233 | Time: 0.48 seconds\n",
            "Epoch: 789 | Train Loss: 0.22426 | Valid Loss: 0.22143 | Time: 0.50 seconds\n",
            "Epoch: 790 | Train Loss: 0.22390 | Valid Loss: 0.22142 | Time: 0.47 seconds\n",
            "Epoch: 791 | Train Loss: 0.22355 | Valid Loss: 0.21893 | Time: 0.49 seconds\n",
            "Epoch: 792 | Train Loss: 0.22319 | Valid Loss: 0.22147 | Time: 0.45 seconds\n",
            "Epoch: 793 | Train Loss: 0.22282 | Valid Loss: 0.22095 | Time: 0.47 seconds\n",
            "Epoch: 794 | Train Loss: 0.22247 | Valid Loss: 0.22036 | Time: 0.46 seconds\n",
            "Epoch: 795 | Train Loss: 0.22211 | Valid Loss: 0.22055 | Time: 0.47 seconds\n",
            "Epoch: 796 | Train Loss: 0.22176 | Valid Loss: 0.22101 | Time: 0.47 seconds\n",
            "Epoch: 797 | Train Loss: 0.22140 | Valid Loss: 0.22018 | Time: 0.47 seconds\n",
            "Epoch: 798 | Train Loss: 0.22109 | Valid Loss: 0.21951 | Time: 0.48 seconds\n",
            "Epoch: 799 | Train Loss: 0.22071 | Valid Loss: 0.21813 | Time: 0.48 seconds\n",
            "Epoch: 800 | Train Loss: 0.22041 | Valid Loss: 0.21958 | Time: 0.47 seconds\n",
            "Epoch: 801 | Train Loss: 0.22002 | Valid Loss: 0.21733 | Time: 0.47 seconds\n",
            "Epoch: 802 | Train Loss: 0.21965 | Valid Loss: 0.21734 | Time: 0.46 seconds\n",
            "Epoch: 803 | Train Loss: 0.21933 | Valid Loss: 0.21871 | Time: 0.46 seconds\n",
            "Epoch: 804 | Train Loss: 0.21895 | Valid Loss: 0.21807 | Time: 0.48 seconds\n",
            "Epoch: 805 | Train Loss: 0.21862 | Valid Loss: 0.21569 | Time: 0.46 seconds\n",
            "Epoch: 806 | Train Loss: 0.21830 | Valid Loss: 0.21463 | Time: 0.47 seconds\n",
            "Epoch: 807 | Train Loss: 0.21793 | Valid Loss: 0.21679 | Time: 0.45 seconds\n",
            "Epoch: 808 | Train Loss: 0.21758 | Valid Loss: 0.21543 | Time: 0.45 seconds\n",
            "Epoch: 809 | Train Loss: 0.21724 | Valid Loss: 0.21515 | Time: 0.47 seconds\n",
            "Epoch: 810 | Train Loss: 0.21692 | Valid Loss: 0.21361 | Time: 0.46 seconds\n",
            "Epoch: 811 | Train Loss: 0.21653 | Valid Loss: 0.21503 | Time: 0.47 seconds\n",
            "Epoch: 812 | Train Loss: 0.21619 | Valid Loss: 0.21393 | Time: 0.46 seconds\n",
            "Epoch: 813 | Train Loss: 0.21585 | Valid Loss: 0.21280 | Time: 0.48 seconds\n",
            "Epoch: 814 | Train Loss: 0.21553 | Valid Loss: 0.21566 | Time: 0.46 seconds\n",
            "Epoch: 815 | Train Loss: 0.21517 | Valid Loss: 0.21359 | Time: 0.47 seconds\n",
            "Epoch: 816 | Train Loss: 0.21486 | Valid Loss: 0.21290 | Time: 0.47 seconds\n",
            "Epoch: 817 | Train Loss: 0.21450 | Valid Loss: 0.21125 | Time: 0.48 seconds\n",
            "Epoch: 818 | Train Loss: 0.21413 | Valid Loss: 0.21144 | Time: 0.45 seconds\n",
            "Epoch: 819 | Train Loss: 0.21382 | Valid Loss: 0.21235 | Time: 0.47 seconds\n",
            "Epoch: 820 | Train Loss: 0.21345 | Valid Loss: 0.21141 | Time: 0.47 seconds\n",
            "Epoch: 821 | Train Loss: 0.21317 | Valid Loss: 0.21036 | Time: 0.46 seconds\n",
            "Epoch: 822 | Train Loss: 0.21279 | Valid Loss: 0.21170 | Time: 0.48 seconds\n",
            "Epoch: 823 | Train Loss: 0.21247 | Valid Loss: 0.21020 | Time: 0.48 seconds\n",
            "Epoch: 824 | Train Loss: 0.21210 | Valid Loss: 0.20987 | Time: 0.47 seconds\n",
            "Epoch: 825 | Train Loss: 0.21176 | Valid Loss: 0.21101 | Time: 0.48 seconds\n",
            "Epoch: 826 | Train Loss: 0.21146 | Valid Loss: 0.20993 | Time: 0.47 seconds\n",
            "Epoch: 827 | Train Loss: 0.21114 | Valid Loss: 0.20817 | Time: 0.48 seconds\n",
            "Epoch: 828 | Train Loss: 0.21077 | Valid Loss: 0.20801 | Time: 0.48 seconds\n",
            "Epoch: 829 | Train Loss: 0.21047 | Valid Loss: 0.20822 | Time: 0.48 seconds\n",
            "Epoch: 830 | Train Loss: 0.21011 | Valid Loss: 0.20682 | Time: 0.48 seconds\n",
            "Epoch: 831 | Train Loss: 0.20981 | Valid Loss: 0.20670 | Time: 0.47 seconds\n",
            "Epoch: 832 | Train Loss: 0.20945 | Valid Loss: 0.20765 | Time: 0.48 seconds\n",
            "Epoch: 833 | Train Loss: 0.20911 | Valid Loss: 0.20774 | Time: 0.46 seconds\n",
            "Epoch: 834 | Train Loss: 0.20876 | Valid Loss: 0.20901 | Time: 0.47 seconds\n",
            "Epoch: 835 | Train Loss: 0.20851 | Valid Loss: 0.20496 | Time: 0.48 seconds\n",
            "Epoch: 836 | Train Loss: 0.20812 | Valid Loss: 0.20484 | Time: 0.48 seconds\n",
            "Epoch: 837 | Train Loss: 0.20782 | Valid Loss: 0.20567 | Time: 0.47 seconds\n",
            "Epoch: 838 | Train Loss: 0.20747 | Valid Loss: 0.20664 | Time: 0.46 seconds\n",
            "Epoch: 839 | Train Loss: 0.20712 | Valid Loss: 0.20483 | Time: 0.49 seconds\n",
            "Epoch: 840 | Train Loss: 0.20683 | Valid Loss: 0.20347 | Time: 0.47 seconds\n",
            "Epoch: 841 | Train Loss: 0.20651 | Valid Loss: 0.20521 | Time: 0.49 seconds\n",
            "Epoch: 842 | Train Loss: 0.20613 | Valid Loss: 0.20374 | Time: 0.46 seconds\n",
            "Epoch: 843 | Train Loss: 0.20585 | Valid Loss: 0.20449 | Time: 0.47 seconds\n",
            "Epoch: 844 | Train Loss: 0.20547 | Valid Loss: 0.20239 | Time: 0.47 seconds\n",
            "Epoch: 845 | Train Loss: 0.20517 | Valid Loss: 0.20450 | Time: 0.47 seconds\n",
            "Epoch: 846 | Train Loss: 0.20489 | Valid Loss: 0.20272 | Time: 0.46 seconds\n",
            "Epoch: 847 | Train Loss: 0.20453 | Valid Loss: 0.20200 | Time: 0.50 seconds\n",
            "Epoch: 848 | Train Loss: 0.20422 | Valid Loss: 0.20208 | Time: 0.48 seconds\n",
            "Epoch: 849 | Train Loss: 0.20392 | Valid Loss: 0.20261 | Time: 0.47 seconds\n",
            "Epoch: 850 | Train Loss: 0.20361 | Valid Loss: 0.20210 | Time: 0.48 seconds\n",
            "Epoch: 851 | Train Loss: 0.20327 | Valid Loss: 0.20092 | Time: 0.48 seconds\n",
            "Epoch: 852 | Train Loss: 0.20295 | Valid Loss: 0.20106 | Time: 0.49 seconds\n",
            "Epoch: 853 | Train Loss: 0.20259 | Valid Loss: 0.20037 | Time: 0.50 seconds\n",
            "Epoch: 854 | Train Loss: 0.20231 | Valid Loss: 0.20028 | Time: 0.48 seconds\n",
            "Epoch: 855 | Train Loss: 0.20196 | Valid Loss: 0.20116 | Time: 0.48 seconds\n",
            "Epoch: 856 | Train Loss: 0.20162 | Valid Loss: 0.19853 | Time: 0.49 seconds\n",
            "Epoch: 857 | Train Loss: 0.20133 | Valid Loss: 0.20007 | Time: 0.47 seconds\n",
            "Epoch: 858 | Train Loss: 0.20104 | Valid Loss: 0.19906 | Time: 0.47 seconds\n",
            "Epoch: 859 | Train Loss: 0.20071 | Valid Loss: 0.19901 | Time: 0.46 seconds\n",
            "Epoch: 860 | Train Loss: 0.20039 | Valid Loss: 0.19843 | Time: 0.47 seconds\n",
            "Epoch: 861 | Train Loss: 0.20006 | Valid Loss: 0.19840 | Time: 0.47 seconds\n",
            "Epoch: 862 | Train Loss: 0.19972 | Valid Loss: 0.19937 | Time: 0.48 seconds\n",
            "Epoch: 863 | Train Loss: 0.19943 | Valid Loss: 0.19805 | Time: 0.47 seconds\n",
            "Epoch: 864 | Train Loss: 0.19907 | Valid Loss: 0.19850 | Time: 0.47 seconds\n",
            "Epoch: 865 | Train Loss: 0.19881 | Valid Loss: 0.19702 | Time: 0.47 seconds\n",
            "Epoch: 866 | Train Loss: 0.19851 | Valid Loss: 0.19788 | Time: 0.46 seconds\n",
            "Epoch: 867 | Train Loss: 0.19821 | Valid Loss: 0.19706 | Time: 0.48 seconds\n",
            "Epoch: 868 | Train Loss: 0.19789 | Valid Loss: 0.19657 | Time: 0.47 seconds\n",
            "Epoch: 869 | Train Loss: 0.19754 | Valid Loss: 0.19529 | Time: 0.50 seconds\n",
            "Epoch: 870 | Train Loss: 0.19722 | Valid Loss: 0.19582 | Time: 0.49 seconds\n",
            "Epoch: 871 | Train Loss: 0.19696 | Valid Loss: 0.19624 | Time: 0.49 seconds\n",
            "Epoch: 872 | Train Loss: 0.19660 | Valid Loss: 0.19497 | Time: 0.47 seconds\n",
            "Epoch: 873 | Train Loss: 0.19633 | Valid Loss: 0.19334 | Time: 0.48 seconds\n",
            "Epoch: 874 | Train Loss: 0.19598 | Valid Loss: 0.19460 | Time: 0.45 seconds\n",
            "Epoch: 875 | Train Loss: 0.19570 | Valid Loss: 0.19414 | Time: 0.47 seconds\n",
            "Epoch: 876 | Train Loss: 0.19535 | Valid Loss: 0.19311 | Time: 0.47 seconds\n",
            "Epoch: 877 | Train Loss: 0.19507 | Valid Loss: 0.19296 | Time: 0.48 seconds\n",
            "Epoch: 878 | Train Loss: 0.19475 | Valid Loss: 0.19205 | Time: 0.48 seconds\n",
            "Epoch: 879 | Train Loss: 0.19448 | Valid Loss: 0.19216 | Time: 0.46 seconds\n",
            "Epoch: 880 | Train Loss: 0.19411 | Valid Loss: 0.19276 | Time: 0.46 seconds\n",
            "Epoch: 881 | Train Loss: 0.19382 | Valid Loss: 0.19366 | Time: 0.46 seconds\n",
            "Epoch: 882 | Train Loss: 0.19352 | Valid Loss: 0.19180 | Time: 0.49 seconds\n",
            "Epoch: 883 | Train Loss: 0.19323 | Valid Loss: 0.19094 | Time: 0.47 seconds\n",
            "Epoch: 884 | Train Loss: 0.19291 | Valid Loss: 0.19057 | Time: 0.49 seconds\n",
            "Epoch: 885 | Train Loss: 0.19261 | Valid Loss: 0.18992 | Time: 0.46 seconds\n",
            "Epoch: 886 | Train Loss: 0.19231 | Valid Loss: 0.19083 | Time: 0.48 seconds\n",
            "Epoch: 887 | Train Loss: 0.19201 | Valid Loss: 0.18898 | Time: 0.47 seconds\n",
            "Epoch: 888 | Train Loss: 0.19170 | Valid Loss: 0.19134 | Time: 0.47 seconds\n",
            "Epoch: 889 | Train Loss: 0.19139 | Valid Loss: 0.19041 | Time: 0.45 seconds\n",
            "Epoch: 890 | Train Loss: 0.19113 | Valid Loss: 0.18828 | Time: 0.48 seconds\n",
            "Epoch: 891 | Train Loss: 0.19083 | Valid Loss: 0.18868 | Time: 0.47 seconds\n",
            "Epoch: 892 | Train Loss: 0.19049 | Valid Loss: 0.19011 | Time: 0.49 seconds\n",
            "Epoch: 893 | Train Loss: 0.19021 | Valid Loss: 0.18808 | Time: 0.46 seconds\n",
            "Epoch: 894 | Train Loss: 0.18992 | Valid Loss: 0.18847 | Time: 0.46 seconds\n",
            "Epoch: 895 | Train Loss: 0.18959 | Valid Loss: 0.18833 | Time: 0.47 seconds\n",
            "Epoch: 896 | Train Loss: 0.18933 | Valid Loss: 0.18644 | Time: 0.47 seconds\n",
            "Epoch: 897 | Train Loss: 0.18902 | Valid Loss: 0.18855 | Time: 0.48 seconds\n",
            "Epoch: 898 | Train Loss: 0.18867 | Valid Loss: 0.18806 | Time: 0.45 seconds\n",
            "Epoch: 899 | Train Loss: 0.18838 | Valid Loss: 0.18715 | Time: 0.47 seconds\n",
            "Epoch: 900 | Train Loss: 0.18809 | Valid Loss: 0.18728 | Time: 0.47 seconds\n",
            "Epoch: 901 | Train Loss: 0.18782 | Valid Loss: 0.18656 | Time: 0.47 seconds\n",
            "Epoch: 902 | Train Loss: 0.18753 | Valid Loss: 0.18639 | Time: 0.46 seconds\n",
            "Epoch: 903 | Train Loss: 0.18723 | Valid Loss: 0.18625 | Time: 0.48 seconds\n",
            "Epoch: 904 | Train Loss: 0.18693 | Valid Loss: 0.18460 | Time: 0.48 seconds\n",
            "Epoch: 905 | Train Loss: 0.18664 | Valid Loss: 0.18478 | Time: 0.47 seconds\n",
            "Epoch: 906 | Train Loss: 0.18636 | Valid Loss: 0.18670 | Time: 0.47 seconds\n",
            "Epoch: 907 | Train Loss: 0.18606 | Valid Loss: 0.18617 | Time: 0.47 seconds\n",
            "Epoch: 908 | Train Loss: 0.18577 | Valid Loss: 0.18397 | Time: 0.48 seconds\n",
            "Epoch: 909 | Train Loss: 0.18547 | Valid Loss: 0.18461 | Time: 0.46 seconds\n",
            "Epoch: 910 | Train Loss: 0.18521 | Valid Loss: 0.18330 | Time: 0.49 seconds\n",
            "Epoch: 911 | Train Loss: 0.18489 | Valid Loss: 0.18422 | Time: 0.47 seconds\n",
            "Epoch: 912 | Train Loss: 0.18461 | Valid Loss: 0.18361 | Time: 0.46 seconds\n",
            "Epoch: 913 | Train Loss: 0.18432 | Valid Loss: 0.18242 | Time: 0.46 seconds\n",
            "Epoch: 914 | Train Loss: 0.18400 | Valid Loss: 0.18231 | Time: 0.47 seconds\n",
            "Epoch: 915 | Train Loss: 0.18373 | Valid Loss: 0.18267 | Time: 0.47 seconds\n",
            "Epoch: 916 | Train Loss: 0.18348 | Valid Loss: 0.18195 | Time: 0.47 seconds\n",
            "Epoch: 917 | Train Loss: 0.18316 | Valid Loss: 0.18165 | Time: 0.47 seconds\n",
            "Epoch: 918 | Train Loss: 0.18289 | Valid Loss: 0.18205 | Time: 0.48 seconds\n",
            "Epoch: 919 | Train Loss: 0.18256 | Valid Loss: 0.18079 | Time: 0.47 seconds\n",
            "Epoch: 920 | Train Loss: 0.18227 | Valid Loss: 0.18149 | Time: 0.49 seconds\n",
            "Epoch: 921 | Train Loss: 0.18203 | Valid Loss: 0.18086 | Time: 0.47 seconds\n",
            "Epoch: 922 | Train Loss: 0.18171 | Valid Loss: 0.17999 | Time: 0.46 seconds\n",
            "Epoch: 923 | Train Loss: 0.18140 | Valid Loss: 0.17960 | Time: 0.48 seconds\n",
            "Epoch: 924 | Train Loss: 0.18115 | Valid Loss: 0.18085 | Time: 0.47 seconds\n",
            "Epoch: 925 | Train Loss: 0.18087 | Valid Loss: 0.18010 | Time: 0.48 seconds\n",
            "Epoch: 926 | Train Loss: 0.18059 | Valid Loss: 0.17896 | Time: 0.47 seconds\n",
            "Epoch: 927 | Train Loss: 0.18029 | Valid Loss: 0.17903 | Time: 0.47 seconds\n",
            "Epoch: 928 | Train Loss: 0.18000 | Valid Loss: 0.17721 | Time: 0.47 seconds\n",
            "Epoch: 929 | Train Loss: 0.17973 | Valid Loss: 0.17833 | Time: 0.47 seconds\n",
            "Epoch: 930 | Train Loss: 0.17945 | Valid Loss: 0.17778 | Time: 0.46 seconds\n",
            "Epoch: 931 | Train Loss: 0.17918 | Valid Loss: 0.17812 | Time: 0.47 seconds\n",
            "Epoch: 932 | Train Loss: 0.17891 | Valid Loss: 0.17665 | Time: 0.46 seconds\n",
            "Epoch: 933 | Train Loss: 0.17861 | Valid Loss: 0.17851 | Time: 0.47 seconds\n",
            "Epoch: 934 | Train Loss: 0.17833 | Valid Loss: 0.17662 | Time: 0.47 seconds\n",
            "Epoch: 935 | Train Loss: 0.17805 | Valid Loss: 0.17672 | Time: 0.47 seconds\n",
            "Epoch: 936 | Train Loss: 0.17781 | Valid Loss: 0.17624 | Time: 0.47 seconds\n",
            "Epoch: 937 | Train Loss: 0.17751 | Valid Loss: 0.17633 | Time: 0.47 seconds\n",
            "Epoch: 938 | Train Loss: 0.17721 | Valid Loss: 0.17641 | Time: 0.47 seconds\n",
            "Epoch: 939 | Train Loss: 0.17695 | Valid Loss: 0.17473 | Time: 0.48 seconds\n",
            "Epoch: 940 | Train Loss: 0.17662 | Valid Loss: 0.17522 | Time: 0.48 seconds\n",
            "Epoch: 941 | Train Loss: 0.17637 | Valid Loss: 0.17445 | Time: 0.47 seconds\n",
            "Epoch: 942 | Train Loss: 0.17610 | Valid Loss: 0.17512 | Time: 0.47 seconds\n",
            "Epoch: 943 | Train Loss: 0.17584 | Valid Loss: 0.17495 | Time: 0.45 seconds\n",
            "Epoch: 944 | Train Loss: 0.17554 | Valid Loss: 0.17291 | Time: 0.48 seconds\n",
            "Epoch: 945 | Train Loss: 0.17525 | Valid Loss: 0.17442 | Time: 0.47 seconds\n",
            "Epoch: 946 | Train Loss: 0.17500 | Valid Loss: 0.17368 | Time: 0.46 seconds\n",
            "Epoch: 947 | Train Loss: 0.17474 | Valid Loss: 0.17253 | Time: 0.47 seconds\n",
            "Epoch: 948 | Train Loss: 0.17448 | Valid Loss: 0.17394 | Time: 0.45 seconds\n",
            "Epoch: 949 | Train Loss: 0.17419 | Valid Loss: 0.17265 | Time: 0.46 seconds\n",
            "Epoch: 950 | Train Loss: 0.17390 | Valid Loss: 0.17235 | Time: 0.47 seconds\n",
            "Epoch: 951 | Train Loss: 0.17369 | Valid Loss: 0.17163 | Time: 0.50 seconds\n",
            "Epoch: 952 | Train Loss: 0.17339 | Valid Loss: 0.17328 | Time: 0.48 seconds\n",
            "Epoch: 953 | Train Loss: 0.17312 | Valid Loss: 0.17202 | Time: 0.47 seconds\n",
            "Epoch: 954 | Train Loss: 0.17285 | Valid Loss: 0.17268 | Time: 0.47 seconds\n",
            "Epoch: 955 | Train Loss: 0.17254 | Valid Loss: 0.17076 | Time: 0.48 seconds\n",
            "Epoch: 956 | Train Loss: 0.17229 | Valid Loss: 0.17125 | Time: 0.48 seconds\n",
            "Epoch: 957 | Train Loss: 0.17200 | Valid Loss: 0.17135 | Time: 0.47 seconds\n",
            "Epoch: 958 | Train Loss: 0.17174 | Valid Loss: 0.17022 | Time: 0.46 seconds\n",
            "Epoch: 959 | Train Loss: 0.17145 | Valid Loss: 0.17015 | Time: 0.49 seconds\n",
            "Epoch: 960 | Train Loss: 0.17122 | Valid Loss: 0.16956 | Time: 0.47 seconds\n",
            "Epoch: 961 | Train Loss: 0.17097 | Valid Loss: 0.16881 | Time: 0.49 seconds\n",
            "Epoch: 962 | Train Loss: 0.17067 | Valid Loss: 0.16965 | Time: 0.47 seconds\n",
            "Epoch: 963 | Train Loss: 0.17042 | Valid Loss: 0.16843 | Time: 0.47 seconds\n",
            "Epoch: 964 | Train Loss: 0.17015 | Valid Loss: 0.16849 | Time: 0.47 seconds\n",
            "Epoch: 965 | Train Loss: 0.16989 | Valid Loss: 0.17011 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16962 | Valid Loss: 0.16733 | Time: 0.49 seconds\n",
            "Epoch: 967 | Train Loss: 0.16936 | Valid Loss: 0.16807 | Time: 0.46 seconds\n",
            "Epoch: 968 | Train Loss: 0.16909 | Valid Loss: 0.16830 | Time: 0.49 seconds\n",
            "Epoch: 969 | Train Loss: 0.16882 | Valid Loss: 0.16762 | Time: 0.47 seconds\n",
            "Epoch: 970 | Train Loss: 0.16855 | Valid Loss: 0.16706 | Time: 0.47 seconds\n",
            "Epoch: 971 | Train Loss: 0.16830 | Valid Loss: 0.16732 | Time: 0.47 seconds\n",
            "Epoch: 972 | Train Loss: 0.16803 | Valid Loss: 0.16639 | Time: 0.48 seconds\n",
            "Epoch: 973 | Train Loss: 0.16774 | Valid Loss: 0.16680 | Time: 0.46 seconds\n",
            "Epoch: 974 | Train Loss: 0.16750 | Valid Loss: 0.16506 | Time: 0.51 seconds\n",
            "Epoch: 975 | Train Loss: 0.16723 | Valid Loss: 0.16629 | Time: 0.46 seconds\n",
            "Epoch: 976 | Train Loss: 0.16699 | Valid Loss: 0.16637 | Time: 0.48 seconds\n",
            "Epoch: 977 | Train Loss: 0.16669 | Valid Loss: 0.16588 | Time: 0.46 seconds\n",
            "Epoch: 978 | Train Loss: 0.16650 | Valid Loss: 0.16497 | Time: 0.47 seconds\n",
            "Epoch: 979 | Train Loss: 0.16621 | Valid Loss: 0.16559 | Time: 0.49 seconds\n",
            "Epoch: 980 | Train Loss: 0.16591 | Valid Loss: 0.16369 | Time: 0.47 seconds\n",
            "Epoch: 981 | Train Loss: 0.16568 | Valid Loss: 0.16482 | Time: 0.48 seconds\n",
            "Epoch: 982 | Train Loss: 0.16543 | Valid Loss: 0.16560 | Time: 0.46 seconds\n",
            "Epoch: 983 | Train Loss: 0.16517 | Valid Loss: 0.16420 | Time: 0.47 seconds\n",
            "Epoch: 984 | Train Loss: 0.16489 | Valid Loss: 0.16350 | Time: 0.48 seconds\n",
            "Epoch: 985 | Train Loss: 0.16467 | Valid Loss: 0.16490 | Time: 0.47 seconds\n",
            "Epoch: 986 | Train Loss: 0.16440 | Valid Loss: 0.16350 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16413 | Valid Loss: 0.16260 | Time: 0.47 seconds\n",
            "Epoch: 988 | Train Loss: 0.16390 | Valid Loss: 0.16345 | Time: 0.46 seconds\n",
            "Epoch: 989 | Train Loss: 0.16363 | Valid Loss: 0.16177 | Time: 0.48 seconds\n",
            "Epoch: 990 | Train Loss: 0.16334 | Valid Loss: 0.16253 | Time: 0.46 seconds\n",
            "Epoch: 991 | Train Loss: 0.16312 | Valid Loss: 0.16155 | Time: 0.47 seconds\n",
            "Epoch: 992 | Train Loss: 0.16285 | Valid Loss: 0.16169 | Time: 0.48 seconds\n",
            "Epoch: 993 | Train Loss: 0.16260 | Valid Loss: 0.16062 | Time: 0.46 seconds\n",
            "Epoch: 994 | Train Loss: 0.16238 | Valid Loss: 0.16155 | Time: 0.48 seconds\n",
            "Epoch: 995 | Train Loss: 0.16212 | Valid Loss: 0.15992 | Time: 0.47 seconds\n",
            "Epoch: 996 | Train Loss: 0.16185 | Valid Loss: 0.16030 | Time: 0.47 seconds\n",
            "Epoch: 997 | Train Loss: 0.16155 | Valid Loss: 0.15992 | Time: 0.46 seconds\n",
            "Epoch: 998 | Train Loss: 0.16136 | Valid Loss: 0.15991 | Time: 0.49 seconds\n",
            "Epoch: 999 | Train Loss: 0.16110 | Valid Loss: 0.16108 | Time: 0.46 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16085 | Valid Loss: 0.15976 | Time: 0.50 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 1000\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.89 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 6]: 31.66981\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 7...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71484 | Valid Loss: 0.71223 | Time: 0.48 seconds\n",
            "Epoch: 2 | Train Loss: 0.71430 | Valid Loss: 0.71505 | Time: 0.49 seconds\n",
            "Epoch: 3 | Train Loss: 0.71377 | Valid Loss: 0.71384 | Time: 0.46 seconds\n",
            "Epoch: 4 | Train Loss: 0.71329 | Valid Loss: 0.71452 | Time: 0.47 seconds\n",
            "Epoch: 5 | Train Loss: 0.71278 | Valid Loss: 0.71290 | Time: 0.46 seconds\n",
            "Epoch: 6 | Train Loss: 0.71233 | Valid Loss: 0.71242 | Time: 0.50 seconds\n",
            "Epoch: 7 | Train Loss: 0.71187 | Valid Loss: 0.71286 | Time: 0.46 seconds\n",
            "Epoch: 8 | Train Loss: 0.71146 | Valid Loss: 0.71172 | Time: 0.48 seconds\n",
            "Epoch: 9 | Train Loss: 0.71104 | Valid Loss: 0.71079 | Time: 0.47 seconds\n",
            "Epoch: 10 | Train Loss: 0.71063 | Valid Loss: 0.71134 | Time: 0.49 seconds\n",
            "Epoch: 11 | Train Loss: 0.71022 | Valid Loss: 0.71081 | Time: 0.45 seconds\n",
            "Epoch: 12 | Train Loss: 0.70985 | Valid Loss: 0.71042 | Time: 0.48 seconds\n",
            "Epoch: 13 | Train Loss: 0.70947 | Valid Loss: 0.71038 | Time: 0.47 seconds\n",
            "Epoch: 14 | Train Loss: 0.70911 | Valid Loss: 0.70993 | Time: 0.46 seconds\n",
            "Epoch: 15 | Train Loss: 0.70876 | Valid Loss: 0.70961 | Time: 0.47 seconds\n",
            "Epoch: 16 | Train Loss: 0.70841 | Valid Loss: 0.70933 | Time: 0.50 seconds\n",
            "Epoch: 17 | Train Loss: 0.70805 | Valid Loss: 0.70895 | Time: 0.48 seconds\n",
            "Epoch: 18 | Train Loss: 0.70772 | Valid Loss: 0.70819 | Time: 0.46 seconds\n",
            "Epoch: 19 | Train Loss: 0.70738 | Valid Loss: 0.70731 | Time: 0.48 seconds\n",
            "Epoch: 20 | Train Loss: 0.70704 | Valid Loss: 0.70757 | Time: 0.45 seconds\n",
            "Epoch: 21 | Train Loss: 0.70672 | Valid Loss: 0.70726 | Time: 0.48 seconds\n",
            "Epoch: 22 | Train Loss: 0.70639 | Valid Loss: 0.70687 | Time: 0.48 seconds\n",
            "Epoch: 23 | Train Loss: 0.70608 | Valid Loss: 0.70634 | Time: 0.47 seconds\n",
            "Epoch: 24 | Train Loss: 0.70576 | Valid Loss: 0.70686 | Time: 0.46 seconds\n",
            "Epoch: 25 | Train Loss: 0.70543 | Valid Loss: 0.70642 | Time: 0.46 seconds\n",
            "Epoch: 26 | Train Loss: 0.70513 | Valid Loss: 0.70578 | Time: 0.47 seconds\n",
            "Epoch: 27 | Train Loss: 0.70479 | Valid Loss: 0.70545 | Time: 0.48 seconds\n",
            "Epoch: 28 | Train Loss: 0.70451 | Valid Loss: 0.70595 | Time: 0.46 seconds\n",
            "Epoch: 29 | Train Loss: 0.70417 | Valid Loss: 0.70520 | Time: 0.46 seconds\n",
            "Epoch: 30 | Train Loss: 0.70386 | Valid Loss: 0.70474 | Time: 0.48 seconds\n",
            "Epoch: 31 | Train Loss: 0.70354 | Valid Loss: 0.70356 | Time: 0.49 seconds\n",
            "Epoch: 32 | Train Loss: 0.70322 | Valid Loss: 0.70440 | Time: 0.47 seconds\n",
            "Epoch: 33 | Train Loss: 0.70292 | Valid Loss: 0.70349 | Time: 0.46 seconds\n",
            "Epoch: 34 | Train Loss: 0.70260 | Valid Loss: 0.70316 | Time: 0.49 seconds\n",
            "Epoch: 35 | Train Loss: 0.70228 | Valid Loss: 0.70305 | Time: 0.49 seconds\n",
            "Epoch: 36 | Train Loss: 0.70195 | Valid Loss: 0.70348 | Time: 0.47 seconds\n",
            "Epoch: 37 | Train Loss: 0.70164 | Valid Loss: 0.70234 | Time: 0.46 seconds\n",
            "Epoch: 38 | Train Loss: 0.70132 | Valid Loss: 0.70219 | Time: 0.47 seconds\n",
            "Epoch: 39 | Train Loss: 0.70099 | Valid Loss: 0.70121 | Time: 0.47 seconds\n",
            "Epoch: 40 | Train Loss: 0.70065 | Valid Loss: 0.70147 | Time: 0.46 seconds\n",
            "Epoch: 41 | Train Loss: 0.70033 | Valid Loss: 0.70112 | Time: 0.48 seconds\n",
            "Epoch: 42 | Train Loss: 0.70001 | Valid Loss: 0.70006 | Time: 0.46 seconds\n",
            "Epoch: 43 | Train Loss: 0.69966 | Valid Loss: 0.70024 | Time: 0.47 seconds\n",
            "Epoch: 44 | Train Loss: 0.69932 | Valid Loss: 0.69975 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69898 | Valid Loss: 0.69987 | Time: 0.46 seconds\n",
            "Epoch: 46 | Train Loss: 0.69864 | Valid Loss: 0.69932 | Time: 0.48 seconds\n",
            "Epoch: 47 | Train Loss: 0.69828 | Valid Loss: 0.69918 | Time: 0.48 seconds\n",
            "Epoch: 48 | Train Loss: 0.69793 | Valid Loss: 0.69873 | Time: 0.46 seconds\n",
            "Epoch: 49 | Train Loss: 0.69758 | Valid Loss: 0.69830 | Time: 0.48 seconds\n",
            "Epoch: 50 | Train Loss: 0.69721 | Valid Loss: 0.69756 | Time: 0.47 seconds\n",
            "Epoch: 51 | Train Loss: 0.69685 | Valid Loss: 0.69749 | Time: 0.48 seconds\n",
            "Epoch: 52 | Train Loss: 0.69648 | Valid Loss: 0.69715 | Time: 0.47 seconds\n",
            "Epoch: 53 | Train Loss: 0.69611 | Valid Loss: 0.69668 | Time: 0.48 seconds\n",
            "Epoch: 54 | Train Loss: 0.69573 | Valid Loss: 0.69590 | Time: 0.47 seconds\n",
            "Epoch: 55 | Train Loss: 0.69535 | Valid Loss: 0.69638 | Time: 0.46 seconds\n",
            "Epoch: 56 | Train Loss: 0.69497 | Valid Loss: 0.69564 | Time: 0.47 seconds\n",
            "Epoch: 57 | Train Loss: 0.69458 | Valid Loss: 0.69615 | Time: 0.47 seconds\n",
            "Epoch: 58 | Train Loss: 0.69419 | Valid Loss: 0.69426 | Time: 0.48 seconds\n",
            "Epoch: 59 | Train Loss: 0.69380 | Valid Loss: 0.69412 | Time: 0.47 seconds\n",
            "Epoch: 60 | Train Loss: 0.69339 | Valid Loss: 0.69436 | Time: 0.48 seconds\n",
            "Epoch: 61 | Train Loss: 0.69298 | Valid Loss: 0.69406 | Time: 0.48 seconds\n",
            "Epoch: 62 | Train Loss: 0.69258 | Valid Loss: 0.69362 | Time: 0.48 seconds\n",
            "Epoch: 63 | Train Loss: 0.69216 | Valid Loss: 0.69325 | Time: 0.46 seconds\n",
            "Epoch: 64 | Train Loss: 0.69176 | Valid Loss: 0.69249 | Time: 0.47 seconds\n",
            "Epoch: 65 | Train Loss: 0.69133 | Valid Loss: 0.69196 | Time: 0.48 seconds\n",
            "Epoch: 66 | Train Loss: 0.69090 | Valid Loss: 0.69116 | Time: 0.48 seconds\n",
            "Epoch: 67 | Train Loss: 0.69047 | Valid Loss: 0.69101 | Time: 0.46 seconds\n",
            "Epoch: 68 | Train Loss: 0.69003 | Valid Loss: 0.69062 | Time: 0.47 seconds\n",
            "Epoch: 69 | Train Loss: 0.68960 | Valid Loss: 0.68974 | Time: 0.47 seconds\n",
            "Epoch: 70 | Train Loss: 0.68916 | Valid Loss: 0.68985 | Time: 0.47 seconds\n",
            "Epoch: 71 | Train Loss: 0.68870 | Valid Loss: 0.68894 | Time: 0.48 seconds\n",
            "Epoch: 72 | Train Loss: 0.68825 | Valid Loss: 0.68806 | Time: 0.47 seconds\n",
            "Epoch: 73 | Train Loss: 0.68780 | Valid Loss: 0.68860 | Time: 0.47 seconds\n",
            "Epoch: 74 | Train Loss: 0.68734 | Valid Loss: 0.68768 | Time: 0.47 seconds\n",
            "Epoch: 75 | Train Loss: 0.68689 | Valid Loss: 0.68773 | Time: 0.49 seconds\n",
            "Epoch: 76 | Train Loss: 0.68641 | Valid Loss: 0.68750 | Time: 0.48 seconds\n",
            "Epoch: 77 | Train Loss: 0.68594 | Valid Loss: 0.68642 | Time: 0.48 seconds\n",
            "Epoch: 78 | Train Loss: 0.68547 | Valid Loss: 0.68641 | Time: 0.46 seconds\n",
            "Epoch: 79 | Train Loss: 0.68499 | Valid Loss: 0.68551 | Time: 0.47 seconds\n",
            "Epoch: 80 | Train Loss: 0.68451 | Valid Loss: 0.68504 | Time: 0.48 seconds\n",
            "Epoch: 81 | Train Loss: 0.68402 | Valid Loss: 0.68482 | Time: 0.48 seconds\n",
            "Epoch: 82 | Train Loss: 0.68354 | Valid Loss: 0.68424 | Time: 0.48 seconds\n",
            "Epoch: 83 | Train Loss: 0.68304 | Valid Loss: 0.68366 | Time: 0.48 seconds\n",
            "Epoch: 84 | Train Loss: 0.68253 | Valid Loss: 0.68314 | Time: 0.49 seconds\n",
            "Epoch: 85 | Train Loss: 0.68202 | Valid Loss: 0.68256 | Time: 0.46 seconds\n",
            "Epoch: 86 | Train Loss: 0.68153 | Valid Loss: 0.68191 | Time: 0.48 seconds\n",
            "Epoch: 87 | Train Loss: 0.68102 | Valid Loss: 0.68147 | Time: 0.48 seconds\n",
            "Epoch: 88 | Train Loss: 0.68050 | Valid Loss: 0.68157 | Time: 0.47 seconds\n",
            "Epoch: 89 | Train Loss: 0.67998 | Valid Loss: 0.68025 | Time: 0.47 seconds\n",
            "Epoch: 90 | Train Loss: 0.67945 | Valid Loss: 0.67993 | Time: 0.47 seconds\n",
            "Epoch: 91 | Train Loss: 0.67892 | Valid Loss: 0.67945 | Time: 0.48 seconds\n",
            "Epoch: 92 | Train Loss: 0.67839 | Valid Loss: 0.67845 | Time: 0.47 seconds\n",
            "Epoch: 93 | Train Loss: 0.67786 | Valid Loss: 0.67893 | Time: 0.46 seconds\n",
            "Epoch: 94 | Train Loss: 0.67732 | Valid Loss: 0.67837 | Time: 0.49 seconds\n",
            "Epoch: 95 | Train Loss: 0.67678 | Valid Loss: 0.67747 | Time: 0.48 seconds\n",
            "Epoch: 96 | Train Loss: 0.67622 | Valid Loss: 0.67668 | Time: 0.48 seconds\n",
            "Epoch: 97 | Train Loss: 0.67568 | Valid Loss: 0.67596 | Time: 0.48 seconds\n",
            "Epoch: 98 | Train Loss: 0.67511 | Valid Loss: 0.67560 | Time: 0.46 seconds\n",
            "Epoch: 99 | Train Loss: 0.67456 | Valid Loss: 0.67560 | Time: 0.48 seconds\n",
            "Epoch: 100 | Train Loss: 0.67402 | Valid Loss: 0.67480 | Time: 0.46 seconds\n",
            "Epoch: 101 | Train Loss: 0.67344 | Valid Loss: 0.67437 | Time: 0.49 seconds\n",
            "Epoch: 102 | Train Loss: 0.67286 | Valid Loss: 0.67415 | Time: 0.46 seconds\n",
            "Epoch: 103 | Train Loss: 0.67229 | Valid Loss: 0.67299 | Time: 0.49 seconds\n",
            "Epoch: 104 | Train Loss: 0.67171 | Valid Loss: 0.67225 | Time: 0.47 seconds\n",
            "Epoch: 105 | Train Loss: 0.67112 | Valid Loss: 0.67233 | Time: 0.47 seconds\n",
            "Epoch: 106 | Train Loss: 0.67055 | Valid Loss: 0.67145 | Time: 0.49 seconds\n",
            "Epoch: 107 | Train Loss: 0.66995 | Valid Loss: 0.67101 | Time: 0.48 seconds\n",
            "Epoch: 108 | Train Loss: 0.66936 | Valid Loss: 0.67028 | Time: 0.47 seconds\n",
            "Epoch: 109 | Train Loss: 0.66877 | Valid Loss: 0.66885 | Time: 0.48 seconds\n",
            "Epoch: 110 | Train Loss: 0.66815 | Valid Loss: 0.66900 | Time: 0.48 seconds\n",
            "Epoch: 111 | Train Loss: 0.66755 | Valid Loss: 0.66858 | Time: 0.49 seconds\n",
            "Epoch: 112 | Train Loss: 0.66694 | Valid Loss: 0.66762 | Time: 0.46 seconds\n",
            "Epoch: 113 | Train Loss: 0.66632 | Valid Loss: 0.66732 | Time: 0.47 seconds\n",
            "Epoch: 114 | Train Loss: 0.66572 | Valid Loss: 0.66606 | Time: 0.48 seconds\n",
            "Epoch: 115 | Train Loss: 0.66509 | Valid Loss: 0.66592 | Time: 0.46 seconds\n",
            "Epoch: 116 | Train Loss: 0.66445 | Valid Loss: 0.66475 | Time: 0.48 seconds\n",
            "Epoch: 117 | Train Loss: 0.66383 | Valid Loss: 0.66472 | Time: 0.47 seconds\n",
            "Epoch: 118 | Train Loss: 0.66320 | Valid Loss: 0.66423 | Time: 0.48 seconds\n",
            "Epoch: 119 | Train Loss: 0.66257 | Valid Loss: 0.66451 | Time: 0.46 seconds\n",
            "Epoch: 120 | Train Loss: 0.66192 | Valid Loss: 0.66232 | Time: 0.47 seconds\n",
            "Epoch: 121 | Train Loss: 0.66128 | Valid Loss: 0.66158 | Time: 0.48 seconds\n",
            "Epoch: 122 | Train Loss: 0.66064 | Valid Loss: 0.66136 | Time: 0.49 seconds\n",
            "Epoch: 123 | Train Loss: 0.65998 | Valid Loss: 0.66029 | Time: 0.46 seconds\n",
            "Epoch: 124 | Train Loss: 0.65933 | Valid Loss: 0.66034 | Time: 0.47 seconds\n",
            "Epoch: 125 | Train Loss: 0.65868 | Valid Loss: 0.65929 | Time: 0.47 seconds\n",
            "Epoch: 126 | Train Loss: 0.65801 | Valid Loss: 0.65816 | Time: 0.47 seconds\n",
            "Epoch: 127 | Train Loss: 0.65737 | Valid Loss: 0.65777 | Time: 0.46 seconds\n",
            "Epoch: 128 | Train Loss: 0.65669 | Valid Loss: 0.65744 | Time: 0.48 seconds\n",
            "Epoch: 129 | Train Loss: 0.65602 | Valid Loss: 0.65652 | Time: 0.49 seconds\n",
            "Epoch: 130 | Train Loss: 0.65535 | Valid Loss: 0.65578 | Time: 0.46 seconds\n",
            "Epoch: 131 | Train Loss: 0.65467 | Valid Loss: 0.65509 | Time: 0.48 seconds\n",
            "Epoch: 132 | Train Loss: 0.65400 | Valid Loss: 0.65438 | Time: 0.46 seconds\n",
            "Epoch: 133 | Train Loss: 0.65330 | Valid Loss: 0.65362 | Time: 0.48 seconds\n",
            "Epoch: 134 | Train Loss: 0.65263 | Valid Loss: 0.65342 | Time: 0.47 seconds\n",
            "Epoch: 135 | Train Loss: 0.65193 | Valid Loss: 0.65198 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65124 | Valid Loss: 0.65111 | Time: 0.46 seconds\n",
            "Epoch: 137 | Train Loss: 0.65055 | Valid Loss: 0.65035 | Time: 0.49 seconds\n",
            "Epoch: 138 | Train Loss: 0.64985 | Valid Loss: 0.65040 | Time: 0.46 seconds\n",
            "Epoch: 139 | Train Loss: 0.64914 | Valid Loss: 0.65032 | Time: 0.47 seconds\n",
            "Epoch: 140 | Train Loss: 0.64844 | Valid Loss: 0.64973 | Time: 0.46 seconds\n",
            "Epoch: 141 | Train Loss: 0.64774 | Valid Loss: 0.64822 | Time: 0.47 seconds\n",
            "Epoch: 142 | Train Loss: 0.64703 | Valid Loss: 0.64806 | Time: 0.49 seconds\n",
            "Epoch: 143 | Train Loss: 0.64631 | Valid Loss: 0.64785 | Time: 0.46 seconds\n",
            "Epoch: 144 | Train Loss: 0.64560 | Valid Loss: 0.64715 | Time: 0.48 seconds\n",
            "Epoch: 145 | Train Loss: 0.64488 | Valid Loss: 0.64565 | Time: 0.47 seconds\n",
            "Epoch: 146 | Train Loss: 0.64417 | Valid Loss: 0.64560 | Time: 0.48 seconds\n",
            "Epoch: 147 | Train Loss: 0.64344 | Valid Loss: 0.64404 | Time: 0.49 seconds\n",
            "Epoch: 148 | Train Loss: 0.64272 | Valid Loss: 0.64302 | Time: 0.48 seconds\n",
            "Epoch: 149 | Train Loss: 0.64200 | Valid Loss: 0.64204 | Time: 0.46 seconds\n",
            "Epoch: 150 | Train Loss: 0.64126 | Valid Loss: 0.64293 | Time: 0.47 seconds\n",
            "Epoch: 151 | Train Loss: 0.64052 | Valid Loss: 0.64062 | Time: 0.47 seconds\n",
            "Epoch: 152 | Train Loss: 0.63980 | Valid Loss: 0.63985 | Time: 0.49 seconds\n",
            "Epoch: 153 | Train Loss: 0.63905 | Valid Loss: 0.63901 | Time: 0.47 seconds\n",
            "Epoch: 154 | Train Loss: 0.63832 | Valid Loss: 0.63931 | Time: 0.47 seconds\n",
            "Epoch: 155 | Train Loss: 0.63757 | Valid Loss: 0.63862 | Time: 0.46 seconds\n",
            "Epoch: 156 | Train Loss: 0.63683 | Valid Loss: 0.63689 | Time: 0.48 seconds\n",
            "Epoch: 157 | Train Loss: 0.63608 | Valid Loss: 0.63759 | Time: 0.48 seconds\n",
            "Epoch: 158 | Train Loss: 0.63533 | Valid Loss: 0.63578 | Time: 0.47 seconds\n",
            "Epoch: 159 | Train Loss: 0.63458 | Valid Loss: 0.63482 | Time: 0.48 seconds\n",
            "Epoch: 160 | Train Loss: 0.63382 | Valid Loss: 0.63541 | Time: 0.48 seconds\n",
            "Epoch: 161 | Train Loss: 0.63307 | Valid Loss: 0.63370 | Time: 0.47 seconds\n",
            "Epoch: 162 | Train Loss: 0.63230 | Valid Loss: 0.63256 | Time: 0.47 seconds\n",
            "Epoch: 163 | Train Loss: 0.63155 | Valid Loss: 0.63213 | Time: 0.48 seconds\n",
            "Epoch: 164 | Train Loss: 0.63078 | Valid Loss: 0.63127 | Time: 0.46 seconds\n",
            "Epoch: 165 | Train Loss: 0.63001 | Valid Loss: 0.63115 | Time: 0.50 seconds\n",
            "Epoch: 166 | Train Loss: 0.62924 | Valid Loss: 0.62976 | Time: 0.46 seconds\n",
            "Epoch: 167 | Train Loss: 0.62848 | Valid Loss: 0.62968 | Time: 0.49 seconds\n",
            "Epoch: 168 | Train Loss: 0.62771 | Valid Loss: 0.62902 | Time: 0.48 seconds\n",
            "Epoch: 169 | Train Loss: 0.62694 | Valid Loss: 0.62800 | Time: 0.48 seconds\n",
            "Epoch: 170 | Train Loss: 0.62616 | Valid Loss: 0.62635 | Time: 0.48 seconds\n",
            "Epoch: 171 | Train Loss: 0.62539 | Valid Loss: 0.62499 | Time: 0.47 seconds\n",
            "Epoch: 172 | Train Loss: 0.62461 | Valid Loss: 0.62447 | Time: 0.47 seconds\n",
            "Epoch: 173 | Train Loss: 0.62383 | Valid Loss: 0.62491 | Time: 0.45 seconds\n",
            "Epoch: 174 | Train Loss: 0.62306 | Valid Loss: 0.62277 | Time: 0.47 seconds\n",
            "Epoch: 175 | Train Loss: 0.62226 | Valid Loss: 0.62359 | Time: 0.46 seconds\n",
            "Epoch: 176 | Train Loss: 0.62147 | Valid Loss: 0.62386 | Time: 0.48 seconds\n",
            "Epoch: 177 | Train Loss: 0.62069 | Valid Loss: 0.62033 | Time: 0.46 seconds\n",
            "Epoch: 178 | Train Loss: 0.61990 | Valid Loss: 0.62012 | Time: 0.47 seconds\n",
            "Epoch: 179 | Train Loss: 0.61912 | Valid Loss: 0.61986 | Time: 0.46 seconds\n",
            "Epoch: 180 | Train Loss: 0.61831 | Valid Loss: 0.61917 | Time: 0.48 seconds\n",
            "Epoch: 181 | Train Loss: 0.61753 | Valid Loss: 0.61948 | Time: 0.46 seconds\n",
            "Epoch: 182 | Train Loss: 0.61673 | Valid Loss: 0.61816 | Time: 0.47 seconds\n",
            "Epoch: 183 | Train Loss: 0.61593 | Valid Loss: 0.61723 | Time: 0.46 seconds\n",
            "Epoch: 184 | Train Loss: 0.61513 | Valid Loss: 0.61594 | Time: 0.47 seconds\n",
            "Epoch: 185 | Train Loss: 0.61433 | Valid Loss: 0.61287 | Time: 0.48 seconds\n",
            "Epoch: 186 | Train Loss: 0.61352 | Valid Loss: 0.61302 | Time: 0.46 seconds\n",
            "Epoch: 187 | Train Loss: 0.61273 | Valid Loss: 0.61376 | Time: 0.46 seconds\n",
            "Epoch: 188 | Train Loss: 0.61193 | Valid Loss: 0.61144 | Time: 0.47 seconds\n",
            "Epoch: 189 | Train Loss: 0.61111 | Valid Loss: 0.61151 | Time: 0.47 seconds\n",
            "Epoch: 190 | Train Loss: 0.61032 | Valid Loss: 0.61089 | Time: 0.48 seconds\n",
            "Epoch: 191 | Train Loss: 0.60950 | Valid Loss: 0.60902 | Time: 0.47 seconds\n",
            "Epoch: 192 | Train Loss: 0.60869 | Valid Loss: 0.60840 | Time: 0.47 seconds\n",
            "Epoch: 193 | Train Loss: 0.60788 | Valid Loss: 0.60757 | Time: 0.48 seconds\n",
            "Epoch: 194 | Train Loss: 0.60707 | Valid Loss: 0.60714 | Time: 0.47 seconds\n",
            "Epoch: 195 | Train Loss: 0.60626 | Valid Loss: 0.60639 | Time: 0.47 seconds\n",
            "Epoch: 196 | Train Loss: 0.60544 | Valid Loss: 0.60628 | Time: 0.46 seconds\n",
            "Epoch: 197 | Train Loss: 0.60462 | Valid Loss: 0.60639 | Time: 0.47 seconds\n",
            "Epoch: 198 | Train Loss: 0.60381 | Valid Loss: 0.60531 | Time: 0.47 seconds\n",
            "Epoch: 199 | Train Loss: 0.60299 | Valid Loss: 0.60339 | Time: 0.47 seconds\n",
            "Epoch: 200 | Train Loss: 0.60217 | Valid Loss: 0.60307 | Time: 0.47 seconds\n",
            "Epoch: 201 | Train Loss: 0.60135 | Valid Loss: 0.60126 | Time: 0.47 seconds\n",
            "Epoch: 202 | Train Loss: 0.60052 | Valid Loss: 0.60259 | Time: 0.48 seconds\n",
            "Epoch: 203 | Train Loss: 0.59972 | Valid Loss: 0.60073 | Time: 0.47 seconds\n",
            "Epoch: 204 | Train Loss: 0.59888 | Valid Loss: 0.60111 | Time: 0.46 seconds\n",
            "Epoch: 205 | Train Loss: 0.59805 | Valid Loss: 0.59897 | Time: 0.46 seconds\n",
            "Epoch: 206 | Train Loss: 0.59723 | Valid Loss: 0.59850 | Time: 0.48 seconds\n",
            "Epoch: 207 | Train Loss: 0.59640 | Valid Loss: 0.59831 | Time: 0.48 seconds\n",
            "Epoch: 208 | Train Loss: 0.59558 | Valid Loss: 0.59583 | Time: 0.47 seconds\n",
            "Epoch: 209 | Train Loss: 0.59475 | Valid Loss: 0.59512 | Time: 0.47 seconds\n",
            "Epoch: 210 | Train Loss: 0.59392 | Valid Loss: 0.59411 | Time: 0.46 seconds\n",
            "Epoch: 211 | Train Loss: 0.59308 | Valid Loss: 0.59353 | Time: 0.47 seconds\n",
            "Epoch: 212 | Train Loss: 0.59226 | Valid Loss: 0.59326 | Time: 0.47 seconds\n",
            "Epoch: 213 | Train Loss: 0.59142 | Valid Loss: 0.59320 | Time: 0.47 seconds\n",
            "Epoch: 214 | Train Loss: 0.59059 | Valid Loss: 0.59172 | Time: 0.48 seconds\n",
            "Epoch: 215 | Train Loss: 0.58975 | Valid Loss: 0.59148 | Time: 0.48 seconds\n",
            "Epoch: 216 | Train Loss: 0.58891 | Valid Loss: 0.58755 | Time: 0.47 seconds\n",
            "Epoch: 217 | Train Loss: 0.58807 | Valid Loss: 0.58988 | Time: 0.47 seconds\n",
            "Epoch: 218 | Train Loss: 0.58724 | Valid Loss: 0.58725 | Time: 0.49 seconds\n",
            "Epoch: 219 | Train Loss: 0.58640 | Valid Loss: 0.58784 | Time: 0.46 seconds\n",
            "Epoch: 220 | Train Loss: 0.58557 | Valid Loss: 0.58627 | Time: 0.46 seconds\n",
            "Epoch: 221 | Train Loss: 0.58472 | Valid Loss: 0.58461 | Time: 0.48 seconds\n",
            "Epoch: 222 | Train Loss: 0.58387 | Valid Loss: 0.58560 | Time: 0.47 seconds\n",
            "Epoch: 223 | Train Loss: 0.58303 | Valid Loss: 0.58320 | Time: 0.47 seconds\n",
            "Epoch: 224 | Train Loss: 0.58219 | Valid Loss: 0.58392 | Time: 0.45 seconds\n",
            "Epoch: 225 | Train Loss: 0.58135 | Valid Loss: 0.58160 | Time: 0.46 seconds\n",
            "Epoch: 226 | Train Loss: 0.58050 | Valid Loss: 0.57933 | Time: 0.51 seconds\n",
            "Epoch: 227 | Train Loss: 0.57965 | Valid Loss: 0.58034 | Time: 0.46 seconds\n",
            "Epoch: 228 | Train Loss: 0.57880 | Valid Loss: 0.58007 | Time: 0.47 seconds\n",
            "Epoch: 229 | Train Loss: 0.57796 | Valid Loss: 0.57871 | Time: 0.47 seconds\n",
            "Epoch: 230 | Train Loss: 0.57711 | Valid Loss: 0.57763 | Time: 0.48 seconds\n",
            "Epoch: 231 | Train Loss: 0.57626 | Valid Loss: 0.57677 | Time: 0.48 seconds\n",
            "Epoch: 232 | Train Loss: 0.57542 | Valid Loss: 0.57596 | Time: 0.49 seconds\n",
            "Epoch: 233 | Train Loss: 0.57455 | Valid Loss: 0.57517 | Time: 0.47 seconds\n",
            "Epoch: 234 | Train Loss: 0.57370 | Valid Loss: 0.57546 | Time: 0.47 seconds\n",
            "Epoch: 235 | Train Loss: 0.57285 | Valid Loss: 0.57275 | Time: 0.48 seconds\n",
            "Epoch: 236 | Train Loss: 0.57200 | Valid Loss: 0.57300 | Time: 0.47 seconds\n",
            "Epoch: 237 | Train Loss: 0.57114 | Valid Loss: 0.57229 | Time: 0.47 seconds\n",
            "Epoch: 238 | Train Loss: 0.57029 | Valid Loss: 0.57154 | Time: 0.48 seconds\n",
            "Epoch: 239 | Train Loss: 0.56943 | Valid Loss: 0.56893 | Time: 0.46 seconds\n",
            "Epoch: 240 | Train Loss: 0.56857 | Valid Loss: 0.56891 | Time: 0.47 seconds\n",
            "Epoch: 241 | Train Loss: 0.56771 | Valid Loss: 0.56928 | Time: 0.49 seconds\n",
            "Epoch: 242 | Train Loss: 0.56687 | Valid Loss: 0.56838 | Time: 0.47 seconds\n",
            "Epoch: 243 | Train Loss: 0.56601 | Valid Loss: 0.56730 | Time: 0.48 seconds\n",
            "Epoch: 244 | Train Loss: 0.56516 | Valid Loss: 0.56644 | Time: 0.48 seconds\n",
            "Epoch: 245 | Train Loss: 0.56428 | Valid Loss: 0.56489 | Time: 0.48 seconds\n",
            "Epoch: 246 | Train Loss: 0.56342 | Valid Loss: 0.56438 | Time: 0.46 seconds\n",
            "Epoch: 247 | Train Loss: 0.56258 | Valid Loss: 0.56296 | Time: 0.49 seconds\n",
            "Epoch: 248 | Train Loss: 0.56170 | Valid Loss: 0.56444 | Time: 0.46 seconds\n",
            "Epoch: 249 | Train Loss: 0.56083 | Valid Loss: 0.56132 | Time: 0.48 seconds\n",
            "Epoch: 250 | Train Loss: 0.55998 | Valid Loss: 0.56018 | Time: 0.48 seconds\n",
            "Epoch: 251 | Train Loss: 0.55912 | Valid Loss: 0.56018 | Time: 0.48 seconds\n",
            "Epoch: 252 | Train Loss: 0.55827 | Valid Loss: 0.55787 | Time: 0.49 seconds\n",
            "Epoch: 253 | Train Loss: 0.55740 | Valid Loss: 0.55618 | Time: 0.48 seconds\n",
            "Epoch: 254 | Train Loss: 0.55654 | Valid Loss: 0.55696 | Time: 0.46 seconds\n",
            "Epoch: 255 | Train Loss: 0.55567 | Valid Loss: 0.55678 | Time: 0.46 seconds\n",
            "Epoch: 256 | Train Loss: 0.55481 | Valid Loss: 0.55491 | Time: 0.48 seconds\n",
            "Epoch: 257 | Train Loss: 0.55394 | Valid Loss: 0.55269 | Time: 0.47 seconds\n",
            "Epoch: 258 | Train Loss: 0.55307 | Valid Loss: 0.55409 | Time: 0.47 seconds\n",
            "Epoch: 259 | Train Loss: 0.55220 | Valid Loss: 0.55283 | Time: 0.46 seconds\n",
            "Epoch: 260 | Train Loss: 0.55134 | Valid Loss: 0.55164 | Time: 0.48 seconds\n",
            "Epoch: 261 | Train Loss: 0.55047 | Valid Loss: 0.55136 | Time: 0.47 seconds\n",
            "Epoch: 262 | Train Loss: 0.54961 | Valid Loss: 0.55154 | Time: 0.48 seconds\n",
            "Epoch: 263 | Train Loss: 0.54873 | Valid Loss: 0.54895 | Time: 0.47 seconds\n",
            "Epoch: 264 | Train Loss: 0.54786 | Valid Loss: 0.54941 | Time: 0.49 seconds\n",
            "Epoch: 265 | Train Loss: 0.54699 | Valid Loss: 0.54854 | Time: 0.46 seconds\n",
            "Epoch: 266 | Train Loss: 0.54614 | Valid Loss: 0.54836 | Time: 0.48 seconds\n",
            "Epoch: 267 | Train Loss: 0.54526 | Valid Loss: 0.54313 | Time: 0.47 seconds\n",
            "Epoch: 268 | Train Loss: 0.54439 | Valid Loss: 0.54422 | Time: 0.47 seconds\n",
            "Epoch: 269 | Train Loss: 0.54353 | Valid Loss: 0.54446 | Time: 0.46 seconds\n",
            "Epoch: 270 | Train Loss: 0.54265 | Valid Loss: 0.54435 | Time: 0.45 seconds\n",
            "Epoch: 271 | Train Loss: 0.54176 | Valid Loss: 0.54146 | Time: 0.48 seconds\n",
            "Epoch: 272 | Train Loss: 0.54091 | Valid Loss: 0.54193 | Time: 0.48 seconds\n",
            "Epoch: 273 | Train Loss: 0.54003 | Valid Loss: 0.54057 | Time: 0.49 seconds\n",
            "Epoch: 274 | Train Loss: 0.53916 | Valid Loss: 0.53925 | Time: 0.46 seconds\n",
            "Epoch: 275 | Train Loss: 0.53827 | Valid Loss: 0.54062 | Time: 0.47 seconds\n",
            "Epoch: 276 | Train Loss: 0.53741 | Valid Loss: 0.53818 | Time: 0.46 seconds\n",
            "Epoch: 277 | Train Loss: 0.53654 | Valid Loss: 0.53754 | Time: 0.49 seconds\n",
            "Epoch: 278 | Train Loss: 0.53567 | Valid Loss: 0.53641 | Time: 0.47 seconds\n",
            "Epoch: 279 | Train Loss: 0.53481 | Valid Loss: 0.53476 | Time: 0.48 seconds\n",
            "Epoch: 280 | Train Loss: 0.53392 | Valid Loss: 0.53540 | Time: 0.46 seconds\n",
            "Epoch: 281 | Train Loss: 0.53305 | Valid Loss: 0.53472 | Time: 0.47 seconds\n",
            "Epoch: 282 | Train Loss: 0.53218 | Valid Loss: 0.53385 | Time: 0.47 seconds\n",
            "Epoch: 283 | Train Loss: 0.53129 | Valid Loss: 0.53461 | Time: 0.46 seconds\n",
            "Epoch: 284 | Train Loss: 0.53044 | Valid Loss: 0.53235 | Time: 0.47 seconds\n",
            "Epoch: 285 | Train Loss: 0.52957 | Valid Loss: 0.53099 | Time: 0.47 seconds\n",
            "Epoch: 286 | Train Loss: 0.52870 | Valid Loss: 0.53106 | Time: 0.48 seconds\n",
            "Epoch: 287 | Train Loss: 0.52782 | Valid Loss: 0.52822 | Time: 0.46 seconds\n",
            "Epoch: 288 | Train Loss: 0.52693 | Valid Loss: 0.52724 | Time: 0.47 seconds\n",
            "Epoch: 289 | Train Loss: 0.52608 | Valid Loss: 0.52679 | Time: 0.46 seconds\n",
            "Epoch: 290 | Train Loss: 0.52520 | Valid Loss: 0.52623 | Time: 0.48 seconds\n",
            "Epoch: 291 | Train Loss: 0.52432 | Valid Loss: 0.52854 | Time: 0.45 seconds\n",
            "Epoch: 292 | Train Loss: 0.52344 | Valid Loss: 0.52496 | Time: 0.49 seconds\n",
            "Epoch: 293 | Train Loss: 0.52257 | Valid Loss: 0.52353 | Time: 0.46 seconds\n",
            "Epoch: 294 | Train Loss: 0.52169 | Valid Loss: 0.52174 | Time: 0.49 seconds\n",
            "Epoch: 295 | Train Loss: 0.52081 | Valid Loss: 0.52372 | Time: 0.46 seconds\n",
            "Epoch: 296 | Train Loss: 0.51995 | Valid Loss: 0.52207 | Time: 0.45 seconds\n",
            "Epoch: 297 | Train Loss: 0.51907 | Valid Loss: 0.51933 | Time: 0.48 seconds\n",
            "Epoch: 298 | Train Loss: 0.51821 | Valid Loss: 0.52006 | Time: 0.47 seconds\n",
            "Epoch: 299 | Train Loss: 0.51733 | Valid Loss: 0.51777 | Time: 0.49 seconds\n",
            "Epoch: 300 | Train Loss: 0.51646 | Valid Loss: 0.51971 | Time: 0.46 seconds\n",
            "Epoch: 301 | Train Loss: 0.51559 | Valid Loss: 0.51693 | Time: 0.48 seconds\n",
            "Epoch: 302 | Train Loss: 0.51472 | Valid Loss: 0.51756 | Time: 0.47 seconds\n",
            "Epoch: 303 | Train Loss: 0.51386 | Valid Loss: 0.51543 | Time: 0.48 seconds\n",
            "Epoch: 304 | Train Loss: 0.51296 | Valid Loss: 0.51598 | Time: 0.46 seconds\n",
            "Epoch: 305 | Train Loss: 0.51210 | Valid Loss: 0.51350 | Time: 0.48 seconds\n",
            "Epoch: 306 | Train Loss: 0.51121 | Valid Loss: 0.51223 | Time: 0.48 seconds\n",
            "Epoch: 307 | Train Loss: 0.51035 | Valid Loss: 0.51064 | Time: 0.49 seconds\n",
            "Epoch: 308 | Train Loss: 0.50949 | Valid Loss: 0.51315 | Time: 0.49 seconds\n",
            "Epoch: 309 | Train Loss: 0.50860 | Valid Loss: 0.50836 | Time: 0.48 seconds\n",
            "Epoch: 310 | Train Loss: 0.50773 | Valid Loss: 0.50870 | Time: 0.47 seconds\n",
            "Epoch: 311 | Train Loss: 0.50685 | Valid Loss: 0.50695 | Time: 0.47 seconds\n",
            "Epoch: 312 | Train Loss: 0.50600 | Valid Loss: 0.50618 | Time: 0.47 seconds\n",
            "Epoch: 313 | Train Loss: 0.50513 | Valid Loss: 0.50669 | Time: 0.47 seconds\n",
            "Epoch: 314 | Train Loss: 0.50427 | Valid Loss: 0.50435 | Time: 0.48 seconds\n",
            "Epoch: 315 | Train Loss: 0.50337 | Valid Loss: 0.50648 | Time: 0.46 seconds\n",
            "Epoch: 316 | Train Loss: 0.50251 | Valid Loss: 0.50276 | Time: 0.48 seconds\n",
            "Epoch: 317 | Train Loss: 0.50164 | Valid Loss: 0.50260 | Time: 0.48 seconds\n",
            "Epoch: 318 | Train Loss: 0.50077 | Valid Loss: 0.50317 | Time: 0.50 seconds\n",
            "Epoch: 319 | Train Loss: 0.49991 | Valid Loss: 0.50164 | Time: 0.48 seconds\n",
            "Epoch: 320 | Train Loss: 0.49905 | Valid Loss: 0.49906 | Time: 0.49 seconds\n",
            "Epoch: 321 | Train Loss: 0.49816 | Valid Loss: 0.49857 | Time: 0.47 seconds\n",
            "Epoch: 322 | Train Loss: 0.49728 | Valid Loss: 0.49824 | Time: 0.48 seconds\n",
            "Epoch: 323 | Train Loss: 0.49643 | Valid Loss: 0.49831 | Time: 0.47 seconds\n",
            "Epoch: 324 | Train Loss: 0.49557 | Valid Loss: 0.49736 | Time: 0.47 seconds\n",
            "Epoch: 325 | Train Loss: 0.49472 | Valid Loss: 0.49644 | Time: 0.46 seconds\n",
            "Epoch: 326 | Train Loss: 0.49382 | Valid Loss: 0.49354 | Time: 0.49 seconds\n",
            "Epoch: 327 | Train Loss: 0.49297 | Valid Loss: 0.49399 | Time: 0.48 seconds\n",
            "Epoch: 328 | Train Loss: 0.49209 | Valid Loss: 0.49294 | Time: 0.46 seconds\n",
            "Epoch: 329 | Train Loss: 0.49123 | Valid Loss: 0.49249 | Time: 0.48 seconds\n",
            "Epoch: 330 | Train Loss: 0.49039 | Valid Loss: 0.49116 | Time: 0.49 seconds\n",
            "Epoch: 331 | Train Loss: 0.48952 | Valid Loss: 0.49169 | Time: 0.46 seconds\n",
            "Epoch: 332 | Train Loss: 0.48864 | Valid Loss: 0.48945 | Time: 0.47 seconds\n",
            "Epoch: 333 | Train Loss: 0.48780 | Valid Loss: 0.48824 | Time: 0.47 seconds\n",
            "Epoch: 334 | Train Loss: 0.48693 | Valid Loss: 0.48638 | Time: 0.48 seconds\n",
            "Epoch: 335 | Train Loss: 0.48606 | Valid Loss: 0.48892 | Time: 0.46 seconds\n",
            "Epoch: 336 | Train Loss: 0.48519 | Valid Loss: 0.48758 | Time: 0.47 seconds\n",
            "Epoch: 337 | Train Loss: 0.48436 | Valid Loss: 0.48699 | Time: 0.47 seconds\n",
            "Epoch: 338 | Train Loss: 0.48348 | Valid Loss: 0.48654 | Time: 0.45 seconds\n",
            "Epoch: 339 | Train Loss: 0.48264 | Valid Loss: 0.48461 | Time: 0.46 seconds\n",
            "Epoch: 340 | Train Loss: 0.48176 | Valid Loss: 0.48396 | Time: 0.48 seconds\n",
            "Epoch: 341 | Train Loss: 0.48090 | Valid Loss: 0.48237 | Time: 0.47 seconds\n",
            "Epoch: 342 | Train Loss: 0.48007 | Valid Loss: 0.48046 | Time: 0.47 seconds\n",
            "Epoch: 343 | Train Loss: 0.47920 | Valid Loss: 0.47994 | Time: 0.46 seconds\n",
            "Epoch: 344 | Train Loss: 0.47834 | Valid Loss: 0.47879 | Time: 0.48 seconds\n",
            "Epoch: 345 | Train Loss: 0.47749 | Valid Loss: 0.47946 | Time: 0.49 seconds\n",
            "Epoch: 346 | Train Loss: 0.47664 | Valid Loss: 0.47808 | Time: 0.48 seconds\n",
            "Epoch: 347 | Train Loss: 0.47578 | Valid Loss: 0.47731 | Time: 0.46 seconds\n",
            "Epoch: 348 | Train Loss: 0.47493 | Valid Loss: 0.47673 | Time: 0.48 seconds\n",
            "Epoch: 349 | Train Loss: 0.47410 | Valid Loss: 0.47474 | Time: 0.49 seconds\n",
            "Epoch: 350 | Train Loss: 0.47322 | Valid Loss: 0.47388 | Time: 0.47 seconds\n",
            "Epoch: 351 | Train Loss: 0.47239 | Valid Loss: 0.47333 | Time: 0.47 seconds\n",
            "Epoch: 352 | Train Loss: 0.47154 | Valid Loss: 0.47169 | Time: 0.48 seconds\n",
            "Epoch: 353 | Train Loss: 0.47069 | Valid Loss: 0.47204 | Time: 0.45 seconds\n",
            "Epoch: 354 | Train Loss: 0.46985 | Valid Loss: 0.47179 | Time: 0.45 seconds\n",
            "Epoch: 355 | Train Loss: 0.46897 | Valid Loss: 0.46937 | Time: 0.48 seconds\n",
            "Epoch: 356 | Train Loss: 0.46816 | Valid Loss: 0.46964 | Time: 0.47 seconds\n",
            "Epoch: 357 | Train Loss: 0.46731 | Valid Loss: 0.46708 | Time: 0.48 seconds\n",
            "Epoch: 358 | Train Loss: 0.46646 | Valid Loss: 0.46816 | Time: 0.47 seconds\n",
            "Epoch: 359 | Train Loss: 0.46563 | Valid Loss: 0.46744 | Time: 0.46 seconds\n",
            "Epoch: 360 | Train Loss: 0.46478 | Valid Loss: 0.46495 | Time: 0.47 seconds\n",
            "Epoch: 361 | Train Loss: 0.46393 | Valid Loss: 0.46545 | Time: 0.47 seconds\n",
            "Epoch: 362 | Train Loss: 0.46309 | Valid Loss: 0.46410 | Time: 0.46 seconds\n",
            "Epoch: 363 | Train Loss: 0.46222 | Valid Loss: 0.46484 | Time: 0.47 seconds\n",
            "Epoch: 364 | Train Loss: 0.46143 | Valid Loss: 0.46235 | Time: 0.46 seconds\n",
            "Epoch: 365 | Train Loss: 0.46060 | Valid Loss: 0.46194 | Time: 0.48 seconds\n",
            "Epoch: 366 | Train Loss: 0.45975 | Valid Loss: 0.46179 | Time: 0.45 seconds\n",
            "Epoch: 367 | Train Loss: 0.45892 | Valid Loss: 0.46103 | Time: 0.47 seconds\n",
            "Epoch: 368 | Train Loss: 0.45807 | Valid Loss: 0.45986 | Time: 0.48 seconds\n",
            "Epoch: 369 | Train Loss: 0.45725 | Valid Loss: 0.45924 | Time: 0.47 seconds\n",
            "Epoch: 370 | Train Loss: 0.45642 | Valid Loss: 0.45824 | Time: 0.48 seconds\n",
            "Epoch: 371 | Train Loss: 0.45557 | Valid Loss: 0.45553 | Time: 0.47 seconds\n",
            "Epoch: 372 | Train Loss: 0.45475 | Valid Loss: 0.45496 | Time: 0.50 seconds\n",
            "Epoch: 373 | Train Loss: 0.45393 | Valid Loss: 0.45461 | Time: 0.46 seconds\n",
            "Epoch: 374 | Train Loss: 0.45309 | Valid Loss: 0.45678 | Time: 0.47 seconds\n",
            "Epoch: 375 | Train Loss: 0.45227 | Valid Loss: 0.45350 | Time: 0.46 seconds\n",
            "Epoch: 376 | Train Loss: 0.45144 | Valid Loss: 0.45399 | Time: 0.48 seconds\n",
            "Epoch: 377 | Train Loss: 0.45062 | Valid Loss: 0.45304 | Time: 0.47 seconds\n",
            "Epoch: 378 | Train Loss: 0.44980 | Valid Loss: 0.45196 | Time: 0.47 seconds\n",
            "Epoch: 379 | Train Loss: 0.44897 | Valid Loss: 0.45056 | Time: 0.47 seconds\n",
            "Epoch: 380 | Train Loss: 0.44816 | Valid Loss: 0.45264 | Time: 0.48 seconds\n",
            "Epoch: 381 | Train Loss: 0.44733 | Valid Loss: 0.44671 | Time: 0.46 seconds\n",
            "Epoch: 382 | Train Loss: 0.44651 | Valid Loss: 0.44704 | Time: 0.47 seconds\n",
            "Epoch: 383 | Train Loss: 0.44571 | Valid Loss: 0.44792 | Time: 0.47 seconds\n",
            "Epoch: 384 | Train Loss: 0.44487 | Valid Loss: 0.44494 | Time: 0.47 seconds\n",
            "Epoch: 385 | Train Loss: 0.44409 | Valid Loss: 0.44571 | Time: 0.49 seconds\n",
            "Epoch: 386 | Train Loss: 0.44327 | Valid Loss: 0.44412 | Time: 0.47 seconds\n",
            "Epoch: 387 | Train Loss: 0.44244 | Valid Loss: 0.44370 | Time: 0.48 seconds\n",
            "Epoch: 388 | Train Loss: 0.44166 | Valid Loss: 0.44439 | Time: 0.47 seconds\n",
            "Epoch: 389 | Train Loss: 0.44082 | Valid Loss: 0.44330 | Time: 0.48 seconds\n",
            "Epoch: 390 | Train Loss: 0.44003 | Valid Loss: 0.44215 | Time: 0.46 seconds\n",
            "Epoch: 391 | Train Loss: 0.43923 | Valid Loss: 0.44191 | Time: 0.48 seconds\n",
            "Epoch: 392 | Train Loss: 0.43842 | Valid Loss: 0.44047 | Time: 0.47 seconds\n",
            "Epoch: 393 | Train Loss: 0.43758 | Valid Loss: 0.44003 | Time: 0.50 seconds\n",
            "Epoch: 394 | Train Loss: 0.43679 | Valid Loss: 0.43913 | Time: 0.46 seconds\n",
            "Epoch: 395 | Train Loss: 0.43599 | Valid Loss: 0.43833 | Time: 0.47 seconds\n",
            "Epoch: 396 | Train Loss: 0.43521 | Valid Loss: 0.43720 | Time: 0.49 seconds\n",
            "Epoch: 397 | Train Loss: 0.43440 | Valid Loss: 0.43484 | Time: 0.48 seconds\n",
            "Epoch: 398 | Train Loss: 0.43361 | Valid Loss: 0.43617 | Time: 0.47 seconds\n",
            "Epoch: 399 | Train Loss: 0.43282 | Valid Loss: 0.43513 | Time: 0.46 seconds\n",
            "Epoch: 400 | Train Loss: 0.43202 | Valid Loss: 0.43212 | Time: 0.48 seconds\n",
            "Epoch: 401 | Train Loss: 0.43121 | Valid Loss: 0.43174 | Time: 0.48 seconds\n",
            "Epoch: 402 | Train Loss: 0.43044 | Valid Loss: 0.42957 | Time: 0.48 seconds\n",
            "Epoch: 403 | Train Loss: 0.42965 | Valid Loss: 0.43174 | Time: 0.46 seconds\n",
            "Epoch: 404 | Train Loss: 0.42885 | Valid Loss: 0.43125 | Time: 0.47 seconds\n",
            "Epoch: 405 | Train Loss: 0.42807 | Valid Loss: 0.43106 | Time: 0.46 seconds\n",
            "Epoch: 406 | Train Loss: 0.42727 | Valid Loss: 0.42949 | Time: 0.47 seconds\n",
            "Epoch: 407 | Train Loss: 0.42651 | Valid Loss: 0.42813 | Time: 0.48 seconds\n",
            "Epoch: 408 | Train Loss: 0.42569 | Valid Loss: 0.42625 | Time: 0.48 seconds\n",
            "Epoch: 409 | Train Loss: 0.42492 | Valid Loss: 0.42573 | Time: 0.47 seconds\n",
            "Epoch: 410 | Train Loss: 0.42415 | Valid Loss: 0.42383 | Time: 0.46 seconds\n",
            "Epoch: 411 | Train Loss: 0.42336 | Valid Loss: 0.42523 | Time: 0.47 seconds\n",
            "Epoch: 412 | Train Loss: 0.42260 | Valid Loss: 0.42264 | Time: 0.49 seconds\n",
            "Epoch: 413 | Train Loss: 0.42180 | Valid Loss: 0.42421 | Time: 0.46 seconds\n",
            "Epoch: 414 | Train Loss: 0.42100 | Valid Loss: 0.42096 | Time: 0.47 seconds\n",
            "Epoch: 415 | Train Loss: 0.42022 | Valid Loss: 0.42173 | Time: 0.47 seconds\n",
            "Epoch: 416 | Train Loss: 0.41948 | Valid Loss: 0.42336 | Time: 0.46 seconds\n",
            "Epoch: 417 | Train Loss: 0.41871 | Valid Loss: 0.42024 | Time: 0.48 seconds\n",
            "Epoch: 418 | Train Loss: 0.41794 | Valid Loss: 0.41909 | Time: 0.47 seconds\n",
            "Epoch: 419 | Train Loss: 0.41718 | Valid Loss: 0.41699 | Time: 0.48 seconds\n",
            "Epoch: 420 | Train Loss: 0.41643 | Valid Loss: 0.41799 | Time: 0.46 seconds\n",
            "Epoch: 421 | Train Loss: 0.41567 | Valid Loss: 0.41520 | Time: 0.49 seconds\n",
            "Epoch: 422 | Train Loss: 0.41485 | Valid Loss: 0.41673 | Time: 0.46 seconds\n",
            "Epoch: 423 | Train Loss: 0.41410 | Valid Loss: 0.41511 | Time: 0.46 seconds\n",
            "Epoch: 424 | Train Loss: 0.41337 | Valid Loss: 0.41695 | Time: 0.46 seconds\n",
            "Epoch: 425 | Train Loss: 0.41261 | Valid Loss: 0.41366 | Time: 0.46 seconds\n",
            "Epoch: 426 | Train Loss: 0.41188 | Valid Loss: 0.41415 | Time: 0.47 seconds\n",
            "Epoch: 427 | Train Loss: 0.41111 | Valid Loss: 0.41309 | Time: 0.47 seconds\n",
            "Epoch: 428 | Train Loss: 0.41030 | Valid Loss: 0.41374 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40962 | Valid Loss: 0.41473 | Time: 0.45 seconds\n",
            "Epoch: 430 | Train Loss: 0.40883 | Valid Loss: 0.41177 | Time: 0.48 seconds\n",
            "Epoch: 431 | Train Loss: 0.40810 | Valid Loss: 0.40866 | Time: 0.46 seconds\n",
            "Epoch: 432 | Train Loss: 0.40734 | Valid Loss: 0.41047 | Time: 0.48 seconds\n",
            "Epoch: 433 | Train Loss: 0.40660 | Valid Loss: 0.40764 | Time: 0.46 seconds\n",
            "Epoch: 434 | Train Loss: 0.40586 | Valid Loss: 0.40385 | Time: 0.47 seconds\n",
            "Epoch: 435 | Train Loss: 0.40511 | Valid Loss: 0.40713 | Time: 0.46 seconds\n",
            "Epoch: 436 | Train Loss: 0.40435 | Valid Loss: 0.40459 | Time: 0.46 seconds\n",
            "Epoch: 437 | Train Loss: 0.40365 | Valid Loss: 0.40475 | Time: 0.47 seconds\n",
            "Epoch: 438 | Train Loss: 0.40290 | Valid Loss: 0.40387 | Time: 0.46 seconds\n",
            "Epoch: 439 | Train Loss: 0.40216 | Valid Loss: 0.40283 | Time: 0.50 seconds\n",
            "Epoch: 440 | Train Loss: 0.40145 | Valid Loss: 0.40143 | Time: 0.48 seconds\n",
            "Epoch: 441 | Train Loss: 0.40070 | Valid Loss: 0.40291 | Time: 0.47 seconds\n",
            "Epoch: 442 | Train Loss: 0.39994 | Valid Loss: 0.40011 | Time: 0.47 seconds\n",
            "Epoch: 443 | Train Loss: 0.39922 | Valid Loss: 0.40266 | Time: 0.47 seconds\n",
            "Epoch: 444 | Train Loss: 0.39849 | Valid Loss: 0.40214 | Time: 0.45 seconds\n",
            "Epoch: 445 | Train Loss: 0.39775 | Valid Loss: 0.39847 | Time: 0.47 seconds\n",
            "Epoch: 446 | Train Loss: 0.39702 | Valid Loss: 0.39891 | Time: 0.45 seconds\n",
            "Epoch: 447 | Train Loss: 0.39629 | Valid Loss: 0.39764 | Time: 0.48 seconds\n",
            "Epoch: 448 | Train Loss: 0.39560 | Valid Loss: 0.39609 | Time: 0.48 seconds\n",
            "Epoch: 449 | Train Loss: 0.39485 | Valid Loss: 0.39692 | Time: 0.47 seconds\n",
            "Epoch: 450 | Train Loss: 0.39415 | Valid Loss: 0.39461 | Time: 0.47 seconds\n",
            "Epoch: 451 | Train Loss: 0.39345 | Valid Loss: 0.39437 | Time: 0.46 seconds\n",
            "Epoch: 452 | Train Loss: 0.39274 | Valid Loss: 0.39357 | Time: 0.48 seconds\n",
            "Epoch: 453 | Train Loss: 0.39199 | Valid Loss: 0.39258 | Time: 0.48 seconds\n",
            "Epoch: 454 | Train Loss: 0.39128 | Valid Loss: 0.39322 | Time: 0.50 seconds\n",
            "Epoch: 455 | Train Loss: 0.39057 | Valid Loss: 0.39095 | Time: 0.46 seconds\n",
            "Epoch: 456 | Train Loss: 0.38986 | Valid Loss: 0.39312 | Time: 0.46 seconds\n",
            "Epoch: 457 | Train Loss: 0.38918 | Valid Loss: 0.39075 | Time: 0.50 seconds\n",
            "Epoch: 458 | Train Loss: 0.38850 | Valid Loss: 0.38975 | Time: 0.49 seconds\n",
            "Epoch: 459 | Train Loss: 0.38781 | Valid Loss: 0.38839 | Time: 0.47 seconds\n",
            "Epoch: 460 | Train Loss: 0.38705 | Valid Loss: 0.38909 | Time: 0.48 seconds\n",
            "Epoch: 461 | Train Loss: 0.38633 | Valid Loss: 0.38728 | Time: 0.47 seconds\n",
            "Epoch: 462 | Train Loss: 0.38567 | Valid Loss: 0.38647 | Time: 0.48 seconds\n",
            "Epoch: 463 | Train Loss: 0.38495 | Valid Loss: 0.38748 | Time: 0.45 seconds\n",
            "Epoch: 464 | Train Loss: 0.38428 | Valid Loss: 0.38546 | Time: 0.46 seconds\n",
            "Epoch: 465 | Train Loss: 0.38357 | Valid Loss: 0.38494 | Time: 0.50 seconds\n",
            "Epoch: 466 | Train Loss: 0.38287 | Valid Loss: 0.38393 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38220 | Valid Loss: 0.38155 | Time: 0.49 seconds\n",
            "Epoch: 468 | Train Loss: 0.38148 | Valid Loss: 0.38398 | Time: 0.46 seconds\n",
            "Epoch: 469 | Train Loss: 0.38082 | Valid Loss: 0.38224 | Time: 0.47 seconds\n",
            "Epoch: 470 | Train Loss: 0.38013 | Valid Loss: 0.38051 | Time: 0.46 seconds\n",
            "Epoch: 471 | Train Loss: 0.37945 | Valid Loss: 0.38043 | Time: 0.46 seconds\n",
            "Epoch: 472 | Train Loss: 0.37875 | Valid Loss: 0.38061 | Time: 0.46 seconds\n",
            "Epoch: 473 | Train Loss: 0.37803 | Valid Loss: 0.37862 | Time: 0.48 seconds\n",
            "Epoch: 474 | Train Loss: 0.37738 | Valid Loss: 0.38097 | Time: 0.47 seconds\n",
            "Epoch: 475 | Train Loss: 0.37676 | Valid Loss: 0.37940 | Time: 0.46 seconds\n",
            "Epoch: 476 | Train Loss: 0.37602 | Valid Loss: 0.37655 | Time: 0.48 seconds\n",
            "Epoch: 477 | Train Loss: 0.37535 | Valid Loss: 0.37731 | Time: 0.46 seconds\n",
            "Epoch: 478 | Train Loss: 0.37467 | Valid Loss: 0.37761 | Time: 0.47 seconds\n",
            "Epoch: 479 | Train Loss: 0.37399 | Valid Loss: 0.37596 | Time: 0.46 seconds\n",
            "Epoch: 480 | Train Loss: 0.37337 | Valid Loss: 0.37447 | Time: 0.47 seconds\n",
            "Epoch: 481 | Train Loss: 0.37269 | Valid Loss: 0.37480 | Time: 0.45 seconds\n",
            "Epoch: 482 | Train Loss: 0.37199 | Valid Loss: 0.37617 | Time: 0.47 seconds\n",
            "Epoch: 483 | Train Loss: 0.37137 | Valid Loss: 0.37464 | Time: 0.47 seconds\n",
            "Epoch: 484 | Train Loss: 0.37071 | Valid Loss: 0.37172 | Time: 0.48 seconds\n",
            "Epoch: 485 | Train Loss: 0.37003 | Valid Loss: 0.37140 | Time: 0.47 seconds\n",
            "Epoch: 486 | Train Loss: 0.36936 | Valid Loss: 0.37109 | Time: 0.48 seconds\n",
            "Epoch: 487 | Train Loss: 0.36874 | Valid Loss: 0.37143 | Time: 0.46 seconds\n",
            "Epoch: 488 | Train Loss: 0.36803 | Valid Loss: 0.36845 | Time: 0.49 seconds\n",
            "Epoch: 489 | Train Loss: 0.36740 | Valid Loss: 0.36925 | Time: 0.47 seconds\n",
            "Epoch: 490 | Train Loss: 0.36677 | Valid Loss: 0.36591 | Time: 0.48 seconds\n",
            "Epoch: 491 | Train Loss: 0.36609 | Valid Loss: 0.36718 | Time: 0.47 seconds\n",
            "Epoch: 492 | Train Loss: 0.36543 | Valid Loss: 0.36848 | Time: 0.45 seconds\n",
            "Epoch: 493 | Train Loss: 0.36482 | Valid Loss: 0.36574 | Time: 0.47 seconds\n",
            "Epoch: 494 | Train Loss: 0.36415 | Valid Loss: 0.36779 | Time: 0.50 seconds\n",
            "Epoch: 495 | Train Loss: 0.36351 | Valid Loss: 0.36441 | Time: 0.48 seconds\n",
            "Epoch: 496 | Train Loss: 0.36286 | Valid Loss: 0.36355 | Time: 0.47 seconds\n",
            "Epoch: 497 | Train Loss: 0.36220 | Valid Loss: 0.36269 | Time: 0.48 seconds\n",
            "Epoch: 498 | Train Loss: 0.36157 | Valid Loss: 0.36570 | Time: 0.47 seconds\n",
            "Epoch: 499 | Train Loss: 0.36093 | Valid Loss: 0.36027 | Time: 0.48 seconds\n",
            "Epoch: 500 | Train Loss: 0.36031 | Valid Loss: 0.36519 | Time: 0.46 seconds\n",
            "Epoch: 501 | Train Loss: 0.35965 | Valid Loss: 0.36283 | Time: 0.46 seconds\n",
            "Epoch: 502 | Train Loss: 0.35906 | Valid Loss: 0.36258 | Time: 0.47 seconds\n",
            "Epoch: 503 | Train Loss: 0.35842 | Valid Loss: 0.35985 | Time: 0.49 seconds\n",
            "Epoch: 504 | Train Loss: 0.35775 | Valid Loss: 0.35951 | Time: 0.48 seconds\n",
            "Epoch: 505 | Train Loss: 0.35718 | Valid Loss: 0.35810 | Time: 0.46 seconds\n",
            "Epoch: 506 | Train Loss: 0.35651 | Valid Loss: 0.35736 | Time: 0.48 seconds\n",
            "Epoch: 507 | Train Loss: 0.35590 | Valid Loss: 0.35898 | Time: 0.47 seconds\n",
            "Epoch: 508 | Train Loss: 0.35523 | Valid Loss: 0.35788 | Time: 0.49 seconds\n",
            "Epoch: 509 | Train Loss: 0.35462 | Valid Loss: 0.35847 | Time: 0.46 seconds\n",
            "Epoch: 510 | Train Loss: 0.35407 | Valid Loss: 0.35701 | Time: 0.47 seconds\n",
            "Epoch: 511 | Train Loss: 0.35340 | Valid Loss: 0.35468 | Time: 0.47 seconds\n",
            "Epoch: 512 | Train Loss: 0.35278 | Valid Loss: 0.35335 | Time: 0.48 seconds\n",
            "Epoch: 513 | Train Loss: 0.35218 | Valid Loss: 0.35395 | Time: 0.48 seconds\n",
            "Epoch: 514 | Train Loss: 0.35157 | Valid Loss: 0.35324 | Time: 0.48 seconds\n",
            "Epoch: 515 | Train Loss: 0.35097 | Valid Loss: 0.35290 | Time: 0.48 seconds\n",
            "Epoch: 516 | Train Loss: 0.35035 | Valid Loss: 0.35207 | Time: 0.49 seconds\n",
            "Epoch: 517 | Train Loss: 0.34972 | Valid Loss: 0.35154 | Time: 0.49 seconds\n",
            "Epoch: 518 | Train Loss: 0.34909 | Valid Loss: 0.34865 | Time: 0.51 seconds\n",
            "Epoch: 519 | Train Loss: 0.34851 | Valid Loss: 0.34856 | Time: 0.47 seconds\n",
            "Epoch: 520 | Train Loss: 0.34794 | Valid Loss: 0.34947 | Time: 0.47 seconds\n",
            "Epoch: 521 | Train Loss: 0.34731 | Valid Loss: 0.34731 | Time: 0.47 seconds\n",
            "Epoch: 522 | Train Loss: 0.34672 | Valid Loss: 0.34781 | Time: 0.46 seconds\n",
            "Epoch: 523 | Train Loss: 0.34608 | Valid Loss: 0.34720 | Time: 0.53 seconds\n",
            "Epoch: 524 | Train Loss: 0.34546 | Valid Loss: 0.34636 | Time: 0.49 seconds\n",
            "Epoch: 525 | Train Loss: 0.34485 | Valid Loss: 0.34614 | Time: 0.49 seconds\n",
            "Epoch: 526 | Train Loss: 0.34429 | Valid Loss: 0.34418 | Time: 0.47 seconds\n",
            "Epoch: 527 | Train Loss: 0.34369 | Valid Loss: 0.34414 | Time: 0.48 seconds\n",
            "Epoch: 528 | Train Loss: 0.34308 | Valid Loss: 0.34348 | Time: 0.47 seconds\n",
            "Epoch: 529 | Train Loss: 0.34249 | Valid Loss: 0.34632 | Time: 0.47 seconds\n",
            "Epoch: 530 | Train Loss: 0.34191 | Valid Loss: 0.34450 | Time: 0.45 seconds\n",
            "Epoch: 531 | Train Loss: 0.34133 | Valid Loss: 0.34320 | Time: 0.47 seconds\n",
            "Epoch: 532 | Train Loss: 0.34074 | Valid Loss: 0.34315 | Time: 0.47 seconds\n",
            "Epoch: 533 | Train Loss: 0.34015 | Valid Loss: 0.34422 | Time: 0.48 seconds\n",
            "Epoch: 534 | Train Loss: 0.33956 | Valid Loss: 0.34037 | Time: 0.47 seconds\n",
            "Epoch: 535 | Train Loss: 0.33902 | Valid Loss: 0.34016 | Time: 0.47 seconds\n",
            "Epoch: 536 | Train Loss: 0.33843 | Valid Loss: 0.33994 | Time: 0.46 seconds\n",
            "Epoch: 537 | Train Loss: 0.33777 | Valid Loss: 0.33953 | Time: 0.49 seconds\n",
            "Epoch: 538 | Train Loss: 0.33726 | Valid Loss: 0.33853 | Time: 0.47 seconds\n",
            "Epoch: 539 | Train Loss: 0.33664 | Valid Loss: 0.33996 | Time: 0.49 seconds\n",
            "Epoch: 540 | Train Loss: 0.33607 | Valid Loss: 0.33863 | Time: 0.46 seconds\n",
            "Epoch: 541 | Train Loss: 0.33550 | Valid Loss: 0.33778 | Time: 0.46 seconds\n",
            "Epoch: 542 | Train Loss: 0.33490 | Valid Loss: 0.33686 | Time: 0.47 seconds\n",
            "Epoch: 543 | Train Loss: 0.33437 | Valid Loss: 0.33559 | Time: 0.47 seconds\n",
            "Epoch: 544 | Train Loss: 0.33379 | Valid Loss: 0.33659 | Time: 0.48 seconds\n",
            "Epoch: 545 | Train Loss: 0.33323 | Valid Loss: 0.33557 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33266 | Valid Loss: 0.33346 | Time: 0.48 seconds\n",
            "Epoch: 547 | Train Loss: 0.33210 | Valid Loss: 0.33416 | Time: 0.46 seconds\n",
            "Epoch: 548 | Train Loss: 0.33151 | Valid Loss: 0.33298 | Time: 0.49 seconds\n",
            "Epoch: 549 | Train Loss: 0.33097 | Valid Loss: 0.33245 | Time: 0.47 seconds\n",
            "Epoch: 550 | Train Loss: 0.33036 | Valid Loss: 0.33243 | Time: 0.50 seconds\n",
            "Epoch: 551 | Train Loss: 0.32985 | Valid Loss: 0.33103 | Time: 0.48 seconds\n",
            "Epoch: 552 | Train Loss: 0.32927 | Valid Loss: 0.33068 | Time: 0.47 seconds\n",
            "Epoch: 553 | Train Loss: 0.32873 | Valid Loss: 0.33205 | Time: 0.48 seconds\n",
            "Epoch: 554 | Train Loss: 0.32818 | Valid Loss: 0.33024 | Time: 0.46 seconds\n",
            "Epoch: 555 | Train Loss: 0.32760 | Valid Loss: 0.33007 | Time: 0.48 seconds\n",
            "Epoch: 556 | Train Loss: 0.32704 | Valid Loss: 0.32695 | Time: 0.48 seconds\n",
            "Epoch: 557 | Train Loss: 0.32649 | Valid Loss: 0.32774 | Time: 0.48 seconds\n",
            "Epoch: 558 | Train Loss: 0.32592 | Valid Loss: 0.32821 | Time: 0.48 seconds\n",
            "Epoch: 559 | Train Loss: 0.32536 | Valid Loss: 0.32858 | Time: 0.47 seconds\n",
            "Epoch: 560 | Train Loss: 0.32483 | Valid Loss: 0.32793 | Time: 0.47 seconds\n",
            "Epoch: 561 | Train Loss: 0.32431 | Valid Loss: 0.32762 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32373 | Valid Loss: 0.32335 | Time: 0.46 seconds\n",
            "Epoch: 563 | Train Loss: 0.32319 | Valid Loss: 0.32584 | Time: 0.46 seconds\n",
            "Epoch: 564 | Train Loss: 0.32264 | Valid Loss: 0.32300 | Time: 0.46 seconds\n",
            "Epoch: 565 | Train Loss: 0.32212 | Valid Loss: 0.32610 | Time: 0.48 seconds\n",
            "Epoch: 566 | Train Loss: 0.32157 | Valid Loss: 0.32341 | Time: 0.46 seconds\n",
            "Epoch: 567 | Train Loss: 0.32103 | Valid Loss: 0.32451 | Time: 0.46 seconds\n",
            "Epoch: 568 | Train Loss: 0.32045 | Valid Loss: 0.32154 | Time: 0.47 seconds\n",
            "Epoch: 569 | Train Loss: 0.31992 | Valid Loss: 0.32093 | Time: 0.47 seconds\n",
            "Epoch: 570 | Train Loss: 0.31944 | Valid Loss: 0.32062 | Time: 0.48 seconds\n",
            "Epoch: 571 | Train Loss: 0.31887 | Valid Loss: 0.32127 | Time: 0.46 seconds\n",
            "Epoch: 572 | Train Loss: 0.31831 | Valid Loss: 0.32201 | Time: 0.46 seconds\n",
            "Epoch: 573 | Train Loss: 0.31783 | Valid Loss: 0.31752 | Time: 0.46 seconds\n",
            "Epoch: 574 | Train Loss: 0.31728 | Valid Loss: 0.31855 | Time: 0.47 seconds\n",
            "Epoch: 575 | Train Loss: 0.31676 | Valid Loss: 0.31818 | Time: 0.47 seconds\n",
            "Epoch: 576 | Train Loss: 0.31622 | Valid Loss: 0.31997 | Time: 0.47 seconds\n",
            "Epoch: 577 | Train Loss: 0.31570 | Valid Loss: 0.31786 | Time: 0.45 seconds\n",
            "Epoch: 578 | Train Loss: 0.31515 | Valid Loss: 0.31561 | Time: 0.46 seconds\n",
            "Epoch: 579 | Train Loss: 0.31468 | Valid Loss: 0.31633 | Time: 0.47 seconds\n",
            "Epoch: 580 | Train Loss: 0.31412 | Valid Loss: 0.31708 | Time: 0.46 seconds\n",
            "Epoch: 581 | Train Loss: 0.31355 | Valid Loss: 0.31564 | Time: 0.47 seconds\n",
            "Epoch: 582 | Train Loss: 0.31305 | Valid Loss: 0.31716 | Time: 0.46 seconds\n",
            "Epoch: 583 | Train Loss: 0.31256 | Valid Loss: 0.31439 | Time: 0.47 seconds\n",
            "Epoch: 584 | Train Loss: 0.31199 | Valid Loss: 0.31562 | Time: 0.46 seconds\n",
            "Epoch: 585 | Train Loss: 0.31148 | Valid Loss: 0.31109 | Time: 0.47 seconds\n",
            "Epoch: 586 | Train Loss: 0.31103 | Valid Loss: 0.31225 | Time: 0.47 seconds\n",
            "Epoch: 587 | Train Loss: 0.31046 | Valid Loss: 0.31375 | Time: 0.48 seconds\n",
            "Epoch: 588 | Train Loss: 0.30999 | Valid Loss: 0.30987 | Time: 0.46 seconds\n",
            "Epoch: 589 | Train Loss: 0.30948 | Valid Loss: 0.30953 | Time: 0.49 seconds\n",
            "Epoch: 590 | Train Loss: 0.30887 | Valid Loss: 0.31177 | Time: 0.45 seconds\n",
            "Epoch: 591 | Train Loss: 0.30843 | Valid Loss: 0.30929 | Time: 0.48 seconds\n",
            "Epoch: 592 | Train Loss: 0.30793 | Valid Loss: 0.30958 | Time: 0.48 seconds\n",
            "Epoch: 593 | Train Loss: 0.30737 | Valid Loss: 0.31020 | Time: 0.45 seconds\n",
            "Epoch: 594 | Train Loss: 0.30693 | Valid Loss: 0.30872 | Time: 0.47 seconds\n",
            "Epoch: 595 | Train Loss: 0.30639 | Valid Loss: 0.30837 | Time: 0.47 seconds\n",
            "Epoch: 596 | Train Loss: 0.30585 | Valid Loss: 0.30621 | Time: 0.48 seconds\n",
            "Epoch: 597 | Train Loss: 0.30536 | Valid Loss: 0.30781 | Time: 0.45 seconds\n",
            "Epoch: 598 | Train Loss: 0.30486 | Valid Loss: 0.30772 | Time: 0.46 seconds\n",
            "Epoch: 599 | Train Loss: 0.30437 | Valid Loss: 0.30545 | Time: 0.46 seconds\n",
            "Epoch: 600 | Train Loss: 0.30388 | Valid Loss: 0.30317 | Time: 0.47 seconds\n",
            "Epoch: 601 | Train Loss: 0.30336 | Valid Loss: 0.30567 | Time: 0.47 seconds\n",
            "Epoch: 602 | Train Loss: 0.30287 | Valid Loss: 0.30472 | Time: 0.46 seconds\n",
            "Epoch: 603 | Train Loss: 0.30236 | Valid Loss: 0.30384 | Time: 0.47 seconds\n",
            "Epoch: 604 | Train Loss: 0.30186 | Valid Loss: 0.30373 | Time: 0.45 seconds\n",
            "Epoch: 605 | Train Loss: 0.30136 | Valid Loss: 0.30251 | Time: 0.48 seconds\n",
            "Epoch: 606 | Train Loss: 0.30089 | Valid Loss: 0.30455 | Time: 0.47 seconds\n",
            "Epoch: 607 | Train Loss: 0.30037 | Valid Loss: 0.30289 | Time: 0.46 seconds\n",
            "Epoch: 608 | Train Loss: 0.29990 | Valid Loss: 0.30062 | Time: 0.46 seconds\n",
            "Epoch: 609 | Train Loss: 0.29938 | Valid Loss: 0.30094 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29889 | Valid Loss: 0.30054 | Time: 0.48 seconds\n",
            "Epoch: 611 | Train Loss: 0.29842 | Valid Loss: 0.29816 | Time: 0.49 seconds\n",
            "Epoch: 612 | Train Loss: 0.29793 | Valid Loss: 0.29804 | Time: 0.48 seconds\n",
            "Epoch: 613 | Train Loss: 0.29746 | Valid Loss: 0.29759 | Time: 0.47 seconds\n",
            "Epoch: 614 | Train Loss: 0.29696 | Valid Loss: 0.29898 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29649 | Valid Loss: 0.29827 | Time: 0.47 seconds\n",
            "Epoch: 616 | Train Loss: 0.29598 | Valid Loss: 0.29774 | Time: 0.48 seconds\n",
            "Epoch: 617 | Train Loss: 0.29547 | Valid Loss: 0.29616 | Time: 0.47 seconds\n",
            "Epoch: 618 | Train Loss: 0.29499 | Valid Loss: 0.29547 | Time: 0.47 seconds\n",
            "Epoch: 619 | Train Loss: 0.29450 | Valid Loss: 0.29689 | Time: 0.46 seconds\n",
            "Epoch: 620 | Train Loss: 0.29403 | Valid Loss: 0.29795 | Time: 0.48 seconds\n",
            "Epoch: 621 | Train Loss: 0.29357 | Valid Loss: 0.29574 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29311 | Valid Loss: 0.29400 | Time: 0.47 seconds\n",
            "Epoch: 623 | Train Loss: 0.29261 | Valid Loss: 0.29438 | Time: 0.46 seconds\n",
            "Epoch: 624 | Train Loss: 0.29218 | Valid Loss: 0.29435 | Time: 0.47 seconds\n",
            "Epoch: 625 | Train Loss: 0.29165 | Valid Loss: 0.29387 | Time: 0.48 seconds\n",
            "Epoch: 626 | Train Loss: 0.29118 | Valid Loss: 0.29489 | Time: 0.49 seconds\n",
            "Epoch: 627 | Train Loss: 0.29071 | Valid Loss: 0.29104 | Time: 0.46 seconds\n",
            "Epoch: 628 | Train Loss: 0.29020 | Valid Loss: 0.29242 | Time: 0.45 seconds\n",
            "Epoch: 629 | Train Loss: 0.28974 | Valid Loss: 0.29133 | Time: 0.47 seconds\n",
            "Epoch: 630 | Train Loss: 0.28928 | Valid Loss: 0.28959 | Time: 0.49 seconds\n",
            "Epoch: 631 | Train Loss: 0.28882 | Valid Loss: 0.28912 | Time: 0.47 seconds\n",
            "Epoch: 632 | Train Loss: 0.28833 | Valid Loss: 0.28928 | Time: 0.47 seconds\n",
            "Epoch: 633 | Train Loss: 0.28787 | Valid Loss: 0.29024 | Time: 0.46 seconds\n",
            "Epoch: 634 | Train Loss: 0.28740 | Valid Loss: 0.28858 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28693 | Valid Loss: 0.28995 | Time: 0.46 seconds\n",
            "Epoch: 636 | Train Loss: 0.28645 | Valid Loss: 0.28922 | Time: 0.46 seconds\n",
            "Epoch: 637 | Train Loss: 0.28599 | Valid Loss: 0.28563 | Time: 0.48 seconds\n",
            "Epoch: 638 | Train Loss: 0.28550 | Valid Loss: 0.28863 | Time: 0.48 seconds\n",
            "Epoch: 639 | Train Loss: 0.28508 | Valid Loss: 0.28430 | Time: 0.50 seconds\n",
            "Epoch: 640 | Train Loss: 0.28459 | Valid Loss: 0.28614 | Time: 0.45 seconds\n",
            "Epoch: 641 | Train Loss: 0.28414 | Valid Loss: 0.28777 | Time: 0.45 seconds\n",
            "Epoch: 642 | Train Loss: 0.28369 | Valid Loss: 0.28446 | Time: 0.48 seconds\n",
            "Epoch: 643 | Train Loss: 0.28322 | Valid Loss: 0.28406 | Time: 0.48 seconds\n",
            "Epoch: 644 | Train Loss: 0.28277 | Valid Loss: 0.28477 | Time: 0.48 seconds\n",
            "Epoch: 645 | Train Loss: 0.28229 | Valid Loss: 0.28167 | Time: 0.48 seconds\n",
            "Epoch: 646 | Train Loss: 0.28190 | Valid Loss: 0.28455 | Time: 0.47 seconds\n",
            "Epoch: 647 | Train Loss: 0.28140 | Valid Loss: 0.28111 | Time: 0.46 seconds\n",
            "Epoch: 648 | Train Loss: 0.28098 | Valid Loss: 0.28132 | Time: 0.46 seconds\n",
            "Epoch: 649 | Train Loss: 0.28048 | Valid Loss: 0.28294 | Time: 0.46 seconds\n",
            "Epoch: 650 | Train Loss: 0.28004 | Valid Loss: 0.27959 | Time: 0.49 seconds\n",
            "Epoch: 651 | Train Loss: 0.27959 | Valid Loss: 0.28102 | Time: 0.46 seconds\n",
            "Epoch: 652 | Train Loss: 0.27915 | Valid Loss: 0.28066 | Time: 0.46 seconds\n",
            "Epoch: 653 | Train Loss: 0.27867 | Valid Loss: 0.28093 | Time: 0.46 seconds\n",
            "Epoch: 654 | Train Loss: 0.27822 | Valid Loss: 0.28005 | Time: 0.46 seconds\n",
            "Epoch: 655 | Train Loss: 0.27778 | Valid Loss: 0.27812 | Time: 0.46 seconds\n",
            "Epoch: 656 | Train Loss: 0.27730 | Valid Loss: 0.27896 | Time: 0.46 seconds\n",
            "Epoch: 657 | Train Loss: 0.27689 | Valid Loss: 0.27964 | Time: 0.47 seconds\n",
            "Epoch: 658 | Train Loss: 0.27640 | Valid Loss: 0.27969 | Time: 0.45 seconds\n",
            "Epoch: 659 | Train Loss: 0.27599 | Valid Loss: 0.27607 | Time: 0.47 seconds\n",
            "Epoch: 660 | Train Loss: 0.27549 | Valid Loss: 0.27814 | Time: 0.45 seconds\n",
            "Epoch: 661 | Train Loss: 0.27510 | Valid Loss: 0.27584 | Time: 0.48 seconds\n",
            "Epoch: 662 | Train Loss: 0.27464 | Valid Loss: 0.27675 | Time: 0.45 seconds\n",
            "Epoch: 663 | Train Loss: 0.27419 | Valid Loss: 0.27587 | Time: 0.47 seconds\n",
            "Epoch: 664 | Train Loss: 0.27378 | Valid Loss: 0.27624 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27329 | Valid Loss: 0.27425 | Time: 0.47 seconds\n",
            "Epoch: 666 | Train Loss: 0.27285 | Valid Loss: 0.27614 | Time: 0.47 seconds\n",
            "Epoch: 667 | Train Loss: 0.27248 | Valid Loss: 0.27457 | Time: 0.48 seconds\n",
            "Epoch: 668 | Train Loss: 0.27201 | Valid Loss: 0.27311 | Time: 0.47 seconds\n",
            "Epoch: 669 | Train Loss: 0.27156 | Valid Loss: 0.27294 | Time: 0.46 seconds\n",
            "Epoch: 670 | Train Loss: 0.27114 | Valid Loss: 0.27199 | Time: 0.48 seconds\n",
            "Epoch: 671 | Train Loss: 0.27071 | Valid Loss: 0.27160 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27024 | Valid Loss: 0.27299 | Time: 0.47 seconds\n",
            "Epoch: 673 | Train Loss: 0.26985 | Valid Loss: 0.27312 | Time: 0.48 seconds\n",
            "Epoch: 674 | Train Loss: 0.26941 | Valid Loss: 0.27156 | Time: 0.47 seconds\n",
            "Epoch: 675 | Train Loss: 0.26898 | Valid Loss: 0.27029 | Time: 0.46 seconds\n",
            "Epoch: 676 | Train Loss: 0.26857 | Valid Loss: 0.26990 | Time: 0.47 seconds\n",
            "Epoch: 677 | Train Loss: 0.26808 | Valid Loss: 0.27049 | Time: 0.45 seconds\n",
            "Epoch: 678 | Train Loss: 0.26765 | Valid Loss: 0.26991 | Time: 0.48 seconds\n",
            "Epoch: 679 | Train Loss: 0.26724 | Valid Loss: 0.26958 | Time: 0.47 seconds\n",
            "Epoch: 680 | Train Loss: 0.26681 | Valid Loss: 0.26761 | Time: 0.47 seconds\n",
            "Epoch: 681 | Train Loss: 0.26640 | Valid Loss: 0.26808 | Time: 0.47 seconds\n",
            "Epoch: 682 | Train Loss: 0.26597 | Valid Loss: 0.26806 | Time: 0.45 seconds\n",
            "Epoch: 683 | Train Loss: 0.26552 | Valid Loss: 0.26776 | Time: 0.47 seconds\n",
            "Epoch: 684 | Train Loss: 0.26507 | Valid Loss: 0.26747 | Time: 0.47 seconds\n",
            "Epoch: 685 | Train Loss: 0.26466 | Valid Loss: 0.26561 | Time: 0.47 seconds\n",
            "Epoch: 686 | Train Loss: 0.26424 | Valid Loss: 0.26690 | Time: 0.47 seconds\n",
            "Epoch: 687 | Train Loss: 0.26382 | Valid Loss: 0.26496 | Time: 0.47 seconds\n",
            "Epoch: 688 | Train Loss: 0.26341 | Valid Loss: 0.26585 | Time: 0.45 seconds\n",
            "Epoch: 689 | Train Loss: 0.26296 | Valid Loss: 0.26382 | Time: 0.48 seconds\n",
            "Epoch: 690 | Train Loss: 0.26253 | Valid Loss: 0.26416 | Time: 0.45 seconds\n",
            "Epoch: 691 | Train Loss: 0.26213 | Valid Loss: 0.26385 | Time: 0.47 seconds\n",
            "Epoch: 692 | Train Loss: 0.26174 | Valid Loss: 0.26410 | Time: 0.46 seconds\n",
            "Epoch: 693 | Train Loss: 0.26126 | Valid Loss: 0.26481 | Time: 0.49 seconds\n",
            "Epoch: 694 | Train Loss: 0.26090 | Valid Loss: 0.26198 | Time: 0.50 seconds\n",
            "Epoch: 695 | Train Loss: 0.26045 | Valid Loss: 0.26086 | Time: 0.46 seconds\n",
            "Epoch: 696 | Train Loss: 0.26007 | Valid Loss: 0.26066 | Time: 0.48 seconds\n",
            "Epoch: 697 | Train Loss: 0.25963 | Valid Loss: 0.26029 | Time: 0.46 seconds\n",
            "Epoch: 698 | Train Loss: 0.25921 | Valid Loss: 0.26096 | Time: 0.46 seconds\n",
            "Epoch: 699 | Train Loss: 0.25879 | Valid Loss: 0.25920 | Time: 0.46 seconds\n",
            "Epoch: 700 | Train Loss: 0.25837 | Valid Loss: 0.25952 | Time: 0.48 seconds\n",
            "Epoch: 701 | Train Loss: 0.25793 | Valid Loss: 0.26050 | Time: 0.45 seconds\n",
            "Epoch: 702 | Train Loss: 0.25757 | Valid Loss: 0.25862 | Time: 0.47 seconds\n",
            "Epoch: 703 | Train Loss: 0.25714 | Valid Loss: 0.26056 | Time: 0.45 seconds\n",
            "Epoch: 704 | Train Loss: 0.25676 | Valid Loss: 0.25803 | Time: 0.47 seconds\n",
            "Epoch: 705 | Train Loss: 0.25630 | Valid Loss: 0.25803 | Time: 0.46 seconds\n",
            "Epoch: 706 | Train Loss: 0.25587 | Valid Loss: 0.25597 | Time: 0.47 seconds\n",
            "Epoch: 707 | Train Loss: 0.25549 | Valid Loss: 0.25841 | Time: 0.49 seconds\n",
            "Epoch: 708 | Train Loss: 0.25510 | Valid Loss: 0.25595 | Time: 0.48 seconds\n",
            "Epoch: 709 | Train Loss: 0.25468 | Valid Loss: 0.25593 | Time: 0.46 seconds\n",
            "Epoch: 710 | Train Loss: 0.25429 | Valid Loss: 0.25625 | Time: 0.46 seconds\n",
            "Epoch: 711 | Train Loss: 0.25386 | Valid Loss: 0.25551 | Time: 0.47 seconds\n",
            "Epoch: 712 | Train Loss: 0.25345 | Valid Loss: 0.25580 | Time: 0.47 seconds\n",
            "Epoch: 713 | Train Loss: 0.25305 | Valid Loss: 0.25407 | Time: 0.48 seconds\n",
            "Epoch: 714 | Train Loss: 0.25266 | Valid Loss: 0.25597 | Time: 0.48 seconds\n",
            "Epoch: 715 | Train Loss: 0.25222 | Valid Loss: 0.25461 | Time: 0.47 seconds\n",
            "Epoch: 716 | Train Loss: 0.25187 | Valid Loss: 0.25236 | Time: 0.47 seconds\n",
            "Epoch: 717 | Train Loss: 0.25147 | Valid Loss: 0.25199 | Time: 0.47 seconds\n",
            "Epoch: 718 | Train Loss: 0.25102 | Valid Loss: 0.25197 | Time: 0.48 seconds\n",
            "Epoch: 719 | Train Loss: 0.25063 | Valid Loss: 0.25265 | Time: 0.46 seconds\n",
            "Epoch: 720 | Train Loss: 0.25026 | Valid Loss: 0.25231 | Time: 0.47 seconds\n",
            "Epoch: 721 | Train Loss: 0.24981 | Valid Loss: 0.25259 | Time: 0.46 seconds\n",
            "Epoch: 722 | Train Loss: 0.24947 | Valid Loss: 0.25039 | Time: 0.50 seconds\n",
            "Epoch: 723 | Train Loss: 0.24902 | Valid Loss: 0.25096 | Time: 0.46 seconds\n",
            "Epoch: 724 | Train Loss: 0.24861 | Valid Loss: 0.24945 | Time: 0.47 seconds\n",
            "Epoch: 725 | Train Loss: 0.24823 | Valid Loss: 0.24838 | Time: 0.48 seconds\n",
            "Epoch: 726 | Train Loss: 0.24786 | Valid Loss: 0.24904 | Time: 0.48 seconds\n",
            "Epoch: 727 | Train Loss: 0.24747 | Valid Loss: 0.24814 | Time: 0.47 seconds\n",
            "Epoch: 728 | Train Loss: 0.24711 | Valid Loss: 0.24904 | Time: 0.46 seconds\n",
            "Epoch: 729 | Train Loss: 0.24667 | Valid Loss: 0.24767 | Time: 0.46 seconds\n",
            "Epoch: 730 | Train Loss: 0.24626 | Valid Loss: 0.24698 | Time: 0.49 seconds\n",
            "Epoch: 731 | Train Loss: 0.24586 | Valid Loss: 0.24714 | Time: 0.48 seconds\n",
            "Epoch: 732 | Train Loss: 0.24551 | Valid Loss: 0.24798 | Time: 0.46 seconds\n",
            "Epoch: 733 | Train Loss: 0.24507 | Valid Loss: 0.24651 | Time: 0.47 seconds\n",
            "Epoch: 734 | Train Loss: 0.24469 | Valid Loss: 0.24463 | Time: 0.47 seconds\n",
            "Epoch: 735 | Train Loss: 0.24435 | Valid Loss: 0.24580 | Time: 0.48 seconds\n",
            "Epoch: 736 | Train Loss: 0.24393 | Valid Loss: 0.24596 | Time: 0.47 seconds\n",
            "Epoch: 737 | Train Loss: 0.24353 | Valid Loss: 0.24511 | Time: 0.46 seconds\n",
            "Epoch: 738 | Train Loss: 0.24316 | Valid Loss: 0.24284 | Time: 0.46 seconds\n",
            "Epoch: 739 | Train Loss: 0.24278 | Valid Loss: 0.24491 | Time: 0.46 seconds\n",
            "Epoch: 740 | Train Loss: 0.24235 | Valid Loss: 0.24395 | Time: 0.45 seconds\n",
            "Epoch: 741 | Train Loss: 0.24200 | Valid Loss: 0.24539 | Time: 0.46 seconds\n",
            "Epoch: 742 | Train Loss: 0.24165 | Valid Loss: 0.24391 | Time: 0.45 seconds\n",
            "Epoch: 743 | Train Loss: 0.24121 | Valid Loss: 0.24135 | Time: 0.47 seconds\n",
            "Epoch: 744 | Train Loss: 0.24084 | Valid Loss: 0.24180 | Time: 0.45 seconds\n",
            "Epoch: 745 | Train Loss: 0.24048 | Valid Loss: 0.24357 | Time: 0.45 seconds\n",
            "Epoch: 746 | Train Loss: 0.24006 | Valid Loss: 0.24139 | Time: 0.48 seconds\n",
            "Epoch: 747 | Train Loss: 0.23975 | Valid Loss: 0.24119 | Time: 0.45 seconds\n",
            "Epoch: 748 | Train Loss: 0.23929 | Valid Loss: 0.24237 | Time: 0.46 seconds\n",
            "Epoch: 749 | Train Loss: 0.23896 | Valid Loss: 0.24036 | Time: 0.48 seconds\n",
            "Epoch: 750 | Train Loss: 0.23856 | Valid Loss: 0.24061 | Time: 0.47 seconds\n",
            "Epoch: 751 | Train Loss: 0.23815 | Valid Loss: 0.23973 | Time: 0.47 seconds\n",
            "Epoch: 752 | Train Loss: 0.23778 | Valid Loss: 0.23846 | Time: 0.48 seconds\n",
            "Epoch: 753 | Train Loss: 0.23742 | Valid Loss: 0.23945 | Time: 0.45 seconds\n",
            "Epoch: 754 | Train Loss: 0.23703 | Valid Loss: 0.23802 | Time: 0.47 seconds\n",
            "Epoch: 755 | Train Loss: 0.23666 | Valid Loss: 0.23737 | Time: 0.47 seconds\n",
            "Epoch: 756 | Train Loss: 0.23626 | Valid Loss: 0.23777 | Time: 0.46 seconds\n",
            "Epoch: 757 | Train Loss: 0.23591 | Valid Loss: 0.23710 | Time: 0.48 seconds\n",
            "Epoch: 758 | Train Loss: 0.23551 | Valid Loss: 0.23762 | Time: 0.46 seconds\n",
            "Epoch: 759 | Train Loss: 0.23516 | Valid Loss: 0.23664 | Time: 0.47 seconds\n",
            "Epoch: 760 | Train Loss: 0.23479 | Valid Loss: 0.23654 | Time: 0.46 seconds\n",
            "Epoch: 761 | Train Loss: 0.23442 | Valid Loss: 0.23747 | Time: 0.46 seconds\n",
            "Epoch: 762 | Train Loss: 0.23404 | Valid Loss: 0.23504 | Time: 0.46 seconds\n",
            "Epoch: 763 | Train Loss: 0.23368 | Valid Loss: 0.23368 | Time: 0.50 seconds\n",
            "Epoch: 764 | Train Loss: 0.23329 | Valid Loss: 0.23546 | Time: 0.45 seconds\n",
            "Epoch: 765 | Train Loss: 0.23291 | Valid Loss: 0.23423 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23253 | Valid Loss: 0.23402 | Time: 0.46 seconds\n",
            "Epoch: 767 | Train Loss: 0.23218 | Valid Loss: 0.23477 | Time: 0.48 seconds\n",
            "Epoch: 768 | Train Loss: 0.23180 | Valid Loss: 0.23152 | Time: 0.47 seconds\n",
            "Epoch: 769 | Train Loss: 0.23141 | Valid Loss: 0.23348 | Time: 0.47 seconds\n",
            "Epoch: 770 | Train Loss: 0.23109 | Valid Loss: 0.23360 | Time: 0.47 seconds\n",
            "Epoch: 771 | Train Loss: 0.23068 | Valid Loss: 0.23310 | Time: 0.46 seconds\n",
            "Epoch: 772 | Train Loss: 0.23034 | Valid Loss: 0.23201 | Time: 0.48 seconds\n",
            "Epoch: 773 | Train Loss: 0.22994 | Valid Loss: 0.23122 | Time: 0.47 seconds\n",
            "Epoch: 774 | Train Loss: 0.22961 | Valid Loss: 0.23075 | Time: 0.49 seconds\n",
            "Epoch: 775 | Train Loss: 0.22927 | Valid Loss: 0.23219 | Time: 0.46 seconds\n",
            "Epoch: 776 | Train Loss: 0.22889 | Valid Loss: 0.23027 | Time: 0.48 seconds\n",
            "Epoch: 777 | Train Loss: 0.22851 | Valid Loss: 0.23109 | Time: 0.45 seconds\n",
            "Epoch: 778 | Train Loss: 0.22815 | Valid Loss: 0.23063 | Time: 0.47 seconds\n",
            "Epoch: 779 | Train Loss: 0.22780 | Valid Loss: 0.22882 | Time: 0.47 seconds\n",
            "Epoch: 780 | Train Loss: 0.22743 | Valid Loss: 0.22995 | Time: 0.47 seconds\n",
            "Epoch: 781 | Train Loss: 0.22707 | Valid Loss: 0.22758 | Time: 0.46 seconds\n",
            "Epoch: 782 | Train Loss: 0.22669 | Valid Loss: 0.22931 | Time: 0.46 seconds\n",
            "Epoch: 783 | Train Loss: 0.22632 | Valid Loss: 0.22857 | Time: 0.49 seconds\n",
            "Epoch: 784 | Train Loss: 0.22600 | Valid Loss: 0.22740 | Time: 0.48 seconds\n",
            "Epoch: 785 | Train Loss: 0.22562 | Valid Loss: 0.22754 | Time: 0.47 seconds\n",
            "Epoch: 786 | Train Loss: 0.22529 | Valid Loss: 0.22615 | Time: 0.46 seconds\n",
            "Epoch: 787 | Train Loss: 0.22490 | Valid Loss: 0.22570 | Time: 0.48 seconds\n",
            "Epoch: 788 | Train Loss: 0.22455 | Valid Loss: 0.22703 | Time: 0.46 seconds\n",
            "Epoch: 789 | Train Loss: 0.22418 | Valid Loss: 0.22389 | Time: 0.49 seconds\n",
            "Epoch: 790 | Train Loss: 0.22382 | Valid Loss: 0.22564 | Time: 0.47 seconds\n",
            "Epoch: 791 | Train Loss: 0.22351 | Valid Loss: 0.22548 | Time: 0.48 seconds\n",
            "Epoch: 792 | Train Loss: 0.22315 | Valid Loss: 0.22401 | Time: 0.45 seconds\n",
            "Epoch: 793 | Train Loss: 0.22278 | Valid Loss: 0.22507 | Time: 0.48 seconds\n",
            "Epoch: 794 | Train Loss: 0.22238 | Valid Loss: 0.22399 | Time: 0.46 seconds\n",
            "Epoch: 795 | Train Loss: 0.22209 | Valid Loss: 0.22245 | Time: 0.48 seconds\n",
            "Epoch: 796 | Train Loss: 0.22169 | Valid Loss: 0.22444 | Time: 0.46 seconds\n",
            "Epoch: 797 | Train Loss: 0.22138 | Valid Loss: 0.22441 | Time: 0.46 seconds\n",
            "Epoch: 798 | Train Loss: 0.22100 | Valid Loss: 0.22315 | Time: 0.46 seconds\n",
            "Epoch: 799 | Train Loss: 0.22066 | Valid Loss: 0.22146 | Time: 0.46 seconds\n",
            "Epoch: 800 | Train Loss: 0.22028 | Valid Loss: 0.22250 | Time: 0.47 seconds\n",
            "Epoch: 801 | Train Loss: 0.21995 | Valid Loss: 0.22114 | Time: 0.47 seconds\n",
            "Epoch: 802 | Train Loss: 0.21964 | Valid Loss: 0.22117 | Time: 0.48 seconds\n",
            "Epoch: 803 | Train Loss: 0.21929 | Valid Loss: 0.22136 | Time: 0.48 seconds\n",
            "Epoch: 804 | Train Loss: 0.21891 | Valid Loss: 0.22021 | Time: 0.47 seconds\n",
            "Epoch: 805 | Train Loss: 0.21859 | Valid Loss: 0.21986 | Time: 0.46 seconds\n",
            "Epoch: 806 | Train Loss: 0.21825 | Valid Loss: 0.21905 | Time: 0.47 seconds\n",
            "Epoch: 807 | Train Loss: 0.21786 | Valid Loss: 0.21923 | Time: 0.45 seconds\n",
            "Epoch: 808 | Train Loss: 0.21754 | Valid Loss: 0.21919 | Time: 0.45 seconds\n",
            "Epoch: 809 | Train Loss: 0.21719 | Valid Loss: 0.21850 | Time: 0.48 seconds\n",
            "Epoch: 810 | Train Loss: 0.21684 | Valid Loss: 0.21938 | Time: 0.45 seconds\n",
            "Epoch: 811 | Train Loss: 0.21646 | Valid Loss: 0.21801 | Time: 0.46 seconds\n",
            "Epoch: 812 | Train Loss: 0.21616 | Valid Loss: 0.21827 | Time: 0.45 seconds\n",
            "Epoch: 813 | Train Loss: 0.21585 | Valid Loss: 0.21829 | Time: 0.46 seconds\n",
            "Epoch: 814 | Train Loss: 0.21550 | Valid Loss: 0.21611 | Time: 0.46 seconds\n",
            "Epoch: 815 | Train Loss: 0.21517 | Valid Loss: 0.21545 | Time: 0.48 seconds\n",
            "Epoch: 816 | Train Loss: 0.21481 | Valid Loss: 0.21618 | Time: 0.45 seconds\n",
            "Epoch: 817 | Train Loss: 0.21446 | Valid Loss: 0.21612 | Time: 0.46 seconds\n",
            "Epoch: 818 | Train Loss: 0.21415 | Valid Loss: 0.21535 | Time: 0.47 seconds\n",
            "Epoch: 819 | Train Loss: 0.21376 | Valid Loss: 0.21526 | Time: 0.45 seconds\n",
            "Epoch: 820 | Train Loss: 0.21343 | Valid Loss: 0.21497 | Time: 0.50 seconds\n",
            "Epoch: 821 | Train Loss: 0.21310 | Valid Loss: 0.21401 | Time: 0.47 seconds\n",
            "Epoch: 822 | Train Loss: 0.21276 | Valid Loss: 0.21434 | Time: 0.46 seconds\n",
            "Epoch: 823 | Train Loss: 0.21244 | Valid Loss: 0.21447 | Time: 0.45 seconds\n",
            "Epoch: 824 | Train Loss: 0.21210 | Valid Loss: 0.21530 | Time: 0.46 seconds\n",
            "Epoch: 825 | Train Loss: 0.21174 | Valid Loss: 0.21381 | Time: 0.45 seconds\n",
            "Epoch: 826 | Train Loss: 0.21143 | Valid Loss: 0.21330 | Time: 0.47 seconds\n",
            "Epoch: 827 | Train Loss: 0.21108 | Valid Loss: 0.21367 | Time: 0.45 seconds\n",
            "Epoch: 828 | Train Loss: 0.21072 | Valid Loss: 0.21236 | Time: 0.46 seconds\n",
            "Epoch: 829 | Train Loss: 0.21040 | Valid Loss: 0.21323 | Time: 0.46 seconds\n",
            "Epoch: 830 | Train Loss: 0.21010 | Valid Loss: 0.21069 | Time: 0.48 seconds\n",
            "Epoch: 831 | Train Loss: 0.20975 | Valid Loss: 0.21233 | Time: 0.47 seconds\n",
            "Epoch: 832 | Train Loss: 0.20942 | Valid Loss: 0.21145 | Time: 0.45 seconds\n",
            "Epoch: 833 | Train Loss: 0.20906 | Valid Loss: 0.21199 | Time: 0.46 seconds\n",
            "Epoch: 834 | Train Loss: 0.20875 | Valid Loss: 0.21010 | Time: 0.46 seconds\n",
            "Epoch: 835 | Train Loss: 0.20842 | Valid Loss: 0.21005 | Time: 0.47 seconds\n",
            "Epoch: 836 | Train Loss: 0.20810 | Valid Loss: 0.20989 | Time: 0.45 seconds\n",
            "Epoch: 837 | Train Loss: 0.20781 | Valid Loss: 0.20936 | Time: 0.47 seconds\n",
            "Epoch: 838 | Train Loss: 0.20745 | Valid Loss: 0.20956 | Time: 0.47 seconds\n",
            "Epoch: 839 | Train Loss: 0.20709 | Valid Loss: 0.20949 | Time: 0.46 seconds\n",
            "Epoch: 840 | Train Loss: 0.20678 | Valid Loss: 0.20765 | Time: 0.45 seconds\n",
            "Epoch: 841 | Train Loss: 0.20646 | Valid Loss: 0.20816 | Time: 0.45 seconds\n",
            "Epoch: 842 | Train Loss: 0.20612 | Valid Loss: 0.20777 | Time: 0.46 seconds\n",
            "Epoch: 843 | Train Loss: 0.20578 | Valid Loss: 0.20826 | Time: 0.45 seconds\n",
            "Epoch: 844 | Train Loss: 0.20548 | Valid Loss: 0.20664 | Time: 0.47 seconds\n",
            "Epoch: 845 | Train Loss: 0.20516 | Valid Loss: 0.20717 | Time: 0.46 seconds\n",
            "Epoch: 846 | Train Loss: 0.20486 | Valid Loss: 0.20535 | Time: 0.47 seconds\n",
            "Epoch: 847 | Train Loss: 0.20450 | Valid Loss: 0.20523 | Time: 0.45 seconds\n",
            "Epoch: 848 | Train Loss: 0.20419 | Valid Loss: 0.20531 | Time: 0.48 seconds\n",
            "Epoch: 849 | Train Loss: 0.20387 | Valid Loss: 0.20534 | Time: 0.45 seconds\n",
            "Epoch: 850 | Train Loss: 0.20352 | Valid Loss: 0.20651 | Time: 0.45 seconds\n",
            "Epoch: 851 | Train Loss: 0.20323 | Valid Loss: 0.20692 | Time: 0.49 seconds\n",
            "Epoch: 852 | Train Loss: 0.20289 | Valid Loss: 0.20489 | Time: 0.47 seconds\n",
            "Epoch: 853 | Train Loss: 0.20254 | Valid Loss: 0.20280 | Time: 0.47 seconds\n",
            "Epoch: 854 | Train Loss: 0.20225 | Valid Loss: 0.20393 | Time: 0.46 seconds\n",
            "Epoch: 855 | Train Loss: 0.20192 | Valid Loss: 0.20269 | Time: 0.48 seconds\n",
            "Epoch: 856 | Train Loss: 0.20159 | Valid Loss: 0.20258 | Time: 0.47 seconds\n",
            "Epoch: 857 | Train Loss: 0.20128 | Valid Loss: 0.20396 | Time: 0.46 seconds\n",
            "Epoch: 858 | Train Loss: 0.20095 | Valid Loss: 0.20207 | Time: 0.46 seconds\n",
            "Epoch: 859 | Train Loss: 0.20068 | Valid Loss: 0.20109 | Time: 0.47 seconds\n",
            "Epoch: 860 | Train Loss: 0.20038 | Valid Loss: 0.20211 | Time: 0.47 seconds\n",
            "Epoch: 861 | Train Loss: 0.20004 | Valid Loss: 0.20294 | Time: 0.47 seconds\n",
            "Epoch: 862 | Train Loss: 0.19971 | Valid Loss: 0.20087 | Time: 0.45 seconds\n",
            "Epoch: 863 | Train Loss: 0.19940 | Valid Loss: 0.20087 | Time: 0.46 seconds\n",
            "Epoch: 864 | Train Loss: 0.19905 | Valid Loss: 0.20089 | Time: 0.48 seconds\n",
            "Epoch: 865 | Train Loss: 0.19879 | Valid Loss: 0.19953 | Time: 0.48 seconds\n",
            "Epoch: 866 | Train Loss: 0.19851 | Valid Loss: 0.20036 | Time: 0.45 seconds\n",
            "Epoch: 867 | Train Loss: 0.19811 | Valid Loss: 0.19778 | Time: 0.45 seconds\n",
            "Epoch: 868 | Train Loss: 0.19782 | Valid Loss: 0.19999 | Time: 0.46 seconds\n",
            "Epoch: 869 | Train Loss: 0.19752 | Valid Loss: 0.19782 | Time: 0.45 seconds\n",
            "Epoch: 870 | Train Loss: 0.19723 | Valid Loss: 0.19863 | Time: 0.46 seconds\n",
            "Epoch: 871 | Train Loss: 0.19688 | Valid Loss: 0.19838 | Time: 0.46 seconds\n",
            "Epoch: 872 | Train Loss: 0.19658 | Valid Loss: 0.19841 | Time: 0.46 seconds\n",
            "Epoch: 873 | Train Loss: 0.19624 | Valid Loss: 0.19834 | Time: 0.45 seconds\n",
            "Epoch: 874 | Train Loss: 0.19592 | Valid Loss: 0.19786 | Time: 0.46 seconds\n",
            "Epoch: 875 | Train Loss: 0.19564 | Valid Loss: 0.19828 | Time: 0.47 seconds\n",
            "Epoch: 876 | Train Loss: 0.19532 | Valid Loss: 0.19752 | Time: 0.46 seconds\n",
            "Epoch: 877 | Train Loss: 0.19499 | Valid Loss: 0.19640 | Time: 0.47 seconds\n",
            "Epoch: 878 | Train Loss: 0.19472 | Valid Loss: 0.19665 | Time: 0.45 seconds\n",
            "Epoch: 879 | Train Loss: 0.19442 | Valid Loss: 0.19578 | Time: 0.47 seconds\n",
            "Epoch: 880 | Train Loss: 0.19409 | Valid Loss: 0.19515 | Time: 0.47 seconds\n",
            "Epoch: 881 | Train Loss: 0.19379 | Valid Loss: 0.19373 | Time: 0.46 seconds\n",
            "Epoch: 882 | Train Loss: 0.19350 | Valid Loss: 0.19511 | Time: 0.45 seconds\n",
            "Epoch: 883 | Train Loss: 0.19320 | Valid Loss: 0.19401 | Time: 0.45 seconds\n",
            "Epoch: 884 | Train Loss: 0.19288 | Valid Loss: 0.19264 | Time: 0.45 seconds\n",
            "Epoch: 885 | Train Loss: 0.19259 | Valid Loss: 0.19607 | Time: 0.45 seconds\n",
            "Epoch: 886 | Train Loss: 0.19227 | Valid Loss: 0.19414 | Time: 0.46 seconds\n",
            "Epoch: 887 | Train Loss: 0.19197 | Valid Loss: 0.19179 | Time: 0.47 seconds\n",
            "Epoch: 888 | Train Loss: 0.19169 | Valid Loss: 0.19414 | Time: 0.46 seconds\n",
            "Epoch: 889 | Train Loss: 0.19138 | Valid Loss: 0.19365 | Time: 0.45 seconds\n",
            "Epoch: 890 | Train Loss: 0.19105 | Valid Loss: 0.19320 | Time: 0.47 seconds\n",
            "Epoch: 891 | Train Loss: 0.19075 | Valid Loss: 0.19136 | Time: 0.46 seconds\n",
            "Epoch: 892 | Train Loss: 0.19047 | Valid Loss: 0.19201 | Time: 0.47 seconds\n",
            "Epoch: 893 | Train Loss: 0.19021 | Valid Loss: 0.19265 | Time: 0.46 seconds\n",
            "Epoch: 894 | Train Loss: 0.18984 | Valid Loss: 0.19142 | Time: 0.46 seconds\n",
            "Epoch: 895 | Train Loss: 0.18958 | Valid Loss: 0.19039 | Time: 0.46 seconds\n",
            "Epoch: 896 | Train Loss: 0.18927 | Valid Loss: 0.19135 | Time: 0.45 seconds\n",
            "Epoch: 897 | Train Loss: 0.18895 | Valid Loss: 0.19014 | Time: 0.47 seconds\n",
            "Epoch: 898 | Train Loss: 0.18868 | Valid Loss: 0.19015 | Time: 0.46 seconds\n",
            "Epoch: 899 | Train Loss: 0.18839 | Valid Loss: 0.19050 | Time: 0.46 seconds\n",
            "Epoch: 900 | Train Loss: 0.18809 | Valid Loss: 0.19026 | Time: 0.46 seconds\n",
            "Epoch: 901 | Train Loss: 0.18777 | Valid Loss: 0.18903 | Time: 0.50 seconds\n",
            "Epoch: 902 | Train Loss: 0.18748 | Valid Loss: 0.18875 | Time: 0.48 seconds\n",
            "Epoch: 903 | Train Loss: 0.18718 | Valid Loss: 0.18876 | Time: 0.46 seconds\n",
            "Epoch: 904 | Train Loss: 0.18688 | Valid Loss: 0.19008 | Time: 0.45 seconds\n",
            "Epoch: 905 | Train Loss: 0.18662 | Valid Loss: 0.18789 | Time: 0.47 seconds\n",
            "Epoch: 906 | Train Loss: 0.18632 | Valid Loss: 0.18697 | Time: 0.46 seconds\n",
            "Epoch: 907 | Train Loss: 0.18603 | Valid Loss: 0.18793 | Time: 0.46 seconds\n",
            "Epoch: 908 | Train Loss: 0.18573 | Valid Loss: 0.18774 | Time: 0.46 seconds\n",
            "Epoch: 909 | Train Loss: 0.18543 | Valid Loss: 0.18793 | Time: 0.45 seconds\n",
            "Epoch: 910 | Train Loss: 0.18515 | Valid Loss: 0.18628 | Time: 0.48 seconds\n",
            "Epoch: 911 | Train Loss: 0.18486 | Valid Loss: 0.18762 | Time: 0.46 seconds\n",
            "Epoch: 912 | Train Loss: 0.18456 | Valid Loss: 0.18599 | Time: 0.47 seconds\n",
            "Epoch: 913 | Train Loss: 0.18429 | Valid Loss: 0.18567 | Time: 0.47 seconds\n",
            "Epoch: 914 | Train Loss: 0.18402 | Valid Loss: 0.18597 | Time: 0.46 seconds\n",
            "Epoch: 915 | Train Loss: 0.18370 | Valid Loss: 0.18365 | Time: 0.46 seconds\n",
            "Epoch: 916 | Train Loss: 0.18340 | Valid Loss: 0.18416 | Time: 0.44 seconds\n",
            "Epoch: 917 | Train Loss: 0.18309 | Valid Loss: 0.18475 | Time: 0.46 seconds\n",
            "Epoch: 918 | Train Loss: 0.18284 | Valid Loss: 0.18407 | Time: 0.45 seconds\n",
            "Epoch: 919 | Train Loss: 0.18255 | Valid Loss: 0.18346 | Time: 0.47 seconds\n",
            "Epoch: 920 | Train Loss: 0.18225 | Valid Loss: 0.18254 | Time: 0.46 seconds\n",
            "Epoch: 921 | Train Loss: 0.18195 | Valid Loss: 0.18491 | Time: 0.47 seconds\n",
            "Epoch: 922 | Train Loss: 0.18168 | Valid Loss: 0.18343 | Time: 0.46 seconds\n",
            "Epoch: 923 | Train Loss: 0.18141 | Valid Loss: 0.18346 | Time: 0.46 seconds\n",
            "Epoch: 924 | Train Loss: 0.18112 | Valid Loss: 0.18309 | Time: 0.45 seconds\n",
            "Epoch: 925 | Train Loss: 0.18083 | Valid Loss: 0.18167 | Time: 0.48 seconds\n",
            "Epoch: 926 | Train Loss: 0.18058 | Valid Loss: 0.18205 | Time: 0.47 seconds\n",
            "Epoch: 927 | Train Loss: 0.18024 | Valid Loss: 0.18215 | Time: 0.45 seconds\n",
            "Epoch: 928 | Train Loss: 0.17994 | Valid Loss: 0.18145 | Time: 0.46 seconds\n",
            "Epoch: 929 | Train Loss: 0.17973 | Valid Loss: 0.18177 | Time: 0.45 seconds\n",
            "Epoch: 930 | Train Loss: 0.17942 | Valid Loss: 0.18011 | Time: 0.47 seconds\n",
            "Epoch: 931 | Train Loss: 0.17912 | Valid Loss: 0.17972 | Time: 0.45 seconds\n",
            "Epoch: 932 | Train Loss: 0.17885 | Valid Loss: 0.18035 | Time: 0.46 seconds\n",
            "Epoch: 933 | Train Loss: 0.17858 | Valid Loss: 0.18037 | Time: 0.45 seconds\n",
            "Epoch: 934 | Train Loss: 0.17828 | Valid Loss: 0.18003 | Time: 0.46 seconds\n",
            "Epoch: 935 | Train Loss: 0.17803 | Valid Loss: 0.18002 | Time: 0.46 seconds\n",
            "Epoch: 936 | Train Loss: 0.17775 | Valid Loss: 0.17866 | Time: 0.47 seconds\n",
            "Epoch: 937 | Train Loss: 0.17746 | Valid Loss: 0.17871 | Time: 0.47 seconds\n",
            "Epoch: 938 | Train Loss: 0.17717 | Valid Loss: 0.17819 | Time: 0.45 seconds\n",
            "Epoch: 939 | Train Loss: 0.17692 | Valid Loss: 0.17851 | Time: 0.48 seconds\n",
            "Epoch: 940 | Train Loss: 0.17665 | Valid Loss: 0.17857 | Time: 0.45 seconds\n",
            "Epoch: 941 | Train Loss: 0.17635 | Valid Loss: 0.17764 | Time: 0.46 seconds\n",
            "Epoch: 942 | Train Loss: 0.17605 | Valid Loss: 0.17726 | Time: 0.46 seconds\n",
            "Epoch: 943 | Train Loss: 0.17575 | Valid Loss: 0.17661 | Time: 0.46 seconds\n",
            "Epoch: 944 | Train Loss: 0.17553 | Valid Loss: 0.17678 | Time: 0.45 seconds\n",
            "Epoch: 945 | Train Loss: 0.17522 | Valid Loss: 0.17686 | Time: 0.46 seconds\n",
            "Epoch: 946 | Train Loss: 0.17499 | Valid Loss: 0.17741 | Time: 0.45 seconds\n",
            "Epoch: 947 | Train Loss: 0.17465 | Valid Loss: 0.17668 | Time: 0.45 seconds\n",
            "Epoch: 948 | Train Loss: 0.17441 | Valid Loss: 0.17610 | Time: 0.47 seconds\n",
            "Epoch: 949 | Train Loss: 0.17414 | Valid Loss: 0.17483 | Time: 0.46 seconds\n",
            "Epoch: 950 | Train Loss: 0.17388 | Valid Loss: 0.17494 | Time: 0.46 seconds\n",
            "Epoch: 951 | Train Loss: 0.17362 | Valid Loss: 0.17454 | Time: 0.47 seconds\n",
            "Epoch: 952 | Train Loss: 0.17331 | Valid Loss: 0.17472 | Time: 0.46 seconds\n",
            "Epoch: 953 | Train Loss: 0.17308 | Valid Loss: 0.17426 | Time: 0.48 seconds\n",
            "Epoch: 954 | Train Loss: 0.17279 | Valid Loss: 0.17420 | Time: 0.49 seconds\n",
            "Epoch: 955 | Train Loss: 0.17252 | Valid Loss: 0.17341 | Time: 0.47 seconds\n",
            "Epoch: 956 | Train Loss: 0.17223 | Valid Loss: 0.17350 | Time: 0.46 seconds\n",
            "Epoch: 957 | Train Loss: 0.17198 | Valid Loss: 0.17291 | Time: 0.48 seconds\n",
            "Epoch: 958 | Train Loss: 0.17167 | Valid Loss: 0.17259 | Time: 0.49 seconds\n",
            "Epoch: 959 | Train Loss: 0.17146 | Valid Loss: 0.17270 | Time: 0.45 seconds\n",
            "Epoch: 960 | Train Loss: 0.17117 | Valid Loss: 0.17248 | Time: 0.45 seconds\n",
            "Epoch: 961 | Train Loss: 0.17092 | Valid Loss: 0.17201 | Time: 0.47 seconds\n",
            "Epoch: 962 | Train Loss: 0.17064 | Valid Loss: 0.17218 | Time: 0.45 seconds\n",
            "Epoch: 963 | Train Loss: 0.17035 | Valid Loss: 0.17091 | Time: 0.47 seconds\n",
            "Epoch: 964 | Train Loss: 0.17011 | Valid Loss: 0.17139 | Time: 0.45 seconds\n",
            "Epoch: 965 | Train Loss: 0.16984 | Valid Loss: 0.17004 | Time: 0.46 seconds\n",
            "Epoch: 966 | Train Loss: 0.16956 | Valid Loss: 0.17129 | Time: 0.45 seconds\n",
            "Epoch: 967 | Train Loss: 0.16932 | Valid Loss: 0.17049 | Time: 0.46 seconds\n",
            "Epoch: 968 | Train Loss: 0.16905 | Valid Loss: 0.17023 | Time: 0.45 seconds\n",
            "Epoch: 969 | Train Loss: 0.16880 | Valid Loss: 0.16925 | Time: 0.51 seconds\n",
            "Epoch: 970 | Train Loss: 0.16848 | Valid Loss: 0.16971 | Time: 0.46 seconds\n",
            "Epoch: 971 | Train Loss: 0.16826 | Valid Loss: 0.16987 | Time: 0.46 seconds\n",
            "Epoch: 972 | Train Loss: 0.16799 | Valid Loss: 0.16907 | Time: 0.49 seconds\n",
            "Epoch: 973 | Train Loss: 0.16773 | Valid Loss: 0.16801 | Time: 0.48 seconds\n",
            "Epoch: 974 | Train Loss: 0.16746 | Valid Loss: 0.16942 | Time: 0.47 seconds\n",
            "Epoch: 975 | Train Loss: 0.16720 | Valid Loss: 0.16958 | Time: 0.45 seconds\n",
            "Epoch: 976 | Train Loss: 0.16692 | Valid Loss: 0.16886 | Time: 0.46 seconds\n",
            "Epoch: 977 | Train Loss: 0.16667 | Valid Loss: 0.16844 | Time: 0.47 seconds\n",
            "Epoch: 978 | Train Loss: 0.16642 | Valid Loss: 0.16952 | Time: 0.47 seconds\n",
            "Epoch: 979 | Train Loss: 0.16618 | Valid Loss: 0.16778 | Time: 0.45 seconds\n",
            "Epoch: 980 | Train Loss: 0.16588 | Valid Loss: 0.16789 | Time: 0.47 seconds\n",
            "Epoch: 981 | Train Loss: 0.16565 | Valid Loss: 0.16777 | Time: 0.46 seconds\n",
            "Epoch: 982 | Train Loss: 0.16541 | Valid Loss: 0.16755 | Time: 0.46 seconds\n",
            "Epoch: 983 | Train Loss: 0.16512 | Valid Loss: 0.16768 | Time: 0.44 seconds\n",
            "Epoch: 984 | Train Loss: 0.16490 | Valid Loss: 0.16622 | Time: 0.46 seconds\n",
            "Epoch: 985 | Train Loss: 0.16462 | Valid Loss: 0.16582 | Time: 0.48 seconds\n",
            "Epoch: 986 | Train Loss: 0.16437 | Valid Loss: 0.16820 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16410 | Valid Loss: 0.16470 | Time: 0.47 seconds\n",
            "Epoch: 988 | Train Loss: 0.16384 | Valid Loss: 0.16540 | Time: 0.45 seconds\n",
            "Epoch: 989 | Train Loss: 0.16359 | Valid Loss: 0.16457 | Time: 0.49 seconds\n",
            "Epoch: 990 | Train Loss: 0.16334 | Valid Loss: 0.16502 | Time: 0.47 seconds\n",
            "Epoch: 991 | Train Loss: 0.16309 | Valid Loss: 0.16460 | Time: 0.46 seconds\n",
            "Epoch: 992 | Train Loss: 0.16284 | Valid Loss: 0.16416 | Time: 0.45 seconds\n",
            "Epoch: 993 | Train Loss: 0.16257 | Valid Loss: 0.16377 | Time: 0.46 seconds\n",
            "Epoch: 994 | Train Loss: 0.16230 | Valid Loss: 0.16319 | Time: 0.45 seconds\n",
            "Epoch: 995 | Train Loss: 0.16206 | Valid Loss: 0.16321 | Time: 0.45 seconds\n",
            "Epoch: 996 | Train Loss: 0.16183 | Valid Loss: 0.16226 | Time: 0.47 seconds\n",
            "Epoch: 997 | Train Loss: 0.16153 | Valid Loss: 0.16226 | Time: 0.47 seconds\n",
            "Epoch: 998 | Train Loss: 0.16129 | Valid Loss: 0.16187 | Time: 0.47 seconds\n",
            "Epoch: 999 | Train Loss: 0.16108 | Valid Loss: 0.16237 | Time: 0.45 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16080 | Valid Loss: 0.16195 | Time: 0.47 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 998\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.84 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 7]: 32.94501\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 8...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71492 | Valid Loss: 0.71269 | Time: 0.47 seconds\n",
            "Epoch: 2 | Train Loss: 0.71435 | Valid Loss: 0.71446 | Time: 0.47 seconds\n",
            "Epoch: 3 | Train Loss: 0.71383 | Valid Loss: 0.71366 | Time: 0.46 seconds\n",
            "Epoch: 4 | Train Loss: 0.71333 | Valid Loss: 0.71368 | Time: 0.46 seconds\n",
            "Epoch: 5 | Train Loss: 0.71285 | Valid Loss: 0.71343 | Time: 0.45 seconds\n",
            "Epoch: 6 | Train Loss: 0.71239 | Valid Loss: 0.71306 | Time: 0.46 seconds\n",
            "Epoch: 7 | Train Loss: 0.71192 | Valid Loss: 0.71311 | Time: 0.46 seconds\n",
            "Epoch: 8 | Train Loss: 0.71150 | Valid Loss: 0.71217 | Time: 0.47 seconds\n",
            "Epoch: 9 | Train Loss: 0.71108 | Valid Loss: 0.71176 | Time: 0.45 seconds\n",
            "Epoch: 10 | Train Loss: 0.71069 | Valid Loss: 0.71097 | Time: 0.46 seconds\n",
            "Epoch: 11 | Train Loss: 0.71029 | Valid Loss: 0.71122 | Time: 0.46 seconds\n",
            "Epoch: 12 | Train Loss: 0.70989 | Valid Loss: 0.71069 | Time: 0.47 seconds\n",
            "Epoch: 13 | Train Loss: 0.70953 | Valid Loss: 0.71062 | Time: 0.47 seconds\n",
            "Epoch: 14 | Train Loss: 0.70915 | Valid Loss: 0.70983 | Time: 0.47 seconds\n",
            "Epoch: 15 | Train Loss: 0.70880 | Valid Loss: 0.70930 | Time: 0.48 seconds\n",
            "Epoch: 16 | Train Loss: 0.70844 | Valid Loss: 0.70893 | Time: 0.46 seconds\n",
            "Epoch: 17 | Train Loss: 0.70808 | Valid Loss: 0.70852 | Time: 0.48 seconds\n",
            "Epoch: 18 | Train Loss: 0.70776 | Valid Loss: 0.70845 | Time: 0.49 seconds\n",
            "Epoch: 19 | Train Loss: 0.70743 | Valid Loss: 0.70839 | Time: 0.48 seconds\n",
            "Epoch: 20 | Train Loss: 0.70709 | Valid Loss: 0.70796 | Time: 0.48 seconds\n",
            "Epoch: 21 | Train Loss: 0.70677 | Valid Loss: 0.70815 | Time: 0.46 seconds\n",
            "Epoch: 22 | Train Loss: 0.70644 | Valid Loss: 0.70746 | Time: 0.47 seconds\n",
            "Epoch: 23 | Train Loss: 0.70612 | Valid Loss: 0.70669 | Time: 0.47 seconds\n",
            "Epoch: 24 | Train Loss: 0.70580 | Valid Loss: 0.70646 | Time: 0.48 seconds\n",
            "Epoch: 25 | Train Loss: 0.70548 | Valid Loss: 0.70607 | Time: 0.48 seconds\n",
            "Epoch: 26 | Train Loss: 0.70515 | Valid Loss: 0.70633 | Time: 0.45 seconds\n",
            "Epoch: 27 | Train Loss: 0.70484 | Valid Loss: 0.70621 | Time: 0.46 seconds\n",
            "Epoch: 28 | Train Loss: 0.70452 | Valid Loss: 0.70531 | Time: 0.47 seconds\n",
            "Epoch: 29 | Train Loss: 0.70422 | Valid Loss: 0.70565 | Time: 0.47 seconds\n",
            "Epoch: 30 | Train Loss: 0.70390 | Valid Loss: 0.70500 | Time: 0.48 seconds\n",
            "Epoch: 31 | Train Loss: 0.70358 | Valid Loss: 0.70464 | Time: 0.48 seconds\n",
            "Epoch: 32 | Train Loss: 0.70324 | Valid Loss: 0.70428 | Time: 0.48 seconds\n",
            "Epoch: 33 | Train Loss: 0.70295 | Valid Loss: 0.70377 | Time: 0.46 seconds\n",
            "Epoch: 34 | Train Loss: 0.70263 | Valid Loss: 0.70333 | Time: 0.49 seconds\n",
            "Epoch: 35 | Train Loss: 0.70232 | Valid Loss: 0.70364 | Time: 0.46 seconds\n",
            "Epoch: 36 | Train Loss: 0.70199 | Valid Loss: 0.70329 | Time: 0.48 seconds\n",
            "Epoch: 37 | Train Loss: 0.70167 | Valid Loss: 0.70265 | Time: 0.47 seconds\n",
            "Epoch: 38 | Train Loss: 0.70136 | Valid Loss: 0.70222 | Time: 0.48 seconds\n",
            "Epoch: 39 | Train Loss: 0.70103 | Valid Loss: 0.70207 | Time: 0.48 seconds\n",
            "Epoch: 40 | Train Loss: 0.70069 | Valid Loss: 0.70207 | Time: 0.47 seconds\n",
            "Epoch: 41 | Train Loss: 0.70036 | Valid Loss: 0.70118 | Time: 0.48 seconds\n",
            "Epoch: 42 | Train Loss: 0.70004 | Valid Loss: 0.70077 | Time: 0.47 seconds\n",
            "Epoch: 43 | Train Loss: 0.69970 | Valid Loss: 0.70081 | Time: 0.47 seconds\n",
            "Epoch: 44 | Train Loss: 0.69936 | Valid Loss: 0.70040 | Time: 0.46 seconds\n",
            "Epoch: 45 | Train Loss: 0.69902 | Valid Loss: 0.70020 | Time: 0.49 seconds\n",
            "Epoch: 46 | Train Loss: 0.69867 | Valid Loss: 0.69952 | Time: 0.47 seconds\n",
            "Epoch: 47 | Train Loss: 0.69832 | Valid Loss: 0.69982 | Time: 0.47 seconds\n",
            "Epoch: 48 | Train Loss: 0.69796 | Valid Loss: 0.69915 | Time: 0.47 seconds\n",
            "Epoch: 49 | Train Loss: 0.69761 | Valid Loss: 0.69916 | Time: 0.47 seconds\n",
            "Epoch: 50 | Train Loss: 0.69725 | Valid Loss: 0.69824 | Time: 0.47 seconds\n",
            "Epoch: 51 | Train Loss: 0.69688 | Valid Loss: 0.69827 | Time: 0.49 seconds\n",
            "Epoch: 52 | Train Loss: 0.69651 | Valid Loss: 0.69755 | Time: 0.47 seconds\n",
            "Epoch: 53 | Train Loss: 0.69615 | Valid Loss: 0.69744 | Time: 0.48 seconds\n",
            "Epoch: 54 | Train Loss: 0.69576 | Valid Loss: 0.69760 | Time: 0.48 seconds\n",
            "Epoch: 55 | Train Loss: 0.69539 | Valid Loss: 0.69575 | Time: 0.47 seconds\n",
            "Epoch: 56 | Train Loss: 0.69501 | Valid Loss: 0.69626 | Time: 0.47 seconds\n",
            "Epoch: 57 | Train Loss: 0.69461 | Valid Loss: 0.69573 | Time: 0.46 seconds\n",
            "Epoch: 58 | Train Loss: 0.69421 | Valid Loss: 0.69556 | Time: 0.49 seconds\n",
            "Epoch: 59 | Train Loss: 0.69383 | Valid Loss: 0.69501 | Time: 0.47 seconds\n",
            "Epoch: 60 | Train Loss: 0.69343 | Valid Loss: 0.69539 | Time: 0.48 seconds\n",
            "Epoch: 61 | Train Loss: 0.69302 | Valid Loss: 0.69485 | Time: 0.46 seconds\n",
            "Epoch: 62 | Train Loss: 0.69261 | Valid Loss: 0.69428 | Time: 0.47 seconds\n",
            "Epoch: 63 | Train Loss: 0.69219 | Valid Loss: 0.69329 | Time: 0.46 seconds\n",
            "Epoch: 64 | Train Loss: 0.69178 | Valid Loss: 0.69276 | Time: 0.49 seconds\n",
            "Epoch: 65 | Train Loss: 0.69135 | Valid Loss: 0.69212 | Time: 0.46 seconds\n",
            "Epoch: 66 | Train Loss: 0.69092 | Valid Loss: 0.69235 | Time: 0.47 seconds\n",
            "Epoch: 67 | Train Loss: 0.69050 | Valid Loss: 0.69185 | Time: 0.46 seconds\n",
            "Epoch: 68 | Train Loss: 0.69007 | Valid Loss: 0.69087 | Time: 0.49 seconds\n",
            "Epoch: 69 | Train Loss: 0.68963 | Valid Loss: 0.69113 | Time: 0.47 seconds\n",
            "Epoch: 70 | Train Loss: 0.68918 | Valid Loss: 0.69078 | Time: 0.46 seconds\n",
            "Epoch: 71 | Train Loss: 0.68874 | Valid Loss: 0.69009 | Time: 0.49 seconds\n",
            "Epoch: 72 | Train Loss: 0.68829 | Valid Loss: 0.68952 | Time: 0.47 seconds\n",
            "Epoch: 73 | Train Loss: 0.68785 | Valid Loss: 0.68916 | Time: 0.48 seconds\n",
            "Epoch: 74 | Train Loss: 0.68737 | Valid Loss: 0.68889 | Time: 0.48 seconds\n",
            "Epoch: 75 | Train Loss: 0.68691 | Valid Loss: 0.68818 | Time: 0.48 seconds\n",
            "Epoch: 76 | Train Loss: 0.68645 | Valid Loss: 0.68824 | Time: 0.46 seconds\n",
            "Epoch: 77 | Train Loss: 0.68597 | Valid Loss: 0.68772 | Time: 0.47 seconds\n",
            "Epoch: 78 | Train Loss: 0.68549 | Valid Loss: 0.68610 | Time: 0.49 seconds\n",
            "Epoch: 79 | Train Loss: 0.68502 | Valid Loss: 0.68618 | Time: 0.47 seconds\n",
            "Epoch: 80 | Train Loss: 0.68453 | Valid Loss: 0.68599 | Time: 0.47 seconds\n",
            "Epoch: 81 | Train Loss: 0.68404 | Valid Loss: 0.68575 | Time: 0.48 seconds\n",
            "Epoch: 82 | Train Loss: 0.68355 | Valid Loss: 0.68512 | Time: 0.47 seconds\n",
            "Epoch: 83 | Train Loss: 0.68307 | Valid Loss: 0.68427 | Time: 0.48 seconds\n",
            "Epoch: 84 | Train Loss: 0.68257 | Valid Loss: 0.68427 | Time: 0.46 seconds\n",
            "Epoch: 85 | Train Loss: 0.68206 | Valid Loss: 0.68392 | Time: 0.46 seconds\n",
            "Epoch: 86 | Train Loss: 0.68155 | Valid Loss: 0.68342 | Time: 0.48 seconds\n",
            "Epoch: 87 | Train Loss: 0.68104 | Valid Loss: 0.68206 | Time: 0.47 seconds\n",
            "Epoch: 88 | Train Loss: 0.68053 | Valid Loss: 0.68200 | Time: 0.48 seconds\n",
            "Epoch: 89 | Train Loss: 0.68001 | Valid Loss: 0.68113 | Time: 0.48 seconds\n",
            "Epoch: 90 | Train Loss: 0.67949 | Valid Loss: 0.68084 | Time: 0.47 seconds\n",
            "Epoch: 91 | Train Loss: 0.67897 | Valid Loss: 0.68013 | Time: 0.47 seconds\n",
            "Epoch: 92 | Train Loss: 0.67842 | Valid Loss: 0.68010 | Time: 0.47 seconds\n",
            "Epoch: 93 | Train Loss: 0.67788 | Valid Loss: 0.67990 | Time: 0.46 seconds\n",
            "Epoch: 94 | Train Loss: 0.67736 | Valid Loss: 0.67976 | Time: 0.49 seconds\n",
            "Epoch: 95 | Train Loss: 0.67681 | Valid Loss: 0.67836 | Time: 0.46 seconds\n",
            "Epoch: 96 | Train Loss: 0.67626 | Valid Loss: 0.67792 | Time: 0.48 seconds\n",
            "Epoch: 97 | Train Loss: 0.67571 | Valid Loss: 0.67671 | Time: 0.47 seconds\n",
            "Epoch: 98 | Train Loss: 0.67516 | Valid Loss: 0.67657 | Time: 0.47 seconds\n",
            "Epoch: 99 | Train Loss: 0.67459 | Valid Loss: 0.67606 | Time: 0.49 seconds\n",
            "Epoch: 100 | Train Loss: 0.67404 | Valid Loss: 0.67582 | Time: 0.47 seconds\n",
            "Epoch: 101 | Train Loss: 0.67347 | Valid Loss: 0.67479 | Time: 0.49 seconds\n",
            "Epoch: 102 | Train Loss: 0.67290 | Valid Loss: 0.67418 | Time: 0.48 seconds\n",
            "Epoch: 103 | Train Loss: 0.67232 | Valid Loss: 0.67416 | Time: 0.50 seconds\n",
            "Epoch: 104 | Train Loss: 0.67174 | Valid Loss: 0.67365 | Time: 0.46 seconds\n",
            "Epoch: 105 | Train Loss: 0.67116 | Valid Loss: 0.67306 | Time: 0.49 seconds\n",
            "Epoch: 106 | Train Loss: 0.67057 | Valid Loss: 0.67176 | Time: 0.47 seconds\n",
            "Epoch: 107 | Train Loss: 0.66998 | Valid Loss: 0.67212 | Time: 0.47 seconds\n",
            "Epoch: 108 | Train Loss: 0.66939 | Valid Loss: 0.67110 | Time: 0.48 seconds\n",
            "Epoch: 109 | Train Loss: 0.66879 | Valid Loss: 0.67037 | Time: 0.49 seconds\n",
            "Epoch: 110 | Train Loss: 0.66819 | Valid Loss: 0.67007 | Time: 0.46 seconds\n",
            "Epoch: 111 | Train Loss: 0.66758 | Valid Loss: 0.66962 | Time: 0.47 seconds\n",
            "Epoch: 112 | Train Loss: 0.66697 | Valid Loss: 0.66853 | Time: 0.47 seconds\n",
            "Epoch: 113 | Train Loss: 0.66636 | Valid Loss: 0.66849 | Time: 0.47 seconds\n",
            "Epoch: 114 | Train Loss: 0.66574 | Valid Loss: 0.66780 | Time: 0.47 seconds\n",
            "Epoch: 115 | Train Loss: 0.66512 | Valid Loss: 0.66690 | Time: 0.48 seconds\n",
            "Epoch: 116 | Train Loss: 0.66450 | Valid Loss: 0.66658 | Time: 0.47 seconds\n",
            "Epoch: 117 | Train Loss: 0.66387 | Valid Loss: 0.66641 | Time: 0.49 seconds\n",
            "Epoch: 118 | Train Loss: 0.66324 | Valid Loss: 0.66546 | Time: 0.48 seconds\n",
            "Epoch: 119 | Train Loss: 0.66259 | Valid Loss: 0.66497 | Time: 0.47 seconds\n",
            "Epoch: 120 | Train Loss: 0.66196 | Valid Loss: 0.66437 | Time: 0.47 seconds\n",
            "Epoch: 121 | Train Loss: 0.66132 | Valid Loss: 0.66413 | Time: 0.47 seconds\n",
            "Epoch: 122 | Train Loss: 0.66067 | Valid Loss: 0.66232 | Time: 0.48 seconds\n",
            "Epoch: 123 | Train Loss: 0.66003 | Valid Loss: 0.66223 | Time: 0.46 seconds\n",
            "Epoch: 124 | Train Loss: 0.65936 | Valid Loss: 0.66119 | Time: 0.48 seconds\n",
            "Epoch: 125 | Train Loss: 0.65871 | Valid Loss: 0.65986 | Time: 0.46 seconds\n",
            "Epoch: 126 | Train Loss: 0.65807 | Valid Loss: 0.66048 | Time: 0.49 seconds\n",
            "Epoch: 127 | Train Loss: 0.65739 | Valid Loss: 0.65967 | Time: 0.46 seconds\n",
            "Epoch: 128 | Train Loss: 0.65673 | Valid Loss: 0.65885 | Time: 0.46 seconds\n",
            "Epoch: 129 | Train Loss: 0.65606 | Valid Loss: 0.65855 | Time: 0.48 seconds\n",
            "Epoch: 130 | Train Loss: 0.65538 | Valid Loss: 0.65765 | Time: 0.49 seconds\n",
            "Epoch: 131 | Train Loss: 0.65470 | Valid Loss: 0.65711 | Time: 0.48 seconds\n",
            "Epoch: 132 | Train Loss: 0.65403 | Valid Loss: 0.65565 | Time: 0.46 seconds\n",
            "Epoch: 133 | Train Loss: 0.65335 | Valid Loss: 0.65500 | Time: 0.47 seconds\n",
            "Epoch: 134 | Train Loss: 0.65265 | Valid Loss: 0.65351 | Time: 0.47 seconds\n",
            "Epoch: 135 | Train Loss: 0.65198 | Valid Loss: 0.65423 | Time: 0.47 seconds\n",
            "Epoch: 136 | Train Loss: 0.65128 | Valid Loss: 0.65321 | Time: 0.46 seconds\n",
            "Epoch: 137 | Train Loss: 0.65058 | Valid Loss: 0.65238 | Time: 0.48 seconds\n",
            "Epoch: 138 | Train Loss: 0.64989 | Valid Loss: 0.65169 | Time: 0.47 seconds\n",
            "Epoch: 139 | Train Loss: 0.64918 | Valid Loss: 0.65153 | Time: 0.50 seconds\n",
            "Epoch: 140 | Train Loss: 0.64849 | Valid Loss: 0.64969 | Time: 0.47 seconds\n",
            "Epoch: 141 | Train Loss: 0.64778 | Valid Loss: 0.65008 | Time: 0.47 seconds\n",
            "Epoch: 142 | Train Loss: 0.64707 | Valid Loss: 0.64807 | Time: 0.47 seconds\n",
            "Epoch: 143 | Train Loss: 0.64636 | Valid Loss: 0.64723 | Time: 0.48 seconds\n",
            "Epoch: 144 | Train Loss: 0.64565 | Valid Loss: 0.64694 | Time: 0.49 seconds\n",
            "Epoch: 145 | Train Loss: 0.64492 | Valid Loss: 0.64680 | Time: 0.46 seconds\n",
            "Epoch: 146 | Train Loss: 0.64420 | Valid Loss: 0.64800 | Time: 0.48 seconds\n",
            "Epoch: 147 | Train Loss: 0.64348 | Valid Loss: 0.64563 | Time: 0.47 seconds\n",
            "Epoch: 148 | Train Loss: 0.64275 | Valid Loss: 0.64476 | Time: 0.48 seconds\n",
            "Epoch: 149 | Train Loss: 0.64203 | Valid Loss: 0.64445 | Time: 0.49 seconds\n",
            "Epoch: 150 | Train Loss: 0.64130 | Valid Loss: 0.64369 | Time: 0.47 seconds\n",
            "Epoch: 151 | Train Loss: 0.64057 | Valid Loss: 0.64244 | Time: 0.47 seconds\n",
            "Epoch: 152 | Train Loss: 0.63983 | Valid Loss: 0.64199 | Time: 0.48 seconds\n",
            "Epoch: 153 | Train Loss: 0.63911 | Valid Loss: 0.64179 | Time: 0.48 seconds\n",
            "Epoch: 154 | Train Loss: 0.63835 | Valid Loss: 0.64065 | Time: 0.48 seconds\n",
            "Epoch: 155 | Train Loss: 0.63761 | Valid Loss: 0.63904 | Time: 0.47 seconds\n",
            "Epoch: 156 | Train Loss: 0.63686 | Valid Loss: 0.63848 | Time: 0.47 seconds\n",
            "Epoch: 157 | Train Loss: 0.63612 | Valid Loss: 0.63956 | Time: 0.47 seconds\n",
            "Epoch: 158 | Train Loss: 0.63537 | Valid Loss: 0.63636 | Time: 0.47 seconds\n",
            "Epoch: 159 | Train Loss: 0.63462 | Valid Loss: 0.63745 | Time: 0.47 seconds\n",
            "Epoch: 160 | Train Loss: 0.63387 | Valid Loss: 0.63732 | Time: 0.47 seconds\n",
            "Epoch: 161 | Train Loss: 0.63310 | Valid Loss: 0.63481 | Time: 0.47 seconds\n",
            "Epoch: 162 | Train Loss: 0.63234 | Valid Loss: 0.63445 | Time: 0.47 seconds\n",
            "Epoch: 163 | Train Loss: 0.63159 | Valid Loss: 0.63514 | Time: 0.46 seconds\n",
            "Epoch: 164 | Train Loss: 0.63082 | Valid Loss: 0.63332 | Time: 0.48 seconds\n",
            "Epoch: 165 | Train Loss: 0.63006 | Valid Loss: 0.63100 | Time: 0.49 seconds\n",
            "Epoch: 166 | Train Loss: 0.62930 | Valid Loss: 0.63106 | Time: 0.46 seconds\n",
            "Epoch: 167 | Train Loss: 0.62851 | Valid Loss: 0.62955 | Time: 0.48 seconds\n",
            "Epoch: 168 | Train Loss: 0.62776 | Valid Loss: 0.63037 | Time: 0.47 seconds\n",
            "Epoch: 169 | Train Loss: 0.62697 | Valid Loss: 0.62934 | Time: 0.48 seconds\n",
            "Epoch: 170 | Train Loss: 0.62620 | Valid Loss: 0.62875 | Time: 0.47 seconds\n",
            "Epoch: 171 | Train Loss: 0.62542 | Valid Loss: 0.62648 | Time: 0.48 seconds\n",
            "Epoch: 172 | Train Loss: 0.62464 | Valid Loss: 0.62587 | Time: 0.48 seconds\n",
            "Epoch: 173 | Train Loss: 0.62387 | Valid Loss: 0.62543 | Time: 0.49 seconds\n",
            "Epoch: 174 | Train Loss: 0.62309 | Valid Loss: 0.62602 | Time: 0.47 seconds\n",
            "Epoch: 175 | Train Loss: 0.62231 | Valid Loss: 0.62483 | Time: 0.47 seconds\n",
            "Epoch: 176 | Train Loss: 0.62152 | Valid Loss: 0.62197 | Time: 0.50 seconds\n",
            "Epoch: 177 | Train Loss: 0.62072 | Valid Loss: 0.62302 | Time: 0.46 seconds\n",
            "Epoch: 178 | Train Loss: 0.61994 | Valid Loss: 0.62163 | Time: 0.50 seconds\n",
            "Epoch: 179 | Train Loss: 0.61915 | Valid Loss: 0.62133 | Time: 0.46 seconds\n",
            "Epoch: 180 | Train Loss: 0.61836 | Valid Loss: 0.62140 | Time: 0.49 seconds\n",
            "Epoch: 181 | Train Loss: 0.61757 | Valid Loss: 0.62110 | Time: 0.47 seconds\n",
            "Epoch: 182 | Train Loss: 0.61677 | Valid Loss: 0.62097 | Time: 0.49 seconds\n",
            "Epoch: 183 | Train Loss: 0.61597 | Valid Loss: 0.61791 | Time: 0.48 seconds\n",
            "Epoch: 184 | Train Loss: 0.61516 | Valid Loss: 0.61793 | Time: 0.48 seconds\n",
            "Epoch: 185 | Train Loss: 0.61436 | Valid Loss: 0.61661 | Time: 0.47 seconds\n",
            "Epoch: 186 | Train Loss: 0.61357 | Valid Loss: 0.61622 | Time: 0.50 seconds\n",
            "Epoch: 187 | Train Loss: 0.61277 | Valid Loss: 0.61529 | Time: 0.48 seconds\n",
            "Epoch: 188 | Train Loss: 0.61196 | Valid Loss: 0.61421 | Time: 0.47 seconds\n",
            "Epoch: 189 | Train Loss: 0.61117 | Valid Loss: 0.61405 | Time: 0.46 seconds\n",
            "Epoch: 190 | Train Loss: 0.61036 | Valid Loss: 0.61264 | Time: 0.47 seconds\n",
            "Epoch: 191 | Train Loss: 0.60955 | Valid Loss: 0.61220 | Time: 0.48 seconds\n",
            "Epoch: 192 | Train Loss: 0.60874 | Valid Loss: 0.61157 | Time: 0.47 seconds\n",
            "Epoch: 193 | Train Loss: 0.60793 | Valid Loss: 0.60979 | Time: 0.48 seconds\n",
            "Epoch: 194 | Train Loss: 0.60712 | Valid Loss: 0.61118 | Time: 0.46 seconds\n",
            "Epoch: 195 | Train Loss: 0.60630 | Valid Loss: 0.60835 | Time: 0.48 seconds\n",
            "Epoch: 196 | Train Loss: 0.60549 | Valid Loss: 0.60735 | Time: 0.47 seconds\n",
            "Epoch: 197 | Train Loss: 0.60468 | Valid Loss: 0.60933 | Time: 0.48 seconds\n",
            "Epoch: 198 | Train Loss: 0.60386 | Valid Loss: 0.60682 | Time: 0.46 seconds\n",
            "Epoch: 199 | Train Loss: 0.60304 | Valid Loss: 0.60641 | Time: 0.47 seconds\n",
            "Epoch: 200 | Train Loss: 0.60222 | Valid Loss: 0.60351 | Time: 0.47 seconds\n",
            "Epoch: 201 | Train Loss: 0.60140 | Valid Loss: 0.60458 | Time: 0.48 seconds\n",
            "Epoch: 202 | Train Loss: 0.60057 | Valid Loss: 0.60250 | Time: 0.47 seconds\n",
            "Epoch: 203 | Train Loss: 0.59976 | Valid Loss: 0.60304 | Time: 0.50 seconds\n",
            "Epoch: 204 | Train Loss: 0.59893 | Valid Loss: 0.60110 | Time: 0.47 seconds\n",
            "Epoch: 205 | Train Loss: 0.59810 | Valid Loss: 0.59989 | Time: 0.46 seconds\n",
            "Epoch: 206 | Train Loss: 0.59727 | Valid Loss: 0.59852 | Time: 0.49 seconds\n",
            "Epoch: 207 | Train Loss: 0.59645 | Valid Loss: 0.59837 | Time: 0.47 seconds\n",
            "Epoch: 208 | Train Loss: 0.59563 | Valid Loss: 0.59747 | Time: 0.48 seconds\n",
            "Epoch: 209 | Train Loss: 0.59479 | Valid Loss: 0.59772 | Time: 0.47 seconds\n",
            "Epoch: 210 | Train Loss: 0.59397 | Valid Loss: 0.59544 | Time: 0.49 seconds\n",
            "Epoch: 211 | Train Loss: 0.59312 | Valid Loss: 0.59484 | Time: 0.48 seconds\n",
            "Epoch: 212 | Train Loss: 0.59231 | Valid Loss: 0.59527 | Time: 0.46 seconds\n",
            "Epoch: 213 | Train Loss: 0.59147 | Valid Loss: 0.59437 | Time: 0.47 seconds\n",
            "Epoch: 214 | Train Loss: 0.59063 | Valid Loss: 0.59358 | Time: 0.47 seconds\n",
            "Epoch: 215 | Train Loss: 0.58979 | Valid Loss: 0.59104 | Time: 0.47 seconds\n",
            "Epoch: 216 | Train Loss: 0.58897 | Valid Loss: 0.59084 | Time: 0.48 seconds\n",
            "Epoch: 217 | Train Loss: 0.58812 | Valid Loss: 0.59134 | Time: 0.47 seconds\n",
            "Epoch: 218 | Train Loss: 0.58728 | Valid Loss: 0.58926 | Time: 0.48 seconds\n",
            "Epoch: 219 | Train Loss: 0.58644 | Valid Loss: 0.59062 | Time: 0.45 seconds\n",
            "Epoch: 220 | Train Loss: 0.58560 | Valid Loss: 0.58842 | Time: 0.47 seconds\n",
            "Epoch: 221 | Train Loss: 0.58476 | Valid Loss: 0.58791 | Time: 0.49 seconds\n",
            "Epoch: 222 | Train Loss: 0.58393 | Valid Loss: 0.58729 | Time: 0.46 seconds\n",
            "Epoch: 223 | Train Loss: 0.58308 | Valid Loss: 0.58573 | Time: 0.47 seconds\n",
            "Epoch: 224 | Train Loss: 0.58224 | Valid Loss: 0.58485 | Time: 0.47 seconds\n",
            "Epoch: 225 | Train Loss: 0.58139 | Valid Loss: 0.58329 | Time: 0.49 seconds\n",
            "Epoch: 226 | Train Loss: 0.58055 | Valid Loss: 0.58209 | Time: 0.47 seconds\n",
            "Epoch: 227 | Train Loss: 0.57970 | Valid Loss: 0.58184 | Time: 0.50 seconds\n",
            "Epoch: 228 | Train Loss: 0.57887 | Valid Loss: 0.58177 | Time: 0.47 seconds\n",
            "Epoch: 229 | Train Loss: 0.57800 | Valid Loss: 0.58097 | Time: 0.48 seconds\n",
            "Epoch: 230 | Train Loss: 0.57716 | Valid Loss: 0.57980 | Time: 0.47 seconds\n",
            "Epoch: 231 | Train Loss: 0.57631 | Valid Loss: 0.58079 | Time: 0.47 seconds\n",
            "Epoch: 232 | Train Loss: 0.57547 | Valid Loss: 0.57889 | Time: 0.47 seconds\n",
            "Epoch: 233 | Train Loss: 0.57461 | Valid Loss: 0.57618 | Time: 0.48 seconds\n",
            "Epoch: 234 | Train Loss: 0.57375 | Valid Loss: 0.57644 | Time: 0.46 seconds\n",
            "Epoch: 235 | Train Loss: 0.57289 | Valid Loss: 0.57756 | Time: 0.45 seconds\n",
            "Epoch: 236 | Train Loss: 0.57205 | Valid Loss: 0.57433 | Time: 0.51 seconds\n",
            "Epoch: 237 | Train Loss: 0.57120 | Valid Loss: 0.57341 | Time: 0.47 seconds\n",
            "Epoch: 238 | Train Loss: 0.57035 | Valid Loss: 0.57357 | Time: 0.50 seconds\n",
            "Epoch: 239 | Train Loss: 0.56948 | Valid Loss: 0.57287 | Time: 0.48 seconds\n",
            "Epoch: 240 | Train Loss: 0.56863 | Valid Loss: 0.57054 | Time: 0.48 seconds\n",
            "Epoch: 241 | Train Loss: 0.56779 | Valid Loss: 0.57110 | Time: 0.47 seconds\n",
            "Epoch: 242 | Train Loss: 0.56692 | Valid Loss: 0.56887 | Time: 0.48 seconds\n",
            "Epoch: 243 | Train Loss: 0.56605 | Valid Loss: 0.56871 | Time: 0.48 seconds\n",
            "Epoch: 244 | Train Loss: 0.56520 | Valid Loss: 0.56813 | Time: 0.48 seconds\n",
            "Epoch: 245 | Train Loss: 0.56434 | Valid Loss: 0.56855 | Time: 0.47 seconds\n",
            "Epoch: 246 | Train Loss: 0.56349 | Valid Loss: 0.56609 | Time: 0.50 seconds\n",
            "Epoch: 247 | Train Loss: 0.56263 | Valid Loss: 0.56386 | Time: 0.48 seconds\n",
            "Epoch: 248 | Train Loss: 0.56177 | Valid Loss: 0.56346 | Time: 0.50 seconds\n",
            "Epoch: 249 | Train Loss: 0.56091 | Valid Loss: 0.56646 | Time: 0.46 seconds\n",
            "Epoch: 250 | Train Loss: 0.56004 | Valid Loss: 0.56048 | Time: 0.49 seconds\n",
            "Epoch: 251 | Train Loss: 0.55918 | Valid Loss: 0.55995 | Time: 0.47 seconds\n",
            "Epoch: 252 | Train Loss: 0.55833 | Valid Loss: 0.56080 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55746 | Valid Loss: 0.56229 | Time: 0.47 seconds\n",
            "Epoch: 254 | Train Loss: 0.55659 | Valid Loss: 0.55848 | Time: 0.48 seconds\n",
            "Epoch: 255 | Train Loss: 0.55574 | Valid Loss: 0.55858 | Time: 0.48 seconds\n",
            "Epoch: 256 | Train Loss: 0.55487 | Valid Loss: 0.55947 | Time: 0.47 seconds\n",
            "Epoch: 257 | Train Loss: 0.55400 | Valid Loss: 0.55689 | Time: 0.48 seconds\n",
            "Epoch: 258 | Train Loss: 0.55313 | Valid Loss: 0.55738 | Time: 0.46 seconds\n",
            "Epoch: 259 | Train Loss: 0.55227 | Valid Loss: 0.55467 | Time: 0.48 seconds\n",
            "Epoch: 260 | Train Loss: 0.55139 | Valid Loss: 0.55269 | Time: 0.48 seconds\n",
            "Epoch: 261 | Train Loss: 0.55054 | Valid Loss: 0.55204 | Time: 0.47 seconds\n",
            "Epoch: 262 | Train Loss: 0.54966 | Valid Loss: 0.55335 | Time: 0.46 seconds\n",
            "Epoch: 263 | Train Loss: 0.54880 | Valid Loss: 0.55149 | Time: 0.48 seconds\n",
            "Epoch: 264 | Train Loss: 0.54793 | Valid Loss: 0.55108 | Time: 0.49 seconds\n",
            "Epoch: 265 | Train Loss: 0.54707 | Valid Loss: 0.54974 | Time: 0.48 seconds\n",
            "Epoch: 266 | Train Loss: 0.54618 | Valid Loss: 0.54816 | Time: 0.47 seconds\n",
            "Epoch: 267 | Train Loss: 0.54532 | Valid Loss: 0.54769 | Time: 0.46 seconds\n",
            "Epoch: 268 | Train Loss: 0.54445 | Valid Loss: 0.54683 | Time: 0.47 seconds\n",
            "Epoch: 269 | Train Loss: 0.54358 | Valid Loss: 0.54607 | Time: 0.46 seconds\n",
            "Epoch: 270 | Train Loss: 0.54271 | Valid Loss: 0.54594 | Time: 0.48 seconds\n",
            "Epoch: 271 | Train Loss: 0.54184 | Valid Loss: 0.54399 | Time: 0.48 seconds\n",
            "Epoch: 272 | Train Loss: 0.54097 | Valid Loss: 0.54455 | Time: 0.47 seconds\n",
            "Epoch: 273 | Train Loss: 0.54010 | Valid Loss: 0.54312 | Time: 0.47 seconds\n",
            "Epoch: 274 | Train Loss: 0.53922 | Valid Loss: 0.54168 | Time: 0.48 seconds\n",
            "Epoch: 275 | Train Loss: 0.53835 | Valid Loss: 0.54079 | Time: 0.47 seconds\n",
            "Epoch: 276 | Train Loss: 0.53747 | Valid Loss: 0.54105 | Time: 0.47 seconds\n",
            "Epoch: 277 | Train Loss: 0.53661 | Valid Loss: 0.53902 | Time: 0.48 seconds\n",
            "Epoch: 278 | Train Loss: 0.53575 | Valid Loss: 0.54067 | Time: 0.47 seconds\n",
            "Epoch: 279 | Train Loss: 0.53487 | Valid Loss: 0.53899 | Time: 0.46 seconds\n",
            "Epoch: 280 | Train Loss: 0.53399 | Valid Loss: 0.53726 | Time: 0.49 seconds\n",
            "Epoch: 281 | Train Loss: 0.53312 | Valid Loss: 0.53784 | Time: 0.46 seconds\n",
            "Epoch: 282 | Train Loss: 0.53224 | Valid Loss: 0.53603 | Time: 0.46 seconds\n",
            "Epoch: 283 | Train Loss: 0.53136 | Valid Loss: 0.53357 | Time: 0.49 seconds\n",
            "Epoch: 284 | Train Loss: 0.53050 | Valid Loss: 0.53312 | Time: 0.47 seconds\n",
            "Epoch: 285 | Train Loss: 0.52963 | Valid Loss: 0.53105 | Time: 0.50 seconds\n",
            "Epoch: 286 | Train Loss: 0.52875 | Valid Loss: 0.53180 | Time: 0.46 seconds\n",
            "Epoch: 287 | Train Loss: 0.52787 | Valid Loss: 0.53052 | Time: 0.47 seconds\n",
            "Epoch: 288 | Train Loss: 0.52702 | Valid Loss: 0.53118 | Time: 0.47 seconds\n",
            "Epoch: 289 | Train Loss: 0.52613 | Valid Loss: 0.52872 | Time: 0.47 seconds\n",
            "Epoch: 290 | Train Loss: 0.52525 | Valid Loss: 0.52770 | Time: 0.47 seconds\n",
            "Epoch: 291 | Train Loss: 0.52439 | Valid Loss: 0.52795 | Time: 0.48 seconds\n",
            "Epoch: 292 | Train Loss: 0.52350 | Valid Loss: 0.52549 | Time: 0.47 seconds\n",
            "Epoch: 293 | Train Loss: 0.52265 | Valid Loss: 0.52418 | Time: 0.48 seconds\n",
            "Epoch: 294 | Train Loss: 0.52176 | Valid Loss: 0.52429 | Time: 0.47 seconds\n",
            "Epoch: 295 | Train Loss: 0.52089 | Valid Loss: 0.52304 | Time: 0.49 seconds\n",
            "Epoch: 296 | Train Loss: 0.52003 | Valid Loss: 0.52493 | Time: 0.46 seconds\n",
            "Epoch: 297 | Train Loss: 0.51914 | Valid Loss: 0.52238 | Time: 0.46 seconds\n",
            "Epoch: 298 | Train Loss: 0.51828 | Valid Loss: 0.52163 | Time: 0.47 seconds\n",
            "Epoch: 299 | Train Loss: 0.51741 | Valid Loss: 0.52082 | Time: 0.46 seconds\n",
            "Epoch: 300 | Train Loss: 0.51653 | Valid Loss: 0.51858 | Time: 0.49 seconds\n",
            "Epoch: 301 | Train Loss: 0.51566 | Valid Loss: 0.51937 | Time: 0.46 seconds\n",
            "Epoch: 302 | Train Loss: 0.51480 | Valid Loss: 0.51943 | Time: 0.47 seconds\n",
            "Epoch: 303 | Train Loss: 0.51389 | Valid Loss: 0.51796 | Time: 0.46 seconds\n",
            "Epoch: 304 | Train Loss: 0.51302 | Valid Loss: 0.51749 | Time: 0.50 seconds\n",
            "Epoch: 305 | Train Loss: 0.51215 | Valid Loss: 0.51551 | Time: 0.47 seconds\n",
            "Epoch: 306 | Train Loss: 0.51130 | Valid Loss: 0.51408 | Time: 0.49 seconds\n",
            "Epoch: 307 | Train Loss: 0.51042 | Valid Loss: 0.51386 | Time: 0.49 seconds\n",
            "Epoch: 308 | Train Loss: 0.50955 | Valid Loss: 0.51192 | Time: 0.48 seconds\n",
            "Epoch: 309 | Train Loss: 0.50867 | Valid Loss: 0.51125 | Time: 0.46 seconds\n",
            "Epoch: 310 | Train Loss: 0.50782 | Valid Loss: 0.51121 | Time: 0.48 seconds\n",
            "Epoch: 311 | Train Loss: 0.50695 | Valid Loss: 0.50895 | Time: 0.48 seconds\n",
            "Epoch: 312 | Train Loss: 0.50605 | Valid Loss: 0.50791 | Time: 0.46 seconds\n",
            "Epoch: 313 | Train Loss: 0.50519 | Valid Loss: 0.50704 | Time: 0.49 seconds\n",
            "Epoch: 314 | Train Loss: 0.50432 | Valid Loss: 0.50872 | Time: 0.47 seconds\n",
            "Epoch: 315 | Train Loss: 0.50346 | Valid Loss: 0.50753 | Time: 0.48 seconds\n",
            "Epoch: 316 | Train Loss: 0.50258 | Valid Loss: 0.50492 | Time: 0.46 seconds\n",
            "Epoch: 317 | Train Loss: 0.50171 | Valid Loss: 0.50504 | Time: 0.46 seconds\n",
            "Epoch: 318 | Train Loss: 0.50085 | Valid Loss: 0.50541 | Time: 0.47 seconds\n",
            "Epoch: 319 | Train Loss: 0.49997 | Valid Loss: 0.50392 | Time: 0.48 seconds\n",
            "Epoch: 320 | Train Loss: 0.49910 | Valid Loss: 0.50142 | Time: 0.46 seconds\n",
            "Epoch: 321 | Train Loss: 0.49824 | Valid Loss: 0.50203 | Time: 0.47 seconds\n",
            "Epoch: 322 | Train Loss: 0.49738 | Valid Loss: 0.49973 | Time: 0.47 seconds\n",
            "Epoch: 323 | Train Loss: 0.49651 | Valid Loss: 0.49961 | Time: 0.49 seconds\n",
            "Epoch: 324 | Train Loss: 0.49563 | Valid Loss: 0.49821 | Time: 0.46 seconds\n",
            "Epoch: 325 | Train Loss: 0.49477 | Valid Loss: 0.49745 | Time: 0.46 seconds\n",
            "Epoch: 326 | Train Loss: 0.49391 | Valid Loss: 0.49737 | Time: 0.48 seconds\n",
            "Epoch: 327 | Train Loss: 0.49304 | Valid Loss: 0.49477 | Time: 0.48 seconds\n",
            "Epoch: 328 | Train Loss: 0.49218 | Valid Loss: 0.49593 | Time: 0.46 seconds\n",
            "Epoch: 329 | Train Loss: 0.49132 | Valid Loss: 0.49580 | Time: 0.46 seconds\n",
            "Epoch: 330 | Train Loss: 0.49046 | Valid Loss: 0.49546 | Time: 0.47 seconds\n",
            "Epoch: 331 | Train Loss: 0.48959 | Valid Loss: 0.49164 | Time: 0.46 seconds\n",
            "Epoch: 332 | Train Loss: 0.48872 | Valid Loss: 0.49278 | Time: 0.47 seconds\n",
            "Epoch: 333 | Train Loss: 0.48788 | Valid Loss: 0.49074 | Time: 0.48 seconds\n",
            "Epoch: 334 | Train Loss: 0.48700 | Valid Loss: 0.49230 | Time: 0.49 seconds\n",
            "Epoch: 335 | Train Loss: 0.48614 | Valid Loss: 0.48999 | Time: 0.47 seconds\n",
            "Epoch: 336 | Train Loss: 0.48530 | Valid Loss: 0.48910 | Time: 0.48 seconds\n",
            "Epoch: 337 | Train Loss: 0.48443 | Valid Loss: 0.48647 | Time: 0.47 seconds\n",
            "Epoch: 338 | Train Loss: 0.48356 | Valid Loss: 0.48798 | Time: 0.48 seconds\n",
            "Epoch: 339 | Train Loss: 0.48270 | Valid Loss: 0.48560 | Time: 0.48 seconds\n",
            "Epoch: 340 | Train Loss: 0.48184 | Valid Loss: 0.48715 | Time: 0.45 seconds\n",
            "Epoch: 341 | Train Loss: 0.48098 | Valid Loss: 0.48279 | Time: 0.47 seconds\n",
            "Epoch: 342 | Train Loss: 0.48014 | Valid Loss: 0.48433 | Time: 0.45 seconds\n",
            "Epoch: 343 | Train Loss: 0.47927 | Valid Loss: 0.48205 | Time: 0.48 seconds\n",
            "Epoch: 344 | Train Loss: 0.47843 | Valid Loss: 0.48178 | Time: 0.48 seconds\n",
            "Epoch: 345 | Train Loss: 0.47759 | Valid Loss: 0.48248 | Time: 0.48 seconds\n",
            "Epoch: 346 | Train Loss: 0.47671 | Valid Loss: 0.48022 | Time: 0.47 seconds\n",
            "Epoch: 347 | Train Loss: 0.47586 | Valid Loss: 0.47963 | Time: 0.48 seconds\n",
            "Epoch: 348 | Train Loss: 0.47505 | Valid Loss: 0.47939 | Time: 0.48 seconds\n",
            "Epoch: 349 | Train Loss: 0.47416 | Valid Loss: 0.47889 | Time: 0.49 seconds\n",
            "Epoch: 350 | Train Loss: 0.47332 | Valid Loss: 0.47798 | Time: 0.46 seconds\n",
            "Epoch: 351 | Train Loss: 0.47246 | Valid Loss: 0.47672 | Time: 0.48 seconds\n",
            "Epoch: 352 | Train Loss: 0.47163 | Valid Loss: 0.47429 | Time: 0.47 seconds\n",
            "Epoch: 353 | Train Loss: 0.47078 | Valid Loss: 0.47333 | Time: 0.48 seconds\n",
            "Epoch: 354 | Train Loss: 0.46993 | Valid Loss: 0.47360 | Time: 0.47 seconds\n",
            "Epoch: 355 | Train Loss: 0.46908 | Valid Loss: 0.47178 | Time: 0.47 seconds\n",
            "Epoch: 356 | Train Loss: 0.46824 | Valid Loss: 0.47111 | Time: 0.51 seconds\n",
            "Epoch: 357 | Train Loss: 0.46738 | Valid Loss: 0.47155 | Time: 0.46 seconds\n",
            "Epoch: 358 | Train Loss: 0.46656 | Valid Loss: 0.46917 | Time: 0.50 seconds\n",
            "Epoch: 359 | Train Loss: 0.46571 | Valid Loss: 0.46975 | Time: 0.46 seconds\n",
            "Epoch: 360 | Train Loss: 0.46486 | Valid Loss: 0.46802 | Time: 0.48 seconds\n",
            "Epoch: 361 | Train Loss: 0.46402 | Valid Loss: 0.46710 | Time: 0.46 seconds\n",
            "Epoch: 362 | Train Loss: 0.46318 | Valid Loss: 0.46529 | Time: 0.47 seconds\n",
            "Epoch: 363 | Train Loss: 0.46233 | Valid Loss: 0.46549 | Time: 0.47 seconds\n",
            "Epoch: 364 | Train Loss: 0.46151 | Valid Loss: 0.46598 | Time: 0.48 seconds\n",
            "Epoch: 365 | Train Loss: 0.46065 | Valid Loss: 0.46451 | Time: 0.47 seconds\n",
            "Epoch: 366 | Train Loss: 0.45982 | Valid Loss: 0.46315 | Time: 0.47 seconds\n",
            "Epoch: 367 | Train Loss: 0.45899 | Valid Loss: 0.46108 | Time: 0.47 seconds\n",
            "Epoch: 368 | Train Loss: 0.45816 | Valid Loss: 0.46306 | Time: 0.48 seconds\n",
            "Epoch: 369 | Train Loss: 0.45733 | Valid Loss: 0.45931 | Time: 0.47 seconds\n",
            "Epoch: 370 | Train Loss: 0.45650 | Valid Loss: 0.45986 | Time: 0.47 seconds\n",
            "Epoch: 371 | Train Loss: 0.45566 | Valid Loss: 0.45991 | Time: 0.46 seconds\n",
            "Epoch: 372 | Train Loss: 0.45486 | Valid Loss: 0.45997 | Time: 0.47 seconds\n",
            "Epoch: 373 | Train Loss: 0.45404 | Valid Loss: 0.45873 | Time: 0.47 seconds\n",
            "Epoch: 374 | Train Loss: 0.45320 | Valid Loss: 0.45979 | Time: 0.48 seconds\n",
            "Epoch: 375 | Train Loss: 0.45237 | Valid Loss: 0.45640 | Time: 0.48 seconds\n",
            "Epoch: 376 | Train Loss: 0.45155 | Valid Loss: 0.45305 | Time: 0.48 seconds\n",
            "Epoch: 377 | Train Loss: 0.45072 | Valid Loss: 0.45367 | Time: 0.48 seconds\n",
            "Epoch: 378 | Train Loss: 0.44988 | Valid Loss: 0.45531 | Time: 0.46 seconds\n",
            "Epoch: 379 | Train Loss: 0.44906 | Valid Loss: 0.45394 | Time: 0.47 seconds\n",
            "Epoch: 380 | Train Loss: 0.44823 | Valid Loss: 0.45056 | Time: 0.47 seconds\n",
            "Epoch: 381 | Train Loss: 0.44745 | Valid Loss: 0.45010 | Time: 0.47 seconds\n",
            "Epoch: 382 | Train Loss: 0.44662 | Valid Loss: 0.44831 | Time: 0.48 seconds\n",
            "Epoch: 383 | Train Loss: 0.44579 | Valid Loss: 0.44963 | Time: 0.47 seconds\n",
            "Epoch: 384 | Train Loss: 0.44497 | Valid Loss: 0.44651 | Time: 0.48 seconds\n",
            "Epoch: 385 | Train Loss: 0.44418 | Valid Loss: 0.44936 | Time: 0.46 seconds\n",
            "Epoch: 386 | Train Loss: 0.44338 | Valid Loss: 0.44673 | Time: 0.48 seconds\n",
            "Epoch: 387 | Train Loss: 0.44254 | Valid Loss: 0.44790 | Time: 0.48 seconds\n",
            "Epoch: 388 | Train Loss: 0.44175 | Valid Loss: 0.44503 | Time: 0.49 seconds\n",
            "Epoch: 389 | Train Loss: 0.44092 | Valid Loss: 0.44446 | Time: 0.47 seconds\n",
            "Epoch: 390 | Train Loss: 0.44012 | Valid Loss: 0.44200 | Time: 0.48 seconds\n",
            "Epoch: 391 | Train Loss: 0.43928 | Valid Loss: 0.44505 | Time: 0.47 seconds\n",
            "Epoch: 392 | Train Loss: 0.43851 | Valid Loss: 0.44249 | Time: 0.47 seconds\n",
            "Epoch: 393 | Train Loss: 0.43771 | Valid Loss: 0.44175 | Time: 0.48 seconds\n",
            "Epoch: 394 | Train Loss: 0.43691 | Valid Loss: 0.43876 | Time: 0.48 seconds\n",
            "Epoch: 395 | Train Loss: 0.43612 | Valid Loss: 0.43861 | Time: 0.47 seconds\n",
            "Epoch: 396 | Train Loss: 0.43533 | Valid Loss: 0.43843 | Time: 0.48 seconds\n",
            "Epoch: 397 | Train Loss: 0.43452 | Valid Loss: 0.43835 | Time: 0.47 seconds\n",
            "Epoch: 398 | Train Loss: 0.43369 | Valid Loss: 0.43705 | Time: 0.47 seconds\n",
            "Epoch: 399 | Train Loss: 0.43290 | Valid Loss: 0.43692 | Time: 0.48 seconds\n",
            "Epoch: 400 | Train Loss: 0.43212 | Valid Loss: 0.43608 | Time: 0.48 seconds\n",
            "Epoch: 401 | Train Loss: 0.43130 | Valid Loss: 0.43527 | Time: 0.48 seconds\n",
            "Epoch: 402 | Train Loss: 0.43054 | Valid Loss: 0.43317 | Time: 0.48 seconds\n",
            "Epoch: 403 | Train Loss: 0.42975 | Valid Loss: 0.43197 | Time: 0.50 seconds\n",
            "Epoch: 404 | Train Loss: 0.42893 | Valid Loss: 0.43364 | Time: 0.46 seconds\n",
            "Epoch: 405 | Train Loss: 0.42818 | Valid Loss: 0.43252 | Time: 0.46 seconds\n",
            "Epoch: 406 | Train Loss: 0.42738 | Valid Loss: 0.43007 | Time: 0.49 seconds\n",
            "Epoch: 407 | Train Loss: 0.42658 | Valid Loss: 0.43236 | Time: 0.50 seconds\n",
            "Epoch: 408 | Train Loss: 0.42582 | Valid Loss: 0.43067 | Time: 0.46 seconds\n",
            "Epoch: 409 | Train Loss: 0.42504 | Valid Loss: 0.42908 | Time: 0.48 seconds\n",
            "Epoch: 410 | Train Loss: 0.42426 | Valid Loss: 0.42888 | Time: 0.48 seconds\n",
            "Epoch: 411 | Train Loss: 0.42348 | Valid Loss: 0.42757 | Time: 0.49 seconds\n",
            "Epoch: 412 | Train Loss: 0.42273 | Valid Loss: 0.42440 | Time: 0.47 seconds\n",
            "Epoch: 413 | Train Loss: 0.42189 | Valid Loss: 0.42692 | Time: 0.47 seconds\n",
            "Epoch: 414 | Train Loss: 0.42113 | Valid Loss: 0.42593 | Time: 0.47 seconds\n",
            "Epoch: 415 | Train Loss: 0.42037 | Valid Loss: 0.42562 | Time: 0.46 seconds\n",
            "Epoch: 416 | Train Loss: 0.41958 | Valid Loss: 0.42321 | Time: 0.49 seconds\n",
            "Epoch: 417 | Train Loss: 0.41880 | Valid Loss: 0.42204 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41804 | Valid Loss: 0.41993 | Time: 0.50 seconds\n",
            "Epoch: 419 | Train Loss: 0.41726 | Valid Loss: 0.42095 | Time: 0.47 seconds\n",
            "Epoch: 420 | Train Loss: 0.41653 | Valid Loss: 0.41925 | Time: 0.48 seconds\n",
            "Epoch: 421 | Train Loss: 0.41576 | Valid Loss: 0.41837 | Time: 0.47 seconds\n",
            "Epoch: 422 | Train Loss: 0.41497 | Valid Loss: 0.41673 | Time: 0.48 seconds\n",
            "Epoch: 423 | Train Loss: 0.41421 | Valid Loss: 0.41611 | Time: 0.46 seconds\n",
            "Epoch: 424 | Train Loss: 0.41347 | Valid Loss: 0.41918 | Time: 0.47 seconds\n",
            "Epoch: 425 | Train Loss: 0.41270 | Valid Loss: 0.41728 | Time: 0.46 seconds\n",
            "Epoch: 426 | Train Loss: 0.41195 | Valid Loss: 0.41544 | Time: 0.51 seconds\n",
            "Epoch: 427 | Train Loss: 0.41119 | Valid Loss: 0.41381 | Time: 0.48 seconds\n",
            "Epoch: 428 | Train Loss: 0.41045 | Valid Loss: 0.41612 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40967 | Valid Loss: 0.41084 | Time: 0.47 seconds\n",
            "Epoch: 430 | Train Loss: 0.40897 | Valid Loss: 0.41398 | Time: 0.46 seconds\n",
            "Epoch: 431 | Train Loss: 0.40822 | Valid Loss: 0.41171 | Time: 0.48 seconds\n",
            "Epoch: 432 | Train Loss: 0.40742 | Valid Loss: 0.41199 | Time: 0.46 seconds\n",
            "Epoch: 433 | Train Loss: 0.40671 | Valid Loss: 0.40869 | Time: 0.49 seconds\n",
            "Epoch: 434 | Train Loss: 0.40595 | Valid Loss: 0.40858 | Time: 0.46 seconds\n",
            "Epoch: 435 | Train Loss: 0.40518 | Valid Loss: 0.40896 | Time: 0.48 seconds\n",
            "Epoch: 436 | Train Loss: 0.40447 | Valid Loss: 0.41030 | Time: 0.46 seconds\n",
            "Epoch: 437 | Train Loss: 0.40375 | Valid Loss: 0.40853 | Time: 0.46 seconds\n",
            "Epoch: 438 | Train Loss: 0.40300 | Valid Loss: 0.40739 | Time: 0.46 seconds\n",
            "Epoch: 439 | Train Loss: 0.40227 | Valid Loss: 0.40543 | Time: 0.49 seconds\n",
            "Epoch: 440 | Train Loss: 0.40150 | Valid Loss: 0.40287 | Time: 0.47 seconds\n",
            "Epoch: 441 | Train Loss: 0.40077 | Valid Loss: 0.40543 | Time: 0.48 seconds\n",
            "Epoch: 442 | Train Loss: 0.40008 | Valid Loss: 0.40401 | Time: 0.46 seconds\n",
            "Epoch: 443 | Train Loss: 0.39931 | Valid Loss: 0.40419 | Time: 0.46 seconds\n",
            "Epoch: 444 | Train Loss: 0.39858 | Valid Loss: 0.40441 | Time: 0.48 seconds\n",
            "Epoch: 445 | Train Loss: 0.39788 | Valid Loss: 0.40358 | Time: 0.46 seconds\n",
            "Epoch: 446 | Train Loss: 0.39715 | Valid Loss: 0.40130 | Time: 0.48 seconds\n",
            "Epoch: 447 | Train Loss: 0.39646 | Valid Loss: 0.40072 | Time: 0.48 seconds\n",
            "Epoch: 448 | Train Loss: 0.39572 | Valid Loss: 0.40035 | Time: 0.49 seconds\n",
            "Epoch: 449 | Train Loss: 0.39500 | Valid Loss: 0.39732 | Time: 0.47 seconds\n",
            "Epoch: 450 | Train Loss: 0.39425 | Valid Loss: 0.39740 | Time: 0.47 seconds\n",
            "Epoch: 451 | Train Loss: 0.39348 | Valid Loss: 0.39590 | Time: 0.48 seconds\n",
            "Epoch: 452 | Train Loss: 0.39280 | Valid Loss: 0.39734 | Time: 0.47 seconds\n",
            "Epoch: 453 | Train Loss: 0.39212 | Valid Loss: 0.39605 | Time: 0.47 seconds\n",
            "Epoch: 454 | Train Loss: 0.39142 | Valid Loss: 0.39383 | Time: 0.49 seconds\n",
            "Epoch: 455 | Train Loss: 0.39068 | Valid Loss: 0.39259 | Time: 0.48 seconds\n",
            "Epoch: 456 | Train Loss: 0.38997 | Valid Loss: 0.39330 | Time: 0.47 seconds\n",
            "Epoch: 457 | Train Loss: 0.38923 | Valid Loss: 0.39413 | Time: 0.46 seconds\n",
            "Epoch: 458 | Train Loss: 0.38856 | Valid Loss: 0.39179 | Time: 0.46 seconds\n",
            "Epoch: 459 | Train Loss: 0.38788 | Valid Loss: 0.39096 | Time: 0.49 seconds\n",
            "Epoch: 460 | Train Loss: 0.38719 | Valid Loss: 0.39186 | Time: 0.45 seconds\n",
            "Epoch: 461 | Train Loss: 0.38646 | Valid Loss: 0.39193 | Time: 0.46 seconds\n",
            "Epoch: 462 | Train Loss: 0.38576 | Valid Loss: 0.39037 | Time: 0.47 seconds\n",
            "Epoch: 463 | Train Loss: 0.38506 | Valid Loss: 0.39071 | Time: 0.48 seconds\n",
            "Epoch: 464 | Train Loss: 0.38438 | Valid Loss: 0.38987 | Time: 0.48 seconds\n",
            "Epoch: 465 | Train Loss: 0.38363 | Valid Loss: 0.38695 | Time: 0.48 seconds\n",
            "Epoch: 466 | Train Loss: 0.38297 | Valid Loss: 0.38865 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38231 | Valid Loss: 0.38551 | Time: 0.48 seconds\n",
            "Epoch: 468 | Train Loss: 0.38159 | Valid Loss: 0.38374 | Time: 0.48 seconds\n",
            "Epoch: 469 | Train Loss: 0.38095 | Valid Loss: 0.38530 | Time: 0.48 seconds\n",
            "Epoch: 470 | Train Loss: 0.38023 | Valid Loss: 0.38402 | Time: 0.45 seconds\n",
            "Epoch: 471 | Train Loss: 0.37954 | Valid Loss: 0.38254 | Time: 0.47 seconds\n",
            "Epoch: 472 | Train Loss: 0.37888 | Valid Loss: 0.38217 | Time: 0.49 seconds\n",
            "Epoch: 473 | Train Loss: 0.37815 | Valid Loss: 0.38280 | Time: 0.48 seconds\n",
            "Epoch: 474 | Train Loss: 0.37750 | Valid Loss: 0.37993 | Time: 0.48 seconds\n",
            "Epoch: 475 | Train Loss: 0.37683 | Valid Loss: 0.38272 | Time: 0.47 seconds\n",
            "Epoch: 476 | Train Loss: 0.37615 | Valid Loss: 0.37954 | Time: 0.48 seconds\n",
            "Epoch: 477 | Train Loss: 0.37547 | Valid Loss: 0.38084 | Time: 0.46 seconds\n",
            "Epoch: 478 | Train Loss: 0.37481 | Valid Loss: 0.37962 | Time: 0.47 seconds\n",
            "Epoch: 479 | Train Loss: 0.37409 | Valid Loss: 0.37803 | Time: 0.47 seconds\n",
            "Epoch: 480 | Train Loss: 0.37347 | Valid Loss: 0.37823 | Time: 0.47 seconds\n",
            "Epoch: 481 | Train Loss: 0.37279 | Valid Loss: 0.37696 | Time: 0.47 seconds\n",
            "Epoch: 482 | Train Loss: 0.37215 | Valid Loss: 0.37479 | Time: 0.48 seconds\n",
            "Epoch: 483 | Train Loss: 0.37149 | Valid Loss: 0.37717 | Time: 0.48 seconds\n",
            "Epoch: 484 | Train Loss: 0.37080 | Valid Loss: 0.37470 | Time: 0.47 seconds\n",
            "Epoch: 485 | Train Loss: 0.37015 | Valid Loss: 0.37396 | Time: 0.47 seconds\n",
            "Epoch: 486 | Train Loss: 0.36947 | Valid Loss: 0.37483 | Time: 0.47 seconds\n",
            "Epoch: 487 | Train Loss: 0.36884 | Valid Loss: 0.37297 | Time: 0.49 seconds\n",
            "Epoch: 488 | Train Loss: 0.36819 | Valid Loss: 0.37229 | Time: 0.46 seconds\n",
            "Epoch: 489 | Train Loss: 0.36754 | Valid Loss: 0.37175 | Time: 0.49 seconds\n",
            "Epoch: 490 | Train Loss: 0.36686 | Valid Loss: 0.36947 | Time: 0.47 seconds\n",
            "Epoch: 491 | Train Loss: 0.36622 | Valid Loss: 0.36873 | Time: 0.48 seconds\n",
            "Epoch: 492 | Train Loss: 0.36556 | Valid Loss: 0.36790 | Time: 0.46 seconds\n",
            "Epoch: 493 | Train Loss: 0.36494 | Valid Loss: 0.36915 | Time: 0.48 seconds\n",
            "Epoch: 494 | Train Loss: 0.36424 | Valid Loss: 0.36762 | Time: 0.47 seconds\n",
            "Epoch: 495 | Train Loss: 0.36361 | Valid Loss: 0.36790 | Time: 0.47 seconds\n",
            "Epoch: 496 | Train Loss: 0.36298 | Valid Loss: 0.36705 | Time: 0.50 seconds\n",
            "Epoch: 497 | Train Loss: 0.36233 | Valid Loss: 0.36534 | Time: 0.49 seconds\n",
            "Epoch: 498 | Train Loss: 0.36170 | Valid Loss: 0.36706 | Time: 0.47 seconds\n",
            "Epoch: 499 | Train Loss: 0.36106 | Valid Loss: 0.36390 | Time: 0.48 seconds\n",
            "Epoch: 500 | Train Loss: 0.36040 | Valid Loss: 0.36189 | Time: 0.47 seconds\n",
            "Epoch: 501 | Train Loss: 0.35979 | Valid Loss: 0.36346 | Time: 0.48 seconds\n",
            "Epoch: 502 | Train Loss: 0.35916 | Valid Loss: 0.36313 | Time: 0.47 seconds\n",
            "Epoch: 503 | Train Loss: 0.35853 | Valid Loss: 0.36222 | Time: 0.46 seconds\n",
            "Epoch: 504 | Train Loss: 0.35792 | Valid Loss: 0.35809 | Time: 0.47 seconds\n",
            "Epoch: 505 | Train Loss: 0.35728 | Valid Loss: 0.36307 | Time: 0.46 seconds\n",
            "Epoch: 506 | Train Loss: 0.35664 | Valid Loss: 0.36225 | Time: 0.48 seconds\n",
            "Epoch: 507 | Train Loss: 0.35602 | Valid Loss: 0.36131 | Time: 0.46 seconds\n",
            "Epoch: 508 | Train Loss: 0.35538 | Valid Loss: 0.35771 | Time: 0.47 seconds\n",
            "Epoch: 509 | Train Loss: 0.35475 | Valid Loss: 0.35892 | Time: 0.47 seconds\n",
            "Epoch: 510 | Train Loss: 0.35411 | Valid Loss: 0.35559 | Time: 0.50 seconds\n",
            "Epoch: 511 | Train Loss: 0.35352 | Valid Loss: 0.35757 | Time: 0.45 seconds\n",
            "Epoch: 512 | Train Loss: 0.35292 | Valid Loss: 0.35568 | Time: 0.46 seconds\n",
            "Epoch: 513 | Train Loss: 0.35227 | Valid Loss: 0.35443 | Time: 0.47 seconds\n",
            "Epoch: 514 | Train Loss: 0.35168 | Valid Loss: 0.35548 | Time: 0.48 seconds\n",
            "Epoch: 515 | Train Loss: 0.35107 | Valid Loss: 0.35713 | Time: 0.46 seconds\n",
            "Epoch: 516 | Train Loss: 0.35045 | Valid Loss: 0.35396 | Time: 0.47 seconds\n",
            "Epoch: 517 | Train Loss: 0.34986 | Valid Loss: 0.35584 | Time: 0.47 seconds\n",
            "Epoch: 518 | Train Loss: 0.34923 | Valid Loss: 0.35298 | Time: 0.46 seconds\n",
            "Epoch: 519 | Train Loss: 0.34866 | Valid Loss: 0.35307 | Time: 0.48 seconds\n",
            "Epoch: 520 | Train Loss: 0.34800 | Valid Loss: 0.35121 | Time: 0.47 seconds\n",
            "Epoch: 521 | Train Loss: 0.34742 | Valid Loss: 0.35138 | Time: 0.46 seconds\n",
            "Epoch: 522 | Train Loss: 0.34680 | Valid Loss: 0.35044 | Time: 0.48 seconds\n",
            "Epoch: 523 | Train Loss: 0.34622 | Valid Loss: 0.34862 | Time: 0.48 seconds\n",
            "Epoch: 524 | Train Loss: 0.34564 | Valid Loss: 0.34886 | Time: 0.47 seconds\n",
            "Epoch: 525 | Train Loss: 0.34499 | Valid Loss: 0.35121 | Time: 0.46 seconds\n",
            "Epoch: 526 | Train Loss: 0.34441 | Valid Loss: 0.34739 | Time: 0.46 seconds\n",
            "Epoch: 527 | Train Loss: 0.34380 | Valid Loss: 0.34760 | Time: 0.47 seconds\n",
            "Epoch: 528 | Train Loss: 0.34322 | Valid Loss: 0.34809 | Time: 0.45 seconds\n",
            "Epoch: 529 | Train Loss: 0.34267 | Valid Loss: 0.34941 | Time: 0.47 seconds\n",
            "Epoch: 530 | Train Loss: 0.34203 | Valid Loss: 0.34647 | Time: 0.48 seconds\n",
            "Epoch: 531 | Train Loss: 0.34143 | Valid Loss: 0.34606 | Time: 0.47 seconds\n",
            "Epoch: 532 | Train Loss: 0.34084 | Valid Loss: 0.34489 | Time: 0.49 seconds\n",
            "Epoch: 533 | Train Loss: 0.34027 | Valid Loss: 0.34271 | Time: 0.47 seconds\n",
            "Epoch: 534 | Train Loss: 0.33969 | Valid Loss: 0.34714 | Time: 0.48 seconds\n",
            "Epoch: 535 | Train Loss: 0.33908 | Valid Loss: 0.34158 | Time: 0.47 seconds\n",
            "Epoch: 536 | Train Loss: 0.33853 | Valid Loss: 0.34243 | Time: 0.48 seconds\n",
            "Epoch: 537 | Train Loss: 0.33791 | Valid Loss: 0.34372 | Time: 0.47 seconds\n",
            "Epoch: 538 | Train Loss: 0.33736 | Valid Loss: 0.34048 | Time: 0.47 seconds\n",
            "Epoch: 539 | Train Loss: 0.33677 | Valid Loss: 0.34102 | Time: 0.47 seconds\n",
            "Epoch: 540 | Train Loss: 0.33617 | Valid Loss: 0.34099 | Time: 0.48 seconds\n",
            "Epoch: 541 | Train Loss: 0.33562 | Valid Loss: 0.34021 | Time: 0.47 seconds\n",
            "Epoch: 542 | Train Loss: 0.33501 | Valid Loss: 0.33874 | Time: 0.49 seconds\n",
            "Epoch: 543 | Train Loss: 0.33449 | Valid Loss: 0.34009 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33388 | Valid Loss: 0.33868 | Time: 0.48 seconds\n",
            "Epoch: 545 | Train Loss: 0.33334 | Valid Loss: 0.33647 | Time: 0.47 seconds\n",
            "Epoch: 546 | Train Loss: 0.33279 | Valid Loss: 0.33698 | Time: 0.46 seconds\n",
            "Epoch: 547 | Train Loss: 0.33223 | Valid Loss: 0.33365 | Time: 0.49 seconds\n",
            "Epoch: 548 | Train Loss: 0.33163 | Valid Loss: 0.33609 | Time: 0.49 seconds\n",
            "Epoch: 549 | Train Loss: 0.33111 | Valid Loss: 0.33536 | Time: 0.48 seconds\n",
            "Epoch: 550 | Train Loss: 0.33053 | Valid Loss: 0.33551 | Time: 0.47 seconds\n",
            "Epoch: 551 | Train Loss: 0.32994 | Valid Loss: 0.33342 | Time: 0.48 seconds\n",
            "Epoch: 552 | Train Loss: 0.32935 | Valid Loss: 0.33241 | Time: 0.47 seconds\n",
            "Epoch: 553 | Train Loss: 0.32880 | Valid Loss: 0.33276 | Time: 0.47 seconds\n",
            "Epoch: 554 | Train Loss: 0.32825 | Valid Loss: 0.33094 | Time: 0.47 seconds\n",
            "Epoch: 555 | Train Loss: 0.32773 | Valid Loss: 0.33081 | Time: 0.48 seconds\n",
            "Epoch: 556 | Train Loss: 0.32713 | Valid Loss: 0.33133 | Time: 0.46 seconds\n",
            "Epoch: 557 | Train Loss: 0.32658 | Valid Loss: 0.33216 | Time: 0.47 seconds\n",
            "Epoch: 558 | Train Loss: 0.32607 | Valid Loss: 0.33131 | Time: 0.47 seconds\n",
            "Epoch: 559 | Train Loss: 0.32547 | Valid Loss: 0.32777 | Time: 0.47 seconds\n",
            "Epoch: 560 | Train Loss: 0.32494 | Valid Loss: 0.33053 | Time: 0.48 seconds\n",
            "Epoch: 561 | Train Loss: 0.32438 | Valid Loss: 0.32837 | Time: 0.45 seconds\n",
            "Epoch: 562 | Train Loss: 0.32384 | Valid Loss: 0.32716 | Time: 0.47 seconds\n",
            "Epoch: 563 | Train Loss: 0.32333 | Valid Loss: 0.32810 | Time: 0.48 seconds\n",
            "Epoch: 564 | Train Loss: 0.32278 | Valid Loss: 0.32686 | Time: 0.47 seconds\n",
            "Epoch: 565 | Train Loss: 0.32219 | Valid Loss: 0.32478 | Time: 0.47 seconds\n",
            "Epoch: 566 | Train Loss: 0.32168 | Valid Loss: 0.32641 | Time: 0.47 seconds\n",
            "Epoch: 567 | Train Loss: 0.32117 | Valid Loss: 0.32320 | Time: 0.47 seconds\n",
            "Epoch: 568 | Train Loss: 0.32060 | Valid Loss: 0.32426 | Time: 0.48 seconds\n",
            "Epoch: 569 | Train Loss: 0.32006 | Valid Loss: 0.32323 | Time: 0.46 seconds\n",
            "Epoch: 570 | Train Loss: 0.31954 | Valid Loss: 0.32156 | Time: 0.47 seconds\n",
            "Epoch: 571 | Train Loss: 0.31898 | Valid Loss: 0.32140 | Time: 0.46 seconds\n",
            "Epoch: 572 | Train Loss: 0.31847 | Valid Loss: 0.32206 | Time: 0.47 seconds\n",
            "Epoch: 573 | Train Loss: 0.31793 | Valid Loss: 0.32092 | Time: 0.48 seconds\n",
            "Epoch: 574 | Train Loss: 0.31737 | Valid Loss: 0.32009 | Time: 0.47 seconds\n",
            "Epoch: 575 | Train Loss: 0.31688 | Valid Loss: 0.32134 | Time: 0.47 seconds\n",
            "Epoch: 576 | Train Loss: 0.31635 | Valid Loss: 0.32038 | Time: 0.46 seconds\n",
            "Epoch: 577 | Train Loss: 0.31580 | Valid Loss: 0.31859 | Time: 0.49 seconds\n",
            "Epoch: 578 | Train Loss: 0.31529 | Valid Loss: 0.31627 | Time: 0.47 seconds\n",
            "Epoch: 579 | Train Loss: 0.31477 | Valid Loss: 0.31874 | Time: 0.47 seconds\n",
            "Epoch: 580 | Train Loss: 0.31423 | Valid Loss: 0.31726 | Time: 0.47 seconds\n",
            "Epoch: 581 | Train Loss: 0.31372 | Valid Loss: 0.31721 | Time: 0.48 seconds\n",
            "Epoch: 582 | Train Loss: 0.31316 | Valid Loss: 0.31548 | Time: 0.48 seconds\n",
            "Epoch: 583 | Train Loss: 0.31269 | Valid Loss: 0.31659 | Time: 0.48 seconds\n",
            "Epoch: 584 | Train Loss: 0.31213 | Valid Loss: 0.31593 | Time: 0.46 seconds\n",
            "Epoch: 585 | Train Loss: 0.31164 | Valid Loss: 0.31620 | Time: 0.46 seconds\n",
            "Epoch: 586 | Train Loss: 0.31108 | Valid Loss: 0.31385 | Time: 0.49 seconds\n",
            "Epoch: 587 | Train Loss: 0.31055 | Valid Loss: 0.31580 | Time: 0.46 seconds\n",
            "Epoch: 588 | Train Loss: 0.31004 | Valid Loss: 0.31387 | Time: 0.47 seconds\n",
            "Epoch: 589 | Train Loss: 0.30957 | Valid Loss: 0.31370 | Time: 0.47 seconds\n",
            "Epoch: 590 | Train Loss: 0.30905 | Valid Loss: 0.31281 | Time: 0.47 seconds\n",
            "Epoch: 591 | Train Loss: 0.30854 | Valid Loss: 0.31242 | Time: 0.46 seconds\n",
            "Epoch: 592 | Train Loss: 0.30802 | Valid Loss: 0.31130 | Time: 0.50 seconds\n",
            "Epoch: 593 | Train Loss: 0.30753 | Valid Loss: 0.30999 | Time: 0.47 seconds\n",
            "Epoch: 594 | Train Loss: 0.30699 | Valid Loss: 0.31098 | Time: 0.47 seconds\n",
            "Epoch: 595 | Train Loss: 0.30645 | Valid Loss: 0.30910 | Time: 0.47 seconds\n",
            "Epoch: 596 | Train Loss: 0.30599 | Valid Loss: 0.31102 | Time: 0.49 seconds\n",
            "Epoch: 597 | Train Loss: 0.30549 | Valid Loss: 0.30985 | Time: 0.46 seconds\n",
            "Epoch: 598 | Train Loss: 0.30500 | Valid Loss: 0.30813 | Time: 0.49 seconds\n",
            "Epoch: 599 | Train Loss: 0.30445 | Valid Loss: 0.30957 | Time: 0.46 seconds\n",
            "Epoch: 600 | Train Loss: 0.30396 | Valid Loss: 0.30802 | Time: 0.46 seconds\n",
            "Epoch: 601 | Train Loss: 0.30345 | Valid Loss: 0.30566 | Time: 0.48 seconds\n",
            "Epoch: 602 | Train Loss: 0.30296 | Valid Loss: 0.30551 | Time: 0.48 seconds\n",
            "Epoch: 603 | Train Loss: 0.30248 | Valid Loss: 0.30615 | Time: 0.47 seconds\n",
            "Epoch: 604 | Train Loss: 0.30197 | Valid Loss: 0.30610 | Time: 0.46 seconds\n",
            "Epoch: 605 | Train Loss: 0.30147 | Valid Loss: 0.30527 | Time: 0.48 seconds\n",
            "Epoch: 606 | Train Loss: 0.30099 | Valid Loss: 0.30568 | Time: 0.47 seconds\n",
            "Epoch: 607 | Train Loss: 0.30049 | Valid Loss: 0.30404 | Time: 0.49 seconds\n",
            "Epoch: 608 | Train Loss: 0.30001 | Valid Loss: 0.30503 | Time: 0.46 seconds\n",
            "Epoch: 609 | Train Loss: 0.29951 | Valid Loss: 0.30489 | Time: 0.48 seconds\n",
            "Epoch: 610 | Train Loss: 0.29900 | Valid Loss: 0.30376 | Time: 0.47 seconds\n",
            "Epoch: 611 | Train Loss: 0.29854 | Valid Loss: 0.30197 | Time: 0.49 seconds\n",
            "Epoch: 612 | Train Loss: 0.29806 | Valid Loss: 0.30189 | Time: 0.48 seconds\n",
            "Epoch: 613 | Train Loss: 0.29752 | Valid Loss: 0.29954 | Time: 0.47 seconds\n",
            "Epoch: 614 | Train Loss: 0.29710 | Valid Loss: 0.29916 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29659 | Valid Loss: 0.29833 | Time: 0.46 seconds\n",
            "Epoch: 616 | Train Loss: 0.29610 | Valid Loss: 0.29942 | Time: 0.48 seconds\n",
            "Epoch: 617 | Train Loss: 0.29559 | Valid Loss: 0.30172 | Time: 0.48 seconds\n",
            "Epoch: 618 | Train Loss: 0.29514 | Valid Loss: 0.29877 | Time: 0.48 seconds\n",
            "Epoch: 619 | Train Loss: 0.29462 | Valid Loss: 0.29760 | Time: 0.47 seconds\n",
            "Epoch: 620 | Train Loss: 0.29415 | Valid Loss: 0.30024 | Time: 0.47 seconds\n",
            "Epoch: 621 | Train Loss: 0.29370 | Valid Loss: 0.29612 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29317 | Valid Loss: 0.29842 | Time: 0.46 seconds\n",
            "Epoch: 623 | Train Loss: 0.29268 | Valid Loss: 0.29498 | Time: 0.48 seconds\n",
            "Epoch: 624 | Train Loss: 0.29221 | Valid Loss: 0.29598 | Time: 0.47 seconds\n",
            "Epoch: 625 | Train Loss: 0.29178 | Valid Loss: 0.29565 | Time: 0.47 seconds\n",
            "Epoch: 626 | Train Loss: 0.29129 | Valid Loss: 0.29675 | Time: 0.47 seconds\n",
            "Epoch: 627 | Train Loss: 0.29084 | Valid Loss: 0.29449 | Time: 0.46 seconds\n",
            "Epoch: 628 | Train Loss: 0.29037 | Valid Loss: 0.29203 | Time: 0.47 seconds\n",
            "Epoch: 629 | Train Loss: 0.28987 | Valid Loss: 0.29279 | Time: 0.47 seconds\n",
            "Epoch: 630 | Train Loss: 0.28939 | Valid Loss: 0.29307 | Time: 0.46 seconds\n",
            "Epoch: 631 | Train Loss: 0.28889 | Valid Loss: 0.29179 | Time: 0.47 seconds\n",
            "Epoch: 632 | Train Loss: 0.28844 | Valid Loss: 0.29305 | Time: 0.45 seconds\n",
            "Epoch: 633 | Train Loss: 0.28801 | Valid Loss: 0.29224 | Time: 0.47 seconds\n",
            "Epoch: 634 | Train Loss: 0.28750 | Valid Loss: 0.29146 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28707 | Valid Loss: 0.28992 | Time: 0.48 seconds\n",
            "Epoch: 636 | Train Loss: 0.28660 | Valid Loss: 0.28825 | Time: 0.46 seconds\n",
            "Epoch: 637 | Train Loss: 0.28615 | Valid Loss: 0.28952 | Time: 0.47 seconds\n",
            "Epoch: 638 | Train Loss: 0.28567 | Valid Loss: 0.28713 | Time: 0.46 seconds\n",
            "Epoch: 639 | Train Loss: 0.28521 | Valid Loss: 0.28966 | Time: 0.47 seconds\n",
            "Epoch: 640 | Train Loss: 0.28476 | Valid Loss: 0.29020 | Time: 0.47 seconds\n",
            "Epoch: 641 | Train Loss: 0.28426 | Valid Loss: 0.28624 | Time: 0.46 seconds\n",
            "Epoch: 642 | Train Loss: 0.28382 | Valid Loss: 0.28607 | Time: 0.48 seconds\n",
            "Epoch: 643 | Train Loss: 0.28333 | Valid Loss: 0.28793 | Time: 0.45 seconds\n",
            "Epoch: 644 | Train Loss: 0.28285 | Valid Loss: 0.28765 | Time: 0.48 seconds\n",
            "Epoch: 645 | Train Loss: 0.28243 | Valid Loss: 0.28415 | Time: 0.47 seconds\n",
            "Epoch: 646 | Train Loss: 0.28199 | Valid Loss: 0.28584 | Time: 0.47 seconds\n",
            "Epoch: 647 | Train Loss: 0.28151 | Valid Loss: 0.28460 | Time: 0.47 seconds\n",
            "Epoch: 648 | Train Loss: 0.28106 | Valid Loss: 0.28468 | Time: 0.47 seconds\n",
            "Epoch: 649 | Train Loss: 0.28059 | Valid Loss: 0.28667 | Time: 0.47 seconds\n",
            "Epoch: 650 | Train Loss: 0.28017 | Valid Loss: 0.28245 | Time: 0.47 seconds\n",
            "Epoch: 651 | Train Loss: 0.27969 | Valid Loss: 0.28138 | Time: 0.47 seconds\n",
            "Epoch: 652 | Train Loss: 0.27924 | Valid Loss: 0.28295 | Time: 0.48 seconds\n",
            "Epoch: 653 | Train Loss: 0.27877 | Valid Loss: 0.28426 | Time: 0.46 seconds\n",
            "Epoch: 654 | Train Loss: 0.27838 | Valid Loss: 0.28222 | Time: 0.45 seconds\n",
            "Epoch: 655 | Train Loss: 0.27789 | Valid Loss: 0.28161 | Time: 0.48 seconds\n",
            "Epoch: 656 | Train Loss: 0.27747 | Valid Loss: 0.27952 | Time: 0.46 seconds\n",
            "Epoch: 657 | Train Loss: 0.27697 | Valid Loss: 0.28124 | Time: 0.48 seconds\n",
            "Epoch: 658 | Train Loss: 0.27654 | Valid Loss: 0.27938 | Time: 0.47 seconds\n",
            "Epoch: 659 | Train Loss: 0.27609 | Valid Loss: 0.27965 | Time: 0.47 seconds\n",
            "Epoch: 660 | Train Loss: 0.27563 | Valid Loss: 0.27904 | Time: 0.48 seconds\n",
            "Epoch: 661 | Train Loss: 0.27523 | Valid Loss: 0.28006 | Time: 0.48 seconds\n",
            "Epoch: 662 | Train Loss: 0.27477 | Valid Loss: 0.28069 | Time: 0.46 seconds\n",
            "Epoch: 663 | Train Loss: 0.27436 | Valid Loss: 0.27574 | Time: 0.48 seconds\n",
            "Epoch: 664 | Train Loss: 0.27389 | Valid Loss: 0.27798 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27344 | Valid Loss: 0.27712 | Time: 0.46 seconds\n",
            "Epoch: 666 | Train Loss: 0.27301 | Valid Loss: 0.27705 | Time: 0.46 seconds\n",
            "Epoch: 667 | Train Loss: 0.27254 | Valid Loss: 0.27408 | Time: 0.48 seconds\n",
            "Epoch: 668 | Train Loss: 0.27213 | Valid Loss: 0.27581 | Time: 0.50 seconds\n",
            "Epoch: 669 | Train Loss: 0.27170 | Valid Loss: 0.27590 | Time: 0.46 seconds\n",
            "Epoch: 670 | Train Loss: 0.27122 | Valid Loss: 0.27659 | Time: 0.48 seconds\n",
            "Epoch: 671 | Train Loss: 0.27086 | Valid Loss: 0.27375 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27036 | Valid Loss: 0.27326 | Time: 0.47 seconds\n",
            "Epoch: 673 | Train Loss: 0.26990 | Valid Loss: 0.27520 | Time: 0.47 seconds\n",
            "Epoch: 674 | Train Loss: 0.26948 | Valid Loss: 0.27295 | Time: 0.49 seconds\n",
            "Epoch: 675 | Train Loss: 0.26907 | Valid Loss: 0.27199 | Time: 0.46 seconds\n",
            "Epoch: 676 | Train Loss: 0.26866 | Valid Loss: 0.27321 | Time: 0.47 seconds\n",
            "Epoch: 677 | Train Loss: 0.26823 | Valid Loss: 0.27242 | Time: 0.47 seconds\n",
            "Epoch: 678 | Train Loss: 0.26777 | Valid Loss: 0.27302 | Time: 0.49 seconds\n",
            "Epoch: 679 | Train Loss: 0.26733 | Valid Loss: 0.27195 | Time: 0.46 seconds\n",
            "Epoch: 680 | Train Loss: 0.26691 | Valid Loss: 0.27089 | Time: 0.46 seconds\n",
            "Epoch: 681 | Train Loss: 0.26648 | Valid Loss: 0.27021 | Time: 0.48 seconds\n",
            "Epoch: 682 | Train Loss: 0.26610 | Valid Loss: 0.26945 | Time: 0.48 seconds\n",
            "Epoch: 683 | Train Loss: 0.26561 | Valid Loss: 0.26814 | Time: 0.47 seconds\n",
            "Epoch: 684 | Train Loss: 0.26520 | Valid Loss: 0.26943 | Time: 0.46 seconds\n",
            "Epoch: 685 | Train Loss: 0.26481 | Valid Loss: 0.26840 | Time: 0.48 seconds\n",
            "Epoch: 686 | Train Loss: 0.26440 | Valid Loss: 0.26787 | Time: 0.46 seconds\n",
            "Epoch: 687 | Train Loss: 0.26396 | Valid Loss: 0.26818 | Time: 0.49 seconds\n",
            "Epoch: 688 | Train Loss: 0.26350 | Valid Loss: 0.26788 | Time: 0.45 seconds\n",
            "Epoch: 689 | Train Loss: 0.26310 | Valid Loss: 0.26456 | Time: 0.49 seconds\n",
            "Epoch: 690 | Train Loss: 0.26269 | Valid Loss: 0.26653 | Time: 0.46 seconds\n",
            "Epoch: 691 | Train Loss: 0.26226 | Valid Loss: 0.26578 | Time: 0.46 seconds\n",
            "Epoch: 692 | Train Loss: 0.26184 | Valid Loss: 0.26649 | Time: 0.46 seconds\n",
            "Epoch: 693 | Train Loss: 0.26144 | Valid Loss: 0.26454 | Time: 0.47 seconds\n",
            "Epoch: 694 | Train Loss: 0.26097 | Valid Loss: 0.26419 | Time: 0.47 seconds\n",
            "Epoch: 695 | Train Loss: 0.26056 | Valid Loss: 0.26231 | Time: 0.46 seconds\n",
            "Epoch: 696 | Train Loss: 0.26014 | Valid Loss: 0.26348 | Time: 0.46 seconds\n",
            "Epoch: 697 | Train Loss: 0.25973 | Valid Loss: 0.26380 | Time: 0.47 seconds\n",
            "Epoch: 698 | Train Loss: 0.25932 | Valid Loss: 0.26303 | Time: 0.48 seconds\n",
            "Epoch: 699 | Train Loss: 0.25888 | Valid Loss: 0.26266 | Time: 0.46 seconds\n",
            "Epoch: 700 | Train Loss: 0.25846 | Valid Loss: 0.26308 | Time: 0.47 seconds\n",
            "Epoch: 701 | Train Loss: 0.25808 | Valid Loss: 0.26210 | Time: 0.47 seconds\n",
            "Epoch: 702 | Train Loss: 0.25767 | Valid Loss: 0.26019 | Time: 0.48 seconds\n",
            "Epoch: 703 | Train Loss: 0.25721 | Valid Loss: 0.25979 | Time: 0.46 seconds\n",
            "Epoch: 704 | Train Loss: 0.25687 | Valid Loss: 0.26010 | Time: 0.46 seconds\n",
            "Epoch: 705 | Train Loss: 0.25638 | Valid Loss: 0.26129 | Time: 0.46 seconds\n",
            "Epoch: 706 | Train Loss: 0.25603 | Valid Loss: 0.25977 | Time: 0.47 seconds\n",
            "Epoch: 707 | Train Loss: 0.25561 | Valid Loss: 0.25899 | Time: 0.48 seconds\n",
            "Epoch: 708 | Train Loss: 0.25520 | Valid Loss: 0.25934 | Time: 0.46 seconds\n",
            "Epoch: 709 | Train Loss: 0.25473 | Valid Loss: 0.25880 | Time: 0.47 seconds\n",
            "Epoch: 710 | Train Loss: 0.25437 | Valid Loss: 0.25772 | Time: 0.47 seconds\n",
            "Epoch: 711 | Train Loss: 0.25395 | Valid Loss: 0.25791 | Time: 0.47 seconds\n",
            "Epoch: 712 | Train Loss: 0.25354 | Valid Loss: 0.25714 | Time: 0.48 seconds\n",
            "Epoch: 713 | Train Loss: 0.25318 | Valid Loss: 0.25723 | Time: 0.47 seconds\n",
            "Epoch: 714 | Train Loss: 0.25279 | Valid Loss: 0.25582 | Time: 0.49 seconds\n",
            "Epoch: 715 | Train Loss: 0.25237 | Valid Loss: 0.25563 | Time: 0.47 seconds\n",
            "Epoch: 716 | Train Loss: 0.25197 | Valid Loss: 0.25518 | Time: 0.47 seconds\n",
            "Epoch: 717 | Train Loss: 0.25154 | Valid Loss: 0.25389 | Time: 0.48 seconds\n",
            "Epoch: 718 | Train Loss: 0.25112 | Valid Loss: 0.25441 | Time: 0.46 seconds\n",
            "Epoch: 719 | Train Loss: 0.25075 | Valid Loss: 0.25445 | Time: 0.46 seconds\n",
            "Epoch: 720 | Train Loss: 0.25035 | Valid Loss: 0.25287 | Time: 0.48 seconds\n",
            "Epoch: 721 | Train Loss: 0.24997 | Valid Loss: 0.25296 | Time: 0.48 seconds\n",
            "Epoch: 722 | Train Loss: 0.24956 | Valid Loss: 0.25203 | Time: 0.48 seconds\n",
            "Epoch: 723 | Train Loss: 0.24912 | Valid Loss: 0.25322 | Time: 0.47 seconds\n",
            "Epoch: 724 | Train Loss: 0.24877 | Valid Loss: 0.25213 | Time: 0.48 seconds\n",
            "Epoch: 725 | Train Loss: 0.24837 | Valid Loss: 0.25036 | Time: 0.47 seconds\n",
            "Epoch: 726 | Train Loss: 0.24797 | Valid Loss: 0.25067 | Time: 0.47 seconds\n",
            "Epoch: 727 | Train Loss: 0.24760 | Valid Loss: 0.25160 | Time: 0.45 seconds\n",
            "Epoch: 728 | Train Loss: 0.24716 | Valid Loss: 0.25007 | Time: 0.49 seconds\n",
            "Epoch: 729 | Train Loss: 0.24677 | Valid Loss: 0.25228 | Time: 0.47 seconds\n",
            "Epoch: 730 | Train Loss: 0.24638 | Valid Loss: 0.24823 | Time: 0.47 seconds\n",
            "Epoch: 731 | Train Loss: 0.24598 | Valid Loss: 0.24937 | Time: 0.46 seconds\n",
            "Epoch: 732 | Train Loss: 0.24559 | Valid Loss: 0.24940 | Time: 0.47 seconds\n",
            "Epoch: 733 | Train Loss: 0.24521 | Valid Loss: 0.24794 | Time: 0.48 seconds\n",
            "Epoch: 734 | Train Loss: 0.24480 | Valid Loss: 0.24835 | Time: 0.46 seconds\n",
            "Epoch: 735 | Train Loss: 0.24438 | Valid Loss: 0.24810 | Time: 0.47 seconds\n",
            "Epoch: 736 | Train Loss: 0.24401 | Valid Loss: 0.24753 | Time: 0.47 seconds\n",
            "Epoch: 737 | Train Loss: 0.24368 | Valid Loss: 0.24616 | Time: 0.48 seconds\n",
            "Epoch: 738 | Train Loss: 0.24326 | Valid Loss: 0.24765 | Time: 0.47 seconds\n",
            "Epoch: 739 | Train Loss: 0.24289 | Valid Loss: 0.24674 | Time: 0.46 seconds\n",
            "Epoch: 740 | Train Loss: 0.24250 | Valid Loss: 0.24558 | Time: 0.46 seconds\n",
            "Epoch: 741 | Train Loss: 0.24210 | Valid Loss: 0.24596 | Time: 0.46 seconds\n",
            "Epoch: 742 | Train Loss: 0.24173 | Valid Loss: 0.24435 | Time: 0.47 seconds\n",
            "Epoch: 743 | Train Loss: 0.24129 | Valid Loss: 0.24476 | Time: 0.48 seconds\n",
            "Epoch: 744 | Train Loss: 0.24099 | Valid Loss: 0.24595 | Time: 0.46 seconds\n",
            "Epoch: 745 | Train Loss: 0.24058 | Valid Loss: 0.24354 | Time: 0.48 seconds\n",
            "Epoch: 746 | Train Loss: 0.24015 | Valid Loss: 0.24329 | Time: 0.47 seconds\n",
            "Epoch: 747 | Train Loss: 0.23979 | Valid Loss: 0.24530 | Time: 0.46 seconds\n",
            "Epoch: 748 | Train Loss: 0.23944 | Valid Loss: 0.24221 | Time: 0.50 seconds\n",
            "Epoch: 749 | Train Loss: 0.23900 | Valid Loss: 0.24342 | Time: 0.47 seconds\n",
            "Epoch: 750 | Train Loss: 0.23866 | Valid Loss: 0.24236 | Time: 0.47 seconds\n",
            "Epoch: 751 | Train Loss: 0.23828 | Valid Loss: 0.24191 | Time: 0.48 seconds\n",
            "Epoch: 752 | Train Loss: 0.23792 | Valid Loss: 0.24109 | Time: 0.48 seconds\n",
            "Epoch: 753 | Train Loss: 0.23748 | Valid Loss: 0.24196 | Time: 0.46 seconds\n",
            "Epoch: 754 | Train Loss: 0.23715 | Valid Loss: 0.24143 | Time: 0.46 seconds\n",
            "Epoch: 755 | Train Loss: 0.23675 | Valid Loss: 0.24020 | Time: 0.47 seconds\n",
            "Epoch: 756 | Train Loss: 0.23638 | Valid Loss: 0.23904 | Time: 0.48 seconds\n",
            "Epoch: 757 | Train Loss: 0.23602 | Valid Loss: 0.24006 | Time: 0.47 seconds\n",
            "Epoch: 758 | Train Loss: 0.23563 | Valid Loss: 0.24198 | Time: 0.47 seconds\n",
            "Epoch: 759 | Train Loss: 0.23526 | Valid Loss: 0.23715 | Time: 0.47 seconds\n",
            "Epoch: 760 | Train Loss: 0.23490 | Valid Loss: 0.23863 | Time: 0.46 seconds\n",
            "Epoch: 761 | Train Loss: 0.23449 | Valid Loss: 0.23748 | Time: 0.47 seconds\n",
            "Epoch: 762 | Train Loss: 0.23413 | Valid Loss: 0.23755 | Time: 0.46 seconds\n",
            "Epoch: 763 | Train Loss: 0.23377 | Valid Loss: 0.23694 | Time: 0.49 seconds\n",
            "Epoch: 764 | Train Loss: 0.23340 | Valid Loss: 0.23709 | Time: 0.48 seconds\n",
            "Epoch: 765 | Train Loss: 0.23299 | Valid Loss: 0.23615 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23267 | Valid Loss: 0.23419 | Time: 0.46 seconds\n",
            "Epoch: 767 | Train Loss: 0.23226 | Valid Loss: 0.23625 | Time: 0.48 seconds\n",
            "Epoch: 768 | Train Loss: 0.23191 | Valid Loss: 0.23329 | Time: 0.47 seconds\n",
            "Epoch: 769 | Train Loss: 0.23153 | Valid Loss: 0.23483 | Time: 0.47 seconds\n",
            "Epoch: 770 | Train Loss: 0.23114 | Valid Loss: 0.23402 | Time: 0.45 seconds\n",
            "Epoch: 771 | Train Loss: 0.23078 | Valid Loss: 0.23280 | Time: 0.47 seconds\n",
            "Epoch: 772 | Train Loss: 0.23040 | Valid Loss: 0.23437 | Time: 0.48 seconds\n",
            "Epoch: 773 | Train Loss: 0.23005 | Valid Loss: 0.23586 | Time: 0.46 seconds\n",
            "Epoch: 774 | Train Loss: 0.22971 | Valid Loss: 0.23347 | Time: 0.47 seconds\n",
            "Epoch: 775 | Train Loss: 0.22933 | Valid Loss: 0.23324 | Time: 0.46 seconds\n",
            "Epoch: 776 | Train Loss: 0.22899 | Valid Loss: 0.23057 | Time: 0.49 seconds\n",
            "Epoch: 777 | Train Loss: 0.22866 | Valid Loss: 0.23234 | Time: 0.46 seconds\n",
            "Epoch: 778 | Train Loss: 0.22828 | Valid Loss: 0.23250 | Time: 0.47 seconds\n",
            "Epoch: 779 | Train Loss: 0.22785 | Valid Loss: 0.23273 | Time: 0.46 seconds\n",
            "Epoch: 780 | Train Loss: 0.22753 | Valid Loss: 0.23006 | Time: 0.48 seconds\n",
            "Epoch: 781 | Train Loss: 0.22717 | Valid Loss: 0.23195 | Time: 0.46 seconds\n",
            "Epoch: 782 | Train Loss: 0.22681 | Valid Loss: 0.23078 | Time: 0.48 seconds\n",
            "Epoch: 783 | Train Loss: 0.22645 | Valid Loss: 0.22841 | Time: 0.47 seconds\n",
            "Epoch: 784 | Train Loss: 0.22605 | Valid Loss: 0.22991 | Time: 0.47 seconds\n",
            "Epoch: 785 | Train Loss: 0.22570 | Valid Loss: 0.22904 | Time: 0.47 seconds\n",
            "Epoch: 786 | Train Loss: 0.22537 | Valid Loss: 0.22800 | Time: 0.51 seconds\n",
            "Epoch: 787 | Train Loss: 0.22500 | Valid Loss: 0.22927 | Time: 0.47 seconds\n",
            "Epoch: 788 | Train Loss: 0.22461 | Valid Loss: 0.22862 | Time: 0.46 seconds\n",
            "Epoch: 789 | Train Loss: 0.22428 | Valid Loss: 0.22795 | Time: 0.47 seconds\n",
            "Epoch: 790 | Train Loss: 0.22396 | Valid Loss: 0.22716 | Time: 0.46 seconds\n",
            "Epoch: 791 | Train Loss: 0.22359 | Valid Loss: 0.22726 | Time: 0.48 seconds\n",
            "Epoch: 792 | Train Loss: 0.22326 | Valid Loss: 0.22688 | Time: 0.48 seconds\n",
            "Epoch: 793 | Train Loss: 0.22289 | Valid Loss: 0.22534 | Time: 0.48 seconds\n",
            "Epoch: 794 | Train Loss: 0.22251 | Valid Loss: 0.22438 | Time: 0.47 seconds\n",
            "Epoch: 795 | Train Loss: 0.22218 | Valid Loss: 0.22506 | Time: 0.48 seconds\n",
            "Epoch: 796 | Train Loss: 0.22181 | Valid Loss: 0.22589 | Time: 0.47 seconds\n",
            "Epoch: 797 | Train Loss: 0.22148 | Valid Loss: 0.22701 | Time: 0.49 seconds\n",
            "Epoch: 798 | Train Loss: 0.22112 | Valid Loss: 0.22429 | Time: 0.47 seconds\n",
            "Epoch: 799 | Train Loss: 0.22073 | Valid Loss: 0.22346 | Time: 0.49 seconds\n",
            "Epoch: 800 | Train Loss: 0.22043 | Valid Loss: 0.22398 | Time: 0.46 seconds\n",
            "Epoch: 801 | Train Loss: 0.22004 | Valid Loss: 0.22299 | Time: 0.48 seconds\n",
            "Epoch: 802 | Train Loss: 0.21969 | Valid Loss: 0.22359 | Time: 0.47 seconds\n",
            "Epoch: 803 | Train Loss: 0.21938 | Valid Loss: 0.22431 | Time: 0.47 seconds\n",
            "Epoch: 804 | Train Loss: 0.21899 | Valid Loss: 0.22405 | Time: 0.47 seconds\n",
            "Epoch: 805 | Train Loss: 0.21863 | Valid Loss: 0.21970 | Time: 0.47 seconds\n",
            "Epoch: 806 | Train Loss: 0.21834 | Valid Loss: 0.22035 | Time: 0.49 seconds\n",
            "Epoch: 807 | Train Loss: 0.21799 | Valid Loss: 0.22066 | Time: 0.46 seconds\n",
            "Epoch: 808 | Train Loss: 0.21767 | Valid Loss: 0.21969 | Time: 0.48 seconds\n",
            "Epoch: 809 | Train Loss: 0.21728 | Valid Loss: 0.21918 | Time: 0.47 seconds\n",
            "Epoch: 810 | Train Loss: 0.21694 | Valid Loss: 0.22059 | Time: 0.47 seconds\n",
            "Epoch: 811 | Train Loss: 0.21662 | Valid Loss: 0.21975 | Time: 0.46 seconds\n",
            "Epoch: 812 | Train Loss: 0.21625 | Valid Loss: 0.21791 | Time: 0.48 seconds\n",
            "Epoch: 813 | Train Loss: 0.21593 | Valid Loss: 0.21881 | Time: 0.46 seconds\n",
            "Epoch: 814 | Train Loss: 0.21556 | Valid Loss: 0.21882 | Time: 0.48 seconds\n",
            "Epoch: 815 | Train Loss: 0.21521 | Valid Loss: 0.21822 | Time: 0.47 seconds\n",
            "Epoch: 816 | Train Loss: 0.21491 | Valid Loss: 0.21668 | Time: 0.47 seconds\n",
            "Epoch: 817 | Train Loss: 0.21457 | Valid Loss: 0.21704 | Time: 0.47 seconds\n",
            "Epoch: 818 | Train Loss: 0.21421 | Valid Loss: 0.21757 | Time: 0.46 seconds\n",
            "Epoch: 819 | Train Loss: 0.21383 | Valid Loss: 0.21739 | Time: 0.48 seconds\n",
            "Epoch: 820 | Train Loss: 0.21353 | Valid Loss: 0.21719 | Time: 0.48 seconds\n",
            "Epoch: 821 | Train Loss: 0.21318 | Valid Loss: 0.21503 | Time: 0.48 seconds\n",
            "Epoch: 822 | Train Loss: 0.21287 | Valid Loss: 0.21482 | Time: 0.46 seconds\n",
            "Epoch: 823 | Train Loss: 0.21254 | Valid Loss: 0.21568 | Time: 0.47 seconds\n",
            "Epoch: 824 | Train Loss: 0.21217 | Valid Loss: 0.21583 | Time: 0.47 seconds\n",
            "Epoch: 825 | Train Loss: 0.21184 | Valid Loss: 0.21411 | Time: 0.50 seconds\n",
            "Epoch: 826 | Train Loss: 0.21153 | Valid Loss: 0.21540 | Time: 0.48 seconds\n",
            "Epoch: 827 | Train Loss: 0.21117 | Valid Loss: 0.21370 | Time: 0.49 seconds\n",
            "Epoch: 828 | Train Loss: 0.21086 | Valid Loss: 0.21306 | Time: 0.47 seconds\n",
            "Epoch: 829 | Train Loss: 0.21048 | Valid Loss: 0.21358 | Time: 0.49 seconds\n",
            "Epoch: 830 | Train Loss: 0.21016 | Valid Loss: 0.21259 | Time: 0.47 seconds\n",
            "Epoch: 831 | Train Loss: 0.20982 | Valid Loss: 0.21373 | Time: 0.47 seconds\n",
            "Epoch: 832 | Train Loss: 0.20953 | Valid Loss: 0.21290 | Time: 0.50 seconds\n",
            "Epoch: 833 | Train Loss: 0.20917 | Valid Loss: 0.21436 | Time: 0.48 seconds\n",
            "Epoch: 834 | Train Loss: 0.20882 | Valid Loss: 0.21258 | Time: 0.48 seconds\n",
            "Epoch: 835 | Train Loss: 0.20851 | Valid Loss: 0.21275 | Time: 0.47 seconds\n",
            "Epoch: 836 | Train Loss: 0.20818 | Valid Loss: 0.21034 | Time: 0.51 seconds\n",
            "Epoch: 837 | Train Loss: 0.20784 | Valid Loss: 0.21046 | Time: 0.49 seconds\n",
            "Epoch: 838 | Train Loss: 0.20751 | Valid Loss: 0.21070 | Time: 0.48 seconds\n",
            "Epoch: 839 | Train Loss: 0.20719 | Valid Loss: 0.20947 | Time: 0.47 seconds\n",
            "Epoch: 840 | Train Loss: 0.20685 | Valid Loss: 0.20765 | Time: 0.48 seconds\n",
            "Epoch: 841 | Train Loss: 0.20655 | Valid Loss: 0.21032 | Time: 0.49 seconds\n",
            "Epoch: 842 | Train Loss: 0.20625 | Valid Loss: 0.20901 | Time: 0.47 seconds\n",
            "Epoch: 843 | Train Loss: 0.20586 | Valid Loss: 0.21041 | Time: 0.46 seconds\n",
            "Epoch: 844 | Train Loss: 0.20559 | Valid Loss: 0.20855 | Time: 0.46 seconds\n",
            "Epoch: 845 | Train Loss: 0.20524 | Valid Loss: 0.20737 | Time: 0.46 seconds\n",
            "Epoch: 846 | Train Loss: 0.20494 | Valid Loss: 0.20769 | Time: 0.49 seconds\n",
            "Epoch: 847 | Train Loss: 0.20460 | Valid Loss: 0.20771 | Time: 0.47 seconds\n",
            "Epoch: 848 | Train Loss: 0.20428 | Valid Loss: 0.20666 | Time: 0.48 seconds\n",
            "Epoch: 849 | Train Loss: 0.20395 | Valid Loss: 0.20763 | Time: 0.47 seconds\n",
            "Epoch: 850 | Train Loss: 0.20363 | Valid Loss: 0.20586 | Time: 0.48 seconds\n",
            "Epoch: 851 | Train Loss: 0.20328 | Valid Loss: 0.20733 | Time: 0.50 seconds\n",
            "Epoch: 852 | Train Loss: 0.20298 | Valid Loss: 0.20525 | Time: 0.47 seconds\n",
            "Epoch: 853 | Train Loss: 0.20265 | Valid Loss: 0.20598 | Time: 0.47 seconds\n",
            "Epoch: 854 | Train Loss: 0.20232 | Valid Loss: 0.20449 | Time: 0.47 seconds\n",
            "Epoch: 855 | Train Loss: 0.20203 | Valid Loss: 0.20457 | Time: 0.49 seconds\n",
            "Epoch: 856 | Train Loss: 0.20168 | Valid Loss: 0.20377 | Time: 0.48 seconds\n",
            "Epoch: 857 | Train Loss: 0.20136 | Valid Loss: 0.20502 | Time: 0.47 seconds\n",
            "Epoch: 858 | Train Loss: 0.20110 | Valid Loss: 0.20307 | Time: 0.47 seconds\n",
            "Epoch: 859 | Train Loss: 0.20074 | Valid Loss: 0.20474 | Time: 0.48 seconds\n",
            "Epoch: 860 | Train Loss: 0.20043 | Valid Loss: 0.20367 | Time: 0.46 seconds\n",
            "Epoch: 861 | Train Loss: 0.20010 | Valid Loss: 0.20308 | Time: 0.50 seconds\n",
            "Epoch: 862 | Train Loss: 0.19978 | Valid Loss: 0.20389 | Time: 0.47 seconds\n",
            "Epoch: 863 | Train Loss: 0.19949 | Valid Loss: 0.20327 | Time: 0.46 seconds\n",
            "Epoch: 864 | Train Loss: 0.19918 | Valid Loss: 0.20212 | Time: 0.50 seconds\n",
            "Epoch: 865 | Train Loss: 0.19884 | Valid Loss: 0.20067 | Time: 0.46 seconds\n",
            "Epoch: 866 | Train Loss: 0.19855 | Valid Loss: 0.20279 | Time: 0.48 seconds\n",
            "Epoch: 867 | Train Loss: 0.19821 | Valid Loss: 0.20106 | Time: 0.45 seconds\n",
            "Epoch: 868 | Train Loss: 0.19794 | Valid Loss: 0.19976 | Time: 0.48 seconds\n",
            "Epoch: 869 | Train Loss: 0.19760 | Valid Loss: 0.20183 | Time: 0.46 seconds\n",
            "Epoch: 870 | Train Loss: 0.19732 | Valid Loss: 0.19956 | Time: 0.47 seconds\n",
            "Epoch: 871 | Train Loss: 0.19698 | Valid Loss: 0.20024 | Time: 0.47 seconds\n",
            "Epoch: 872 | Train Loss: 0.19670 | Valid Loss: 0.20077 | Time: 0.47 seconds\n",
            "Epoch: 873 | Train Loss: 0.19634 | Valid Loss: 0.19934 | Time: 0.46 seconds\n",
            "Epoch: 874 | Train Loss: 0.19605 | Valid Loss: 0.19955 | Time: 0.47 seconds\n",
            "Epoch: 875 | Train Loss: 0.19573 | Valid Loss: 0.19928 | Time: 0.47 seconds\n",
            "Epoch: 876 | Train Loss: 0.19548 | Valid Loss: 0.19825 | Time: 0.47 seconds\n",
            "Epoch: 877 | Train Loss: 0.19512 | Valid Loss: 0.19883 | Time: 0.46 seconds\n",
            "Epoch: 878 | Train Loss: 0.19479 | Valid Loss: 0.19609 | Time: 0.48 seconds\n",
            "Epoch: 879 | Train Loss: 0.19453 | Valid Loss: 0.19670 | Time: 0.48 seconds\n",
            "Epoch: 880 | Train Loss: 0.19419 | Valid Loss: 0.19755 | Time: 0.47 seconds\n",
            "Epoch: 881 | Train Loss: 0.19391 | Valid Loss: 0.19705 | Time: 0.47 seconds\n",
            "Epoch: 882 | Train Loss: 0.19359 | Valid Loss: 0.19679 | Time: 0.47 seconds\n",
            "Epoch: 883 | Train Loss: 0.19326 | Valid Loss: 0.19639 | Time: 0.48 seconds\n",
            "Epoch: 884 | Train Loss: 0.19297 | Valid Loss: 0.19566 | Time: 0.47 seconds\n",
            "Epoch: 885 | Train Loss: 0.19267 | Valid Loss: 0.19689 | Time: 0.48 seconds\n",
            "Epoch: 886 | Train Loss: 0.19237 | Valid Loss: 0.19523 | Time: 0.46 seconds\n",
            "Epoch: 887 | Train Loss: 0.19206 | Valid Loss: 0.19533 | Time: 0.47 seconds\n",
            "Epoch: 888 | Train Loss: 0.19177 | Valid Loss: 0.19446 | Time: 0.47 seconds\n",
            "Epoch: 889 | Train Loss: 0.19148 | Valid Loss: 0.19375 | Time: 0.48 seconds\n",
            "Epoch: 890 | Train Loss: 0.19119 | Valid Loss: 0.19401 | Time: 0.48 seconds\n",
            "Epoch: 891 | Train Loss: 0.19091 | Valid Loss: 0.19318 | Time: 0.47 seconds\n",
            "Epoch: 892 | Train Loss: 0.19057 | Valid Loss: 0.19325 | Time: 0.47 seconds\n",
            "Epoch: 893 | Train Loss: 0.19025 | Valid Loss: 0.19284 | Time: 0.46 seconds\n",
            "Epoch: 894 | Train Loss: 0.18998 | Valid Loss: 0.19270 | Time: 0.48 seconds\n",
            "Epoch: 895 | Train Loss: 0.18968 | Valid Loss: 0.19196 | Time: 0.48 seconds\n",
            "Epoch: 896 | Train Loss: 0.18937 | Valid Loss: 0.19137 | Time: 0.48 seconds\n",
            "Epoch: 897 | Train Loss: 0.18909 | Valid Loss: 0.19156 | Time: 0.46 seconds\n",
            "Epoch: 898 | Train Loss: 0.18872 | Valid Loss: 0.18973 | Time: 0.48 seconds\n",
            "Epoch: 899 | Train Loss: 0.18845 | Valid Loss: 0.19147 | Time: 0.45 seconds\n",
            "Epoch: 900 | Train Loss: 0.18816 | Valid Loss: 0.19151 | Time: 0.48 seconds\n",
            "Epoch: 901 | Train Loss: 0.18788 | Valid Loss: 0.19031 | Time: 0.46 seconds\n",
            "Epoch: 902 | Train Loss: 0.18758 | Valid Loss: 0.19108 | Time: 0.47 seconds\n",
            "Epoch: 903 | Train Loss: 0.18727 | Valid Loss: 0.19104 | Time: 0.46 seconds\n",
            "Epoch: 904 | Train Loss: 0.18699 | Valid Loss: 0.18986 | Time: 0.45 seconds\n",
            "Epoch: 905 | Train Loss: 0.18673 | Valid Loss: 0.19078 | Time: 0.49 seconds\n",
            "Epoch: 906 | Train Loss: 0.18642 | Valid Loss: 0.18913 | Time: 0.48 seconds\n",
            "Epoch: 907 | Train Loss: 0.18611 | Valid Loss: 0.18751 | Time: 0.47 seconds\n",
            "Epoch: 908 | Train Loss: 0.18583 | Valid Loss: 0.18884 | Time: 0.46 seconds\n",
            "Epoch: 909 | Train Loss: 0.18552 | Valid Loss: 0.18873 | Time: 0.47 seconds\n",
            "Epoch: 910 | Train Loss: 0.18522 | Valid Loss: 0.18875 | Time: 0.46 seconds\n",
            "Epoch: 911 | Train Loss: 0.18493 | Valid Loss: 0.18785 | Time: 0.47 seconds\n",
            "Epoch: 912 | Train Loss: 0.18465 | Valid Loss: 0.18710 | Time: 0.49 seconds\n",
            "Epoch: 913 | Train Loss: 0.18434 | Valid Loss: 0.18598 | Time: 0.50 seconds\n",
            "Epoch: 914 | Train Loss: 0.18406 | Valid Loss: 0.18576 | Time: 0.47 seconds\n",
            "Epoch: 915 | Train Loss: 0.18381 | Valid Loss: 0.18649 | Time: 0.47 seconds\n",
            "Epoch: 916 | Train Loss: 0.18346 | Valid Loss: 0.18578 | Time: 0.48 seconds\n",
            "Epoch: 917 | Train Loss: 0.18319 | Valid Loss: 0.18467 | Time: 0.50 seconds\n",
            "Epoch: 918 | Train Loss: 0.18289 | Valid Loss: 0.18499 | Time: 0.47 seconds\n",
            "Epoch: 919 | Train Loss: 0.18264 | Valid Loss: 0.18647 | Time: 0.48 seconds\n",
            "Epoch: 920 | Train Loss: 0.18234 | Valid Loss: 0.18455 | Time: 0.47 seconds\n",
            "Epoch: 921 | Train Loss: 0.18208 | Valid Loss: 0.18477 | Time: 0.46 seconds\n",
            "Epoch: 922 | Train Loss: 0.18176 | Valid Loss: 0.18476 | Time: 0.48 seconds\n",
            "Epoch: 923 | Train Loss: 0.18149 | Valid Loss: 0.18385 | Time: 0.47 seconds\n",
            "Epoch: 924 | Train Loss: 0.18120 | Valid Loss: 0.18474 | Time: 0.48 seconds\n",
            "Epoch: 925 | Train Loss: 0.18090 | Valid Loss: 0.18311 | Time: 0.47 seconds\n",
            "Epoch: 926 | Train Loss: 0.18061 | Valid Loss: 0.18349 | Time: 0.48 seconds\n",
            "Epoch: 927 | Train Loss: 0.18033 | Valid Loss: 0.18257 | Time: 0.48 seconds\n",
            "Epoch: 928 | Train Loss: 0.18007 | Valid Loss: 0.18225 | Time: 0.48 seconds\n",
            "Epoch: 929 | Train Loss: 0.17981 | Valid Loss: 0.18357 | Time: 0.46 seconds\n",
            "Epoch: 930 | Train Loss: 0.17949 | Valid Loss: 0.18340 | Time: 0.46 seconds\n",
            "Epoch: 931 | Train Loss: 0.17920 | Valid Loss: 0.18190 | Time: 0.47 seconds\n",
            "Epoch: 932 | Train Loss: 0.17894 | Valid Loss: 0.18229 | Time: 0.48 seconds\n",
            "Epoch: 933 | Train Loss: 0.17864 | Valid Loss: 0.18216 | Time: 0.46 seconds\n",
            "Epoch: 934 | Train Loss: 0.17839 | Valid Loss: 0.18169 | Time: 0.46 seconds\n",
            "Epoch: 935 | Train Loss: 0.17812 | Valid Loss: 0.18064 | Time: 0.47 seconds\n",
            "Epoch: 936 | Train Loss: 0.17781 | Valid Loss: 0.18057 | Time: 0.47 seconds\n",
            "Epoch: 937 | Train Loss: 0.17754 | Valid Loss: 0.17991 | Time: 0.48 seconds\n",
            "Epoch: 938 | Train Loss: 0.17722 | Valid Loss: 0.17982 | Time: 0.46 seconds\n",
            "Epoch: 939 | Train Loss: 0.17698 | Valid Loss: 0.18082 | Time: 0.47 seconds\n",
            "Epoch: 940 | Train Loss: 0.17670 | Valid Loss: 0.18175 | Time: 0.46 seconds\n",
            "Epoch: 941 | Train Loss: 0.17643 | Valid Loss: 0.17646 | Time: 0.49 seconds\n",
            "Epoch: 942 | Train Loss: 0.17613 | Valid Loss: 0.17962 | Time: 0.50 seconds\n",
            "Epoch: 943 | Train Loss: 0.17587 | Valid Loss: 0.17658 | Time: 0.47 seconds\n",
            "Epoch: 944 | Train Loss: 0.17564 | Valid Loss: 0.17761 | Time: 0.45 seconds\n",
            "Epoch: 945 | Train Loss: 0.17529 | Valid Loss: 0.17808 | Time: 0.48 seconds\n",
            "Epoch: 946 | Train Loss: 0.17506 | Valid Loss: 0.17722 | Time: 0.45 seconds\n",
            "Epoch: 947 | Train Loss: 0.17479 | Valid Loss: 0.17752 | Time: 0.46 seconds\n",
            "Epoch: 948 | Train Loss: 0.17450 | Valid Loss: 0.17694 | Time: 0.49 seconds\n",
            "Epoch: 949 | Train Loss: 0.17424 | Valid Loss: 0.17817 | Time: 0.47 seconds\n",
            "Epoch: 950 | Train Loss: 0.17397 | Valid Loss: 0.17590 | Time: 0.48 seconds\n",
            "Epoch: 951 | Train Loss: 0.17369 | Valid Loss: 0.17689 | Time: 0.47 seconds\n",
            "Epoch: 952 | Train Loss: 0.17339 | Valid Loss: 0.17660 | Time: 0.46 seconds\n",
            "Epoch: 953 | Train Loss: 0.17316 | Valid Loss: 0.17495 | Time: 0.47 seconds\n",
            "Epoch: 954 | Train Loss: 0.17286 | Valid Loss: 0.17578 | Time: 0.47 seconds\n",
            "Epoch: 955 | Train Loss: 0.17261 | Valid Loss: 0.17513 | Time: 0.46 seconds\n",
            "Epoch: 956 | Train Loss: 0.17234 | Valid Loss: 0.17605 | Time: 0.47 seconds\n",
            "Epoch: 957 | Train Loss: 0.17209 | Valid Loss: 0.17403 | Time: 0.46 seconds\n",
            "Epoch: 958 | Train Loss: 0.17180 | Valid Loss: 0.17432 | Time: 0.46 seconds\n",
            "Epoch: 959 | Train Loss: 0.17154 | Valid Loss: 0.17360 | Time: 0.47 seconds\n",
            "Epoch: 960 | Train Loss: 0.17126 | Valid Loss: 0.17335 | Time: 0.48 seconds\n",
            "Epoch: 961 | Train Loss: 0.17099 | Valid Loss: 0.17328 | Time: 0.48 seconds\n",
            "Epoch: 962 | Train Loss: 0.17071 | Valid Loss: 0.17373 | Time: 0.47 seconds\n",
            "Epoch: 963 | Train Loss: 0.17044 | Valid Loss: 0.17236 | Time: 0.48 seconds\n",
            "Epoch: 964 | Train Loss: 0.17020 | Valid Loss: 0.17250 | Time: 0.47 seconds\n",
            "Epoch: 965 | Train Loss: 0.16993 | Valid Loss: 0.17263 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16967 | Valid Loss: 0.17177 | Time: 0.46 seconds\n",
            "Epoch: 967 | Train Loss: 0.16937 | Valid Loss: 0.17236 | Time: 0.47 seconds\n",
            "Epoch: 968 | Train Loss: 0.16913 | Valid Loss: 0.17149 | Time: 0.46 seconds\n",
            "Epoch: 969 | Train Loss: 0.16884 | Valid Loss: 0.17144 | Time: 0.47 seconds\n",
            "Epoch: 970 | Train Loss: 0.16860 | Valid Loss: 0.17106 | Time: 0.48 seconds\n",
            "Epoch: 971 | Train Loss: 0.16835 | Valid Loss: 0.17170 | Time: 0.48 seconds\n",
            "Epoch: 972 | Train Loss: 0.16805 | Valid Loss: 0.17133 | Time: 0.47 seconds\n",
            "Epoch: 973 | Train Loss: 0.16778 | Valid Loss: 0.16954 | Time: 0.47 seconds\n",
            "Epoch: 974 | Train Loss: 0.16756 | Valid Loss: 0.16991 | Time: 0.46 seconds\n",
            "Epoch: 975 | Train Loss: 0.16729 | Valid Loss: 0.16979 | Time: 0.48 seconds\n",
            "Epoch: 976 | Train Loss: 0.16704 | Valid Loss: 0.16880 | Time: 0.50 seconds\n",
            "Epoch: 977 | Train Loss: 0.16675 | Valid Loss: 0.17025 | Time: 0.47 seconds\n",
            "Epoch: 978 | Train Loss: 0.16651 | Valid Loss: 0.16836 | Time: 0.47 seconds\n",
            "Epoch: 979 | Train Loss: 0.16626 | Valid Loss: 0.17017 | Time: 0.47 seconds\n",
            "Epoch: 980 | Train Loss: 0.16599 | Valid Loss: 0.16808 | Time: 0.49 seconds\n",
            "Epoch: 981 | Train Loss: 0.16573 | Valid Loss: 0.16865 | Time: 0.46 seconds\n",
            "Epoch: 982 | Train Loss: 0.16548 | Valid Loss: 0.16703 | Time: 0.47 seconds\n",
            "Epoch: 983 | Train Loss: 0.16520 | Valid Loss: 0.16816 | Time: 0.47 seconds\n",
            "Epoch: 984 | Train Loss: 0.16497 | Valid Loss: 0.16674 | Time: 0.47 seconds\n",
            "Epoch: 985 | Train Loss: 0.16470 | Valid Loss: 0.16663 | Time: 0.48 seconds\n",
            "Epoch: 986 | Train Loss: 0.16443 | Valid Loss: 0.16820 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16420 | Valid Loss: 0.16689 | Time: 0.46 seconds\n",
            "Epoch: 988 | Train Loss: 0.16395 | Valid Loss: 0.16625 | Time: 0.47 seconds\n",
            "Epoch: 989 | Train Loss: 0.16365 | Valid Loss: 0.16682 | Time: 0.47 seconds\n",
            "Epoch: 990 | Train Loss: 0.16344 | Valid Loss: 0.16672 | Time: 0.46 seconds\n",
            "Epoch: 991 | Train Loss: 0.16317 | Valid Loss: 0.16576 | Time: 0.51 seconds\n",
            "Epoch: 992 | Train Loss: 0.16293 | Valid Loss: 0.16516 | Time: 0.46 seconds\n",
            "Epoch: 993 | Train Loss: 0.16264 | Valid Loss: 0.16540 | Time: 0.49 seconds\n",
            "Epoch: 994 | Train Loss: 0.16240 | Valid Loss: 0.16507 | Time: 0.47 seconds\n",
            "Epoch: 995 | Train Loss: 0.16215 | Valid Loss: 0.16315 | Time: 0.48 seconds\n",
            "Epoch: 996 | Train Loss: 0.16191 | Valid Loss: 0.16459 | Time: 0.47 seconds\n",
            "Epoch: 997 | Train Loss: 0.16166 | Valid Loss: 0.16299 | Time: 0.47 seconds\n",
            "Epoch: 998 | Train Loss: 0.16140 | Valid Loss: 0.16387 | Time: 0.46 seconds\n",
            "Epoch: 999 | Train Loss: 0.16114 | Valid Loss: 0.16442 | Time: 0.47 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16088 | Valid Loss: 0.16381 | Time: 0.48 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 997\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.89 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 8]: 31.94207\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 9...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71488 | Valid Loss: 0.71185 | Time: 0.52 seconds\n",
            "Epoch: 2 | Train Loss: 0.71432 | Valid Loss: 0.71449 | Time: 0.47 seconds\n",
            "Epoch: 3 | Train Loss: 0.71381 | Valid Loss: 0.71348 | Time: 0.48 seconds\n",
            "Epoch: 4 | Train Loss: 0.71331 | Valid Loss: 0.71297 | Time: 0.48 seconds\n",
            "Epoch: 5 | Train Loss: 0.71283 | Valid Loss: 0.71266 | Time: 0.49 seconds\n",
            "Epoch: 6 | Train Loss: 0.71236 | Valid Loss: 0.71223 | Time: 0.47 seconds\n",
            "Epoch: 7 | Train Loss: 0.71192 | Valid Loss: 0.71167 | Time: 0.49 seconds\n",
            "Epoch: 8 | Train Loss: 0.71148 | Valid Loss: 0.71184 | Time: 0.48 seconds\n",
            "Epoch: 9 | Train Loss: 0.71106 | Valid Loss: 0.71023 | Time: 0.48 seconds\n",
            "Epoch: 10 | Train Loss: 0.71067 | Valid Loss: 0.71087 | Time: 0.46 seconds\n",
            "Epoch: 11 | Train Loss: 0.71029 | Valid Loss: 0.71046 | Time: 0.48 seconds\n",
            "Epoch: 12 | Train Loss: 0.70989 | Valid Loss: 0.70956 | Time: 0.48 seconds\n",
            "Epoch: 13 | Train Loss: 0.70951 | Valid Loss: 0.70935 | Time: 0.47 seconds\n",
            "Epoch: 14 | Train Loss: 0.70916 | Valid Loss: 0.70893 | Time: 0.47 seconds\n",
            "Epoch: 15 | Train Loss: 0.70880 | Valid Loss: 0.70851 | Time: 0.47 seconds\n",
            "Epoch: 16 | Train Loss: 0.70844 | Valid Loss: 0.70855 | Time: 0.47 seconds\n",
            "Epoch: 17 | Train Loss: 0.70810 | Valid Loss: 0.70862 | Time: 0.45 seconds\n",
            "Epoch: 18 | Train Loss: 0.70775 | Valid Loss: 0.70798 | Time: 0.49 seconds\n",
            "Epoch: 19 | Train Loss: 0.70742 | Valid Loss: 0.70688 | Time: 0.47 seconds\n",
            "Epoch: 20 | Train Loss: 0.70708 | Valid Loss: 0.70706 | Time: 0.47 seconds\n",
            "Epoch: 21 | Train Loss: 0.70675 | Valid Loss: 0.70699 | Time: 0.46 seconds\n",
            "Epoch: 22 | Train Loss: 0.70644 | Valid Loss: 0.70665 | Time: 0.48 seconds\n",
            "Epoch: 23 | Train Loss: 0.70610 | Valid Loss: 0.70655 | Time: 0.47 seconds\n",
            "Epoch: 24 | Train Loss: 0.70579 | Valid Loss: 0.70587 | Time: 0.48 seconds\n",
            "Epoch: 25 | Train Loss: 0.70549 | Valid Loss: 0.70558 | Time: 0.47 seconds\n",
            "Epoch: 26 | Train Loss: 0.70517 | Valid Loss: 0.70511 | Time: 0.48 seconds\n",
            "Epoch: 27 | Train Loss: 0.70483 | Valid Loss: 0.70517 | Time: 0.46 seconds\n",
            "Epoch: 28 | Train Loss: 0.70454 | Valid Loss: 0.70489 | Time: 0.47 seconds\n",
            "Epoch: 29 | Train Loss: 0.70421 | Valid Loss: 0.70436 | Time: 0.48 seconds\n",
            "Epoch: 30 | Train Loss: 0.70389 | Valid Loss: 0.70415 | Time: 0.47 seconds\n",
            "Epoch: 31 | Train Loss: 0.70359 | Valid Loss: 0.70418 | Time: 0.47 seconds\n",
            "Epoch: 32 | Train Loss: 0.70326 | Valid Loss: 0.70307 | Time: 0.47 seconds\n",
            "Epoch: 33 | Train Loss: 0.70295 | Valid Loss: 0.70337 | Time: 0.48 seconds\n",
            "Epoch: 34 | Train Loss: 0.70264 | Valid Loss: 0.70330 | Time: 0.45 seconds\n",
            "Epoch: 35 | Train Loss: 0.70233 | Valid Loss: 0.70215 | Time: 0.48 seconds\n",
            "Epoch: 36 | Train Loss: 0.70200 | Valid Loss: 0.70204 | Time: 0.46 seconds\n",
            "Epoch: 37 | Train Loss: 0.70168 | Valid Loss: 0.70162 | Time: 0.48 seconds\n",
            "Epoch: 38 | Train Loss: 0.70135 | Valid Loss: 0.70161 | Time: 0.47 seconds\n",
            "Epoch: 39 | Train Loss: 0.70102 | Valid Loss: 0.70155 | Time: 0.49 seconds\n",
            "Epoch: 40 | Train Loss: 0.70069 | Valid Loss: 0.70085 | Time: 0.48 seconds\n",
            "Epoch: 41 | Train Loss: 0.70037 | Valid Loss: 0.70036 | Time: 0.48 seconds\n",
            "Epoch: 42 | Train Loss: 0.70003 | Valid Loss: 0.70025 | Time: 0.48 seconds\n",
            "Epoch: 43 | Train Loss: 0.69969 | Valid Loss: 0.69947 | Time: 0.48 seconds\n",
            "Epoch: 44 | Train Loss: 0.69935 | Valid Loss: 0.69956 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69901 | Valid Loss: 0.69962 | Time: 0.46 seconds\n",
            "Epoch: 46 | Train Loss: 0.69868 | Valid Loss: 0.69909 | Time: 0.47 seconds\n",
            "Epoch: 47 | Train Loss: 0.69832 | Valid Loss: 0.69818 | Time: 0.46 seconds\n",
            "Epoch: 48 | Train Loss: 0.69795 | Valid Loss: 0.69802 | Time: 0.49 seconds\n",
            "Epoch: 49 | Train Loss: 0.69760 | Valid Loss: 0.69775 | Time: 0.46 seconds\n",
            "Epoch: 50 | Train Loss: 0.69725 | Valid Loss: 0.69731 | Time: 0.48 seconds\n",
            "Epoch: 51 | Train Loss: 0.69688 | Valid Loss: 0.69740 | Time: 0.45 seconds\n",
            "Epoch: 52 | Train Loss: 0.69653 | Valid Loss: 0.69688 | Time: 0.50 seconds\n",
            "Epoch: 53 | Train Loss: 0.69614 | Valid Loss: 0.69696 | Time: 0.47 seconds\n",
            "Epoch: 54 | Train Loss: 0.69576 | Valid Loss: 0.69637 | Time: 0.47 seconds\n",
            "Epoch: 55 | Train Loss: 0.69539 | Valid Loss: 0.69548 | Time: 0.47 seconds\n",
            "Epoch: 56 | Train Loss: 0.69501 | Valid Loss: 0.69548 | Time: 0.47 seconds\n",
            "Epoch: 57 | Train Loss: 0.69462 | Valid Loss: 0.69558 | Time: 0.48 seconds\n",
            "Epoch: 58 | Train Loss: 0.69422 | Valid Loss: 0.69444 | Time: 0.47 seconds\n",
            "Epoch: 59 | Train Loss: 0.69383 | Valid Loss: 0.69448 | Time: 0.47 seconds\n",
            "Epoch: 60 | Train Loss: 0.69343 | Valid Loss: 0.69411 | Time: 0.48 seconds\n",
            "Epoch: 61 | Train Loss: 0.69301 | Valid Loss: 0.69308 | Time: 0.49 seconds\n",
            "Epoch: 62 | Train Loss: 0.69261 | Valid Loss: 0.69328 | Time: 0.47 seconds\n",
            "Epoch: 63 | Train Loss: 0.69220 | Valid Loss: 0.69292 | Time: 0.47 seconds\n",
            "Epoch: 64 | Train Loss: 0.69178 | Valid Loss: 0.69249 | Time: 0.47 seconds\n",
            "Epoch: 65 | Train Loss: 0.69137 | Valid Loss: 0.69226 | Time: 0.48 seconds\n",
            "Epoch: 66 | Train Loss: 0.69093 | Valid Loss: 0.69166 | Time: 0.47 seconds\n",
            "Epoch: 67 | Train Loss: 0.69051 | Valid Loss: 0.69101 | Time: 0.49 seconds\n",
            "Epoch: 68 | Train Loss: 0.69008 | Valid Loss: 0.69023 | Time: 0.48 seconds\n",
            "Epoch: 69 | Train Loss: 0.68963 | Valid Loss: 0.68992 | Time: 0.48 seconds\n",
            "Epoch: 70 | Train Loss: 0.68919 | Valid Loss: 0.68924 | Time: 0.46 seconds\n",
            "Epoch: 71 | Train Loss: 0.68874 | Valid Loss: 0.68928 | Time: 0.47 seconds\n",
            "Epoch: 72 | Train Loss: 0.68829 | Valid Loss: 0.68850 | Time: 0.47 seconds\n",
            "Epoch: 73 | Train Loss: 0.68784 | Valid Loss: 0.68820 | Time: 0.47 seconds\n",
            "Epoch: 74 | Train Loss: 0.68738 | Valid Loss: 0.68820 | Time: 0.47 seconds\n",
            "Epoch: 75 | Train Loss: 0.68691 | Valid Loss: 0.68747 | Time: 0.46 seconds\n",
            "Epoch: 76 | Train Loss: 0.68644 | Valid Loss: 0.68703 | Time: 0.50 seconds\n",
            "Epoch: 77 | Train Loss: 0.68597 | Valid Loss: 0.68719 | Time: 0.46 seconds\n",
            "Epoch: 78 | Train Loss: 0.68550 | Valid Loss: 0.68580 | Time: 0.47 seconds\n",
            "Epoch: 79 | Train Loss: 0.68502 | Valid Loss: 0.68627 | Time: 0.46 seconds\n",
            "Epoch: 80 | Train Loss: 0.68455 | Valid Loss: 0.68611 | Time: 0.46 seconds\n",
            "Epoch: 81 | Train Loss: 0.68405 | Valid Loss: 0.68473 | Time: 0.47 seconds\n",
            "Epoch: 82 | Train Loss: 0.68356 | Valid Loss: 0.68460 | Time: 0.48 seconds\n",
            "Epoch: 83 | Train Loss: 0.68306 | Valid Loss: 0.68370 | Time: 0.48 seconds\n",
            "Epoch: 84 | Train Loss: 0.68256 | Valid Loss: 0.68302 | Time: 0.49 seconds\n",
            "Epoch: 85 | Train Loss: 0.68207 | Valid Loss: 0.68350 | Time: 0.47 seconds\n",
            "Epoch: 86 | Train Loss: 0.68155 | Valid Loss: 0.68189 | Time: 0.49 seconds\n",
            "Epoch: 87 | Train Loss: 0.68105 | Valid Loss: 0.68156 | Time: 0.48 seconds\n",
            "Epoch: 88 | Train Loss: 0.68052 | Valid Loss: 0.68194 | Time: 0.47 seconds\n",
            "Epoch: 89 | Train Loss: 0.68001 | Valid Loss: 0.68091 | Time: 0.48 seconds\n",
            "Epoch: 90 | Train Loss: 0.67949 | Valid Loss: 0.68006 | Time: 0.49 seconds\n",
            "Epoch: 91 | Train Loss: 0.67896 | Valid Loss: 0.68025 | Time: 0.47 seconds\n",
            "Epoch: 92 | Train Loss: 0.67844 | Valid Loss: 0.67882 | Time: 0.47 seconds\n",
            "Epoch: 93 | Train Loss: 0.67789 | Valid Loss: 0.67817 | Time: 0.48 seconds\n",
            "Epoch: 94 | Train Loss: 0.67735 | Valid Loss: 0.67855 | Time: 0.47 seconds\n",
            "Epoch: 95 | Train Loss: 0.67682 | Valid Loss: 0.67843 | Time: 0.49 seconds\n",
            "Epoch: 96 | Train Loss: 0.67627 | Valid Loss: 0.67631 | Time: 0.46 seconds\n",
            "Epoch: 97 | Train Loss: 0.67572 | Valid Loss: 0.67586 | Time: 0.47 seconds\n",
            "Epoch: 98 | Train Loss: 0.67516 | Valid Loss: 0.67579 | Time: 0.47 seconds\n",
            "Epoch: 99 | Train Loss: 0.67460 | Valid Loss: 0.67555 | Time: 0.48 seconds\n",
            "Epoch: 100 | Train Loss: 0.67404 | Valid Loss: 0.67480 | Time: 0.48 seconds\n",
            "Epoch: 101 | Train Loss: 0.67347 | Valid Loss: 0.67480 | Time: 0.48 seconds\n",
            "Epoch: 102 | Train Loss: 0.67289 | Valid Loss: 0.67334 | Time: 0.47 seconds\n",
            "Epoch: 103 | Train Loss: 0.67233 | Valid Loss: 0.67317 | Time: 0.47 seconds\n",
            "Epoch: 104 | Train Loss: 0.67174 | Valid Loss: 0.67224 | Time: 0.48 seconds\n",
            "Epoch: 105 | Train Loss: 0.67116 | Valid Loss: 0.67190 | Time: 0.47 seconds\n",
            "Epoch: 106 | Train Loss: 0.67057 | Valid Loss: 0.67110 | Time: 0.49 seconds\n",
            "Epoch: 107 | Train Loss: 0.66999 | Valid Loss: 0.67113 | Time: 0.46 seconds\n",
            "Epoch: 108 | Train Loss: 0.66939 | Valid Loss: 0.67006 | Time: 0.47 seconds\n",
            "Epoch: 109 | Train Loss: 0.66880 | Valid Loss: 0.66906 | Time: 0.48 seconds\n",
            "Epoch: 110 | Train Loss: 0.66819 | Valid Loss: 0.66881 | Time: 0.49 seconds\n",
            "Epoch: 111 | Train Loss: 0.66758 | Valid Loss: 0.66939 | Time: 0.48 seconds\n",
            "Epoch: 112 | Train Loss: 0.66698 | Valid Loss: 0.66676 | Time: 0.48 seconds\n",
            "Epoch: 113 | Train Loss: 0.66636 | Valid Loss: 0.66739 | Time: 0.47 seconds\n",
            "Epoch: 114 | Train Loss: 0.66574 | Valid Loss: 0.66679 | Time: 0.47 seconds\n",
            "Epoch: 115 | Train Loss: 0.66512 | Valid Loss: 0.66580 | Time: 0.47 seconds\n",
            "Epoch: 116 | Train Loss: 0.66450 | Valid Loss: 0.66588 | Time: 0.46 seconds\n",
            "Epoch: 117 | Train Loss: 0.66387 | Valid Loss: 0.66548 | Time: 0.47 seconds\n",
            "Epoch: 118 | Train Loss: 0.66323 | Valid Loss: 0.66407 | Time: 0.46 seconds\n",
            "Epoch: 119 | Train Loss: 0.66260 | Valid Loss: 0.66384 | Time: 0.48 seconds\n",
            "Epoch: 120 | Train Loss: 0.66196 | Valid Loss: 0.66311 | Time: 0.48 seconds\n",
            "Epoch: 121 | Train Loss: 0.66132 | Valid Loss: 0.66180 | Time: 0.48 seconds\n",
            "Epoch: 122 | Train Loss: 0.66068 | Valid Loss: 0.66115 | Time: 0.46 seconds\n",
            "Epoch: 123 | Train Loss: 0.66002 | Valid Loss: 0.66107 | Time: 0.47 seconds\n",
            "Epoch: 124 | Train Loss: 0.65938 | Valid Loss: 0.66015 | Time: 0.48 seconds\n",
            "Epoch: 125 | Train Loss: 0.65871 | Valid Loss: 0.65965 | Time: 0.49 seconds\n",
            "Epoch: 126 | Train Loss: 0.65806 | Valid Loss: 0.65968 | Time: 0.47 seconds\n",
            "Epoch: 127 | Train Loss: 0.65739 | Valid Loss: 0.65813 | Time: 0.49 seconds\n",
            "Epoch: 128 | Train Loss: 0.65673 | Valid Loss: 0.65913 | Time: 0.45 seconds\n",
            "Epoch: 129 | Train Loss: 0.65607 | Valid Loss: 0.65771 | Time: 0.47 seconds\n",
            "Epoch: 130 | Train Loss: 0.65538 | Valid Loss: 0.65699 | Time: 0.48 seconds\n",
            "Epoch: 131 | Train Loss: 0.65471 | Valid Loss: 0.65590 | Time: 0.48 seconds\n",
            "Epoch: 132 | Train Loss: 0.65403 | Valid Loss: 0.65477 | Time: 0.48 seconds\n",
            "Epoch: 133 | Train Loss: 0.65335 | Valid Loss: 0.65478 | Time: 0.47 seconds\n",
            "Epoch: 134 | Train Loss: 0.65266 | Valid Loss: 0.65333 | Time: 0.49 seconds\n",
            "Epoch: 135 | Train Loss: 0.65197 | Valid Loss: 0.65354 | Time: 0.48 seconds\n",
            "Epoch: 136 | Train Loss: 0.65128 | Valid Loss: 0.65176 | Time: 0.48 seconds\n",
            "Epoch: 137 | Train Loss: 0.65059 | Valid Loss: 0.65138 | Time: 0.47 seconds\n",
            "Epoch: 138 | Train Loss: 0.64989 | Valid Loss: 0.65028 | Time: 0.49 seconds\n",
            "Epoch: 139 | Train Loss: 0.64918 | Valid Loss: 0.65055 | Time: 0.46 seconds\n",
            "Epoch: 140 | Train Loss: 0.64848 | Valid Loss: 0.64956 | Time: 0.47 seconds\n",
            "Epoch: 141 | Train Loss: 0.64777 | Valid Loss: 0.64837 | Time: 0.46 seconds\n",
            "Epoch: 142 | Train Loss: 0.64706 | Valid Loss: 0.64765 | Time: 0.49 seconds\n",
            "Epoch: 143 | Train Loss: 0.64636 | Valid Loss: 0.64796 | Time: 0.47 seconds\n",
            "Epoch: 144 | Train Loss: 0.64564 | Valid Loss: 0.64641 | Time: 0.48 seconds\n",
            "Epoch: 145 | Train Loss: 0.64493 | Valid Loss: 0.64556 | Time: 0.46 seconds\n",
            "Epoch: 146 | Train Loss: 0.64420 | Valid Loss: 0.64635 | Time: 0.46 seconds\n",
            "Epoch: 147 | Train Loss: 0.64348 | Valid Loss: 0.64456 | Time: 0.48 seconds\n",
            "Epoch: 148 | Train Loss: 0.64276 | Valid Loss: 0.64449 | Time: 0.48 seconds\n",
            "Epoch: 149 | Train Loss: 0.64203 | Valid Loss: 0.64309 | Time: 0.48 seconds\n",
            "Epoch: 150 | Train Loss: 0.64129 | Valid Loss: 0.64185 | Time: 0.46 seconds\n",
            "Epoch: 151 | Train Loss: 0.64057 | Valid Loss: 0.64238 | Time: 0.47 seconds\n",
            "Epoch: 152 | Train Loss: 0.63982 | Valid Loss: 0.64164 | Time: 0.46 seconds\n",
            "Epoch: 153 | Train Loss: 0.63908 | Valid Loss: 0.64046 | Time: 0.49 seconds\n",
            "Epoch: 154 | Train Loss: 0.63834 | Valid Loss: 0.63932 | Time: 0.47 seconds\n",
            "Epoch: 155 | Train Loss: 0.63761 | Valid Loss: 0.63926 | Time: 0.49 seconds\n",
            "Epoch: 156 | Train Loss: 0.63686 | Valid Loss: 0.63843 | Time: 0.46 seconds\n",
            "Epoch: 157 | Train Loss: 0.63611 | Valid Loss: 0.63720 | Time: 0.49 seconds\n",
            "Epoch: 158 | Train Loss: 0.63536 | Valid Loss: 0.63650 | Time: 0.48 seconds\n",
            "Epoch: 159 | Train Loss: 0.63462 | Valid Loss: 0.63635 | Time: 0.48 seconds\n",
            "Epoch: 160 | Train Loss: 0.63386 | Valid Loss: 0.63567 | Time: 0.47 seconds\n",
            "Epoch: 161 | Train Loss: 0.63310 | Valid Loss: 0.63515 | Time: 0.47 seconds\n",
            "Epoch: 162 | Train Loss: 0.63233 | Valid Loss: 0.63408 | Time: 0.48 seconds\n",
            "Epoch: 163 | Train Loss: 0.63159 | Valid Loss: 0.63314 | Time: 0.47 seconds\n",
            "Epoch: 164 | Train Loss: 0.63082 | Valid Loss: 0.63223 | Time: 0.49 seconds\n",
            "Epoch: 165 | Train Loss: 0.63006 | Valid Loss: 0.63237 | Time: 0.47 seconds\n",
            "Epoch: 166 | Train Loss: 0.62929 | Valid Loss: 0.63077 | Time: 0.49 seconds\n",
            "Epoch: 167 | Train Loss: 0.62851 | Valid Loss: 0.63141 | Time: 0.46 seconds\n",
            "Epoch: 168 | Train Loss: 0.62776 | Valid Loss: 0.62868 | Time: 0.48 seconds\n",
            "Epoch: 169 | Train Loss: 0.62698 | Valid Loss: 0.62906 | Time: 0.47 seconds\n",
            "Epoch: 170 | Train Loss: 0.62620 | Valid Loss: 0.62824 | Time: 0.51 seconds\n",
            "Epoch: 171 | Train Loss: 0.62542 | Valid Loss: 0.62761 | Time: 0.46 seconds\n",
            "Epoch: 172 | Train Loss: 0.62464 | Valid Loss: 0.62638 | Time: 0.49 seconds\n",
            "Epoch: 173 | Train Loss: 0.62387 | Valid Loss: 0.62475 | Time: 0.48 seconds\n",
            "Epoch: 174 | Train Loss: 0.62309 | Valid Loss: 0.62421 | Time: 0.50 seconds\n",
            "Epoch: 175 | Train Loss: 0.62230 | Valid Loss: 0.62335 | Time: 0.48 seconds\n",
            "Epoch: 176 | Train Loss: 0.62151 | Valid Loss: 0.62272 | Time: 0.49 seconds\n",
            "Epoch: 177 | Train Loss: 0.62073 | Valid Loss: 0.62226 | Time: 0.48 seconds\n",
            "Epoch: 178 | Train Loss: 0.61994 | Valid Loss: 0.62174 | Time: 0.49 seconds\n",
            "Epoch: 179 | Train Loss: 0.61916 | Valid Loss: 0.61998 | Time: 0.46 seconds\n",
            "Epoch: 180 | Train Loss: 0.61837 | Valid Loss: 0.62079 | Time: 0.46 seconds\n",
            "Epoch: 181 | Train Loss: 0.61756 | Valid Loss: 0.61944 | Time: 0.47 seconds\n",
            "Epoch: 182 | Train Loss: 0.61676 | Valid Loss: 0.61858 | Time: 0.46 seconds\n",
            "Epoch: 183 | Train Loss: 0.61597 | Valid Loss: 0.61800 | Time: 0.48 seconds\n",
            "Epoch: 184 | Train Loss: 0.61518 | Valid Loss: 0.61676 | Time: 0.47 seconds\n",
            "Epoch: 185 | Train Loss: 0.61437 | Valid Loss: 0.61590 | Time: 0.48 seconds\n",
            "Epoch: 186 | Train Loss: 0.61357 | Valid Loss: 0.61456 | Time: 0.46 seconds\n",
            "Epoch: 187 | Train Loss: 0.61276 | Valid Loss: 0.61409 | Time: 0.49 seconds\n",
            "Epoch: 188 | Train Loss: 0.61197 | Valid Loss: 0.61350 | Time: 0.47 seconds\n",
            "Epoch: 189 | Train Loss: 0.61116 | Valid Loss: 0.61380 | Time: 0.46 seconds\n",
            "Epoch: 190 | Train Loss: 0.61035 | Valid Loss: 0.61080 | Time: 0.46 seconds\n",
            "Epoch: 191 | Train Loss: 0.60954 | Valid Loss: 0.61199 | Time: 0.48 seconds\n",
            "Epoch: 192 | Train Loss: 0.60873 | Valid Loss: 0.61160 | Time: 0.46 seconds\n",
            "Epoch: 193 | Train Loss: 0.60793 | Valid Loss: 0.60920 | Time: 0.47 seconds\n",
            "Epoch: 194 | Train Loss: 0.60711 | Valid Loss: 0.60913 | Time: 0.47 seconds\n",
            "Epoch: 195 | Train Loss: 0.60629 | Valid Loss: 0.60708 | Time: 0.49 seconds\n",
            "Epoch: 196 | Train Loss: 0.60549 | Valid Loss: 0.60768 | Time: 0.48 seconds\n",
            "Epoch: 197 | Train Loss: 0.60465 | Valid Loss: 0.60680 | Time: 0.47 seconds\n",
            "Epoch: 198 | Train Loss: 0.60386 | Valid Loss: 0.60467 | Time: 0.47 seconds\n",
            "Epoch: 199 | Train Loss: 0.60303 | Valid Loss: 0.60610 | Time: 0.46 seconds\n",
            "Epoch: 200 | Train Loss: 0.60222 | Valid Loss: 0.60331 | Time: 0.48 seconds\n",
            "Epoch: 201 | Train Loss: 0.60140 | Valid Loss: 0.60269 | Time: 0.48 seconds\n",
            "Epoch: 202 | Train Loss: 0.60057 | Valid Loss: 0.60303 | Time: 0.47 seconds\n",
            "Epoch: 203 | Train Loss: 0.59974 | Valid Loss: 0.60186 | Time: 0.46 seconds\n",
            "Epoch: 204 | Train Loss: 0.59892 | Valid Loss: 0.60097 | Time: 0.47 seconds\n",
            "Epoch: 205 | Train Loss: 0.59810 | Valid Loss: 0.60082 | Time: 0.47 seconds\n",
            "Epoch: 206 | Train Loss: 0.59727 | Valid Loss: 0.59881 | Time: 0.48 seconds\n",
            "Epoch: 207 | Train Loss: 0.59644 | Valid Loss: 0.59790 | Time: 0.48 seconds\n",
            "Epoch: 208 | Train Loss: 0.59562 | Valid Loss: 0.59824 | Time: 0.48 seconds\n",
            "Epoch: 209 | Train Loss: 0.59478 | Valid Loss: 0.59414 | Time: 0.48 seconds\n",
            "Epoch: 210 | Train Loss: 0.59396 | Valid Loss: 0.59537 | Time: 0.45 seconds\n",
            "Epoch: 211 | Train Loss: 0.59313 | Valid Loss: 0.59475 | Time: 0.47 seconds\n",
            "Epoch: 212 | Train Loss: 0.59229 | Valid Loss: 0.59388 | Time: 0.48 seconds\n",
            "Epoch: 213 | Train Loss: 0.59146 | Valid Loss: 0.59319 | Time: 0.49 seconds\n",
            "Epoch: 214 | Train Loss: 0.59063 | Valid Loss: 0.59281 | Time: 0.47 seconds\n",
            "Epoch: 215 | Train Loss: 0.58980 | Valid Loss: 0.59034 | Time: 0.49 seconds\n",
            "Epoch: 216 | Train Loss: 0.58896 | Valid Loss: 0.59098 | Time: 0.48 seconds\n",
            "Epoch: 217 | Train Loss: 0.58812 | Valid Loss: 0.59104 | Time: 0.49 seconds\n",
            "Epoch: 218 | Train Loss: 0.58729 | Valid Loss: 0.58854 | Time: 0.48 seconds\n",
            "Epoch: 219 | Train Loss: 0.58644 | Valid Loss: 0.58963 | Time: 0.48 seconds\n",
            "Epoch: 220 | Train Loss: 0.58560 | Valid Loss: 0.58663 | Time: 0.47 seconds\n",
            "Epoch: 221 | Train Loss: 0.58477 | Valid Loss: 0.58445 | Time: 0.48 seconds\n",
            "Epoch: 222 | Train Loss: 0.58391 | Valid Loss: 0.58522 | Time: 0.46 seconds\n",
            "Epoch: 223 | Train Loss: 0.58307 | Valid Loss: 0.58434 | Time: 0.46 seconds\n",
            "Epoch: 224 | Train Loss: 0.58223 | Valid Loss: 0.58332 | Time: 0.48 seconds\n",
            "Epoch: 225 | Train Loss: 0.58138 | Valid Loss: 0.58349 | Time: 0.47 seconds\n",
            "Epoch: 226 | Train Loss: 0.58055 | Valid Loss: 0.58299 | Time: 0.48 seconds\n",
            "Epoch: 227 | Train Loss: 0.57970 | Valid Loss: 0.58135 | Time: 0.47 seconds\n",
            "Epoch: 228 | Train Loss: 0.57885 | Valid Loss: 0.57898 | Time: 0.47 seconds\n",
            "Epoch: 229 | Train Loss: 0.57801 | Valid Loss: 0.58015 | Time: 0.48 seconds\n",
            "Epoch: 230 | Train Loss: 0.57716 | Valid Loss: 0.57794 | Time: 0.49 seconds\n",
            "Epoch: 231 | Train Loss: 0.57631 | Valid Loss: 0.57879 | Time: 0.46 seconds\n",
            "Epoch: 232 | Train Loss: 0.57545 | Valid Loss: 0.57697 | Time: 0.49 seconds\n",
            "Epoch: 233 | Train Loss: 0.57460 | Valid Loss: 0.57689 | Time: 0.47 seconds\n",
            "Epoch: 234 | Train Loss: 0.57376 | Valid Loss: 0.57594 | Time: 0.48 seconds\n",
            "Epoch: 235 | Train Loss: 0.57290 | Valid Loss: 0.57426 | Time: 0.47 seconds\n",
            "Epoch: 236 | Train Loss: 0.57205 | Valid Loss: 0.57244 | Time: 0.47 seconds\n",
            "Epoch: 237 | Train Loss: 0.57119 | Valid Loss: 0.57296 | Time: 0.46 seconds\n",
            "Epoch: 238 | Train Loss: 0.57035 | Valid Loss: 0.57150 | Time: 0.47 seconds\n",
            "Epoch: 239 | Train Loss: 0.56949 | Valid Loss: 0.57078 | Time: 0.49 seconds\n",
            "Epoch: 240 | Train Loss: 0.56863 | Valid Loss: 0.57199 | Time: 0.45 seconds\n",
            "Epoch: 241 | Train Loss: 0.56778 | Valid Loss: 0.56950 | Time: 0.47 seconds\n",
            "Epoch: 242 | Train Loss: 0.56691 | Valid Loss: 0.56954 | Time: 0.48 seconds\n",
            "Epoch: 243 | Train Loss: 0.56605 | Valid Loss: 0.56708 | Time: 0.48 seconds\n",
            "Epoch: 244 | Train Loss: 0.56519 | Valid Loss: 0.56448 | Time: 0.49 seconds\n",
            "Epoch: 245 | Train Loss: 0.56435 | Valid Loss: 0.56550 | Time: 0.48 seconds\n",
            "Epoch: 246 | Train Loss: 0.56350 | Valid Loss: 0.56617 | Time: 0.45 seconds\n",
            "Epoch: 247 | Train Loss: 0.56262 | Valid Loss: 0.56462 | Time: 0.46 seconds\n",
            "Epoch: 248 | Train Loss: 0.56177 | Valid Loss: 0.56327 | Time: 0.47 seconds\n",
            "Epoch: 249 | Train Loss: 0.56089 | Valid Loss: 0.56313 | Time: 0.49 seconds\n",
            "Epoch: 250 | Train Loss: 0.56004 | Valid Loss: 0.56357 | Time: 0.46 seconds\n",
            "Epoch: 251 | Train Loss: 0.55918 | Valid Loss: 0.56182 | Time: 0.47 seconds\n",
            "Epoch: 252 | Train Loss: 0.55831 | Valid Loss: 0.56059 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55744 | Valid Loss: 0.55945 | Time: 0.48 seconds\n",
            "Epoch: 254 | Train Loss: 0.55659 | Valid Loss: 0.55849 | Time: 0.48 seconds\n",
            "Epoch: 255 | Train Loss: 0.55572 | Valid Loss: 0.55633 | Time: 0.47 seconds\n",
            "Epoch: 256 | Train Loss: 0.55486 | Valid Loss: 0.55771 | Time: 0.47 seconds\n",
            "Epoch: 257 | Train Loss: 0.55400 | Valid Loss: 0.55555 | Time: 0.46 seconds\n",
            "Epoch: 258 | Train Loss: 0.55313 | Valid Loss: 0.55572 | Time: 0.49 seconds\n",
            "Epoch: 259 | Train Loss: 0.55227 | Valid Loss: 0.55576 | Time: 0.46 seconds\n",
            "Epoch: 260 | Train Loss: 0.55140 | Valid Loss: 0.55525 | Time: 0.48 seconds\n",
            "Epoch: 261 | Train Loss: 0.55052 | Valid Loss: 0.55199 | Time: 0.48 seconds\n",
            "Epoch: 262 | Train Loss: 0.54966 | Valid Loss: 0.55153 | Time: 0.50 seconds\n",
            "Epoch: 263 | Train Loss: 0.54879 | Valid Loss: 0.55103 | Time: 0.46 seconds\n",
            "Epoch: 264 | Train Loss: 0.54793 | Valid Loss: 0.55070 | Time: 0.47 seconds\n",
            "Epoch: 265 | Train Loss: 0.54707 | Valid Loss: 0.54985 | Time: 0.51 seconds\n",
            "Epoch: 266 | Train Loss: 0.54618 | Valid Loss: 0.54907 | Time: 0.50 seconds\n",
            "Epoch: 267 | Train Loss: 0.54532 | Valid Loss: 0.54751 | Time: 0.46 seconds\n",
            "Epoch: 268 | Train Loss: 0.54445 | Valid Loss: 0.54406 | Time: 0.46 seconds\n",
            "Epoch: 269 | Train Loss: 0.54358 | Valid Loss: 0.54524 | Time: 0.48 seconds\n",
            "Epoch: 270 | Train Loss: 0.54271 | Valid Loss: 0.54446 | Time: 0.45 seconds\n",
            "Epoch: 271 | Train Loss: 0.54184 | Valid Loss: 0.54342 | Time: 0.48 seconds\n",
            "Epoch: 272 | Train Loss: 0.54097 | Valid Loss: 0.54256 | Time: 0.46 seconds\n",
            "Epoch: 273 | Train Loss: 0.54011 | Valid Loss: 0.54123 | Time: 0.48 seconds\n",
            "Epoch: 274 | Train Loss: 0.53922 | Valid Loss: 0.54317 | Time: 0.45 seconds\n",
            "Epoch: 275 | Train Loss: 0.53835 | Valid Loss: 0.54093 | Time: 0.49 seconds\n",
            "Epoch: 276 | Train Loss: 0.53748 | Valid Loss: 0.53909 | Time: 0.48 seconds\n",
            "Epoch: 277 | Train Loss: 0.53659 | Valid Loss: 0.53727 | Time: 0.48 seconds\n",
            "Epoch: 278 | Train Loss: 0.53572 | Valid Loss: 0.53750 | Time: 0.48 seconds\n",
            "Epoch: 279 | Train Loss: 0.53487 | Valid Loss: 0.53555 | Time: 0.51 seconds\n",
            "Epoch: 280 | Train Loss: 0.53400 | Valid Loss: 0.53778 | Time: 0.47 seconds\n",
            "Epoch: 281 | Train Loss: 0.53311 | Valid Loss: 0.53391 | Time: 0.46 seconds\n",
            "Epoch: 282 | Train Loss: 0.53224 | Valid Loss: 0.53473 | Time: 0.48 seconds\n",
            "Epoch: 283 | Train Loss: 0.53136 | Valid Loss: 0.53057 | Time: 0.48 seconds\n",
            "Epoch: 284 | Train Loss: 0.53052 | Valid Loss: 0.53209 | Time: 0.47 seconds\n",
            "Epoch: 285 | Train Loss: 0.52961 | Valid Loss: 0.53311 | Time: 0.47 seconds\n",
            "Epoch: 286 | Train Loss: 0.52876 | Valid Loss: 0.53110 | Time: 0.49 seconds\n",
            "Epoch: 287 | Train Loss: 0.52787 | Valid Loss: 0.53048 | Time: 0.47 seconds\n",
            "Epoch: 288 | Train Loss: 0.52700 | Valid Loss: 0.52877 | Time: 0.48 seconds\n",
            "Epoch: 289 | Train Loss: 0.52612 | Valid Loss: 0.52880 | Time: 0.45 seconds\n",
            "Epoch: 290 | Train Loss: 0.52528 | Valid Loss: 0.52975 | Time: 0.48 seconds\n",
            "Epoch: 291 | Train Loss: 0.52440 | Valid Loss: 0.52627 | Time: 0.46 seconds\n",
            "Epoch: 292 | Train Loss: 0.52351 | Valid Loss: 0.52719 | Time: 0.47 seconds\n",
            "Epoch: 293 | Train Loss: 0.52265 | Valid Loss: 0.52512 | Time: 0.46 seconds\n",
            "Epoch: 294 | Train Loss: 0.52177 | Valid Loss: 0.52515 | Time: 0.47 seconds\n",
            "Epoch: 295 | Train Loss: 0.52087 | Valid Loss: 0.52303 | Time: 0.47 seconds\n",
            "Epoch: 296 | Train Loss: 0.52001 | Valid Loss: 0.52207 | Time: 0.50 seconds\n",
            "Epoch: 297 | Train Loss: 0.51915 | Valid Loss: 0.52159 | Time: 0.49 seconds\n",
            "Epoch: 298 | Train Loss: 0.51827 | Valid Loss: 0.52042 | Time: 0.48 seconds\n",
            "Epoch: 299 | Train Loss: 0.51741 | Valid Loss: 0.51966 | Time: 0.48 seconds\n",
            "Epoch: 300 | Train Loss: 0.51653 | Valid Loss: 0.51730 | Time: 0.47 seconds\n",
            "Epoch: 301 | Train Loss: 0.51566 | Valid Loss: 0.51864 | Time: 0.48 seconds\n",
            "Epoch: 302 | Train Loss: 0.51478 | Valid Loss: 0.51775 | Time: 0.46 seconds\n",
            "Epoch: 303 | Train Loss: 0.51392 | Valid Loss: 0.51715 | Time: 0.47 seconds\n",
            "Epoch: 304 | Train Loss: 0.51304 | Valid Loss: 0.51778 | Time: 0.46 seconds\n",
            "Epoch: 305 | Train Loss: 0.51216 | Valid Loss: 0.51452 | Time: 0.49 seconds\n",
            "Epoch: 306 | Train Loss: 0.51129 | Valid Loss: 0.51458 | Time: 0.46 seconds\n",
            "Epoch: 307 | Train Loss: 0.51042 | Valid Loss: 0.51325 | Time: 0.47 seconds\n",
            "Epoch: 308 | Train Loss: 0.50955 | Valid Loss: 0.51112 | Time: 0.46 seconds\n",
            "Epoch: 309 | Train Loss: 0.50868 | Valid Loss: 0.51023 | Time: 0.48 seconds\n",
            "Epoch: 310 | Train Loss: 0.50780 | Valid Loss: 0.50910 | Time: 0.49 seconds\n",
            "Epoch: 311 | Train Loss: 0.50693 | Valid Loss: 0.50966 | Time: 0.47 seconds\n",
            "Epoch: 312 | Train Loss: 0.50607 | Valid Loss: 0.50712 | Time: 0.48 seconds\n",
            "Epoch: 313 | Train Loss: 0.50518 | Valid Loss: 0.50631 | Time: 0.47 seconds\n",
            "Epoch: 314 | Train Loss: 0.50431 | Valid Loss: 0.50714 | Time: 0.48 seconds\n",
            "Epoch: 315 | Train Loss: 0.50346 | Valid Loss: 0.50374 | Time: 0.48 seconds\n",
            "Epoch: 316 | Train Loss: 0.50258 | Valid Loss: 0.50460 | Time: 0.47 seconds\n",
            "Epoch: 317 | Train Loss: 0.50173 | Valid Loss: 0.50425 | Time: 0.45 seconds\n",
            "Epoch: 318 | Train Loss: 0.50085 | Valid Loss: 0.50433 | Time: 0.46 seconds\n",
            "Epoch: 319 | Train Loss: 0.49999 | Valid Loss: 0.50226 | Time: 0.47 seconds\n",
            "Epoch: 320 | Train Loss: 0.49912 | Valid Loss: 0.50391 | Time: 0.48 seconds\n",
            "Epoch: 321 | Train Loss: 0.49826 | Valid Loss: 0.50156 | Time: 0.47 seconds\n",
            "Epoch: 322 | Train Loss: 0.49735 | Valid Loss: 0.49898 | Time: 0.48 seconds\n",
            "Epoch: 323 | Train Loss: 0.49651 | Valid Loss: 0.49829 | Time: 0.48 seconds\n",
            "Epoch: 324 | Train Loss: 0.49565 | Valid Loss: 0.49816 | Time: 0.46 seconds\n",
            "Epoch: 325 | Train Loss: 0.49478 | Valid Loss: 0.49719 | Time: 0.48 seconds\n",
            "Epoch: 326 | Train Loss: 0.49392 | Valid Loss: 0.49762 | Time: 0.46 seconds\n",
            "Epoch: 327 | Train Loss: 0.49306 | Valid Loss: 0.49488 | Time: 0.47 seconds\n",
            "Epoch: 328 | Train Loss: 0.49217 | Valid Loss: 0.49370 | Time: 0.46 seconds\n",
            "Epoch: 329 | Train Loss: 0.49130 | Valid Loss: 0.49238 | Time: 0.48 seconds\n",
            "Epoch: 330 | Train Loss: 0.49047 | Valid Loss: 0.49319 | Time: 0.45 seconds\n",
            "Epoch: 331 | Train Loss: 0.48961 | Valid Loss: 0.49108 | Time: 0.47 seconds\n",
            "Epoch: 332 | Train Loss: 0.48873 | Valid Loss: 0.49287 | Time: 0.48 seconds\n",
            "Epoch: 333 | Train Loss: 0.48786 | Valid Loss: 0.49138 | Time: 0.48 seconds\n",
            "Epoch: 334 | Train Loss: 0.48698 | Valid Loss: 0.48960 | Time: 0.47 seconds\n",
            "Epoch: 335 | Train Loss: 0.48615 | Valid Loss: 0.49016 | Time: 0.49 seconds\n",
            "Epoch: 336 | Train Loss: 0.48529 | Valid Loss: 0.48526 | Time: 0.46 seconds\n",
            "Epoch: 337 | Train Loss: 0.48441 | Valid Loss: 0.48676 | Time: 0.47 seconds\n",
            "Epoch: 338 | Train Loss: 0.48358 | Valid Loss: 0.48734 | Time: 0.46 seconds\n",
            "Epoch: 339 | Train Loss: 0.48272 | Valid Loss: 0.48487 | Time: 0.46 seconds\n",
            "Epoch: 340 | Train Loss: 0.48185 | Valid Loss: 0.48470 | Time: 0.48 seconds\n",
            "Epoch: 341 | Train Loss: 0.48099 | Valid Loss: 0.48414 | Time: 0.46 seconds\n",
            "Epoch: 342 | Train Loss: 0.48014 | Valid Loss: 0.48360 | Time: 0.48 seconds\n",
            "Epoch: 343 | Train Loss: 0.47930 | Valid Loss: 0.47983 | Time: 0.47 seconds\n",
            "Epoch: 344 | Train Loss: 0.47844 | Valid Loss: 0.48178 | Time: 0.71 seconds\n",
            "Epoch: 345 | Train Loss: 0.47758 | Valid Loss: 0.48016 | Time: 0.46 seconds\n",
            "Epoch: 346 | Train Loss: 0.47673 | Valid Loss: 0.48051 | Time: 0.47 seconds\n",
            "Epoch: 347 | Train Loss: 0.47586 | Valid Loss: 0.47582 | Time: 0.48 seconds\n",
            "Epoch: 348 | Train Loss: 0.47503 | Valid Loss: 0.47727 | Time: 0.47 seconds\n",
            "Epoch: 349 | Train Loss: 0.47415 | Valid Loss: 0.47519 | Time: 0.46 seconds\n",
            "Epoch: 350 | Train Loss: 0.47332 | Valid Loss: 0.47708 | Time: 0.46 seconds\n",
            "Epoch: 351 | Train Loss: 0.47245 | Valid Loss: 0.47445 | Time: 0.48 seconds\n",
            "Epoch: 352 | Train Loss: 0.47163 | Valid Loss: 0.47298 | Time: 0.48 seconds\n",
            "Epoch: 353 | Train Loss: 0.47075 | Valid Loss: 0.47435 | Time: 0.46 seconds\n",
            "Epoch: 354 | Train Loss: 0.46990 | Valid Loss: 0.47174 | Time: 0.47 seconds\n",
            "Epoch: 355 | Train Loss: 0.46907 | Valid Loss: 0.47042 | Time: 0.47 seconds\n",
            "Epoch: 356 | Train Loss: 0.46822 | Valid Loss: 0.47331 | Time: 0.45 seconds\n",
            "Epoch: 357 | Train Loss: 0.46741 | Valid Loss: 0.46695 | Time: 0.50 seconds\n",
            "Epoch: 358 | Train Loss: 0.46656 | Valid Loss: 0.46647 | Time: 0.46 seconds\n",
            "Epoch: 359 | Train Loss: 0.46569 | Valid Loss: 0.46934 | Time: 0.48 seconds\n",
            "Epoch: 360 | Train Loss: 0.46487 | Valid Loss: 0.46635 | Time: 0.47 seconds\n",
            "Epoch: 361 | Train Loss: 0.46404 | Valid Loss: 0.46715 | Time: 0.48 seconds\n",
            "Epoch: 362 | Train Loss: 0.46319 | Valid Loss: 0.46440 | Time: 0.47 seconds\n",
            "Epoch: 363 | Train Loss: 0.46233 | Valid Loss: 0.46406 | Time: 0.48 seconds\n",
            "Epoch: 364 | Train Loss: 0.46150 | Valid Loss: 0.46494 | Time: 0.46 seconds\n",
            "Epoch: 365 | Train Loss: 0.46066 | Valid Loss: 0.46386 | Time: 0.48 seconds\n",
            "Epoch: 366 | Train Loss: 0.45984 | Valid Loss: 0.46287 | Time: 0.50 seconds\n",
            "Epoch: 367 | Train Loss: 0.45900 | Valid Loss: 0.46008 | Time: 0.48 seconds\n",
            "Epoch: 368 | Train Loss: 0.45817 | Valid Loss: 0.46127 | Time: 0.45 seconds\n",
            "Epoch: 369 | Train Loss: 0.45735 | Valid Loss: 0.45931 | Time: 0.47 seconds\n",
            "Epoch: 370 | Train Loss: 0.45650 | Valid Loss: 0.45874 | Time: 0.48 seconds\n",
            "Epoch: 371 | Train Loss: 0.45568 | Valid Loss: 0.45975 | Time: 0.46 seconds\n",
            "Epoch: 372 | Train Loss: 0.45486 | Valid Loss: 0.45694 | Time: 0.48 seconds\n",
            "Epoch: 373 | Train Loss: 0.45402 | Valid Loss: 0.45661 | Time: 0.46 seconds\n",
            "Epoch: 374 | Train Loss: 0.45318 | Valid Loss: 0.45548 | Time: 0.48 seconds\n",
            "Epoch: 375 | Train Loss: 0.45234 | Valid Loss: 0.45320 | Time: 0.48 seconds\n",
            "Epoch: 376 | Train Loss: 0.45153 | Valid Loss: 0.45312 | Time: 0.48 seconds\n",
            "Epoch: 377 | Train Loss: 0.45072 | Valid Loss: 0.45335 | Time: 0.48 seconds\n",
            "Epoch: 378 | Train Loss: 0.44989 | Valid Loss: 0.45256 | Time: 0.51 seconds\n",
            "Epoch: 379 | Train Loss: 0.44909 | Valid Loss: 0.45089 | Time: 0.49 seconds\n",
            "Epoch: 380 | Train Loss: 0.44823 | Valid Loss: 0.45050 | Time: 0.48 seconds\n",
            "Epoch: 381 | Train Loss: 0.44745 | Valid Loss: 0.45130 | Time: 0.48 seconds\n",
            "Epoch: 382 | Train Loss: 0.44661 | Valid Loss: 0.44957 | Time: 0.48 seconds\n",
            "Epoch: 383 | Train Loss: 0.44581 | Valid Loss: 0.44881 | Time: 0.46 seconds\n",
            "Epoch: 384 | Train Loss: 0.44499 | Valid Loss: 0.44781 | Time: 0.50 seconds\n",
            "Epoch: 385 | Train Loss: 0.44416 | Valid Loss: 0.44746 | Time: 0.47 seconds\n",
            "Epoch: 386 | Train Loss: 0.44336 | Valid Loss: 0.44577 | Time: 0.48 seconds\n",
            "Epoch: 387 | Train Loss: 0.44256 | Valid Loss: 0.44547 | Time: 0.48 seconds\n",
            "Epoch: 388 | Train Loss: 0.44174 | Valid Loss: 0.44494 | Time: 0.48 seconds\n",
            "Epoch: 389 | Train Loss: 0.44091 | Valid Loss: 0.44271 | Time: 0.48 seconds\n",
            "Epoch: 390 | Train Loss: 0.44013 | Valid Loss: 0.44217 | Time: 0.46 seconds\n",
            "Epoch: 391 | Train Loss: 0.43932 | Valid Loss: 0.44321 | Time: 0.47 seconds\n",
            "Epoch: 392 | Train Loss: 0.43852 | Valid Loss: 0.44086 | Time: 0.49 seconds\n",
            "Epoch: 393 | Train Loss: 0.43770 | Valid Loss: 0.44171 | Time: 0.48 seconds\n",
            "Epoch: 394 | Train Loss: 0.43693 | Valid Loss: 0.43775 | Time: 0.47 seconds\n",
            "Epoch: 395 | Train Loss: 0.43611 | Valid Loss: 0.43722 | Time: 0.49 seconds\n",
            "Epoch: 396 | Train Loss: 0.43533 | Valid Loss: 0.43626 | Time: 0.49 seconds\n",
            "Epoch: 397 | Train Loss: 0.43449 | Valid Loss: 0.43671 | Time: 0.46 seconds\n",
            "Epoch: 398 | Train Loss: 0.43371 | Valid Loss: 0.43775 | Time: 0.46 seconds\n",
            "Epoch: 399 | Train Loss: 0.43290 | Valid Loss: 0.43577 | Time: 0.48 seconds\n",
            "Epoch: 400 | Train Loss: 0.43211 | Valid Loss: 0.43554 | Time: 0.49 seconds\n",
            "Epoch: 401 | Train Loss: 0.43131 | Valid Loss: 0.43404 | Time: 0.51 seconds\n",
            "Epoch: 402 | Train Loss: 0.43055 | Valid Loss: 0.43381 | Time: 0.47 seconds\n",
            "Epoch: 403 | Train Loss: 0.42978 | Valid Loss: 0.43402 | Time: 0.46 seconds\n",
            "Epoch: 404 | Train Loss: 0.42894 | Valid Loss: 0.43241 | Time: 0.47 seconds\n",
            "Epoch: 405 | Train Loss: 0.42817 | Valid Loss: 0.43321 | Time: 0.47 seconds\n",
            "Epoch: 406 | Train Loss: 0.42739 | Valid Loss: 0.43024 | Time: 0.49 seconds\n",
            "Epoch: 407 | Train Loss: 0.42657 | Valid Loss: 0.43040 | Time: 0.46 seconds\n",
            "Epoch: 408 | Train Loss: 0.42582 | Valid Loss: 0.42973 | Time: 0.48 seconds\n",
            "Epoch: 409 | Train Loss: 0.42501 | Valid Loss: 0.42772 | Time: 0.47 seconds\n",
            "Epoch: 410 | Train Loss: 0.42425 | Valid Loss: 0.42758 | Time: 0.47 seconds\n",
            "Epoch: 411 | Train Loss: 0.42347 | Valid Loss: 0.42411 | Time: 0.48 seconds\n",
            "Epoch: 412 | Train Loss: 0.42268 | Valid Loss: 0.42473 | Time: 0.47 seconds\n",
            "Epoch: 413 | Train Loss: 0.42189 | Valid Loss: 0.42341 | Time: 0.48 seconds\n",
            "Epoch: 414 | Train Loss: 0.42113 | Valid Loss: 0.42374 | Time: 0.48 seconds\n",
            "Epoch: 415 | Train Loss: 0.42035 | Valid Loss: 0.42302 | Time: 0.48 seconds\n",
            "Epoch: 416 | Train Loss: 0.41957 | Valid Loss: 0.42416 | Time: 0.49 seconds\n",
            "Epoch: 417 | Train Loss: 0.41882 | Valid Loss: 0.42315 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41805 | Valid Loss: 0.42236 | Time: 0.49 seconds\n",
            "Epoch: 419 | Train Loss: 0.41727 | Valid Loss: 0.41800 | Time: 0.48 seconds\n",
            "Epoch: 420 | Train Loss: 0.41655 | Valid Loss: 0.41842 | Time: 0.47 seconds\n",
            "Epoch: 421 | Train Loss: 0.41576 | Valid Loss: 0.41684 | Time: 0.48 seconds\n",
            "Epoch: 422 | Train Loss: 0.41501 | Valid Loss: 0.41843 | Time: 0.47 seconds\n",
            "Epoch: 423 | Train Loss: 0.41419 | Valid Loss: 0.41760 | Time: 0.47 seconds\n",
            "Epoch: 424 | Train Loss: 0.41347 | Valid Loss: 0.41748 | Time: 0.46 seconds\n",
            "Epoch: 425 | Train Loss: 0.41272 | Valid Loss: 0.41499 | Time: 0.49 seconds\n",
            "Epoch: 426 | Train Loss: 0.41194 | Valid Loss: 0.41370 | Time: 0.48 seconds\n",
            "Epoch: 427 | Train Loss: 0.41120 | Valid Loss: 0.41350 | Time: 0.50 seconds\n",
            "Epoch: 428 | Train Loss: 0.41042 | Valid Loss: 0.41359 | Time: 0.47 seconds\n",
            "Epoch: 429 | Train Loss: 0.40969 | Valid Loss: 0.41044 | Time: 0.48 seconds\n",
            "Epoch: 430 | Train Loss: 0.40894 | Valid Loss: 0.41091 | Time: 0.47 seconds\n",
            "Epoch: 431 | Train Loss: 0.40818 | Valid Loss: 0.41360 | Time: 0.49 seconds\n",
            "Epoch: 432 | Train Loss: 0.40744 | Valid Loss: 0.40875 | Time: 0.47 seconds\n",
            "Epoch: 433 | Train Loss: 0.40672 | Valid Loss: 0.41012 | Time: 0.47 seconds\n",
            "Epoch: 434 | Train Loss: 0.40593 | Valid Loss: 0.40572 | Time: 0.48 seconds\n",
            "Epoch: 435 | Train Loss: 0.40523 | Valid Loss: 0.41163 | Time: 0.50 seconds\n",
            "Epoch: 436 | Train Loss: 0.40446 | Valid Loss: 0.40733 | Time: 0.47 seconds\n",
            "Epoch: 437 | Train Loss: 0.40374 | Valid Loss: 0.40493 | Time: 0.47 seconds\n",
            "Epoch: 438 | Train Loss: 0.40303 | Valid Loss: 0.40629 | Time: 0.46 seconds\n",
            "Epoch: 439 | Train Loss: 0.40227 | Valid Loss: 0.40508 | Time: 0.46 seconds\n",
            "Epoch: 440 | Train Loss: 0.40153 | Valid Loss: 0.40344 | Time: 0.48 seconds\n",
            "Epoch: 441 | Train Loss: 0.40084 | Valid Loss: 0.40305 | Time: 0.47 seconds\n",
            "Epoch: 442 | Train Loss: 0.40007 | Valid Loss: 0.40104 | Time: 0.48 seconds\n",
            "Epoch: 443 | Train Loss: 0.39933 | Valid Loss: 0.40244 | Time: 0.47 seconds\n",
            "Epoch: 444 | Train Loss: 0.39862 | Valid Loss: 0.40328 | Time: 0.46 seconds\n",
            "Epoch: 445 | Train Loss: 0.39787 | Valid Loss: 0.39990 | Time: 0.47 seconds\n",
            "Epoch: 446 | Train Loss: 0.39714 | Valid Loss: 0.40104 | Time: 0.50 seconds\n",
            "Epoch: 447 | Train Loss: 0.39643 | Valid Loss: 0.40002 | Time: 0.48 seconds\n",
            "Epoch: 448 | Train Loss: 0.39570 | Valid Loss: 0.39783 | Time: 0.48 seconds\n",
            "Epoch: 449 | Train Loss: 0.39500 | Valid Loss: 0.39690 | Time: 0.50 seconds\n",
            "Epoch: 450 | Train Loss: 0.39426 | Valid Loss: 0.39671 | Time: 0.49 seconds\n",
            "Epoch: 451 | Train Loss: 0.39356 | Valid Loss: 0.39658 | Time: 0.46 seconds\n",
            "Epoch: 452 | Train Loss: 0.39286 | Valid Loss: 0.39582 | Time: 0.52 seconds\n",
            "Epoch: 453 | Train Loss: 0.39212 | Valid Loss: 0.39422 | Time: 0.50 seconds\n",
            "Epoch: 454 | Train Loss: 0.39143 | Valid Loss: 0.39193 | Time: 0.47 seconds\n",
            "Epoch: 455 | Train Loss: 0.39071 | Valid Loss: 0.39075 | Time: 0.47 seconds\n",
            "Epoch: 456 | Train Loss: 0.39002 | Valid Loss: 0.39134 | Time: 0.46 seconds\n",
            "Epoch: 457 | Train Loss: 0.38929 | Valid Loss: 0.39166 | Time: 0.47 seconds\n",
            "Epoch: 458 | Train Loss: 0.38857 | Valid Loss: 0.39279 | Time: 0.47 seconds\n",
            "Epoch: 459 | Train Loss: 0.38787 | Valid Loss: 0.38949 | Time: 0.48 seconds\n",
            "Epoch: 460 | Train Loss: 0.38716 | Valid Loss: 0.38930 | Time: 0.47 seconds\n",
            "Epoch: 461 | Train Loss: 0.38650 | Valid Loss: 0.38987 | Time: 0.47 seconds\n",
            "Epoch: 462 | Train Loss: 0.38575 | Valid Loss: 0.38689 | Time: 0.47 seconds\n",
            "Epoch: 463 | Train Loss: 0.38505 | Valid Loss: 0.38600 | Time: 0.49 seconds\n",
            "Epoch: 464 | Train Loss: 0.38441 | Valid Loss: 0.38657 | Time: 0.46 seconds\n",
            "Epoch: 465 | Train Loss: 0.38371 | Valid Loss: 0.38556 | Time: 0.47 seconds\n",
            "Epoch: 466 | Train Loss: 0.38301 | Valid Loss: 0.38731 | Time: 0.47 seconds\n",
            "Epoch: 467 | Train Loss: 0.38231 | Valid Loss: 0.38407 | Time: 0.48 seconds\n",
            "Epoch: 468 | Train Loss: 0.38163 | Valid Loss: 0.38380 | Time: 0.48 seconds\n",
            "Epoch: 469 | Train Loss: 0.38091 | Valid Loss: 0.38346 | Time: 0.48 seconds\n",
            "Epoch: 470 | Train Loss: 0.38025 | Valid Loss: 0.38458 | Time: 0.47 seconds\n",
            "Epoch: 471 | Train Loss: 0.37959 | Valid Loss: 0.38221 | Time: 0.49 seconds\n",
            "Epoch: 472 | Train Loss: 0.37886 | Valid Loss: 0.38012 | Time: 0.49 seconds\n",
            "Epoch: 473 | Train Loss: 0.37820 | Valid Loss: 0.37820 | Time: 0.48 seconds\n",
            "Epoch: 474 | Train Loss: 0.37754 | Valid Loss: 0.37897 | Time: 0.47 seconds\n",
            "Epoch: 475 | Train Loss: 0.37679 | Valid Loss: 0.37871 | Time: 0.46 seconds\n",
            "Epoch: 476 | Train Loss: 0.37613 | Valid Loss: 0.37942 | Time: 0.47 seconds\n",
            "Epoch: 477 | Train Loss: 0.37545 | Valid Loss: 0.37639 | Time: 0.46 seconds\n",
            "Epoch: 478 | Train Loss: 0.37480 | Valid Loss: 0.37718 | Time: 0.48 seconds\n",
            "Epoch: 479 | Train Loss: 0.37412 | Valid Loss: 0.37711 | Time: 0.46 seconds\n",
            "Epoch: 480 | Train Loss: 0.37348 | Valid Loss: 0.37759 | Time: 0.48 seconds\n",
            "Epoch: 481 | Train Loss: 0.37280 | Valid Loss: 0.37416 | Time: 0.47 seconds\n",
            "Epoch: 482 | Train Loss: 0.37217 | Valid Loss: 0.37387 | Time: 0.48 seconds\n",
            "Epoch: 483 | Train Loss: 0.37149 | Valid Loss: 0.37614 | Time: 0.46 seconds\n",
            "Epoch: 484 | Train Loss: 0.37080 | Valid Loss: 0.37619 | Time: 0.49 seconds\n",
            "Epoch: 485 | Train Loss: 0.37015 | Valid Loss: 0.37301 | Time: 0.50 seconds\n",
            "Epoch: 486 | Train Loss: 0.36949 | Valid Loss: 0.37264 | Time: 0.47 seconds\n",
            "Epoch: 487 | Train Loss: 0.36880 | Valid Loss: 0.37017 | Time: 0.48 seconds\n",
            "Epoch: 488 | Train Loss: 0.36821 | Valid Loss: 0.37158 | Time: 0.48 seconds\n",
            "Epoch: 489 | Train Loss: 0.36753 | Valid Loss: 0.36979 | Time: 0.47 seconds\n",
            "Epoch: 490 | Train Loss: 0.36688 | Valid Loss: 0.36938 | Time: 0.46 seconds\n",
            "Epoch: 491 | Train Loss: 0.36622 | Valid Loss: 0.36686 | Time: 0.48 seconds\n",
            "Epoch: 492 | Train Loss: 0.36556 | Valid Loss: 0.36758 | Time: 0.46 seconds\n",
            "Epoch: 493 | Train Loss: 0.36493 | Valid Loss: 0.36921 | Time: 0.47 seconds\n",
            "Epoch: 494 | Train Loss: 0.36427 | Valid Loss: 0.36685 | Time: 0.48 seconds\n",
            "Epoch: 495 | Train Loss: 0.36362 | Valid Loss: 0.36347 | Time: 0.48 seconds\n",
            "Epoch: 496 | Train Loss: 0.36302 | Valid Loss: 0.36656 | Time: 0.47 seconds\n",
            "Epoch: 497 | Train Loss: 0.36238 | Valid Loss: 0.36434 | Time: 0.48 seconds\n",
            "Epoch: 498 | Train Loss: 0.36171 | Valid Loss: 0.36306 | Time: 0.49 seconds\n",
            "Epoch: 499 | Train Loss: 0.36106 | Valid Loss: 0.36497 | Time: 0.48 seconds\n",
            "Epoch: 500 | Train Loss: 0.36042 | Valid Loss: 0.36439 | Time: 0.46 seconds\n",
            "Epoch: 501 | Train Loss: 0.35979 | Valid Loss: 0.36355 | Time: 0.47 seconds\n",
            "Epoch: 502 | Train Loss: 0.35912 | Valid Loss: 0.35953 | Time: 0.48 seconds\n",
            "Epoch: 503 | Train Loss: 0.35850 | Valid Loss: 0.36070 | Time: 0.46 seconds\n",
            "Epoch: 504 | Train Loss: 0.35790 | Valid Loss: 0.36086 | Time: 0.46 seconds\n",
            "Epoch: 505 | Train Loss: 0.35727 | Valid Loss: 0.36115 | Time: 0.46 seconds\n",
            "Epoch: 506 | Train Loss: 0.35663 | Valid Loss: 0.36078 | Time: 0.48 seconds\n",
            "Epoch: 507 | Train Loss: 0.35601 | Valid Loss: 0.35979 | Time: 0.47 seconds\n",
            "Epoch: 508 | Train Loss: 0.35543 | Valid Loss: 0.36042 | Time: 0.48 seconds\n",
            "Epoch: 509 | Train Loss: 0.35477 | Valid Loss: 0.35590 | Time: 0.46 seconds\n",
            "Epoch: 510 | Train Loss: 0.35415 | Valid Loss: 0.35511 | Time: 0.49 seconds\n",
            "Epoch: 511 | Train Loss: 0.35352 | Valid Loss: 0.35686 | Time: 0.46 seconds\n",
            "Epoch: 512 | Train Loss: 0.35290 | Valid Loss: 0.35631 | Time: 0.46 seconds\n",
            "Epoch: 513 | Train Loss: 0.35229 | Valid Loss: 0.35617 | Time: 0.45 seconds\n",
            "Epoch: 514 | Train Loss: 0.35170 | Valid Loss: 0.35219 | Time: 0.46 seconds\n",
            "Epoch: 515 | Train Loss: 0.35104 | Valid Loss: 0.35605 | Time: 0.47 seconds\n",
            "Epoch: 516 | Train Loss: 0.35042 | Valid Loss: 0.35487 | Time: 0.45 seconds\n",
            "Epoch: 517 | Train Loss: 0.34986 | Valid Loss: 0.35357 | Time: 0.47 seconds\n",
            "Epoch: 518 | Train Loss: 0.34924 | Valid Loss: 0.35262 | Time: 0.46 seconds\n",
            "Epoch: 519 | Train Loss: 0.34861 | Valid Loss: 0.34892 | Time: 0.47 seconds\n",
            "Epoch: 520 | Train Loss: 0.34800 | Valid Loss: 0.35023 | Time: 0.48 seconds\n",
            "Epoch: 521 | Train Loss: 0.34743 | Valid Loss: 0.34951 | Time: 0.47 seconds\n",
            "Epoch: 522 | Train Loss: 0.34682 | Valid Loss: 0.34962 | Time: 0.47 seconds\n",
            "Epoch: 523 | Train Loss: 0.34617 | Valid Loss: 0.34805 | Time: 0.47 seconds\n",
            "Epoch: 524 | Train Loss: 0.34560 | Valid Loss: 0.34752 | Time: 0.46 seconds\n",
            "Epoch: 525 | Train Loss: 0.34501 | Valid Loss: 0.34693 | Time: 0.46 seconds\n",
            "Epoch: 526 | Train Loss: 0.34438 | Valid Loss: 0.34753 | Time: 0.46 seconds\n",
            "Epoch: 527 | Train Loss: 0.34382 | Valid Loss: 0.34761 | Time: 0.46 seconds\n",
            "Epoch: 528 | Train Loss: 0.34324 | Valid Loss: 0.34690 | Time: 0.47 seconds\n",
            "Epoch: 529 | Train Loss: 0.34264 | Valid Loss: 0.34549 | Time: 0.46 seconds\n",
            "Epoch: 530 | Train Loss: 0.34204 | Valid Loss: 0.34569 | Time: 0.46 seconds\n",
            "Epoch: 531 | Train Loss: 0.34145 | Valid Loss: 0.34527 | Time: 0.46 seconds\n",
            "Epoch: 532 | Train Loss: 0.34089 | Valid Loss: 0.34394 | Time: 0.49 seconds\n",
            "Epoch: 533 | Train Loss: 0.34025 | Valid Loss: 0.34148 | Time: 0.46 seconds\n",
            "Epoch: 534 | Train Loss: 0.33967 | Valid Loss: 0.34344 | Time: 0.46 seconds\n",
            "Epoch: 535 | Train Loss: 0.33911 | Valid Loss: 0.34123 | Time: 0.46 seconds\n",
            "Epoch: 536 | Train Loss: 0.33856 | Valid Loss: 0.34017 | Time: 0.47 seconds\n",
            "Epoch: 537 | Train Loss: 0.33796 | Valid Loss: 0.34068 | Time: 0.47 seconds\n",
            "Epoch: 538 | Train Loss: 0.33734 | Valid Loss: 0.33877 | Time: 0.46 seconds\n",
            "Epoch: 539 | Train Loss: 0.33677 | Valid Loss: 0.34008 | Time: 0.46 seconds\n",
            "Epoch: 540 | Train Loss: 0.33619 | Valid Loss: 0.33772 | Time: 0.47 seconds\n",
            "Epoch: 541 | Train Loss: 0.33562 | Valid Loss: 0.34076 | Time: 0.47 seconds\n",
            "Epoch: 542 | Train Loss: 0.33500 | Valid Loss: 0.33478 | Time: 0.46 seconds\n",
            "Epoch: 543 | Train Loss: 0.33450 | Valid Loss: 0.33668 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33395 | Valid Loss: 0.33696 | Time: 0.45 seconds\n",
            "Epoch: 545 | Train Loss: 0.33333 | Valid Loss: 0.33744 | Time: 0.46 seconds\n",
            "Epoch: 546 | Train Loss: 0.33277 | Valid Loss: 0.33647 | Time: 0.46 seconds\n",
            "Epoch: 547 | Train Loss: 0.33220 | Valid Loss: 0.33479 | Time: 0.49 seconds\n",
            "Epoch: 548 | Train Loss: 0.33160 | Valid Loss: 0.33660 | Time: 0.46 seconds\n",
            "Epoch: 549 | Train Loss: 0.33104 | Valid Loss: 0.33402 | Time: 0.47 seconds\n",
            "Epoch: 550 | Train Loss: 0.33051 | Valid Loss: 0.33212 | Time: 0.48 seconds\n",
            "Epoch: 551 | Train Loss: 0.32993 | Valid Loss: 0.33008 | Time: 0.46 seconds\n",
            "Epoch: 552 | Train Loss: 0.32935 | Valid Loss: 0.33245 | Time: 0.48 seconds\n",
            "Epoch: 553 | Train Loss: 0.32883 | Valid Loss: 0.33282 | Time: 0.45 seconds\n",
            "Epoch: 554 | Train Loss: 0.32823 | Valid Loss: 0.33320 | Time: 0.46 seconds\n",
            "Epoch: 555 | Train Loss: 0.32774 | Valid Loss: 0.33009 | Time: 0.46 seconds\n",
            "Epoch: 556 | Train Loss: 0.32714 | Valid Loss: 0.33218 | Time: 0.47 seconds\n",
            "Epoch: 557 | Train Loss: 0.32659 | Valid Loss: 0.32969 | Time: 0.47 seconds\n",
            "Epoch: 558 | Train Loss: 0.32607 | Valid Loss: 0.32888 | Time: 0.48 seconds\n",
            "Epoch: 559 | Train Loss: 0.32553 | Valid Loss: 0.32805 | Time: 0.47 seconds\n",
            "Epoch: 560 | Train Loss: 0.32496 | Valid Loss: 0.32700 | Time: 0.46 seconds\n",
            "Epoch: 561 | Train Loss: 0.32442 | Valid Loss: 0.32719 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32386 | Valid Loss: 0.32628 | Time: 0.48 seconds\n",
            "Epoch: 563 | Train Loss: 0.32333 | Valid Loss: 0.32586 | Time: 0.47 seconds\n",
            "Epoch: 564 | Train Loss: 0.32282 | Valid Loss: 0.32386 | Time: 0.47 seconds\n",
            "Epoch: 565 | Train Loss: 0.32221 | Valid Loss: 0.32595 | Time: 0.47 seconds\n",
            "Epoch: 566 | Train Loss: 0.32169 | Valid Loss: 0.32605 | Time: 0.46 seconds\n",
            "Epoch: 567 | Train Loss: 0.32112 | Valid Loss: 0.32420 | Time: 0.47 seconds\n",
            "Epoch: 568 | Train Loss: 0.32057 | Valid Loss: 0.32400 | Time: 0.46 seconds\n",
            "Epoch: 569 | Train Loss: 0.32005 | Valid Loss: 0.32391 | Time: 0.47 seconds\n",
            "Epoch: 570 | Train Loss: 0.31951 | Valid Loss: 0.32160 | Time: 0.47 seconds\n",
            "Epoch: 571 | Train Loss: 0.31903 | Valid Loss: 0.32131 | Time: 0.47 seconds\n",
            "Epoch: 572 | Train Loss: 0.31844 | Valid Loss: 0.31952 | Time: 0.47 seconds\n",
            "Epoch: 573 | Train Loss: 0.31795 | Valid Loss: 0.32051 | Time: 0.46 seconds\n",
            "Epoch: 574 | Train Loss: 0.31740 | Valid Loss: 0.32260 | Time: 0.47 seconds\n",
            "Epoch: 575 | Train Loss: 0.31681 | Valid Loss: 0.31843 | Time: 0.49 seconds\n",
            "Epoch: 576 | Train Loss: 0.31634 | Valid Loss: 0.31801 | Time: 0.47 seconds\n",
            "Epoch: 577 | Train Loss: 0.31580 | Valid Loss: 0.31935 | Time: 0.46 seconds\n",
            "Epoch: 578 | Train Loss: 0.31526 | Valid Loss: 0.31759 | Time: 0.48 seconds\n",
            "Epoch: 579 | Train Loss: 0.31474 | Valid Loss: 0.31830 | Time: 0.46 seconds\n",
            "Epoch: 580 | Train Loss: 0.31422 | Valid Loss: 0.31729 | Time: 0.47 seconds\n",
            "Epoch: 581 | Train Loss: 0.31369 | Valid Loss: 0.31823 | Time: 0.45 seconds\n",
            "Epoch: 582 | Train Loss: 0.31318 | Valid Loss: 0.31513 | Time: 0.48 seconds\n",
            "Epoch: 583 | Train Loss: 0.31263 | Valid Loss: 0.31495 | Time: 0.48 seconds\n",
            "Epoch: 584 | Train Loss: 0.31216 | Valid Loss: 0.31484 | Time: 0.49 seconds\n",
            "Epoch: 585 | Train Loss: 0.31161 | Valid Loss: 0.31427 | Time: 0.46 seconds\n",
            "Epoch: 586 | Train Loss: 0.31109 | Valid Loss: 0.31386 | Time: 0.46 seconds\n",
            "Epoch: 587 | Train Loss: 0.31058 | Valid Loss: 0.31339 | Time: 0.47 seconds\n",
            "Epoch: 588 | Train Loss: 0.31007 | Valid Loss: 0.31246 | Time: 0.46 seconds\n",
            "Epoch: 589 | Train Loss: 0.30956 | Valid Loss: 0.31284 | Time: 0.47 seconds\n",
            "Epoch: 590 | Train Loss: 0.30908 | Valid Loss: 0.31194 | Time: 0.46 seconds\n",
            "Epoch: 591 | Train Loss: 0.30858 | Valid Loss: 0.31015 | Time: 0.47 seconds\n",
            "Epoch: 592 | Train Loss: 0.30805 | Valid Loss: 0.31188 | Time: 0.46 seconds\n",
            "Epoch: 593 | Train Loss: 0.30750 | Valid Loss: 0.30914 | Time: 0.48 seconds\n",
            "Epoch: 594 | Train Loss: 0.30701 | Valid Loss: 0.30953 | Time: 0.47 seconds\n",
            "Epoch: 595 | Train Loss: 0.30644 | Valid Loss: 0.31237 | Time: 0.47 seconds\n",
            "Epoch: 596 | Train Loss: 0.30597 | Valid Loss: 0.31028 | Time: 0.46 seconds\n",
            "Epoch: 597 | Train Loss: 0.30548 | Valid Loss: 0.30901 | Time: 0.47 seconds\n",
            "Epoch: 598 | Train Loss: 0.30499 | Valid Loss: 0.30876 | Time: 0.48 seconds\n",
            "Epoch: 599 | Train Loss: 0.30447 | Valid Loss: 0.30744 | Time: 0.49 seconds\n",
            "Epoch: 600 | Train Loss: 0.30399 | Valid Loss: 0.30716 | Time: 0.47 seconds\n",
            "Epoch: 601 | Train Loss: 0.30351 | Valid Loss: 0.30647 | Time: 0.46 seconds\n",
            "Epoch: 602 | Train Loss: 0.30296 | Valid Loss: 0.30591 | Time: 0.48 seconds\n",
            "Epoch: 603 | Train Loss: 0.30244 | Valid Loss: 0.30409 | Time: 0.49 seconds\n",
            "Epoch: 604 | Train Loss: 0.30199 | Valid Loss: 0.30485 | Time: 0.47 seconds\n",
            "Epoch: 605 | Train Loss: 0.30151 | Valid Loss: 0.30374 | Time: 0.46 seconds\n",
            "Epoch: 606 | Train Loss: 0.30102 | Valid Loss: 0.30199 | Time: 0.47 seconds\n",
            "Epoch: 607 | Train Loss: 0.30051 | Valid Loss: 0.30273 | Time: 0.47 seconds\n",
            "Epoch: 608 | Train Loss: 0.30003 | Valid Loss: 0.30251 | Time: 0.47 seconds\n",
            "Epoch: 609 | Train Loss: 0.29951 | Valid Loss: 0.30126 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29898 | Valid Loss: 0.30105 | Time: 0.48 seconds\n",
            "Epoch: 611 | Train Loss: 0.29846 | Valid Loss: 0.30105 | Time: 0.45 seconds\n",
            "Epoch: 612 | Train Loss: 0.29806 | Valid Loss: 0.29950 | Time: 0.46 seconds\n",
            "Epoch: 613 | Train Loss: 0.29754 | Valid Loss: 0.29823 | Time: 0.47 seconds\n",
            "Epoch: 614 | Train Loss: 0.29706 | Valid Loss: 0.29825 | Time: 0.46 seconds\n",
            "Epoch: 615 | Train Loss: 0.29654 | Valid Loss: 0.30084 | Time: 0.47 seconds\n",
            "Epoch: 616 | Train Loss: 0.29609 | Valid Loss: 0.29819 | Time: 0.46 seconds\n",
            "Epoch: 617 | Train Loss: 0.29560 | Valid Loss: 0.29757 | Time: 0.49 seconds\n",
            "Epoch: 618 | Train Loss: 0.29515 | Valid Loss: 0.29783 | Time: 0.46 seconds\n",
            "Epoch: 619 | Train Loss: 0.29465 | Valid Loss: 0.29735 | Time: 0.47 seconds\n",
            "Epoch: 620 | Train Loss: 0.29416 | Valid Loss: 0.29741 | Time: 0.46 seconds\n",
            "Epoch: 621 | Train Loss: 0.29366 | Valid Loss: 0.29780 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29320 | Valid Loss: 0.29562 | Time: 0.48 seconds\n",
            "Epoch: 623 | Train Loss: 0.29268 | Valid Loss: 0.29588 | Time: 0.47 seconds\n",
            "Epoch: 624 | Train Loss: 0.29224 | Valid Loss: 0.29564 | Time: 0.46 seconds\n",
            "Epoch: 625 | Train Loss: 0.29177 | Valid Loss: 0.29291 | Time: 0.47 seconds\n",
            "Epoch: 626 | Train Loss: 0.29127 | Valid Loss: 0.29468 | Time: 0.48 seconds\n",
            "Epoch: 627 | Train Loss: 0.29076 | Valid Loss: 0.29350 | Time: 0.47 seconds\n",
            "Epoch: 628 | Train Loss: 0.29035 | Valid Loss: 0.29249 | Time: 0.47 seconds\n",
            "Epoch: 629 | Train Loss: 0.28988 | Valid Loss: 0.29398 | Time: 0.46 seconds\n",
            "Epoch: 630 | Train Loss: 0.28938 | Valid Loss: 0.29125 | Time: 0.48 seconds\n",
            "Epoch: 631 | Train Loss: 0.28886 | Valid Loss: 0.29137 | Time: 0.46 seconds\n",
            "Epoch: 632 | Train Loss: 0.28842 | Valid Loss: 0.29050 | Time: 0.48 seconds\n",
            "Epoch: 633 | Train Loss: 0.28798 | Valid Loss: 0.29043 | Time: 0.47 seconds\n",
            "Epoch: 634 | Train Loss: 0.28754 | Valid Loss: 0.29049 | Time: 0.46 seconds\n",
            "Epoch: 635 | Train Loss: 0.28705 | Valid Loss: 0.29001 | Time: 0.46 seconds\n",
            "Epoch: 636 | Train Loss: 0.28660 | Valid Loss: 0.28999 | Time: 0.49 seconds\n",
            "Epoch: 637 | Train Loss: 0.28614 | Valid Loss: 0.28987 | Time: 0.46 seconds\n",
            "Epoch: 638 | Train Loss: 0.28566 | Valid Loss: 0.28922 | Time: 0.46 seconds\n",
            "Epoch: 639 | Train Loss: 0.28518 | Valid Loss: 0.28780 | Time: 0.51 seconds\n",
            "Epoch: 640 | Train Loss: 0.28471 | Valid Loss: 0.28723 | Time: 0.47 seconds\n",
            "Epoch: 641 | Train Loss: 0.28431 | Valid Loss: 0.28662 | Time: 0.47 seconds\n",
            "Epoch: 642 | Train Loss: 0.28377 | Valid Loss: 0.28435 | Time: 0.47 seconds\n",
            "Epoch: 643 | Train Loss: 0.28335 | Valid Loss: 0.28531 | Time: 0.47 seconds\n",
            "Epoch: 644 | Train Loss: 0.28287 | Valid Loss: 0.28625 | Time: 0.46 seconds\n",
            "Epoch: 645 | Train Loss: 0.28245 | Valid Loss: 0.28497 | Time: 0.47 seconds\n",
            "Epoch: 646 | Train Loss: 0.28194 | Valid Loss: 0.28610 | Time: 0.46 seconds\n",
            "Epoch: 647 | Train Loss: 0.28154 | Valid Loss: 0.28431 | Time: 0.47 seconds\n",
            "Epoch: 648 | Train Loss: 0.28104 | Valid Loss: 0.28046 | Time: 0.46 seconds\n",
            "Epoch: 649 | Train Loss: 0.28059 | Valid Loss: 0.28318 | Time: 0.52 seconds\n",
            "Epoch: 650 | Train Loss: 0.28009 | Valid Loss: 0.28192 | Time: 0.46 seconds\n",
            "Epoch: 651 | Train Loss: 0.27972 | Valid Loss: 0.28128 | Time: 0.47 seconds\n",
            "Epoch: 652 | Train Loss: 0.27923 | Valid Loss: 0.28430 | Time: 0.47 seconds\n",
            "Epoch: 653 | Train Loss: 0.27880 | Valid Loss: 0.28120 | Time: 0.47 seconds\n",
            "Epoch: 654 | Train Loss: 0.27834 | Valid Loss: 0.28251 | Time: 0.46 seconds\n",
            "Epoch: 655 | Train Loss: 0.27787 | Valid Loss: 0.28185 | Time: 0.47 seconds\n",
            "Epoch: 656 | Train Loss: 0.27741 | Valid Loss: 0.27988 | Time: 0.49 seconds\n",
            "Epoch: 657 | Train Loss: 0.27702 | Valid Loss: 0.27830 | Time: 0.46 seconds\n",
            "Epoch: 658 | Train Loss: 0.27655 | Valid Loss: 0.27808 | Time: 0.48 seconds\n",
            "Epoch: 659 | Train Loss: 0.27609 | Valid Loss: 0.27897 | Time: 0.46 seconds\n",
            "Epoch: 660 | Train Loss: 0.27566 | Valid Loss: 0.27888 | Time: 0.47 seconds\n",
            "Epoch: 661 | Train Loss: 0.27519 | Valid Loss: 0.27854 | Time: 0.46 seconds\n",
            "Epoch: 662 | Train Loss: 0.27475 | Valid Loss: 0.27751 | Time: 0.48 seconds\n",
            "Epoch: 663 | Train Loss: 0.27433 | Valid Loss: 0.27674 | Time: 0.48 seconds\n",
            "Epoch: 664 | Train Loss: 0.27389 | Valid Loss: 0.27573 | Time: 0.47 seconds\n",
            "Epoch: 665 | Train Loss: 0.27347 | Valid Loss: 0.27659 | Time: 0.45 seconds\n",
            "Epoch: 666 | Train Loss: 0.27299 | Valid Loss: 0.27610 | Time: 0.45 seconds\n",
            "Epoch: 667 | Train Loss: 0.27251 | Valid Loss: 0.27377 | Time: 0.48 seconds\n",
            "Epoch: 668 | Train Loss: 0.27209 | Valid Loss: 0.27506 | Time: 0.46 seconds\n",
            "Epoch: 669 | Train Loss: 0.27170 | Valid Loss: 0.27354 | Time: 0.47 seconds\n",
            "Epoch: 670 | Train Loss: 0.27123 | Valid Loss: 0.27397 | Time: 0.46 seconds\n",
            "Epoch: 671 | Train Loss: 0.27081 | Valid Loss: 0.27547 | Time: 0.47 seconds\n",
            "Epoch: 672 | Train Loss: 0.27037 | Valid Loss: 0.27197 | Time: 0.48 seconds\n",
            "Epoch: 673 | Train Loss: 0.26996 | Valid Loss: 0.27391 | Time: 0.49 seconds\n",
            "Epoch: 674 | Train Loss: 0.26955 | Valid Loss: 0.27243 | Time: 0.48 seconds\n",
            "Epoch: 675 | Train Loss: 0.26908 | Valid Loss: 0.27365 | Time: 0.48 seconds\n",
            "Epoch: 676 | Train Loss: 0.26867 | Valid Loss: 0.26979 | Time: 0.47 seconds\n",
            "Epoch: 677 | Train Loss: 0.26818 | Valid Loss: 0.27008 | Time: 0.48 seconds\n",
            "Epoch: 678 | Train Loss: 0.26780 | Valid Loss: 0.26964 | Time: 0.46 seconds\n",
            "Epoch: 679 | Train Loss: 0.26735 | Valid Loss: 0.26762 | Time: 0.47 seconds\n",
            "Epoch: 680 | Train Loss: 0.26689 | Valid Loss: 0.26782 | Time: 0.46 seconds\n",
            "Epoch: 681 | Train Loss: 0.26648 | Valid Loss: 0.26727 | Time: 0.47 seconds\n",
            "Epoch: 682 | Train Loss: 0.26607 | Valid Loss: 0.26868 | Time: 0.48 seconds\n",
            "Epoch: 683 | Train Loss: 0.26566 | Valid Loss: 0.26746 | Time: 0.46 seconds\n",
            "Epoch: 684 | Train Loss: 0.26519 | Valid Loss: 0.26799 | Time: 0.47 seconds\n",
            "Epoch: 685 | Train Loss: 0.26478 | Valid Loss: 0.26785 | Time: 0.46 seconds\n",
            "Epoch: 686 | Train Loss: 0.26435 | Valid Loss: 0.26609 | Time: 0.47 seconds\n",
            "Epoch: 687 | Train Loss: 0.26393 | Valid Loss: 0.26729 | Time: 0.47 seconds\n",
            "Epoch: 688 | Train Loss: 0.26352 | Valid Loss: 0.26544 | Time: 0.48 seconds\n",
            "Epoch: 689 | Train Loss: 0.26310 | Valid Loss: 0.26394 | Time: 0.47 seconds\n",
            "Epoch: 690 | Train Loss: 0.26264 | Valid Loss: 0.26453 | Time: 0.47 seconds\n",
            "Epoch: 691 | Train Loss: 0.26224 | Valid Loss: 0.26459 | Time: 0.46 seconds\n",
            "Epoch: 692 | Train Loss: 0.26182 | Valid Loss: 0.26442 | Time: 0.47 seconds\n",
            "Epoch: 693 | Train Loss: 0.26138 | Valid Loss: 0.26460 | Time: 0.47 seconds\n",
            "Epoch: 694 | Train Loss: 0.26097 | Valid Loss: 0.26350 | Time: 0.46 seconds\n",
            "Epoch: 695 | Train Loss: 0.26054 | Valid Loss: 0.26203 | Time: 0.48 seconds\n",
            "Epoch: 696 | Train Loss: 0.26013 | Valid Loss: 0.26315 | Time: 0.45 seconds\n",
            "Epoch: 697 | Train Loss: 0.25975 | Valid Loss: 0.26099 | Time: 0.48 seconds\n",
            "Epoch: 698 | Train Loss: 0.25928 | Valid Loss: 0.26193 | Time: 0.46 seconds\n",
            "Epoch: 699 | Train Loss: 0.25892 | Valid Loss: 0.25980 | Time: 0.49 seconds\n",
            "Epoch: 700 | Train Loss: 0.25849 | Valid Loss: 0.26239 | Time: 0.47 seconds\n",
            "Epoch: 701 | Train Loss: 0.25803 | Valid Loss: 0.25916 | Time: 0.49 seconds\n",
            "Epoch: 702 | Train Loss: 0.25766 | Valid Loss: 0.25991 | Time: 0.48 seconds\n",
            "Epoch: 703 | Train Loss: 0.25725 | Valid Loss: 0.25826 | Time: 0.49 seconds\n",
            "Epoch: 704 | Train Loss: 0.25682 | Valid Loss: 0.25823 | Time: 0.47 seconds\n",
            "Epoch: 705 | Train Loss: 0.25643 | Valid Loss: 0.25869 | Time: 0.48 seconds\n",
            "Epoch: 706 | Train Loss: 0.25602 | Valid Loss: 0.25783 | Time: 0.46 seconds\n",
            "Epoch: 707 | Train Loss: 0.25560 | Valid Loss: 0.25754 | Time: 0.47 seconds\n",
            "Epoch: 708 | Train Loss: 0.25521 | Valid Loss: 0.25802 | Time: 0.48 seconds\n",
            "Epoch: 709 | Train Loss: 0.25480 | Valid Loss: 0.25616 | Time: 0.47 seconds\n",
            "Epoch: 710 | Train Loss: 0.25438 | Valid Loss: 0.25838 | Time: 0.47 seconds\n",
            "Epoch: 711 | Train Loss: 0.25400 | Valid Loss: 0.25643 | Time: 0.46 seconds\n",
            "Epoch: 712 | Train Loss: 0.25356 | Valid Loss: 0.25620 | Time: 0.46 seconds\n",
            "Epoch: 713 | Train Loss: 0.25315 | Valid Loss: 0.25576 | Time: 0.47 seconds\n",
            "Epoch: 714 | Train Loss: 0.25276 | Valid Loss: 0.25559 | Time: 0.48 seconds\n",
            "Epoch: 715 | Train Loss: 0.25231 | Valid Loss: 0.25527 | Time: 0.50 seconds\n",
            "Epoch: 716 | Train Loss: 0.25197 | Valid Loss: 0.25686 | Time: 0.49 seconds\n",
            "Epoch: 717 | Train Loss: 0.25152 | Valid Loss: 0.25356 | Time: 0.46 seconds\n",
            "Epoch: 718 | Train Loss: 0.25115 | Valid Loss: 0.25229 | Time: 0.48 seconds\n",
            "Epoch: 719 | Train Loss: 0.25076 | Valid Loss: 0.25372 | Time: 0.48 seconds\n",
            "Epoch: 720 | Train Loss: 0.25037 | Valid Loss: 0.25458 | Time: 0.46 seconds\n",
            "Epoch: 721 | Train Loss: 0.24998 | Valid Loss: 0.25247 | Time: 0.47 seconds\n",
            "Epoch: 722 | Train Loss: 0.24959 | Valid Loss: 0.25215 | Time: 0.47 seconds\n",
            "Epoch: 723 | Train Loss: 0.24919 | Valid Loss: 0.25286 | Time: 0.47 seconds\n",
            "Epoch: 724 | Train Loss: 0.24873 | Valid Loss: 0.25224 | Time: 0.47 seconds\n",
            "Epoch: 725 | Train Loss: 0.24834 | Valid Loss: 0.25036 | Time: 0.47 seconds\n",
            "Epoch: 726 | Train Loss: 0.24795 | Valid Loss: 0.24915 | Time: 0.46 seconds\n",
            "Epoch: 727 | Train Loss: 0.24754 | Valid Loss: 0.24900 | Time: 0.47 seconds\n",
            "Epoch: 728 | Train Loss: 0.24714 | Valid Loss: 0.25021 | Time: 0.46 seconds\n",
            "Epoch: 729 | Train Loss: 0.24676 | Valid Loss: 0.24800 | Time: 0.50 seconds\n",
            "Epoch: 730 | Train Loss: 0.24637 | Valid Loss: 0.25022 | Time: 0.47 seconds\n",
            "Epoch: 731 | Train Loss: 0.24597 | Valid Loss: 0.24843 | Time: 0.47 seconds\n",
            "Epoch: 732 | Train Loss: 0.24559 | Valid Loss: 0.24670 | Time: 0.46 seconds\n",
            "Epoch: 733 | Train Loss: 0.24523 | Valid Loss: 0.24816 | Time: 0.47 seconds\n",
            "Epoch: 734 | Train Loss: 0.24478 | Valid Loss: 0.24514 | Time: 0.50 seconds\n",
            "Epoch: 735 | Train Loss: 0.24444 | Valid Loss: 0.24673 | Time: 0.47 seconds\n",
            "Epoch: 736 | Train Loss: 0.24404 | Valid Loss: 0.24576 | Time: 0.47 seconds\n",
            "Epoch: 737 | Train Loss: 0.24362 | Valid Loss: 0.24536 | Time: 0.46 seconds\n",
            "Epoch: 738 | Train Loss: 0.24325 | Valid Loss: 0.24685 | Time: 0.47 seconds\n",
            "Epoch: 739 | Train Loss: 0.24285 | Valid Loss: 0.24655 | Time: 0.46 seconds\n",
            "Epoch: 740 | Train Loss: 0.24247 | Valid Loss: 0.24521 | Time: 0.49 seconds\n",
            "Epoch: 741 | Train Loss: 0.24211 | Valid Loss: 0.24393 | Time: 0.46 seconds\n",
            "Epoch: 742 | Train Loss: 0.24174 | Valid Loss: 0.24453 | Time: 0.47 seconds\n",
            "Epoch: 743 | Train Loss: 0.24132 | Valid Loss: 0.24235 | Time: 0.47 seconds\n",
            "Epoch: 744 | Train Loss: 0.24094 | Valid Loss: 0.24340 | Time: 0.47 seconds\n",
            "Epoch: 745 | Train Loss: 0.24055 | Valid Loss: 0.24560 | Time: 0.48 seconds\n",
            "Epoch: 746 | Train Loss: 0.24019 | Valid Loss: 0.24207 | Time: 0.48 seconds\n",
            "Epoch: 747 | Train Loss: 0.23978 | Valid Loss: 0.24130 | Time: 0.46 seconds\n",
            "Epoch: 748 | Train Loss: 0.23944 | Valid Loss: 0.24283 | Time: 0.46 seconds\n",
            "Epoch: 749 | Train Loss: 0.23904 | Valid Loss: 0.24176 | Time: 0.46 seconds\n",
            "Epoch: 750 | Train Loss: 0.23861 | Valid Loss: 0.24035 | Time: 0.47 seconds\n",
            "Epoch: 751 | Train Loss: 0.23825 | Valid Loss: 0.23970 | Time: 0.50 seconds\n",
            "Epoch: 752 | Train Loss: 0.23792 | Valid Loss: 0.24062 | Time: 0.48 seconds\n",
            "Epoch: 753 | Train Loss: 0.23750 | Valid Loss: 0.24043 | Time: 0.47 seconds\n",
            "Epoch: 754 | Train Loss: 0.23713 | Valid Loss: 0.23974 | Time: 0.46 seconds\n",
            "Epoch: 755 | Train Loss: 0.23676 | Valid Loss: 0.23845 | Time: 0.49 seconds\n",
            "Epoch: 756 | Train Loss: 0.23636 | Valid Loss: 0.23909 | Time: 0.46 seconds\n",
            "Epoch: 757 | Train Loss: 0.23598 | Valid Loss: 0.23852 | Time: 0.47 seconds\n",
            "Epoch: 758 | Train Loss: 0.23565 | Valid Loss: 0.23915 | Time: 0.47 seconds\n",
            "Epoch: 759 | Train Loss: 0.23527 | Valid Loss: 0.23611 | Time: 0.49 seconds\n",
            "Epoch: 760 | Train Loss: 0.23489 | Valid Loss: 0.23527 | Time: 0.50 seconds\n",
            "Epoch: 761 | Train Loss: 0.23452 | Valid Loss: 0.23777 | Time: 0.47 seconds\n",
            "Epoch: 762 | Train Loss: 0.23413 | Valid Loss: 0.23677 | Time: 0.46 seconds\n",
            "Epoch: 763 | Train Loss: 0.23377 | Valid Loss: 0.23408 | Time: 0.47 seconds\n",
            "Epoch: 764 | Train Loss: 0.23340 | Valid Loss: 0.23692 | Time: 0.49 seconds\n",
            "Epoch: 765 | Train Loss: 0.23302 | Valid Loss: 0.23456 | Time: 0.46 seconds\n",
            "Epoch: 766 | Train Loss: 0.23266 | Valid Loss: 0.23682 | Time: 0.48 seconds\n",
            "Epoch: 767 | Train Loss: 0.23226 | Valid Loss: 0.23482 | Time: 0.46 seconds\n",
            "Epoch: 768 | Train Loss: 0.23193 | Valid Loss: 0.23307 | Time: 0.49 seconds\n",
            "Epoch: 769 | Train Loss: 0.23153 | Valid Loss: 0.23267 | Time: 0.48 seconds\n",
            "Epoch: 770 | Train Loss: 0.23115 | Valid Loss: 0.23338 | Time: 0.47 seconds\n",
            "Epoch: 771 | Train Loss: 0.23084 | Valid Loss: 0.23357 | Time: 0.47 seconds\n",
            "Epoch: 772 | Train Loss: 0.23041 | Valid Loss: 0.23250 | Time: 0.49 seconds\n",
            "Epoch: 773 | Train Loss: 0.23005 | Valid Loss: 0.23291 | Time: 0.48 seconds\n",
            "Epoch: 774 | Train Loss: 0.22968 | Valid Loss: 0.22914 | Time: 0.48 seconds\n",
            "Epoch: 775 | Train Loss: 0.22933 | Valid Loss: 0.23260 | Time: 0.47 seconds\n",
            "Epoch: 776 | Train Loss: 0.22897 | Valid Loss: 0.23178 | Time: 0.48 seconds\n",
            "Epoch: 777 | Train Loss: 0.22865 | Valid Loss: 0.23182 | Time: 0.46 seconds\n",
            "Epoch: 778 | Train Loss: 0.22828 | Valid Loss: 0.23038 | Time: 0.47 seconds\n",
            "Epoch: 779 | Train Loss: 0.22788 | Valid Loss: 0.22935 | Time: 0.47 seconds\n",
            "Epoch: 780 | Train Loss: 0.22754 | Valid Loss: 0.22810 | Time: 0.46 seconds\n",
            "Epoch: 781 | Train Loss: 0.22716 | Valid Loss: 0.22715 | Time: 0.48 seconds\n",
            "Epoch: 782 | Train Loss: 0.22679 | Valid Loss: 0.23006 | Time: 0.46 seconds\n",
            "Epoch: 783 | Train Loss: 0.22643 | Valid Loss: 0.22968 | Time: 0.46 seconds\n",
            "Epoch: 784 | Train Loss: 0.22607 | Valid Loss: 0.22696 | Time: 0.47 seconds\n",
            "Epoch: 785 | Train Loss: 0.22576 | Valid Loss: 0.22845 | Time: 0.48 seconds\n",
            "Epoch: 786 | Train Loss: 0.22533 | Valid Loss: 0.22665 | Time: 0.48 seconds\n",
            "Epoch: 787 | Train Loss: 0.22504 | Valid Loss: 0.22597 | Time: 0.48 seconds\n",
            "Epoch: 788 | Train Loss: 0.22464 | Valid Loss: 0.22699 | Time: 0.48 seconds\n",
            "Epoch: 789 | Train Loss: 0.22429 | Valid Loss: 0.22647 | Time: 0.47 seconds\n",
            "Epoch: 790 | Train Loss: 0.22395 | Valid Loss: 0.22504 | Time: 0.46 seconds\n",
            "Epoch: 791 | Train Loss: 0.22357 | Valid Loss: 0.22592 | Time: 0.45 seconds\n",
            "Epoch: 792 | Train Loss: 0.22325 | Valid Loss: 0.22617 | Time: 0.49 seconds\n",
            "Epoch: 793 | Train Loss: 0.22291 | Valid Loss: 0.22330 | Time: 0.47 seconds\n",
            "Epoch: 794 | Train Loss: 0.22254 | Valid Loss: 0.22653 | Time: 0.47 seconds\n",
            "Epoch: 795 | Train Loss: 0.22220 | Valid Loss: 0.22328 | Time: 0.47 seconds\n",
            "Epoch: 796 | Train Loss: 0.22182 | Valid Loss: 0.22340 | Time: 0.46 seconds\n",
            "Epoch: 797 | Train Loss: 0.22144 | Valid Loss: 0.22342 | Time: 0.46 seconds\n",
            "Epoch: 798 | Train Loss: 0.22112 | Valid Loss: 0.22321 | Time: 0.47 seconds\n",
            "Epoch: 799 | Train Loss: 0.22075 | Valid Loss: 0.22418 | Time: 0.46 seconds\n",
            "Epoch: 800 | Train Loss: 0.22040 | Valid Loss: 0.22170 | Time: 0.47 seconds\n",
            "Epoch: 801 | Train Loss: 0.22007 | Valid Loss: 0.22208 | Time: 0.45 seconds\n",
            "Epoch: 802 | Train Loss: 0.21976 | Valid Loss: 0.22252 | Time: 0.46 seconds\n",
            "Epoch: 803 | Train Loss: 0.21937 | Valid Loss: 0.22122 | Time: 0.48 seconds\n",
            "Epoch: 804 | Train Loss: 0.21900 | Valid Loss: 0.22181 | Time: 0.45 seconds\n",
            "Epoch: 805 | Train Loss: 0.21868 | Valid Loss: 0.22231 | Time: 0.47 seconds\n",
            "Epoch: 806 | Train Loss: 0.21833 | Valid Loss: 0.22067 | Time: 0.46 seconds\n",
            "Epoch: 807 | Train Loss: 0.21801 | Valid Loss: 0.22002 | Time: 0.47 seconds\n",
            "Epoch: 808 | Train Loss: 0.21762 | Valid Loss: 0.22095 | Time: 0.47 seconds\n",
            "Epoch: 809 | Train Loss: 0.21728 | Valid Loss: 0.22035 | Time: 0.46 seconds\n",
            "Epoch: 810 | Train Loss: 0.21691 | Valid Loss: 0.21901 | Time: 0.48 seconds\n",
            "Epoch: 811 | Train Loss: 0.21660 | Valid Loss: 0.21862 | Time: 0.49 seconds\n",
            "Epoch: 812 | Train Loss: 0.21628 | Valid Loss: 0.21994 | Time: 0.45 seconds\n",
            "Epoch: 813 | Train Loss: 0.21590 | Valid Loss: 0.21595 | Time: 0.49 seconds\n",
            "Epoch: 814 | Train Loss: 0.21557 | Valid Loss: 0.21764 | Time: 0.46 seconds\n",
            "Epoch: 815 | Train Loss: 0.21524 | Valid Loss: 0.21819 | Time: 0.46 seconds\n",
            "Epoch: 816 | Train Loss: 0.21487 | Valid Loss: 0.21672 | Time: 0.48 seconds\n",
            "Epoch: 817 | Train Loss: 0.21456 | Valid Loss: 0.21818 | Time: 0.47 seconds\n",
            "Epoch: 818 | Train Loss: 0.21424 | Valid Loss: 0.21684 | Time: 0.48 seconds\n",
            "Epoch: 819 | Train Loss: 0.21384 | Valid Loss: 0.21649 | Time: 0.47 seconds\n",
            "Epoch: 820 | Train Loss: 0.21350 | Valid Loss: 0.21581 | Time: 0.48 seconds\n",
            "Epoch: 821 | Train Loss: 0.21319 | Valid Loss: 0.21517 | Time: 0.48 seconds\n",
            "Epoch: 822 | Train Loss: 0.21285 | Valid Loss: 0.21489 | Time: 0.47 seconds\n",
            "Epoch: 823 | Train Loss: 0.21254 | Valid Loss: 0.21547 | Time: 0.46 seconds\n",
            "Epoch: 824 | Train Loss: 0.21213 | Valid Loss: 0.21298 | Time: 0.48 seconds\n",
            "Epoch: 825 | Train Loss: 0.21183 | Valid Loss: 0.21323 | Time: 0.45 seconds\n",
            "Epoch: 826 | Train Loss: 0.21151 | Valid Loss: 0.21570 | Time: 0.47 seconds\n",
            "Epoch: 827 | Train Loss: 0.21117 | Valid Loss: 0.21312 | Time: 0.46 seconds\n",
            "Epoch: 828 | Train Loss: 0.21087 | Valid Loss: 0.21185 | Time: 0.46 seconds\n",
            "Epoch: 829 | Train Loss: 0.21051 | Valid Loss: 0.21245 | Time: 0.46 seconds\n",
            "Epoch: 830 | Train Loss: 0.21017 | Valid Loss: 0.21413 | Time: 0.47 seconds\n",
            "Epoch: 831 | Train Loss: 0.20986 | Valid Loss: 0.21170 | Time: 0.48 seconds\n",
            "Epoch: 832 | Train Loss: 0.20955 | Valid Loss: 0.21289 | Time: 0.46 seconds\n",
            "Epoch: 833 | Train Loss: 0.20922 | Valid Loss: 0.21195 | Time: 0.47 seconds\n",
            "Epoch: 834 | Train Loss: 0.20884 | Valid Loss: 0.21224 | Time: 0.46 seconds\n",
            "Epoch: 835 | Train Loss: 0.20851 | Valid Loss: 0.21110 | Time: 0.49 seconds\n",
            "Epoch: 836 | Train Loss: 0.20814 | Valid Loss: 0.20975 | Time: 0.49 seconds\n",
            "Epoch: 837 | Train Loss: 0.20786 | Valid Loss: 0.21097 | Time: 0.47 seconds\n",
            "Epoch: 838 | Train Loss: 0.20753 | Valid Loss: 0.20806 | Time: 0.48 seconds\n",
            "Epoch: 839 | Train Loss: 0.20720 | Valid Loss: 0.20922 | Time: 0.47 seconds\n",
            "Epoch: 840 | Train Loss: 0.20684 | Valid Loss: 0.20937 | Time: 0.45 seconds\n",
            "Epoch: 841 | Train Loss: 0.20654 | Valid Loss: 0.21050 | Time: 0.47 seconds\n",
            "Epoch: 842 | Train Loss: 0.20623 | Valid Loss: 0.20794 | Time: 0.46 seconds\n",
            "Epoch: 843 | Train Loss: 0.20588 | Valid Loss: 0.20948 | Time: 0.46 seconds\n",
            "Epoch: 844 | Train Loss: 0.20556 | Valid Loss: 0.20865 | Time: 0.48 seconds\n",
            "Epoch: 845 | Train Loss: 0.20526 | Valid Loss: 0.20678 | Time: 0.46 seconds\n",
            "Epoch: 846 | Train Loss: 0.20488 | Valid Loss: 0.20721 | Time: 0.47 seconds\n",
            "Epoch: 847 | Train Loss: 0.20457 | Valid Loss: 0.20636 | Time: 0.46 seconds\n",
            "Epoch: 848 | Train Loss: 0.20426 | Valid Loss: 0.20702 | Time: 0.48 seconds\n",
            "Epoch: 849 | Train Loss: 0.20394 | Valid Loss: 0.20781 | Time: 0.45 seconds\n",
            "Epoch: 850 | Train Loss: 0.20366 | Valid Loss: 0.20456 | Time: 0.47 seconds\n",
            "Epoch: 851 | Train Loss: 0.20330 | Valid Loss: 0.20571 | Time: 0.46 seconds\n",
            "Epoch: 852 | Train Loss: 0.20300 | Valid Loss: 0.20450 | Time: 0.48 seconds\n",
            "Epoch: 853 | Train Loss: 0.20267 | Valid Loss: 0.20483 | Time: 0.47 seconds\n",
            "Epoch: 854 | Train Loss: 0.20234 | Valid Loss: 0.20361 | Time: 0.48 seconds\n",
            "Epoch: 855 | Train Loss: 0.20200 | Valid Loss: 0.20390 | Time: 0.46 seconds\n",
            "Epoch: 856 | Train Loss: 0.20169 | Valid Loss: 0.20242 | Time: 0.48 seconds\n",
            "Epoch: 857 | Train Loss: 0.20138 | Valid Loss: 0.20343 | Time: 0.47 seconds\n",
            "Epoch: 858 | Train Loss: 0.20105 | Valid Loss: 0.20356 | Time: 0.47 seconds\n",
            "Epoch: 859 | Train Loss: 0.20072 | Valid Loss: 0.20302 | Time: 0.47 seconds\n",
            "Epoch: 860 | Train Loss: 0.20046 | Valid Loss: 0.20433 | Time: 0.46 seconds\n",
            "Epoch: 861 | Train Loss: 0.20014 | Valid Loss: 0.20439 | Time: 0.47 seconds\n",
            "Epoch: 862 | Train Loss: 0.19980 | Valid Loss: 0.20199 | Time: 0.47 seconds\n",
            "Epoch: 863 | Train Loss: 0.19948 | Valid Loss: 0.20286 | Time: 0.47 seconds\n",
            "Epoch: 864 | Train Loss: 0.19919 | Valid Loss: 0.20173 | Time: 0.46 seconds\n",
            "Epoch: 865 | Train Loss: 0.19885 | Valid Loss: 0.20140 | Time: 0.48 seconds\n",
            "Epoch: 866 | Train Loss: 0.19856 | Valid Loss: 0.20172 | Time: 0.46 seconds\n",
            "Epoch: 867 | Train Loss: 0.19823 | Valid Loss: 0.20112 | Time: 0.48 seconds\n",
            "Epoch: 868 | Train Loss: 0.19792 | Valid Loss: 0.20036 | Time: 0.49 seconds\n",
            "Epoch: 869 | Train Loss: 0.19759 | Valid Loss: 0.19842 | Time: 0.48 seconds\n",
            "Epoch: 870 | Train Loss: 0.19729 | Valid Loss: 0.19990 | Time: 0.47 seconds\n",
            "Epoch: 871 | Train Loss: 0.19699 | Valid Loss: 0.19939 | Time: 0.46 seconds\n",
            "Epoch: 872 | Train Loss: 0.19667 | Valid Loss: 0.19765 | Time: 0.49 seconds\n",
            "Epoch: 873 | Train Loss: 0.19635 | Valid Loss: 0.19890 | Time: 0.46 seconds\n",
            "Epoch: 874 | Train Loss: 0.19603 | Valid Loss: 0.19803 | Time: 0.50 seconds\n",
            "Epoch: 875 | Train Loss: 0.19577 | Valid Loss: 0.19853 | Time: 0.47 seconds\n",
            "Epoch: 876 | Train Loss: 0.19544 | Valid Loss: 0.19694 | Time: 0.47 seconds\n",
            "Epoch: 877 | Train Loss: 0.19511 | Valid Loss: 0.19677 | Time: 0.48 seconds\n",
            "Epoch: 878 | Train Loss: 0.19479 | Valid Loss: 0.19597 | Time: 0.47 seconds\n",
            "Epoch: 879 | Train Loss: 0.19449 | Valid Loss: 0.19575 | Time: 0.47 seconds\n",
            "Epoch: 880 | Train Loss: 0.19420 | Valid Loss: 0.19717 | Time: 0.47 seconds\n",
            "Epoch: 881 | Train Loss: 0.19388 | Valid Loss: 0.19590 | Time: 0.47 seconds\n",
            "Epoch: 882 | Train Loss: 0.19359 | Valid Loss: 0.19474 | Time: 0.50 seconds\n",
            "Epoch: 883 | Train Loss: 0.19329 | Valid Loss: 0.19559 | Time: 0.46 seconds\n",
            "Epoch: 884 | Train Loss: 0.19295 | Valid Loss: 0.19612 | Time: 0.46 seconds\n",
            "Epoch: 885 | Train Loss: 0.19267 | Valid Loss: 0.19351 | Time: 0.47 seconds\n",
            "Epoch: 886 | Train Loss: 0.19237 | Valid Loss: 0.19415 | Time: 0.47 seconds\n",
            "Epoch: 887 | Train Loss: 0.19207 | Valid Loss: 0.19381 | Time: 0.47 seconds\n",
            "Epoch: 888 | Train Loss: 0.19177 | Valid Loss: 0.19284 | Time: 0.46 seconds\n",
            "Epoch: 889 | Train Loss: 0.19145 | Valid Loss: 0.19433 | Time: 0.47 seconds\n",
            "Epoch: 890 | Train Loss: 0.19115 | Valid Loss: 0.19313 | Time: 0.45 seconds\n",
            "Epoch: 891 | Train Loss: 0.19087 | Valid Loss: 0.19263 | Time: 0.48 seconds\n",
            "Epoch: 892 | Train Loss: 0.19054 | Valid Loss: 0.19215 | Time: 0.46 seconds\n",
            "Epoch: 893 | Train Loss: 0.19026 | Valid Loss: 0.19256 | Time: 0.48 seconds\n",
            "Epoch: 894 | Train Loss: 0.18997 | Valid Loss: 0.19073 | Time: 0.46 seconds\n",
            "Epoch: 895 | Train Loss: 0.18969 | Valid Loss: 0.19191 | Time: 0.47 seconds\n",
            "Epoch: 896 | Train Loss: 0.18934 | Valid Loss: 0.19122 | Time: 0.47 seconds\n",
            "Epoch: 897 | Train Loss: 0.18906 | Valid Loss: 0.19107 | Time: 0.46 seconds\n",
            "Epoch: 898 | Train Loss: 0.18879 | Valid Loss: 0.19190 | Time: 0.46 seconds\n",
            "Epoch: 899 | Train Loss: 0.18846 | Valid Loss: 0.19272 | Time: 0.46 seconds\n",
            "Epoch: 900 | Train Loss: 0.18817 | Valid Loss: 0.19058 | Time: 0.48 seconds\n",
            "Epoch: 901 | Train Loss: 0.18789 | Valid Loss: 0.19088 | Time: 0.46 seconds\n",
            "Epoch: 902 | Train Loss: 0.18757 | Valid Loss: 0.18960 | Time: 0.47 seconds\n",
            "Epoch: 903 | Train Loss: 0.18727 | Valid Loss: 0.18918 | Time: 0.47 seconds\n",
            "Epoch: 904 | Train Loss: 0.18701 | Valid Loss: 0.18864 | Time: 0.49 seconds\n",
            "Epoch: 905 | Train Loss: 0.18670 | Valid Loss: 0.18891 | Time: 0.45 seconds\n",
            "Epoch: 906 | Train Loss: 0.18638 | Valid Loss: 0.18798 | Time: 0.48 seconds\n",
            "Epoch: 907 | Train Loss: 0.18608 | Valid Loss: 0.18711 | Time: 0.46 seconds\n",
            "Epoch: 908 | Train Loss: 0.18580 | Valid Loss: 0.18813 | Time: 0.46 seconds\n",
            "Epoch: 909 | Train Loss: 0.18553 | Valid Loss: 0.18813 | Time: 0.47 seconds\n",
            "Epoch: 910 | Train Loss: 0.18523 | Valid Loss: 0.18665 | Time: 0.48 seconds\n",
            "Epoch: 911 | Train Loss: 0.18496 | Valid Loss: 0.18652 | Time: 0.48 seconds\n",
            "Epoch: 912 | Train Loss: 0.18469 | Valid Loss: 0.18673 | Time: 0.48 seconds\n",
            "Epoch: 913 | Train Loss: 0.18437 | Valid Loss: 0.18655 | Time: 0.49 seconds\n",
            "Epoch: 914 | Train Loss: 0.18407 | Valid Loss: 0.18619 | Time: 0.47 seconds\n",
            "Epoch: 915 | Train Loss: 0.18378 | Valid Loss: 0.18500 | Time: 0.49 seconds\n",
            "Epoch: 916 | Train Loss: 0.18349 | Valid Loss: 0.18568 | Time: 0.46 seconds\n",
            "Epoch: 917 | Train Loss: 0.18320 | Valid Loss: 0.18514 | Time: 0.46 seconds\n",
            "Epoch: 918 | Train Loss: 0.18290 | Valid Loss: 0.18482 | Time: 0.48 seconds\n",
            "Epoch: 919 | Train Loss: 0.18262 | Valid Loss: 0.18569 | Time: 0.48 seconds\n",
            "Epoch: 920 | Train Loss: 0.18233 | Valid Loss: 0.18440 | Time: 0.47 seconds\n",
            "Epoch: 921 | Train Loss: 0.18205 | Valid Loss: 0.18550 | Time: 0.46 seconds\n",
            "Epoch: 922 | Train Loss: 0.18180 | Valid Loss: 0.18358 | Time: 0.46 seconds\n",
            "Epoch: 923 | Train Loss: 0.18147 | Valid Loss: 0.18323 | Time: 0.48 seconds\n",
            "Epoch: 924 | Train Loss: 0.18119 | Valid Loss: 0.18435 | Time: 0.48 seconds\n",
            "Epoch: 925 | Train Loss: 0.18094 | Valid Loss: 0.18258 | Time: 0.46 seconds\n",
            "Epoch: 926 | Train Loss: 0.18062 | Valid Loss: 0.18272 | Time: 0.47 seconds\n",
            "Epoch: 927 | Train Loss: 0.18037 | Valid Loss: 0.18168 | Time: 0.48 seconds\n",
            "Epoch: 928 | Train Loss: 0.18010 | Valid Loss: 0.18273 | Time: 0.46 seconds\n",
            "Epoch: 929 | Train Loss: 0.17976 | Valid Loss: 0.18098 | Time: 0.47 seconds\n",
            "Epoch: 930 | Train Loss: 0.17953 | Valid Loss: 0.18174 | Time: 0.47 seconds\n",
            "Epoch: 931 | Train Loss: 0.17922 | Valid Loss: 0.18262 | Time: 0.46 seconds\n",
            "Epoch: 932 | Train Loss: 0.17892 | Valid Loss: 0.18038 | Time: 0.47 seconds\n",
            "Epoch: 933 | Train Loss: 0.17866 | Valid Loss: 0.18019 | Time: 0.48 seconds\n",
            "Epoch: 934 | Train Loss: 0.17840 | Valid Loss: 0.18222 | Time: 0.47 seconds\n",
            "Epoch: 935 | Train Loss: 0.17810 | Valid Loss: 0.17986 | Time: 0.46 seconds\n",
            "Epoch: 936 | Train Loss: 0.17783 | Valid Loss: 0.18019 | Time: 0.46 seconds\n",
            "Epoch: 937 | Train Loss: 0.17753 | Valid Loss: 0.18063 | Time: 0.47 seconds\n",
            "Epoch: 938 | Train Loss: 0.17725 | Valid Loss: 0.17966 | Time: 0.48 seconds\n",
            "Epoch: 939 | Train Loss: 0.17701 | Valid Loss: 0.17937 | Time: 0.48 seconds\n",
            "Epoch: 940 | Train Loss: 0.17674 | Valid Loss: 0.18029 | Time: 0.46 seconds\n",
            "Epoch: 941 | Train Loss: 0.17640 | Valid Loss: 0.17872 | Time: 0.47 seconds\n",
            "Epoch: 942 | Train Loss: 0.17616 | Valid Loss: 0.17882 | Time: 0.45 seconds\n",
            "Epoch: 943 | Train Loss: 0.17586 | Valid Loss: 0.17767 | Time: 0.48 seconds\n",
            "Epoch: 944 | Train Loss: 0.17560 | Valid Loss: 0.17865 | Time: 0.46 seconds\n",
            "Epoch: 945 | Train Loss: 0.17534 | Valid Loss: 0.17809 | Time: 0.46 seconds\n",
            "Epoch: 946 | Train Loss: 0.17507 | Valid Loss: 0.17685 | Time: 0.47 seconds\n",
            "Epoch: 947 | Train Loss: 0.17479 | Valid Loss: 0.17546 | Time: 0.47 seconds\n",
            "Epoch: 948 | Train Loss: 0.17449 | Valid Loss: 0.17670 | Time: 0.48 seconds\n",
            "Epoch: 949 | Train Loss: 0.17425 | Valid Loss: 0.17513 | Time: 0.46 seconds\n",
            "Epoch: 950 | Train Loss: 0.17396 | Valid Loss: 0.17648 | Time: 0.47 seconds\n",
            "Epoch: 951 | Train Loss: 0.17369 | Valid Loss: 0.17626 | Time: 0.46 seconds\n",
            "Epoch: 952 | Train Loss: 0.17342 | Valid Loss: 0.17528 | Time: 0.48 seconds\n",
            "Epoch: 953 | Train Loss: 0.17313 | Valid Loss: 0.17494 | Time: 0.46 seconds\n",
            "Epoch: 954 | Train Loss: 0.17288 | Valid Loss: 0.17491 | Time: 0.49 seconds\n",
            "Epoch: 955 | Train Loss: 0.17260 | Valid Loss: 0.17449 | Time: 0.46 seconds\n",
            "Epoch: 956 | Train Loss: 0.17234 | Valid Loss: 0.17615 | Time: 0.47 seconds\n",
            "Epoch: 957 | Train Loss: 0.17203 | Valid Loss: 0.17531 | Time: 0.48 seconds\n",
            "Epoch: 958 | Train Loss: 0.17179 | Valid Loss: 0.17456 | Time: 0.47 seconds\n",
            "Epoch: 959 | Train Loss: 0.17153 | Valid Loss: 0.17499 | Time: 0.45 seconds\n",
            "Epoch: 960 | Train Loss: 0.17125 | Valid Loss: 0.17357 | Time: 0.47 seconds\n",
            "Epoch: 961 | Train Loss: 0.17099 | Valid Loss: 0.17332 | Time: 0.48 seconds\n",
            "Epoch: 962 | Train Loss: 0.17072 | Valid Loss: 0.17381 | Time: 0.45 seconds\n",
            "Epoch: 963 | Train Loss: 0.17047 | Valid Loss: 0.17109 | Time: 0.48 seconds\n",
            "Epoch: 964 | Train Loss: 0.17018 | Valid Loss: 0.17156 | Time: 0.46 seconds\n",
            "Epoch: 965 | Train Loss: 0.16993 | Valid Loss: 0.17200 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16966 | Valid Loss: 0.17130 | Time: 0.47 seconds\n",
            "Epoch: 967 | Train Loss: 0.16939 | Valid Loss: 0.17211 | Time: 0.47 seconds\n",
            "Epoch: 968 | Train Loss: 0.16914 | Valid Loss: 0.17152 | Time: 0.45 seconds\n",
            "Epoch: 969 | Train Loss: 0.16886 | Valid Loss: 0.17023 | Time: 0.47 seconds\n",
            "Epoch: 970 | Train Loss: 0.16860 | Valid Loss: 0.16927 | Time: 0.49 seconds\n",
            "Epoch: 971 | Train Loss: 0.16832 | Valid Loss: 0.16987 | Time: 0.47 seconds\n",
            "Epoch: 972 | Train Loss: 0.16808 | Valid Loss: 0.16995 | Time: 0.45 seconds\n",
            "Epoch: 973 | Train Loss: 0.16780 | Valid Loss: 0.17035 | Time: 0.45 seconds\n",
            "Epoch: 974 | Train Loss: 0.16758 | Valid Loss: 0.16978 | Time: 0.47 seconds\n",
            "Epoch: 975 | Train Loss: 0.16731 | Valid Loss: 0.16828 | Time: 0.47 seconds\n",
            "Epoch: 976 | Train Loss: 0.16704 | Valid Loss: 0.16854 | Time: 0.47 seconds\n",
            "Epoch: 977 | Train Loss: 0.16674 | Valid Loss: 0.16984 | Time: 0.46 seconds\n",
            "Epoch: 978 | Train Loss: 0.16650 | Valid Loss: 0.16839 | Time: 0.47 seconds\n",
            "Epoch: 979 | Train Loss: 0.16624 | Valid Loss: 0.16845 | Time: 0.47 seconds\n",
            "Epoch: 980 | Train Loss: 0.16600 | Valid Loss: 0.16808 | Time: 0.48 seconds\n",
            "Epoch: 981 | Train Loss: 0.16572 | Valid Loss: 0.16833 | Time: 0.46 seconds\n",
            "Epoch: 982 | Train Loss: 0.16549 | Valid Loss: 0.16716 | Time: 0.49 seconds\n",
            "Epoch: 983 | Train Loss: 0.16520 | Valid Loss: 0.16727 | Time: 0.46 seconds\n",
            "Epoch: 984 | Train Loss: 0.16494 | Valid Loss: 0.16743 | Time: 0.47 seconds\n",
            "Epoch: 985 | Train Loss: 0.16468 | Valid Loss: 0.16658 | Time: 0.46 seconds\n",
            "Epoch: 986 | Train Loss: 0.16443 | Valid Loss: 0.16768 | Time: 0.46 seconds\n",
            "Epoch: 987 | Train Loss: 0.16418 | Valid Loss: 0.16675 | Time: 0.47 seconds\n",
            "Epoch: 988 | Train Loss: 0.16394 | Valid Loss: 0.16667 | Time: 0.46 seconds\n",
            "Epoch: 989 | Train Loss: 0.16365 | Valid Loss: 0.16604 | Time: 0.49 seconds\n",
            "Epoch: 990 | Train Loss: 0.16345 | Valid Loss: 0.16524 | Time: 0.46 seconds\n",
            "Epoch: 991 | Train Loss: 0.16315 | Valid Loss: 0.16538 | Time: 0.48 seconds\n",
            "Epoch: 992 | Train Loss: 0.16293 | Valid Loss: 0.16556 | Time: 0.48 seconds\n",
            "Epoch: 993 | Train Loss: 0.16264 | Valid Loss: 0.16456 | Time: 0.47 seconds\n",
            "Epoch: 994 | Train Loss: 0.16242 | Valid Loss: 0.16432 | Time: 0.47 seconds\n",
            "Epoch: 995 | Train Loss: 0.16214 | Valid Loss: 0.16464 | Time: 0.47 seconds\n",
            "Epoch: 996 | Train Loss: 0.16185 | Valid Loss: 0.16295 | Time: 0.46 seconds\n",
            "Epoch: 997 | Train Loss: 0.16163 | Valid Loss: 0.16296 | Time: 0.47 seconds\n",
            "Epoch: 998 | Train Loss: 0.16142 | Valid Loss: 0.16309 | Time: 0.46 seconds\n",
            "Epoch: 999 | Train Loss: 0.16114 | Valid Loss: 0.16307 | Time: 0.47 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16087 | Valid Loss: 0.16386 | Time: 0.47 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 996\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.89 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 9]: 30.99997\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Model ...\n",
            "\n",
            "1664 -> 1\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Fold 10...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.71488 | Valid Loss: 0.71236 | Time: 0.48 seconds\n",
            "Epoch: 2 | Train Loss: 0.71432 | Valid Loss: 0.71337 | Time: 0.46 seconds\n",
            "Epoch: 3 | Train Loss: 0.71380 | Valid Loss: 0.71292 | Time: 0.47 seconds\n",
            "Epoch: 4 | Train Loss: 0.71330 | Valid Loss: 0.71291 | Time: 0.46 seconds\n",
            "Epoch: 5 | Train Loss: 0.71281 | Valid Loss: 0.71325 | Time: 0.47 seconds\n",
            "Epoch: 6 | Train Loss: 0.71237 | Valid Loss: 0.71192 | Time: 0.47 seconds\n",
            "Epoch: 7 | Train Loss: 0.71191 | Valid Loss: 0.71203 | Time: 0.47 seconds\n",
            "Epoch: 8 | Train Loss: 0.71147 | Valid Loss: 0.71131 | Time: 0.47 seconds\n",
            "Epoch: 9 | Train Loss: 0.71106 | Valid Loss: 0.71148 | Time: 0.47 seconds\n",
            "Epoch: 10 | Train Loss: 0.71065 | Valid Loss: 0.71042 | Time: 0.48 seconds\n",
            "Epoch: 11 | Train Loss: 0.71026 | Valid Loss: 0.70949 | Time: 0.47 seconds\n",
            "Epoch: 12 | Train Loss: 0.70987 | Valid Loss: 0.70952 | Time: 0.46 seconds\n",
            "Epoch: 13 | Train Loss: 0.70951 | Valid Loss: 0.70881 | Time: 0.48 seconds\n",
            "Epoch: 14 | Train Loss: 0.70914 | Valid Loss: 0.70859 | Time: 0.48 seconds\n",
            "Epoch: 15 | Train Loss: 0.70877 | Valid Loss: 0.70822 | Time: 0.48 seconds\n",
            "Epoch: 16 | Train Loss: 0.70842 | Valid Loss: 0.70778 | Time: 0.47 seconds\n",
            "Epoch: 17 | Train Loss: 0.70809 | Valid Loss: 0.70820 | Time: 0.46 seconds\n",
            "Epoch: 18 | Train Loss: 0.70775 | Valid Loss: 0.70772 | Time: 0.49 seconds\n",
            "Epoch: 19 | Train Loss: 0.70741 | Valid Loss: 0.70687 | Time: 0.46 seconds\n",
            "Epoch: 20 | Train Loss: 0.70707 | Valid Loss: 0.70694 | Time: 0.46 seconds\n",
            "Epoch: 21 | Train Loss: 0.70675 | Valid Loss: 0.70631 | Time: 0.49 seconds\n",
            "Epoch: 22 | Train Loss: 0.70643 | Valid Loss: 0.70594 | Time: 0.47 seconds\n",
            "Epoch: 23 | Train Loss: 0.70611 | Valid Loss: 0.70593 | Time: 0.48 seconds\n",
            "Epoch: 24 | Train Loss: 0.70578 | Valid Loss: 0.70543 | Time: 0.47 seconds\n",
            "Epoch: 25 | Train Loss: 0.70545 | Valid Loss: 0.70522 | Time: 0.49 seconds\n",
            "Epoch: 26 | Train Loss: 0.70515 | Valid Loss: 0.70392 | Time: 0.46 seconds\n",
            "Epoch: 27 | Train Loss: 0.70482 | Valid Loss: 0.70478 | Time: 0.47 seconds\n",
            "Epoch: 28 | Train Loss: 0.70451 | Valid Loss: 0.70403 | Time: 0.46 seconds\n",
            "Epoch: 29 | Train Loss: 0.70419 | Valid Loss: 0.70352 | Time: 0.48 seconds\n",
            "Epoch: 30 | Train Loss: 0.70390 | Valid Loss: 0.70402 | Time: 0.47 seconds\n",
            "Epoch: 31 | Train Loss: 0.70356 | Valid Loss: 0.70392 | Time: 0.48 seconds\n",
            "Epoch: 32 | Train Loss: 0.70325 | Valid Loss: 0.70305 | Time: 0.47 seconds\n",
            "Epoch: 33 | Train Loss: 0.70294 | Valid Loss: 0.70301 | Time: 0.47 seconds\n",
            "Epoch: 34 | Train Loss: 0.70263 | Valid Loss: 0.70271 | Time: 0.47 seconds\n",
            "Epoch: 35 | Train Loss: 0.70230 | Valid Loss: 0.70227 | Time: 0.48 seconds\n",
            "Epoch: 36 | Train Loss: 0.70198 | Valid Loss: 0.70237 | Time: 0.47 seconds\n",
            "Epoch: 37 | Train Loss: 0.70166 | Valid Loss: 0.70184 | Time: 0.48 seconds\n",
            "Epoch: 38 | Train Loss: 0.70134 | Valid Loss: 0.70087 | Time: 0.50 seconds\n",
            "Epoch: 39 | Train Loss: 0.70101 | Valid Loss: 0.69990 | Time: 0.48 seconds\n",
            "Epoch: 40 | Train Loss: 0.70068 | Valid Loss: 0.70071 | Time: 0.47 seconds\n",
            "Epoch: 41 | Train Loss: 0.70035 | Valid Loss: 0.70015 | Time: 0.47 seconds\n",
            "Epoch: 42 | Train Loss: 0.70001 | Valid Loss: 0.70061 | Time: 0.47 seconds\n",
            "Epoch: 43 | Train Loss: 0.69969 | Valid Loss: 0.69959 | Time: 0.46 seconds\n",
            "Epoch: 44 | Train Loss: 0.69934 | Valid Loss: 0.69921 | Time: 0.47 seconds\n",
            "Epoch: 45 | Train Loss: 0.69901 | Valid Loss: 0.69916 | Time: 0.48 seconds\n",
            "Epoch: 46 | Train Loss: 0.69866 | Valid Loss: 0.69838 | Time: 0.48 seconds\n",
            "Epoch: 47 | Train Loss: 0.69830 | Valid Loss: 0.69894 | Time: 0.46 seconds\n",
            "Epoch: 48 | Train Loss: 0.69795 | Valid Loss: 0.69795 | Time: 0.47 seconds\n",
            "Epoch: 49 | Train Loss: 0.69760 | Valid Loss: 0.69883 | Time: 0.48 seconds\n",
            "Epoch: 50 | Train Loss: 0.69723 | Valid Loss: 0.69760 | Time: 0.48 seconds\n",
            "Epoch: 51 | Train Loss: 0.69686 | Valid Loss: 0.69741 | Time: 0.48 seconds\n",
            "Epoch: 52 | Train Loss: 0.69651 | Valid Loss: 0.69641 | Time: 0.47 seconds\n",
            "Epoch: 53 | Train Loss: 0.69613 | Valid Loss: 0.69669 | Time: 0.47 seconds\n",
            "Epoch: 54 | Train Loss: 0.69575 | Valid Loss: 0.69506 | Time: 0.49 seconds\n",
            "Epoch: 55 | Train Loss: 0.69537 | Valid Loss: 0.69588 | Time: 0.49 seconds\n",
            "Epoch: 56 | Train Loss: 0.69499 | Valid Loss: 0.69530 | Time: 0.46 seconds\n",
            "Epoch: 57 | Train Loss: 0.69460 | Valid Loss: 0.69480 | Time: 0.49 seconds\n",
            "Epoch: 58 | Train Loss: 0.69422 | Valid Loss: 0.69457 | Time: 0.48 seconds\n",
            "Epoch: 59 | Train Loss: 0.69380 | Valid Loss: 0.69382 | Time: 0.51 seconds\n",
            "Epoch: 60 | Train Loss: 0.69342 | Valid Loss: 0.69348 | Time: 0.47 seconds\n",
            "Epoch: 61 | Train Loss: 0.69300 | Valid Loss: 0.69319 | Time: 0.47 seconds\n",
            "Epoch: 62 | Train Loss: 0.69260 | Valid Loss: 0.69243 | Time: 0.47 seconds\n",
            "Epoch: 63 | Train Loss: 0.69218 | Valid Loss: 0.69230 | Time: 0.47 seconds\n",
            "Epoch: 64 | Train Loss: 0.69176 | Valid Loss: 0.69208 | Time: 0.47 seconds\n",
            "Epoch: 65 | Train Loss: 0.69134 | Valid Loss: 0.69141 | Time: 0.46 seconds\n",
            "Epoch: 66 | Train Loss: 0.69093 | Valid Loss: 0.69075 | Time: 0.48 seconds\n",
            "Epoch: 67 | Train Loss: 0.69049 | Valid Loss: 0.69112 | Time: 0.46 seconds\n",
            "Epoch: 68 | Train Loss: 0.69006 | Valid Loss: 0.69002 | Time: 0.48 seconds\n",
            "Epoch: 69 | Train Loss: 0.68962 | Valid Loss: 0.68983 | Time: 0.48 seconds\n",
            "Epoch: 70 | Train Loss: 0.68917 | Valid Loss: 0.68924 | Time: 0.48 seconds\n",
            "Epoch: 71 | Train Loss: 0.68873 | Valid Loss: 0.68928 | Time: 0.45 seconds\n",
            "Epoch: 72 | Train Loss: 0.68826 | Valid Loss: 0.68791 | Time: 0.48 seconds\n",
            "Epoch: 73 | Train Loss: 0.68782 | Valid Loss: 0.68785 | Time: 0.46 seconds\n",
            "Epoch: 74 | Train Loss: 0.68736 | Valid Loss: 0.68779 | Time: 0.48 seconds\n",
            "Epoch: 75 | Train Loss: 0.68690 | Valid Loss: 0.68665 | Time: 0.47 seconds\n",
            "Epoch: 76 | Train Loss: 0.68644 | Valid Loss: 0.68649 | Time: 0.48 seconds\n",
            "Epoch: 77 | Train Loss: 0.68595 | Valid Loss: 0.68633 | Time: 0.47 seconds\n",
            "Epoch: 78 | Train Loss: 0.68549 | Valid Loss: 0.68532 | Time: 0.48 seconds\n",
            "Epoch: 79 | Train Loss: 0.68501 | Valid Loss: 0.68522 | Time: 0.49 seconds\n",
            "Epoch: 80 | Train Loss: 0.68453 | Valid Loss: 0.68455 | Time: 0.46 seconds\n",
            "Epoch: 81 | Train Loss: 0.68403 | Valid Loss: 0.68364 | Time: 0.48 seconds\n",
            "Epoch: 82 | Train Loss: 0.68354 | Valid Loss: 0.68355 | Time: 0.46 seconds\n",
            "Epoch: 83 | Train Loss: 0.68306 | Valid Loss: 0.68358 | Time: 0.49 seconds\n",
            "Epoch: 84 | Train Loss: 0.68255 | Valid Loss: 0.68282 | Time: 0.48 seconds\n",
            "Epoch: 85 | Train Loss: 0.68206 | Valid Loss: 0.68178 | Time: 0.50 seconds\n",
            "Epoch: 86 | Train Loss: 0.68154 | Valid Loss: 0.68255 | Time: 0.48 seconds\n",
            "Epoch: 87 | Train Loss: 0.68103 | Valid Loss: 0.68218 | Time: 0.48 seconds\n",
            "Epoch: 88 | Train Loss: 0.68051 | Valid Loss: 0.68043 | Time: 0.47 seconds\n",
            "Epoch: 89 | Train Loss: 0.68000 | Valid Loss: 0.68000 | Time: 0.48 seconds\n",
            "Epoch: 90 | Train Loss: 0.67947 | Valid Loss: 0.67939 | Time: 0.45 seconds\n",
            "Epoch: 91 | Train Loss: 0.67895 | Valid Loss: 0.67870 | Time: 0.49 seconds\n",
            "Epoch: 92 | Train Loss: 0.67842 | Valid Loss: 0.67878 | Time: 0.46 seconds\n",
            "Epoch: 93 | Train Loss: 0.67787 | Valid Loss: 0.67867 | Time: 0.48 seconds\n",
            "Epoch: 94 | Train Loss: 0.67733 | Valid Loss: 0.67852 | Time: 0.48 seconds\n",
            "Epoch: 95 | Train Loss: 0.67679 | Valid Loss: 0.67721 | Time: 0.47 seconds\n",
            "Epoch: 96 | Train Loss: 0.67625 | Valid Loss: 0.67735 | Time: 0.48 seconds\n",
            "Epoch: 97 | Train Loss: 0.67570 | Valid Loss: 0.67636 | Time: 0.47 seconds\n",
            "Epoch: 98 | Train Loss: 0.67515 | Valid Loss: 0.67612 | Time: 0.48 seconds\n",
            "Epoch: 99 | Train Loss: 0.67458 | Valid Loss: 0.67493 | Time: 0.47 seconds\n",
            "Epoch: 100 | Train Loss: 0.67402 | Valid Loss: 0.67425 | Time: 0.49 seconds\n",
            "Epoch: 101 | Train Loss: 0.67345 | Valid Loss: 0.67373 | Time: 0.49 seconds\n",
            "Epoch: 102 | Train Loss: 0.67288 | Valid Loss: 0.67301 | Time: 0.48 seconds\n",
            "Epoch: 103 | Train Loss: 0.67230 | Valid Loss: 0.67279 | Time: 0.46 seconds\n",
            "Epoch: 104 | Train Loss: 0.67172 | Valid Loss: 0.67210 | Time: 0.49 seconds\n",
            "Epoch: 105 | Train Loss: 0.67114 | Valid Loss: 0.67151 | Time: 0.48 seconds\n",
            "Epoch: 106 | Train Loss: 0.67055 | Valid Loss: 0.67031 | Time: 0.49 seconds\n",
            "Epoch: 107 | Train Loss: 0.66996 | Valid Loss: 0.67108 | Time: 0.46 seconds\n",
            "Epoch: 108 | Train Loss: 0.66937 | Valid Loss: 0.67016 | Time: 0.49 seconds\n",
            "Epoch: 109 | Train Loss: 0.66877 | Valid Loss: 0.66903 | Time: 0.46 seconds\n",
            "Epoch: 110 | Train Loss: 0.66818 | Valid Loss: 0.66861 | Time: 0.48 seconds\n",
            "Epoch: 111 | Train Loss: 0.66756 | Valid Loss: 0.66838 | Time: 0.47 seconds\n",
            "Epoch: 112 | Train Loss: 0.66696 | Valid Loss: 0.66744 | Time: 0.49 seconds\n",
            "Epoch: 113 | Train Loss: 0.66635 | Valid Loss: 0.66679 | Time: 0.48 seconds\n",
            "Epoch: 114 | Train Loss: 0.66572 | Valid Loss: 0.66656 | Time: 0.46 seconds\n",
            "Epoch: 115 | Train Loss: 0.66511 | Valid Loss: 0.66580 | Time: 0.49 seconds\n",
            "Epoch: 116 | Train Loss: 0.66448 | Valid Loss: 0.66522 | Time: 0.48 seconds\n",
            "Epoch: 117 | Train Loss: 0.66385 | Valid Loss: 0.66396 | Time: 0.47 seconds\n",
            "Epoch: 118 | Train Loss: 0.66321 | Valid Loss: 0.66310 | Time: 0.47 seconds\n",
            "Epoch: 119 | Train Loss: 0.66258 | Valid Loss: 0.66242 | Time: 0.47 seconds\n",
            "Epoch: 120 | Train Loss: 0.66195 | Valid Loss: 0.66286 | Time: 0.46 seconds\n",
            "Epoch: 121 | Train Loss: 0.66130 | Valid Loss: 0.66208 | Time: 0.49 seconds\n",
            "Epoch: 122 | Train Loss: 0.66065 | Valid Loss: 0.66065 | Time: 0.47 seconds\n",
            "Epoch: 123 | Train Loss: 0.66000 | Valid Loss: 0.66083 | Time: 0.48 seconds\n",
            "Epoch: 124 | Train Loss: 0.65935 | Valid Loss: 0.66062 | Time: 0.47 seconds\n",
            "Epoch: 125 | Train Loss: 0.65870 | Valid Loss: 0.65785 | Time: 0.47 seconds\n",
            "Epoch: 126 | Train Loss: 0.65804 | Valid Loss: 0.65839 | Time: 0.47 seconds\n",
            "Epoch: 127 | Train Loss: 0.65737 | Valid Loss: 0.65732 | Time: 0.47 seconds\n",
            "Epoch: 128 | Train Loss: 0.65672 | Valid Loss: 0.65771 | Time: 0.47 seconds\n",
            "Epoch: 129 | Train Loss: 0.65604 | Valid Loss: 0.65637 | Time: 0.47 seconds\n",
            "Epoch: 130 | Train Loss: 0.65537 | Valid Loss: 0.65583 | Time: 0.48 seconds\n",
            "Epoch: 131 | Train Loss: 0.65469 | Valid Loss: 0.65504 | Time: 0.49 seconds\n",
            "Epoch: 132 | Train Loss: 0.65401 | Valid Loss: 0.65430 | Time: 0.48 seconds\n",
            "Epoch: 133 | Train Loss: 0.65333 | Valid Loss: 0.65388 | Time: 0.48 seconds\n",
            "Epoch: 134 | Train Loss: 0.65264 | Valid Loss: 0.65360 | Time: 0.47 seconds\n",
            "Epoch: 135 | Train Loss: 0.65196 | Valid Loss: 0.65277 | Time: 0.48 seconds\n",
            "Epoch: 136 | Train Loss: 0.65126 | Valid Loss: 0.65277 | Time: 0.48 seconds\n",
            "Epoch: 137 | Train Loss: 0.65055 | Valid Loss: 0.65141 | Time: 0.47 seconds\n",
            "Epoch: 138 | Train Loss: 0.64986 | Valid Loss: 0.65095 | Time: 0.47 seconds\n",
            "Epoch: 139 | Train Loss: 0.64918 | Valid Loss: 0.64926 | Time: 0.47 seconds\n",
            "Epoch: 140 | Train Loss: 0.64847 | Valid Loss: 0.65018 | Time: 0.48 seconds\n",
            "Epoch: 141 | Train Loss: 0.64776 | Valid Loss: 0.64884 | Time: 0.47 seconds\n",
            "Epoch: 142 | Train Loss: 0.64705 | Valid Loss: 0.64704 | Time: 0.46 seconds\n",
            "Epoch: 143 | Train Loss: 0.64634 | Valid Loss: 0.64645 | Time: 0.48 seconds\n",
            "Epoch: 144 | Train Loss: 0.64562 | Valid Loss: 0.64558 | Time: 0.48 seconds\n",
            "Epoch: 145 | Train Loss: 0.64490 | Valid Loss: 0.64512 | Time: 0.50 seconds\n",
            "Epoch: 146 | Train Loss: 0.64419 | Valid Loss: 0.64516 | Time: 0.47 seconds\n",
            "Epoch: 147 | Train Loss: 0.64346 | Valid Loss: 0.64488 | Time: 0.50 seconds\n",
            "Epoch: 148 | Train Loss: 0.64274 | Valid Loss: 0.64384 | Time: 0.48 seconds\n",
            "Epoch: 149 | Train Loss: 0.64201 | Valid Loss: 0.64284 | Time: 0.48 seconds\n",
            "Epoch: 150 | Train Loss: 0.64128 | Valid Loss: 0.64164 | Time: 0.48 seconds\n",
            "Epoch: 151 | Train Loss: 0.64054 | Valid Loss: 0.64167 | Time: 0.48 seconds\n",
            "Epoch: 152 | Train Loss: 0.63981 | Valid Loss: 0.64073 | Time: 0.47 seconds\n",
            "Epoch: 153 | Train Loss: 0.63908 | Valid Loss: 0.64030 | Time: 0.48 seconds\n",
            "Epoch: 154 | Train Loss: 0.63833 | Valid Loss: 0.63795 | Time: 0.46 seconds\n",
            "Epoch: 155 | Train Loss: 0.63759 | Valid Loss: 0.63800 | Time: 0.47 seconds\n",
            "Epoch: 156 | Train Loss: 0.63684 | Valid Loss: 0.63783 | Time: 0.49 seconds\n",
            "Epoch: 157 | Train Loss: 0.63609 | Valid Loss: 0.63693 | Time: 0.48 seconds\n",
            "Epoch: 158 | Train Loss: 0.63536 | Valid Loss: 0.63580 | Time: 0.47 seconds\n",
            "Epoch: 159 | Train Loss: 0.63460 | Valid Loss: 0.63589 | Time: 0.47 seconds\n",
            "Epoch: 160 | Train Loss: 0.63385 | Valid Loss: 0.63406 | Time: 0.49 seconds\n",
            "Epoch: 161 | Train Loss: 0.63309 | Valid Loss: 0.63339 | Time: 0.48 seconds\n",
            "Epoch: 162 | Train Loss: 0.63233 | Valid Loss: 0.63282 | Time: 0.47 seconds\n",
            "Epoch: 163 | Train Loss: 0.63156 | Valid Loss: 0.63308 | Time: 0.46 seconds\n",
            "Epoch: 164 | Train Loss: 0.63080 | Valid Loss: 0.63143 | Time: 0.47 seconds\n",
            "Epoch: 165 | Train Loss: 0.63004 | Valid Loss: 0.63019 | Time: 0.46 seconds\n",
            "Epoch: 166 | Train Loss: 0.62928 | Valid Loss: 0.62938 | Time: 0.49 seconds\n",
            "Epoch: 167 | Train Loss: 0.62851 | Valid Loss: 0.63012 | Time: 0.46 seconds\n",
            "Epoch: 168 | Train Loss: 0.62775 | Valid Loss: 0.62989 | Time: 0.46 seconds\n",
            "Epoch: 169 | Train Loss: 0.62696 | Valid Loss: 0.62773 | Time: 0.46 seconds\n",
            "Epoch: 170 | Train Loss: 0.62619 | Valid Loss: 0.62666 | Time: 0.47 seconds\n",
            "Epoch: 171 | Train Loss: 0.62541 | Valid Loss: 0.62591 | Time: 0.48 seconds\n",
            "Epoch: 172 | Train Loss: 0.62462 | Valid Loss: 0.62621 | Time: 0.45 seconds\n",
            "Epoch: 173 | Train Loss: 0.62385 | Valid Loss: 0.62527 | Time: 0.48 seconds\n",
            "Epoch: 174 | Train Loss: 0.62307 | Valid Loss: 0.62281 | Time: 0.46 seconds\n",
            "Epoch: 175 | Train Loss: 0.62229 | Valid Loss: 0.62323 | Time: 0.48 seconds\n",
            "Epoch: 176 | Train Loss: 0.62150 | Valid Loss: 0.62206 | Time: 0.47 seconds\n",
            "Epoch: 177 | Train Loss: 0.62071 | Valid Loss: 0.62263 | Time: 0.47 seconds\n",
            "Epoch: 178 | Train Loss: 0.61992 | Valid Loss: 0.62113 | Time: 0.46 seconds\n",
            "Epoch: 179 | Train Loss: 0.61913 | Valid Loss: 0.62053 | Time: 0.47 seconds\n",
            "Epoch: 180 | Train Loss: 0.61834 | Valid Loss: 0.61944 | Time: 0.49 seconds\n",
            "Epoch: 181 | Train Loss: 0.61754 | Valid Loss: 0.61874 | Time: 0.48 seconds\n",
            "Epoch: 182 | Train Loss: 0.61675 | Valid Loss: 0.61687 | Time: 0.47 seconds\n",
            "Epoch: 183 | Train Loss: 0.61595 | Valid Loss: 0.61594 | Time: 0.47 seconds\n",
            "Epoch: 184 | Train Loss: 0.61516 | Valid Loss: 0.61572 | Time: 0.49 seconds\n",
            "Epoch: 185 | Train Loss: 0.61435 | Valid Loss: 0.61540 | Time: 0.47 seconds\n",
            "Epoch: 186 | Train Loss: 0.61356 | Valid Loss: 0.61355 | Time: 0.49 seconds\n",
            "Epoch: 187 | Train Loss: 0.61275 | Valid Loss: 0.61261 | Time: 0.46 seconds\n",
            "Epoch: 188 | Train Loss: 0.61194 | Valid Loss: 0.61255 | Time: 0.48 seconds\n",
            "Epoch: 189 | Train Loss: 0.61114 | Valid Loss: 0.61253 | Time: 0.46 seconds\n",
            "Epoch: 190 | Train Loss: 0.61033 | Valid Loss: 0.61080 | Time: 0.48 seconds\n",
            "Epoch: 191 | Train Loss: 0.60953 | Valid Loss: 0.61130 | Time: 0.46 seconds\n",
            "Epoch: 192 | Train Loss: 0.60872 | Valid Loss: 0.61006 | Time: 0.49 seconds\n",
            "Epoch: 193 | Train Loss: 0.60792 | Valid Loss: 0.60864 | Time: 0.47 seconds\n",
            "Epoch: 194 | Train Loss: 0.60710 | Valid Loss: 0.60801 | Time: 0.48 seconds\n",
            "Epoch: 195 | Train Loss: 0.60629 | Valid Loss: 0.60692 | Time: 0.47 seconds\n",
            "Epoch: 196 | Train Loss: 0.60546 | Valid Loss: 0.60578 | Time: 0.47 seconds\n",
            "Epoch: 197 | Train Loss: 0.60465 | Valid Loss: 0.60527 | Time: 0.48 seconds\n",
            "Epoch: 198 | Train Loss: 0.60383 | Valid Loss: 0.60440 | Time: 0.48 seconds\n",
            "Epoch: 199 | Train Loss: 0.60303 | Valid Loss: 0.60397 | Time: 0.47 seconds\n",
            "Epoch: 200 | Train Loss: 0.60220 | Valid Loss: 0.60203 | Time: 0.45 seconds\n",
            "Epoch: 201 | Train Loss: 0.60138 | Valid Loss: 0.60201 | Time: 0.48 seconds\n",
            "Epoch: 202 | Train Loss: 0.60056 | Valid Loss: 0.60091 | Time: 0.46 seconds\n",
            "Epoch: 203 | Train Loss: 0.59972 | Valid Loss: 0.60004 | Time: 0.49 seconds\n",
            "Epoch: 204 | Train Loss: 0.59890 | Valid Loss: 0.59981 | Time: 0.47 seconds\n",
            "Epoch: 205 | Train Loss: 0.59808 | Valid Loss: 0.59890 | Time: 0.48 seconds\n",
            "Epoch: 206 | Train Loss: 0.59726 | Valid Loss: 0.59799 | Time: 0.46 seconds\n",
            "Epoch: 207 | Train Loss: 0.59642 | Valid Loss: 0.59732 | Time: 0.49 seconds\n",
            "Epoch: 208 | Train Loss: 0.59560 | Valid Loss: 0.59498 | Time: 0.47 seconds\n",
            "Epoch: 209 | Train Loss: 0.59477 | Valid Loss: 0.59481 | Time: 0.48 seconds\n",
            "Epoch: 210 | Train Loss: 0.59394 | Valid Loss: 0.59420 | Time: 0.49 seconds\n",
            "Epoch: 211 | Train Loss: 0.59310 | Valid Loss: 0.59490 | Time: 0.48 seconds\n",
            "Epoch: 212 | Train Loss: 0.59228 | Valid Loss: 0.59435 | Time: 0.47 seconds\n",
            "Epoch: 213 | Train Loss: 0.59144 | Valid Loss: 0.59195 | Time: 0.49 seconds\n",
            "Epoch: 214 | Train Loss: 0.59061 | Valid Loss: 0.59134 | Time: 0.46 seconds\n",
            "Epoch: 215 | Train Loss: 0.58978 | Valid Loss: 0.59131 | Time: 0.47 seconds\n",
            "Epoch: 216 | Train Loss: 0.58893 | Valid Loss: 0.59087 | Time: 0.48 seconds\n",
            "Epoch: 217 | Train Loss: 0.58811 | Valid Loss: 0.58864 | Time: 0.46 seconds\n",
            "Epoch: 218 | Train Loss: 0.58726 | Valid Loss: 0.58810 | Time: 0.48 seconds\n",
            "Epoch: 219 | Train Loss: 0.58643 | Valid Loss: 0.58766 | Time: 0.48 seconds\n",
            "Epoch: 220 | Train Loss: 0.58559 | Valid Loss: 0.58676 | Time: 0.49 seconds\n",
            "Epoch: 221 | Train Loss: 0.58474 | Valid Loss: 0.58536 | Time: 0.48 seconds\n",
            "Epoch: 222 | Train Loss: 0.58390 | Valid Loss: 0.58519 | Time: 0.47 seconds\n",
            "Epoch: 223 | Train Loss: 0.58306 | Valid Loss: 0.58347 | Time: 0.47 seconds\n",
            "Epoch: 224 | Train Loss: 0.58222 | Valid Loss: 0.58347 | Time: 0.47 seconds\n",
            "Epoch: 225 | Train Loss: 0.58137 | Valid Loss: 0.58345 | Time: 0.47 seconds\n",
            "Epoch: 226 | Train Loss: 0.58053 | Valid Loss: 0.58145 | Time: 0.47 seconds\n",
            "Epoch: 227 | Train Loss: 0.57968 | Valid Loss: 0.58055 | Time: 0.48 seconds\n",
            "Epoch: 228 | Train Loss: 0.57882 | Valid Loss: 0.58017 | Time: 0.48 seconds\n",
            "Epoch: 229 | Train Loss: 0.57799 | Valid Loss: 0.57837 | Time: 0.47 seconds\n",
            "Epoch: 230 | Train Loss: 0.57715 | Valid Loss: 0.57811 | Time: 0.49 seconds\n",
            "Epoch: 231 | Train Loss: 0.57629 | Valid Loss: 0.57772 | Time: 0.47 seconds\n",
            "Epoch: 232 | Train Loss: 0.57543 | Valid Loss: 0.57739 | Time: 0.47 seconds\n",
            "Epoch: 233 | Train Loss: 0.57459 | Valid Loss: 0.57603 | Time: 0.48 seconds\n",
            "Epoch: 234 | Train Loss: 0.57374 | Valid Loss: 0.57574 | Time: 0.48 seconds\n",
            "Epoch: 235 | Train Loss: 0.57289 | Valid Loss: 0.57307 | Time: 0.47 seconds\n",
            "Epoch: 236 | Train Loss: 0.57203 | Valid Loss: 0.57249 | Time: 0.46 seconds\n",
            "Epoch: 237 | Train Loss: 0.57119 | Valid Loss: 0.57271 | Time: 0.47 seconds\n",
            "Epoch: 238 | Train Loss: 0.57032 | Valid Loss: 0.57261 | Time: 0.45 seconds\n",
            "Epoch: 239 | Train Loss: 0.56947 | Valid Loss: 0.56933 | Time: 0.50 seconds\n",
            "Epoch: 240 | Train Loss: 0.56861 | Valid Loss: 0.56940 | Time: 0.45 seconds\n",
            "Epoch: 241 | Train Loss: 0.56776 | Valid Loss: 0.56892 | Time: 0.48 seconds\n",
            "Epoch: 242 | Train Loss: 0.56689 | Valid Loss: 0.56838 | Time: 0.46 seconds\n",
            "Epoch: 243 | Train Loss: 0.56604 | Valid Loss: 0.56886 | Time: 0.46 seconds\n",
            "Epoch: 244 | Train Loss: 0.56518 | Valid Loss: 0.56505 | Time: 0.49 seconds\n",
            "Epoch: 245 | Train Loss: 0.56432 | Valid Loss: 0.56638 | Time: 0.46 seconds\n",
            "Epoch: 246 | Train Loss: 0.56346 | Valid Loss: 0.56541 | Time: 0.47 seconds\n",
            "Epoch: 247 | Train Loss: 0.56260 | Valid Loss: 0.56338 | Time: 0.48 seconds\n",
            "Epoch: 248 | Train Loss: 0.56174 | Valid Loss: 0.56139 | Time: 0.50 seconds\n",
            "Epoch: 249 | Train Loss: 0.56088 | Valid Loss: 0.56171 | Time: 0.46 seconds\n",
            "Epoch: 250 | Train Loss: 0.56002 | Valid Loss: 0.56110 | Time: 0.47 seconds\n",
            "Epoch: 251 | Train Loss: 0.55915 | Valid Loss: 0.56029 | Time: 0.47 seconds\n",
            "Epoch: 252 | Train Loss: 0.55831 | Valid Loss: 0.55993 | Time: 0.47 seconds\n",
            "Epoch: 253 | Train Loss: 0.55743 | Valid Loss: 0.55861 | Time: 0.48 seconds\n",
            "Epoch: 254 | Train Loss: 0.55657 | Valid Loss: 0.55942 | Time: 0.47 seconds\n",
            "Epoch: 255 | Train Loss: 0.55569 | Valid Loss: 0.55743 | Time: 0.47 seconds\n",
            "Epoch: 256 | Train Loss: 0.55485 | Valid Loss: 0.55555 | Time: 0.49 seconds\n",
            "Epoch: 257 | Train Loss: 0.55397 | Valid Loss: 0.55459 | Time: 0.46 seconds\n",
            "Epoch: 258 | Train Loss: 0.55311 | Valid Loss: 0.55519 | Time: 0.47 seconds\n",
            "Epoch: 259 | Train Loss: 0.55225 | Valid Loss: 0.55296 | Time: 0.47 seconds\n",
            "Epoch: 260 | Train Loss: 0.55138 | Valid Loss: 0.55165 | Time: 0.48 seconds\n",
            "Epoch: 261 | Train Loss: 0.55051 | Valid Loss: 0.55116 | Time: 0.48 seconds\n",
            "Epoch: 262 | Train Loss: 0.54964 | Valid Loss: 0.55077 | Time: 0.47 seconds\n",
            "Epoch: 263 | Train Loss: 0.54877 | Valid Loss: 0.54945 | Time: 0.49 seconds\n",
            "Epoch: 264 | Train Loss: 0.54790 | Valid Loss: 0.54796 | Time: 0.48 seconds\n",
            "Epoch: 265 | Train Loss: 0.54703 | Valid Loss: 0.54898 | Time: 0.47 seconds\n",
            "Epoch: 266 | Train Loss: 0.54617 | Valid Loss: 0.54689 | Time: 0.48 seconds\n",
            "Epoch: 267 | Train Loss: 0.54530 | Valid Loss: 0.54680 | Time: 0.50 seconds\n",
            "Epoch: 268 | Train Loss: 0.54443 | Valid Loss: 0.54426 | Time: 0.47 seconds\n",
            "Epoch: 269 | Train Loss: 0.54356 | Valid Loss: 0.54488 | Time: 0.46 seconds\n",
            "Epoch: 270 | Train Loss: 0.54268 | Valid Loss: 0.54453 | Time: 0.46 seconds\n",
            "Epoch: 271 | Train Loss: 0.54182 | Valid Loss: 0.54428 | Time: 0.46 seconds\n",
            "Epoch: 272 | Train Loss: 0.54095 | Valid Loss: 0.54291 | Time: 0.48 seconds\n",
            "Epoch: 273 | Train Loss: 0.54007 | Valid Loss: 0.54071 | Time: 0.46 seconds\n",
            "Epoch: 274 | Train Loss: 0.53921 | Valid Loss: 0.54146 | Time: 0.48 seconds\n",
            "Epoch: 275 | Train Loss: 0.53833 | Valid Loss: 0.53907 | Time: 0.47 seconds\n",
            "Epoch: 276 | Train Loss: 0.53746 | Valid Loss: 0.53948 | Time: 0.48 seconds\n",
            "Epoch: 277 | Train Loss: 0.53660 | Valid Loss: 0.53894 | Time: 0.47 seconds\n",
            "Epoch: 278 | Train Loss: 0.53572 | Valid Loss: 0.53798 | Time: 0.48 seconds\n",
            "Epoch: 279 | Train Loss: 0.53485 | Valid Loss: 0.53651 | Time: 0.48 seconds\n",
            "Epoch: 280 | Train Loss: 0.53397 | Valid Loss: 0.53545 | Time: 0.51 seconds\n",
            "Epoch: 281 | Train Loss: 0.53310 | Valid Loss: 0.53425 | Time: 0.48 seconds\n",
            "Epoch: 282 | Train Loss: 0.53222 | Valid Loss: 0.53585 | Time: 0.47 seconds\n",
            "Epoch: 283 | Train Loss: 0.53134 | Valid Loss: 0.53291 | Time: 0.47 seconds\n",
            "Epoch: 284 | Train Loss: 0.53047 | Valid Loss: 0.53058 | Time: 0.47 seconds\n",
            "Epoch: 285 | Train Loss: 0.52961 | Valid Loss: 0.53200 | Time: 0.45 seconds\n",
            "Epoch: 286 | Train Loss: 0.52874 | Valid Loss: 0.52937 | Time: 0.48 seconds\n",
            "Epoch: 287 | Train Loss: 0.52787 | Valid Loss: 0.52886 | Time: 0.49 seconds\n",
            "Epoch: 288 | Train Loss: 0.52697 | Valid Loss: 0.52862 | Time: 0.48 seconds\n",
            "Epoch: 289 | Train Loss: 0.52611 | Valid Loss: 0.52783 | Time: 0.47 seconds\n",
            "Epoch: 290 | Train Loss: 0.52525 | Valid Loss: 0.52661 | Time: 0.46 seconds\n",
            "Epoch: 291 | Train Loss: 0.52436 | Valid Loss: 0.52374 | Time: 0.49 seconds\n",
            "Epoch: 292 | Train Loss: 0.52347 | Valid Loss: 0.52646 | Time: 0.46 seconds\n",
            "Epoch: 293 | Train Loss: 0.52261 | Valid Loss: 0.52350 | Time: 0.47 seconds\n",
            "Epoch: 294 | Train Loss: 0.52175 | Valid Loss: 0.52384 | Time: 0.46 seconds\n",
            "Epoch: 295 | Train Loss: 0.52090 | Valid Loss: 0.52171 | Time: 0.49 seconds\n",
            "Epoch: 296 | Train Loss: 0.52000 | Valid Loss: 0.52256 | Time: 0.47 seconds\n",
            "Epoch: 297 | Train Loss: 0.51914 | Valid Loss: 0.51906 | Time: 0.48 seconds\n",
            "Epoch: 298 | Train Loss: 0.51823 | Valid Loss: 0.52018 | Time: 0.45 seconds\n",
            "Epoch: 299 | Train Loss: 0.51738 | Valid Loss: 0.51743 | Time: 0.48 seconds\n",
            "Epoch: 300 | Train Loss: 0.51651 | Valid Loss: 0.51839 | Time: 0.48 seconds\n",
            "Epoch: 301 | Train Loss: 0.51563 | Valid Loss: 0.51547 | Time: 0.48 seconds\n",
            "Epoch: 302 | Train Loss: 0.51476 | Valid Loss: 0.51605 | Time: 0.48 seconds\n",
            "Epoch: 303 | Train Loss: 0.51386 | Valid Loss: 0.51682 | Time: 0.47 seconds\n",
            "Epoch: 304 | Train Loss: 0.51300 | Valid Loss: 0.51347 | Time: 0.52 seconds\n",
            "Epoch: 305 | Train Loss: 0.51213 | Valid Loss: 0.51387 | Time: 0.46 seconds\n",
            "Epoch: 306 | Train Loss: 0.51127 | Valid Loss: 0.51154 | Time: 0.49 seconds\n",
            "Epoch: 307 | Train Loss: 0.51039 | Valid Loss: 0.51147 | Time: 0.47 seconds\n",
            "Epoch: 308 | Train Loss: 0.50952 | Valid Loss: 0.50999 | Time: 0.47 seconds\n",
            "Epoch: 309 | Train Loss: 0.50865 | Valid Loss: 0.50900 | Time: 0.48 seconds\n",
            "Epoch: 310 | Train Loss: 0.50778 | Valid Loss: 0.50969 | Time: 0.47 seconds\n",
            "Epoch: 311 | Train Loss: 0.50690 | Valid Loss: 0.50703 | Time: 0.47 seconds\n",
            "Epoch: 312 | Train Loss: 0.50604 | Valid Loss: 0.50525 | Time: 0.49 seconds\n",
            "Epoch: 313 | Train Loss: 0.50518 | Valid Loss: 0.50716 | Time: 0.45 seconds\n",
            "Epoch: 314 | Train Loss: 0.50431 | Valid Loss: 0.50646 | Time: 0.48 seconds\n",
            "Epoch: 315 | Train Loss: 0.50343 | Valid Loss: 0.50672 | Time: 0.45 seconds\n",
            "Epoch: 316 | Train Loss: 0.50256 | Valid Loss: 0.50292 | Time: 0.47 seconds\n",
            "Epoch: 317 | Train Loss: 0.50171 | Valid Loss: 0.50403 | Time: 0.48 seconds\n",
            "Epoch: 318 | Train Loss: 0.50081 | Valid Loss: 0.50323 | Time: 0.49 seconds\n",
            "Epoch: 319 | Train Loss: 0.49997 | Valid Loss: 0.50028 | Time: 0.48 seconds\n",
            "Epoch: 320 | Train Loss: 0.49908 | Valid Loss: 0.50035 | Time: 0.46 seconds\n",
            "Epoch: 321 | Train Loss: 0.49821 | Valid Loss: 0.49924 | Time: 0.48 seconds\n",
            "Epoch: 322 | Train Loss: 0.49734 | Valid Loss: 0.49807 | Time: 0.47 seconds\n",
            "Epoch: 323 | Train Loss: 0.49649 | Valid Loss: 0.49710 | Time: 0.49 seconds\n",
            "Epoch: 324 | Train Loss: 0.49563 | Valid Loss: 0.49642 | Time: 0.46 seconds\n",
            "Epoch: 325 | Train Loss: 0.49475 | Valid Loss: 0.49697 | Time: 0.46 seconds\n",
            "Epoch: 326 | Train Loss: 0.49387 | Valid Loss: 0.49371 | Time: 0.46 seconds\n",
            "Epoch: 327 | Train Loss: 0.49302 | Valid Loss: 0.49183 | Time: 0.49 seconds\n",
            "Epoch: 328 | Train Loss: 0.49215 | Valid Loss: 0.49308 | Time: 0.47 seconds\n",
            "Epoch: 329 | Train Loss: 0.49129 | Valid Loss: 0.49336 | Time: 0.49 seconds\n",
            "Epoch: 330 | Train Loss: 0.49042 | Valid Loss: 0.49006 | Time: 0.47 seconds\n",
            "Epoch: 331 | Train Loss: 0.48957 | Valid Loss: 0.48952 | Time: 0.48 seconds\n",
            "Epoch: 332 | Train Loss: 0.48871 | Valid Loss: 0.49183 | Time: 0.46 seconds\n",
            "Epoch: 333 | Train Loss: 0.48782 | Valid Loss: 0.48998 | Time: 0.47 seconds\n",
            "Epoch: 334 | Train Loss: 0.48697 | Valid Loss: 0.48763 | Time: 0.47 seconds\n",
            "Epoch: 335 | Train Loss: 0.48613 | Valid Loss: 0.48660 | Time: 0.47 seconds\n",
            "Epoch: 336 | Train Loss: 0.48525 | Valid Loss: 0.48749 | Time: 0.49 seconds\n",
            "Epoch: 337 | Train Loss: 0.48440 | Valid Loss: 0.48575 | Time: 0.50 seconds\n",
            "Epoch: 338 | Train Loss: 0.48351 | Valid Loss: 0.48706 | Time: 0.47 seconds\n",
            "Epoch: 339 | Train Loss: 0.48267 | Valid Loss: 0.48526 | Time: 0.46 seconds\n",
            "Epoch: 340 | Train Loss: 0.48181 | Valid Loss: 0.48430 | Time: 0.48 seconds\n",
            "Epoch: 341 | Train Loss: 0.48095 | Valid Loss: 0.48472 | Time: 0.46 seconds\n",
            "Epoch: 342 | Train Loss: 0.48012 | Valid Loss: 0.48203 | Time: 0.49 seconds\n",
            "Epoch: 343 | Train Loss: 0.47926 | Valid Loss: 0.48036 | Time: 0.47 seconds\n",
            "Epoch: 344 | Train Loss: 0.47837 | Valid Loss: 0.48058 | Time: 0.47 seconds\n",
            "Epoch: 345 | Train Loss: 0.47755 | Valid Loss: 0.47895 | Time: 0.46 seconds\n",
            "Epoch: 346 | Train Loss: 0.47669 | Valid Loss: 0.47781 | Time: 0.48 seconds\n",
            "Epoch: 347 | Train Loss: 0.47582 | Valid Loss: 0.47631 | Time: 0.48 seconds\n",
            "Epoch: 348 | Train Loss: 0.47498 | Valid Loss: 0.47625 | Time: 0.49 seconds\n",
            "Epoch: 349 | Train Loss: 0.47412 | Valid Loss: 0.47706 | Time: 0.48 seconds\n",
            "Epoch: 350 | Train Loss: 0.47329 | Valid Loss: 0.47518 | Time: 0.47 seconds\n",
            "Epoch: 351 | Train Loss: 0.47243 | Valid Loss: 0.47115 | Time: 0.48 seconds\n",
            "Epoch: 352 | Train Loss: 0.47159 | Valid Loss: 0.47211 | Time: 0.47 seconds\n",
            "Epoch: 353 | Train Loss: 0.47074 | Valid Loss: 0.47133 | Time: 0.47 seconds\n",
            "Epoch: 354 | Train Loss: 0.46990 | Valid Loss: 0.47253 | Time: 0.47 seconds\n",
            "Epoch: 355 | Train Loss: 0.46906 | Valid Loss: 0.47046 | Time: 0.48 seconds\n",
            "Epoch: 356 | Train Loss: 0.46820 | Valid Loss: 0.46942 | Time: 0.48 seconds\n",
            "Epoch: 357 | Train Loss: 0.46736 | Valid Loss: 0.46811 | Time: 0.47 seconds\n",
            "Epoch: 358 | Train Loss: 0.46652 | Valid Loss: 0.46694 | Time: 0.46 seconds\n",
            "Epoch: 359 | Train Loss: 0.46567 | Valid Loss: 0.46900 | Time: 0.48 seconds\n",
            "Epoch: 360 | Train Loss: 0.46484 | Valid Loss: 0.46765 | Time: 0.48 seconds\n",
            "Epoch: 361 | Train Loss: 0.46399 | Valid Loss: 0.46248 | Time: 0.48 seconds\n",
            "Epoch: 362 | Train Loss: 0.46316 | Valid Loss: 0.46412 | Time: 0.47 seconds\n",
            "Epoch: 363 | Train Loss: 0.46232 | Valid Loss: 0.46343 | Time: 0.46 seconds\n",
            "Epoch: 364 | Train Loss: 0.46146 | Valid Loss: 0.46429 | Time: 0.47 seconds\n",
            "Epoch: 365 | Train Loss: 0.46066 | Valid Loss: 0.46452 | Time: 0.48 seconds\n",
            "Epoch: 366 | Train Loss: 0.45980 | Valid Loss: 0.46468 | Time: 0.47 seconds\n",
            "Epoch: 367 | Train Loss: 0.45896 | Valid Loss: 0.45960 | Time: 0.47 seconds\n",
            "Epoch: 368 | Train Loss: 0.45814 | Valid Loss: 0.45972 | Time: 0.46 seconds\n",
            "Epoch: 369 | Train Loss: 0.45731 | Valid Loss: 0.45902 | Time: 0.47 seconds\n",
            "Epoch: 370 | Train Loss: 0.45647 | Valid Loss: 0.45713 | Time: 0.50 seconds\n",
            "Epoch: 371 | Train Loss: 0.45563 | Valid Loss: 0.45576 | Time: 0.47 seconds\n",
            "Epoch: 372 | Train Loss: 0.45482 | Valid Loss: 0.45493 | Time: 0.48 seconds\n",
            "Epoch: 373 | Train Loss: 0.45398 | Valid Loss: 0.45287 | Time: 0.48 seconds\n",
            "Epoch: 374 | Train Loss: 0.45316 | Valid Loss: 0.45547 | Time: 0.48 seconds\n",
            "Epoch: 375 | Train Loss: 0.45232 | Valid Loss: 0.45418 | Time: 0.49 seconds\n",
            "Epoch: 376 | Train Loss: 0.45149 | Valid Loss: 0.45659 | Time: 0.47 seconds\n",
            "Epoch: 377 | Train Loss: 0.45068 | Valid Loss: 0.45099 | Time: 0.47 seconds\n",
            "Epoch: 378 | Train Loss: 0.44987 | Valid Loss: 0.45434 | Time: 0.46 seconds\n",
            "Epoch: 379 | Train Loss: 0.44906 | Valid Loss: 0.44975 | Time: 0.48 seconds\n",
            "Epoch: 380 | Train Loss: 0.44819 | Valid Loss: 0.45178 | Time: 0.48 seconds\n",
            "Epoch: 381 | Train Loss: 0.44742 | Valid Loss: 0.44883 | Time: 0.49 seconds\n",
            "Epoch: 382 | Train Loss: 0.44658 | Valid Loss: 0.44873 | Time: 0.48 seconds\n",
            "Epoch: 383 | Train Loss: 0.44579 | Valid Loss: 0.44763 | Time: 0.48 seconds\n",
            "Epoch: 384 | Train Loss: 0.44496 | Valid Loss: 0.44500 | Time: 0.48 seconds\n",
            "Epoch: 385 | Train Loss: 0.44413 | Valid Loss: 0.44595 | Time: 0.49 seconds\n",
            "Epoch: 386 | Train Loss: 0.44331 | Valid Loss: 0.44334 | Time: 0.48 seconds\n",
            "Epoch: 387 | Train Loss: 0.44250 | Valid Loss: 0.44202 | Time: 0.47 seconds\n",
            "Epoch: 388 | Train Loss: 0.44170 | Valid Loss: 0.44203 | Time: 0.47 seconds\n",
            "Epoch: 389 | Train Loss: 0.44091 | Valid Loss: 0.44081 | Time: 0.48 seconds\n",
            "Epoch: 390 | Train Loss: 0.44009 | Valid Loss: 0.44333 | Time: 0.46 seconds\n",
            "Epoch: 391 | Train Loss: 0.43929 | Valid Loss: 0.44083 | Time: 0.48 seconds\n",
            "Epoch: 392 | Train Loss: 0.43845 | Valid Loss: 0.44020 | Time: 0.46 seconds\n",
            "Epoch: 393 | Train Loss: 0.43767 | Valid Loss: 0.43913 | Time: 0.46 seconds\n",
            "Epoch: 394 | Train Loss: 0.43686 | Valid Loss: 0.43936 | Time: 0.48 seconds\n",
            "Epoch: 395 | Train Loss: 0.43608 | Valid Loss: 0.43827 | Time: 0.47 seconds\n",
            "Epoch: 396 | Train Loss: 0.43528 | Valid Loss: 0.43761 | Time: 0.47 seconds\n",
            "Epoch: 397 | Train Loss: 0.43447 | Valid Loss: 0.43686 | Time: 0.48 seconds\n",
            "Epoch: 398 | Train Loss: 0.43372 | Valid Loss: 0.43721 | Time: 0.49 seconds\n",
            "Epoch: 399 | Train Loss: 0.43287 | Valid Loss: 0.43600 | Time: 0.47 seconds\n",
            "Epoch: 400 | Train Loss: 0.43208 | Valid Loss: 0.43634 | Time: 0.47 seconds\n",
            "Epoch: 401 | Train Loss: 0.43127 | Valid Loss: 0.43237 | Time: 0.47 seconds\n",
            "Epoch: 402 | Train Loss: 0.43049 | Valid Loss: 0.43395 | Time: 0.48 seconds\n",
            "Epoch: 403 | Train Loss: 0.42969 | Valid Loss: 0.43250 | Time: 0.47 seconds\n",
            "Epoch: 404 | Train Loss: 0.42889 | Valid Loss: 0.43112 | Time: 0.47 seconds\n",
            "Epoch: 405 | Train Loss: 0.42812 | Valid Loss: 0.42704 | Time: 0.47 seconds\n",
            "Epoch: 406 | Train Loss: 0.42735 | Valid Loss: 0.43094 | Time: 0.47 seconds\n",
            "Epoch: 407 | Train Loss: 0.42657 | Valid Loss: 0.42897 | Time: 0.49 seconds\n",
            "Epoch: 408 | Train Loss: 0.42580 | Valid Loss: 0.42724 | Time: 0.47 seconds\n",
            "Epoch: 409 | Train Loss: 0.42499 | Valid Loss: 0.42497 | Time: 0.48 seconds\n",
            "Epoch: 410 | Train Loss: 0.42418 | Valid Loss: 0.42487 | Time: 0.47 seconds\n",
            "Epoch: 411 | Train Loss: 0.42344 | Valid Loss: 0.42600 | Time: 0.48 seconds\n",
            "Epoch: 412 | Train Loss: 0.42268 | Valid Loss: 0.42285 | Time: 0.47 seconds\n",
            "Epoch: 413 | Train Loss: 0.42190 | Valid Loss: 0.42275 | Time: 0.48 seconds\n",
            "Epoch: 414 | Train Loss: 0.42111 | Valid Loss: 0.42204 | Time: 0.46 seconds\n",
            "Epoch: 415 | Train Loss: 0.42033 | Valid Loss: 0.42349 | Time: 0.47 seconds\n",
            "Epoch: 416 | Train Loss: 0.41957 | Valid Loss: 0.42015 | Time: 0.48 seconds\n",
            "Epoch: 417 | Train Loss: 0.41876 | Valid Loss: 0.42064 | Time: 0.47 seconds\n",
            "Epoch: 418 | Train Loss: 0.41802 | Valid Loss: 0.42188 | Time: 0.46 seconds\n",
            "Epoch: 419 | Train Loss: 0.41724 | Valid Loss: 0.41861 | Time: 0.47 seconds\n",
            "Epoch: 420 | Train Loss: 0.41649 | Valid Loss: 0.41982 | Time: 0.47 seconds\n",
            "Epoch: 421 | Train Loss: 0.41575 | Valid Loss: 0.41621 | Time: 0.48 seconds\n",
            "Epoch: 422 | Train Loss: 0.41495 | Valid Loss: 0.41688 | Time: 0.46 seconds\n",
            "Epoch: 423 | Train Loss: 0.41419 | Valid Loss: 0.41572 | Time: 0.47 seconds\n",
            "Epoch: 424 | Train Loss: 0.41344 | Valid Loss: 0.41483 | Time: 0.49 seconds\n",
            "Epoch: 425 | Train Loss: 0.41270 | Valid Loss: 0.41354 | Time: 0.47 seconds\n",
            "Epoch: 426 | Train Loss: 0.41192 | Valid Loss: 0.41314 | Time: 0.47 seconds\n",
            "Epoch: 427 | Train Loss: 0.41117 | Valid Loss: 0.41314 | Time: 0.46 seconds\n",
            "Epoch: 428 | Train Loss: 0.41041 | Valid Loss: 0.41233 | Time: 0.48 seconds\n",
            "Epoch: 429 | Train Loss: 0.40964 | Valid Loss: 0.41248 | Time: 0.45 seconds\n",
            "Epoch: 430 | Train Loss: 0.40893 | Valid Loss: 0.40927 | Time: 0.48 seconds\n",
            "Epoch: 431 | Train Loss: 0.40813 | Valid Loss: 0.40953 | Time: 0.45 seconds\n",
            "Epoch: 432 | Train Loss: 0.40741 | Valid Loss: 0.40833 | Time: 0.47 seconds\n",
            "Epoch: 433 | Train Loss: 0.40666 | Valid Loss: 0.40779 | Time: 0.46 seconds\n",
            "Epoch: 434 | Train Loss: 0.40587 | Valid Loss: 0.40729 | Time: 0.47 seconds\n",
            "Epoch: 435 | Train Loss: 0.40518 | Valid Loss: 0.40795 | Time: 0.47 seconds\n",
            "Epoch: 436 | Train Loss: 0.40444 | Valid Loss: 0.40710 | Time: 0.49 seconds\n",
            "Epoch: 437 | Train Loss: 0.40369 | Valid Loss: 0.40569 | Time: 0.47 seconds\n",
            "Epoch: 438 | Train Loss: 0.40294 | Valid Loss: 0.40449 | Time: 0.46 seconds\n",
            "Epoch: 439 | Train Loss: 0.40221 | Valid Loss: 0.40280 | Time: 0.47 seconds\n",
            "Epoch: 440 | Train Loss: 0.40148 | Valid Loss: 0.40323 | Time: 0.45 seconds\n",
            "Epoch: 441 | Train Loss: 0.40076 | Valid Loss: 0.40387 | Time: 0.49 seconds\n",
            "Epoch: 442 | Train Loss: 0.40003 | Valid Loss: 0.40084 | Time: 0.48 seconds\n",
            "Epoch: 443 | Train Loss: 0.39930 | Valid Loss: 0.40151 | Time: 0.48 seconds\n",
            "Epoch: 444 | Train Loss: 0.39855 | Valid Loss: 0.39915 | Time: 0.47 seconds\n",
            "Epoch: 445 | Train Loss: 0.39785 | Valid Loss: 0.40010 | Time: 0.48 seconds\n",
            "Epoch: 446 | Train Loss: 0.39710 | Valid Loss: 0.39961 | Time: 0.46 seconds\n",
            "Epoch: 447 | Train Loss: 0.39639 | Valid Loss: 0.39920 | Time: 0.49 seconds\n",
            "Epoch: 448 | Train Loss: 0.39566 | Valid Loss: 0.39683 | Time: 0.47 seconds\n",
            "Epoch: 449 | Train Loss: 0.39493 | Valid Loss: 0.39614 | Time: 0.48 seconds\n",
            "Epoch: 450 | Train Loss: 0.39424 | Valid Loss: 0.39508 | Time: 0.48 seconds\n",
            "Epoch: 451 | Train Loss: 0.39349 | Valid Loss: 0.39644 | Time: 0.46 seconds\n",
            "Epoch: 452 | Train Loss: 0.39277 | Valid Loss: 0.39548 | Time: 0.48 seconds\n",
            "Epoch: 453 | Train Loss: 0.39205 | Valid Loss: 0.39556 | Time: 0.45 seconds\n",
            "Epoch: 454 | Train Loss: 0.39136 | Valid Loss: 0.39441 | Time: 0.50 seconds\n",
            "Epoch: 455 | Train Loss: 0.39062 | Valid Loss: 0.39107 | Time: 0.47 seconds\n",
            "Epoch: 456 | Train Loss: 0.38994 | Valid Loss: 0.38959 | Time: 0.49 seconds\n",
            "Epoch: 457 | Train Loss: 0.38927 | Valid Loss: 0.39228 | Time: 0.46 seconds\n",
            "Epoch: 458 | Train Loss: 0.38854 | Valid Loss: 0.38949 | Time: 0.48 seconds\n",
            "Epoch: 459 | Train Loss: 0.38779 | Valid Loss: 0.39031 | Time: 0.45 seconds\n",
            "Epoch: 460 | Train Loss: 0.38710 | Valid Loss: 0.38921 | Time: 0.49 seconds\n",
            "Epoch: 461 | Train Loss: 0.38642 | Valid Loss: 0.38895 | Time: 0.47 seconds\n",
            "Epoch: 462 | Train Loss: 0.38570 | Valid Loss: 0.38684 | Time: 0.48 seconds\n",
            "Epoch: 463 | Train Loss: 0.38502 | Valid Loss: 0.38683 | Time: 0.47 seconds\n",
            "Epoch: 464 | Train Loss: 0.38431 | Valid Loss: 0.38543 | Time: 0.49 seconds\n",
            "Epoch: 465 | Train Loss: 0.38360 | Valid Loss: 0.38649 | Time: 0.47 seconds\n",
            "Epoch: 466 | Train Loss: 0.38295 | Valid Loss: 0.38475 | Time: 0.48 seconds\n",
            "Epoch: 467 | Train Loss: 0.38224 | Valid Loss: 0.38412 | Time: 0.48 seconds\n",
            "Epoch: 468 | Train Loss: 0.38159 | Valid Loss: 0.38563 | Time: 0.46 seconds\n",
            "Epoch: 469 | Train Loss: 0.38087 | Valid Loss: 0.38441 | Time: 0.50 seconds\n",
            "Epoch: 470 | Train Loss: 0.38016 | Valid Loss: 0.38187 | Time: 0.47 seconds\n",
            "Epoch: 471 | Train Loss: 0.37950 | Valid Loss: 0.37862 | Time: 0.48 seconds\n",
            "Epoch: 472 | Train Loss: 0.37884 | Valid Loss: 0.37894 | Time: 0.47 seconds\n",
            "Epoch: 473 | Train Loss: 0.37816 | Valid Loss: 0.38048 | Time: 0.49 seconds\n",
            "Epoch: 474 | Train Loss: 0.37745 | Valid Loss: 0.37770 | Time: 0.50 seconds\n",
            "Epoch: 475 | Train Loss: 0.37680 | Valid Loss: 0.37934 | Time: 0.47 seconds\n",
            "Epoch: 476 | Train Loss: 0.37609 | Valid Loss: 0.37897 | Time: 0.46 seconds\n",
            "Epoch: 477 | Train Loss: 0.37543 | Valid Loss: 0.37703 | Time: 0.48 seconds\n",
            "Epoch: 478 | Train Loss: 0.37477 | Valid Loss: 0.37688 | Time: 0.48 seconds\n",
            "Epoch: 479 | Train Loss: 0.37410 | Valid Loss: 0.37580 | Time: 0.46 seconds\n",
            "Epoch: 480 | Train Loss: 0.37340 | Valid Loss: 0.37304 | Time: 0.48 seconds\n",
            "Epoch: 481 | Train Loss: 0.37277 | Valid Loss: 0.37551 | Time: 0.46 seconds\n",
            "Epoch: 482 | Train Loss: 0.37208 | Valid Loss: 0.37463 | Time: 0.47 seconds\n",
            "Epoch: 483 | Train Loss: 0.37138 | Valid Loss: 0.37353 | Time: 0.46 seconds\n",
            "Epoch: 484 | Train Loss: 0.37076 | Valid Loss: 0.37206 | Time: 0.49 seconds\n",
            "Epoch: 485 | Train Loss: 0.37009 | Valid Loss: 0.37174 | Time: 0.47 seconds\n",
            "Epoch: 486 | Train Loss: 0.36944 | Valid Loss: 0.36896 | Time: 0.49 seconds\n",
            "Epoch: 487 | Train Loss: 0.36876 | Valid Loss: 0.36817 | Time: 0.51 seconds\n",
            "Epoch: 488 | Train Loss: 0.36816 | Valid Loss: 0.37048 | Time: 0.48 seconds\n",
            "Epoch: 489 | Train Loss: 0.36744 | Valid Loss: 0.36919 | Time: 0.46 seconds\n",
            "Epoch: 490 | Train Loss: 0.36680 | Valid Loss: 0.36673 | Time: 0.48 seconds\n",
            "Epoch: 491 | Train Loss: 0.36616 | Valid Loss: 0.36964 | Time: 0.46 seconds\n",
            "Epoch: 492 | Train Loss: 0.36555 | Valid Loss: 0.36881 | Time: 0.46 seconds\n",
            "Epoch: 493 | Train Loss: 0.36490 | Valid Loss: 0.36615 | Time: 0.48 seconds\n",
            "Epoch: 494 | Train Loss: 0.36421 | Valid Loss: 0.36701 | Time: 0.46 seconds\n",
            "Epoch: 495 | Train Loss: 0.36358 | Valid Loss: 0.36407 | Time: 0.47 seconds\n",
            "Epoch: 496 | Train Loss: 0.36296 | Valid Loss: 0.36229 | Time: 0.47 seconds\n",
            "Epoch: 497 | Train Loss: 0.36228 | Valid Loss: 0.36558 | Time: 0.48 seconds\n",
            "Epoch: 498 | Train Loss: 0.36164 | Valid Loss: 0.36414 | Time: 0.49 seconds\n",
            "Epoch: 499 | Train Loss: 0.36100 | Valid Loss: 0.36478 | Time: 0.49 seconds\n",
            "Epoch: 500 | Train Loss: 0.36041 | Valid Loss: 0.36428 | Time: 0.46 seconds\n",
            "Epoch: 501 | Train Loss: 0.35975 | Valid Loss: 0.36368 | Time: 0.47 seconds\n",
            "Epoch: 502 | Train Loss: 0.35911 | Valid Loss: 0.36343 | Time: 0.46 seconds\n",
            "Epoch: 503 | Train Loss: 0.35846 | Valid Loss: 0.36106 | Time: 0.48 seconds\n",
            "Epoch: 504 | Train Loss: 0.35788 | Valid Loss: 0.35810 | Time: 0.46 seconds\n",
            "Epoch: 505 | Train Loss: 0.35720 | Valid Loss: 0.35742 | Time: 0.48 seconds\n",
            "Epoch: 506 | Train Loss: 0.35658 | Valid Loss: 0.35765 | Time: 0.46 seconds\n",
            "Epoch: 507 | Train Loss: 0.35596 | Valid Loss: 0.35806 | Time: 0.47 seconds\n",
            "Epoch: 508 | Train Loss: 0.35536 | Valid Loss: 0.35829 | Time: 0.46 seconds\n",
            "Epoch: 509 | Train Loss: 0.35474 | Valid Loss: 0.35681 | Time: 0.49 seconds\n",
            "Epoch: 510 | Train Loss: 0.35410 | Valid Loss: 0.35657 | Time: 0.48 seconds\n",
            "Epoch: 511 | Train Loss: 0.35350 | Valid Loss: 0.35588 | Time: 0.47 seconds\n",
            "Epoch: 512 | Train Loss: 0.35289 | Valid Loss: 0.35475 | Time: 0.49 seconds\n",
            "Epoch: 513 | Train Loss: 0.35221 | Valid Loss: 0.35239 | Time: 0.47 seconds\n",
            "Epoch: 514 | Train Loss: 0.35162 | Valid Loss: 0.35243 | Time: 0.48 seconds\n",
            "Epoch: 515 | Train Loss: 0.35104 | Valid Loss: 0.35370 | Time: 0.46 seconds\n",
            "Epoch: 516 | Train Loss: 0.35041 | Valid Loss: 0.35312 | Time: 0.49 seconds\n",
            "Epoch: 517 | Train Loss: 0.34981 | Valid Loss: 0.35078 | Time: 0.47 seconds\n",
            "Epoch: 518 | Train Loss: 0.34915 | Valid Loss: 0.35287 | Time: 0.47 seconds\n",
            "Epoch: 519 | Train Loss: 0.34858 | Valid Loss: 0.34891 | Time: 0.46 seconds\n",
            "Epoch: 520 | Train Loss: 0.34794 | Valid Loss: 0.34972 | Time: 0.49 seconds\n",
            "Epoch: 521 | Train Loss: 0.34736 | Valid Loss: 0.34776 | Time: 0.47 seconds\n",
            "Epoch: 522 | Train Loss: 0.34675 | Valid Loss: 0.34863 | Time: 0.47 seconds\n",
            "Epoch: 523 | Train Loss: 0.34616 | Valid Loss: 0.34676 | Time: 0.48 seconds\n",
            "Epoch: 524 | Train Loss: 0.34556 | Valid Loss: 0.34763 | Time: 0.46 seconds\n",
            "Epoch: 525 | Train Loss: 0.34496 | Valid Loss: 0.34828 | Time: 0.47 seconds\n",
            "Epoch: 526 | Train Loss: 0.34440 | Valid Loss: 0.34646 | Time: 0.48 seconds\n",
            "Epoch: 527 | Train Loss: 0.34379 | Valid Loss: 0.34695 | Time: 0.50 seconds\n",
            "Epoch: 528 | Train Loss: 0.34320 | Valid Loss: 0.34226 | Time: 0.49 seconds\n",
            "Epoch: 529 | Train Loss: 0.34261 | Valid Loss: 0.34444 | Time: 0.47 seconds\n",
            "Epoch: 530 | Train Loss: 0.34197 | Valid Loss: 0.34453 | Time: 0.46 seconds\n",
            "Epoch: 531 | Train Loss: 0.34142 | Valid Loss: 0.34287 | Time: 0.49 seconds\n",
            "Epoch: 532 | Train Loss: 0.34081 | Valid Loss: 0.34234 | Time: 0.46 seconds\n",
            "Epoch: 533 | Train Loss: 0.34020 | Valid Loss: 0.34499 | Time: 0.48 seconds\n",
            "Epoch: 534 | Train Loss: 0.33960 | Valid Loss: 0.34299 | Time: 0.47 seconds\n",
            "Epoch: 535 | Train Loss: 0.33903 | Valid Loss: 0.34193 | Time: 0.47 seconds\n",
            "Epoch: 536 | Train Loss: 0.33849 | Valid Loss: 0.33973 | Time: 0.48 seconds\n",
            "Epoch: 537 | Train Loss: 0.33785 | Valid Loss: 0.34235 | Time: 0.48 seconds\n",
            "Epoch: 538 | Train Loss: 0.33728 | Valid Loss: 0.33874 | Time: 0.46 seconds\n",
            "Epoch: 539 | Train Loss: 0.33670 | Valid Loss: 0.33993 | Time: 0.45 seconds\n",
            "Epoch: 540 | Train Loss: 0.33614 | Valid Loss: 0.33847 | Time: 0.48 seconds\n",
            "Epoch: 541 | Train Loss: 0.33559 | Valid Loss: 0.33628 | Time: 0.48 seconds\n",
            "Epoch: 542 | Train Loss: 0.33503 | Valid Loss: 0.33784 | Time: 0.48 seconds\n",
            "Epoch: 543 | Train Loss: 0.33441 | Valid Loss: 0.33585 | Time: 0.46 seconds\n",
            "Epoch: 544 | Train Loss: 0.33387 | Valid Loss: 0.33649 | Time: 0.47 seconds\n",
            "Epoch: 545 | Train Loss: 0.33331 | Valid Loss: 0.33767 | Time: 0.45 seconds\n",
            "Epoch: 546 | Train Loss: 0.33276 | Valid Loss: 0.33258 | Time: 0.49 seconds\n",
            "Epoch: 547 | Train Loss: 0.33218 | Valid Loss: 0.33440 | Time: 0.45 seconds\n",
            "Epoch: 548 | Train Loss: 0.33154 | Valid Loss: 0.33171 | Time: 0.48 seconds\n",
            "Epoch: 549 | Train Loss: 0.33103 | Valid Loss: 0.33216 | Time: 0.48 seconds\n",
            "Epoch: 550 | Train Loss: 0.33048 | Valid Loss: 0.33483 | Time: 0.45 seconds\n",
            "Epoch: 551 | Train Loss: 0.32991 | Valid Loss: 0.33004 | Time: 0.49 seconds\n",
            "Epoch: 552 | Train Loss: 0.32936 | Valid Loss: 0.33165 | Time: 0.47 seconds\n",
            "Epoch: 553 | Train Loss: 0.32876 | Valid Loss: 0.33062 | Time: 0.47 seconds\n",
            "Epoch: 554 | Train Loss: 0.32819 | Valid Loss: 0.32866 | Time: 0.46 seconds\n",
            "Epoch: 555 | Train Loss: 0.32767 | Valid Loss: 0.32997 | Time: 0.46 seconds\n",
            "Epoch: 556 | Train Loss: 0.32709 | Valid Loss: 0.32968 | Time: 0.47 seconds\n",
            "Epoch: 557 | Train Loss: 0.32656 | Valid Loss: 0.32808 | Time: 0.47 seconds\n",
            "Epoch: 558 | Train Loss: 0.32606 | Valid Loss: 0.32758 | Time: 0.47 seconds\n",
            "Epoch: 559 | Train Loss: 0.32545 | Valid Loss: 0.32839 | Time: 0.49 seconds\n",
            "Epoch: 560 | Train Loss: 0.32491 | Valid Loss: 0.32539 | Time: 0.48 seconds\n",
            "Epoch: 561 | Train Loss: 0.32438 | Valid Loss: 0.32541 | Time: 0.47 seconds\n",
            "Epoch: 562 | Train Loss: 0.32380 | Valid Loss: 0.32517 | Time: 0.47 seconds\n",
            "Epoch: 563 | Train Loss: 0.32328 | Valid Loss: 0.32381 | Time: 0.49 seconds\n",
            "Epoch: 564 | Train Loss: 0.32271 | Valid Loss: 0.32444 | Time: 0.47 seconds\n",
            "Epoch: 565 | Train Loss: 0.32222 | Valid Loss: 0.32340 | Time: 0.49 seconds\n",
            "Epoch: 566 | Train Loss: 0.32164 | Valid Loss: 0.32156 | Time: 0.47 seconds\n",
            "Epoch: 567 | Train Loss: 0.32110 | Valid Loss: 0.32208 | Time: 0.46 seconds\n",
            "Epoch: 568 | Train Loss: 0.32057 | Valid Loss: 0.32345 | Time: 0.47 seconds\n",
            "Epoch: 569 | Train Loss: 0.31999 | Valid Loss: 0.32163 | Time: 0.46 seconds\n",
            "Epoch: 570 | Train Loss: 0.31949 | Valid Loss: 0.32230 | Time: 0.49 seconds\n",
            "Epoch: 571 | Train Loss: 0.31892 | Valid Loss: 0.32086 | Time: 0.48 seconds\n",
            "Epoch: 572 | Train Loss: 0.31842 | Valid Loss: 0.31964 | Time: 0.48 seconds\n",
            "Epoch: 573 | Train Loss: 0.31791 | Valid Loss: 0.32017 | Time: 0.47 seconds\n",
            "Epoch: 574 | Train Loss: 0.31734 | Valid Loss: 0.31717 | Time: 0.48 seconds\n",
            "Epoch: 575 | Train Loss: 0.31682 | Valid Loss: 0.31814 | Time: 0.46 seconds\n",
            "Epoch: 576 | Train Loss: 0.31628 | Valid Loss: 0.31735 | Time: 0.49 seconds\n",
            "Epoch: 577 | Train Loss: 0.31573 | Valid Loss: 0.31671 | Time: 0.47 seconds\n",
            "Epoch: 578 | Train Loss: 0.31523 | Valid Loss: 0.31544 | Time: 0.48 seconds\n",
            "Epoch: 579 | Train Loss: 0.31473 | Valid Loss: 0.31569 | Time: 0.47 seconds\n",
            "Epoch: 580 | Train Loss: 0.31419 | Valid Loss: 0.31659 | Time: 0.48 seconds\n",
            "Epoch: 581 | Train Loss: 0.31366 | Valid Loss: 0.31411 | Time: 0.50 seconds\n",
            "Epoch: 582 | Train Loss: 0.31313 | Valid Loss: 0.31578 | Time: 0.49 seconds\n",
            "Epoch: 583 | Train Loss: 0.31262 | Valid Loss: 0.31403 | Time: 0.49 seconds\n",
            "Epoch: 584 | Train Loss: 0.31208 | Valid Loss: 0.31515 | Time: 0.48 seconds\n",
            "Epoch: 585 | Train Loss: 0.31160 | Valid Loss: 0.31141 | Time: 0.49 seconds\n",
            "Epoch: 586 | Train Loss: 0.31106 | Valid Loss: 0.31049 | Time: 0.49 seconds\n",
            "Epoch: 587 | Train Loss: 0.31056 | Valid Loss: 0.31406 | Time: 0.48 seconds\n",
            "Epoch: 588 | Train Loss: 0.31005 | Valid Loss: 0.31084 | Time: 0.45 seconds\n",
            "Epoch: 589 | Train Loss: 0.30947 | Valid Loss: 0.31215 | Time: 0.48 seconds\n",
            "Epoch: 590 | Train Loss: 0.30900 | Valid Loss: 0.31044 | Time: 0.49 seconds\n",
            "Epoch: 591 | Train Loss: 0.30847 | Valid Loss: 0.31077 | Time: 0.48 seconds\n",
            "Epoch: 592 | Train Loss: 0.30798 | Valid Loss: 0.30836 | Time: 0.46 seconds\n",
            "Epoch: 593 | Train Loss: 0.30748 | Valid Loss: 0.30840 | Time: 0.48 seconds\n",
            "Epoch: 594 | Train Loss: 0.30696 | Valid Loss: 0.30732 | Time: 0.47 seconds\n",
            "Epoch: 595 | Train Loss: 0.30642 | Valid Loss: 0.30932 | Time: 0.48 seconds\n",
            "Epoch: 596 | Train Loss: 0.30594 | Valid Loss: 0.30935 | Time: 0.46 seconds\n",
            "Epoch: 597 | Train Loss: 0.30543 | Valid Loss: 0.30698 | Time: 0.47 seconds\n",
            "Epoch: 598 | Train Loss: 0.30493 | Valid Loss: 0.30610 | Time: 0.49 seconds\n",
            "Epoch: 599 | Train Loss: 0.30445 | Valid Loss: 0.30577 | Time: 0.47 seconds\n",
            "Epoch: 600 | Train Loss: 0.30394 | Valid Loss: 0.30518 | Time: 0.48 seconds\n",
            "Epoch: 601 | Train Loss: 0.30348 | Valid Loss: 0.30518 | Time: 0.48 seconds\n",
            "Epoch: 602 | Train Loss: 0.30294 | Valid Loss: 0.30627 | Time: 0.47 seconds\n",
            "Epoch: 603 | Train Loss: 0.30247 | Valid Loss: 0.30468 | Time: 0.48 seconds\n",
            "Epoch: 604 | Train Loss: 0.30191 | Valid Loss: 0.30538 | Time: 0.49 seconds\n",
            "Epoch: 605 | Train Loss: 0.30144 | Valid Loss: 0.30335 | Time: 0.48 seconds\n",
            "Epoch: 606 | Train Loss: 0.30095 | Valid Loss: 0.30219 | Time: 0.50 seconds\n",
            "Epoch: 607 | Train Loss: 0.30050 | Valid Loss: 0.30129 | Time: 0.48 seconds\n",
            "Epoch: 608 | Train Loss: 0.29999 | Valid Loss: 0.30368 | Time: 0.49 seconds\n",
            "Epoch: 609 | Train Loss: 0.29949 | Valid Loss: 0.30109 | Time: 0.47 seconds\n",
            "Epoch: 610 | Train Loss: 0.29900 | Valid Loss: 0.30206 | Time: 0.47 seconds\n",
            "Epoch: 611 | Train Loss: 0.29848 | Valid Loss: 0.30044 | Time: 0.47 seconds\n",
            "Epoch: 612 | Train Loss: 0.29796 | Valid Loss: 0.30269 | Time: 0.48 seconds\n",
            "Epoch: 613 | Train Loss: 0.29747 | Valid Loss: 0.29811 | Time: 0.52 seconds\n",
            "Epoch: 614 | Train Loss: 0.29702 | Valid Loss: 0.30082 | Time: 0.49 seconds\n",
            "Epoch: 615 | Train Loss: 0.29656 | Valid Loss: 0.29826 | Time: 0.46 seconds\n",
            "Epoch: 616 | Train Loss: 0.29604 | Valid Loss: 0.29617 | Time: 0.48 seconds\n",
            "Epoch: 617 | Train Loss: 0.29555 | Valid Loss: 0.29799 | Time: 0.48 seconds\n",
            "Epoch: 618 | Train Loss: 0.29508 | Valid Loss: 0.29658 | Time: 0.46 seconds\n",
            "Epoch: 619 | Train Loss: 0.29464 | Valid Loss: 0.29649 | Time: 0.47 seconds\n",
            "Epoch: 620 | Train Loss: 0.29417 | Valid Loss: 0.29373 | Time: 0.47 seconds\n",
            "Epoch: 621 | Train Loss: 0.29361 | Valid Loss: 0.29650 | Time: 0.47 seconds\n",
            "Epoch: 622 | Train Loss: 0.29317 | Valid Loss: 0.29699 | Time: 0.47 seconds\n",
            "Epoch: 623 | Train Loss: 0.29267 | Valid Loss: 0.29472 | Time: 0.46 seconds\n",
            "Epoch: 624 | Train Loss: 0.29221 | Valid Loss: 0.29255 | Time: 0.47 seconds\n",
            "Epoch: 625 | Train Loss: 0.29172 | Valid Loss: 0.29236 | Time: 0.48 seconds\n",
            "Epoch: 626 | Train Loss: 0.29123 | Valid Loss: 0.29329 | Time: 0.47 seconds\n",
            "Epoch: 627 | Train Loss: 0.29076 | Valid Loss: 0.29244 | Time: 0.46 seconds\n",
            "Epoch: 628 | Train Loss: 0.29026 | Valid Loss: 0.29405 | Time: 0.47 seconds\n",
            "Epoch: 629 | Train Loss: 0.28984 | Valid Loss: 0.29259 | Time: 0.46 seconds\n",
            "Epoch: 630 | Train Loss: 0.28932 | Valid Loss: 0.29028 | Time: 0.48 seconds\n",
            "Epoch: 631 | Train Loss: 0.28891 | Valid Loss: 0.29110 | Time: 0.46 seconds\n",
            "Epoch: 632 | Train Loss: 0.28842 | Valid Loss: 0.29147 | Time: 0.49 seconds\n",
            "Epoch: 633 | Train Loss: 0.28794 | Valid Loss: 0.28875 | Time: 0.49 seconds\n",
            "Epoch: 634 | Train Loss: 0.28747 | Valid Loss: 0.29001 | Time: 0.47 seconds\n",
            "Epoch: 635 | Train Loss: 0.28700 | Valid Loss: 0.29133 | Time: 0.48 seconds\n",
            "Epoch: 636 | Train Loss: 0.28654 | Valid Loss: 0.28856 | Time: 0.49 seconds\n",
            "Epoch: 637 | Train Loss: 0.28612 | Valid Loss: 0.28787 | Time: 0.46 seconds\n",
            "Epoch: 638 | Train Loss: 0.28557 | Valid Loss: 0.28745 | Time: 0.48 seconds\n",
            "Epoch: 639 | Train Loss: 0.28517 | Valid Loss: 0.28822 | Time: 0.45 seconds\n",
            "Epoch: 640 | Train Loss: 0.28471 | Valid Loss: 0.28901 | Time: 0.48 seconds\n",
            "Epoch: 641 | Train Loss: 0.28419 | Valid Loss: 0.28659 | Time: 0.47 seconds\n",
            "Epoch: 642 | Train Loss: 0.28377 | Valid Loss: 0.28489 | Time: 0.49 seconds\n",
            "Epoch: 643 | Train Loss: 0.28329 | Valid Loss: 0.28515 | Time: 0.46 seconds\n",
            "Epoch: 644 | Train Loss: 0.28282 | Valid Loss: 0.28339 | Time: 0.46 seconds\n",
            "Epoch: 645 | Train Loss: 0.28238 | Valid Loss: 0.28416 | Time: 0.48 seconds\n",
            "Epoch: 646 | Train Loss: 0.28195 | Valid Loss: 0.28412 | Time: 0.46 seconds\n",
            "Epoch: 647 | Train Loss: 0.28146 | Valid Loss: 0.28383 | Time: 0.46 seconds\n",
            "Epoch: 648 | Train Loss: 0.28101 | Valid Loss: 0.28306 | Time: 0.46 seconds\n",
            "Epoch: 649 | Train Loss: 0.28058 | Valid Loss: 0.28289 | Time: 0.48 seconds\n",
            "Epoch: 650 | Train Loss: 0.28016 | Valid Loss: 0.28205 | Time: 0.49 seconds\n",
            "Epoch: 651 | Train Loss: 0.27961 | Valid Loss: 0.28237 | Time: 0.48 seconds\n",
            "Epoch: 652 | Train Loss: 0.27920 | Valid Loss: 0.28200 | Time: 0.46 seconds\n",
            "Epoch: 653 | Train Loss: 0.27875 | Valid Loss: 0.28147 | Time: 0.48 seconds\n",
            "Epoch: 654 | Train Loss: 0.27827 | Valid Loss: 0.28168 | Time: 0.51 seconds\n",
            "Epoch: 655 | Train Loss: 0.27790 | Valid Loss: 0.27874 | Time: 0.48 seconds\n",
            "Epoch: 656 | Train Loss: 0.27741 | Valid Loss: 0.27746 | Time: 0.47 seconds\n",
            "Epoch: 657 | Train Loss: 0.27699 | Valid Loss: 0.27850 | Time: 0.47 seconds\n",
            "Epoch: 658 | Train Loss: 0.27652 | Valid Loss: 0.27768 | Time: 0.46 seconds\n",
            "Epoch: 659 | Train Loss: 0.27603 | Valid Loss: 0.27651 | Time: 0.48 seconds\n",
            "Epoch: 660 | Train Loss: 0.27560 | Valid Loss: 0.27725 | Time: 0.47 seconds\n",
            "Epoch: 661 | Train Loss: 0.27512 | Valid Loss: 0.27719 | Time: 0.46 seconds\n",
            "Epoch: 662 | Train Loss: 0.27472 | Valid Loss: 0.27652 | Time: 0.47 seconds\n",
            "Epoch: 663 | Train Loss: 0.27429 | Valid Loss: 0.27472 | Time: 0.48 seconds\n",
            "Epoch: 664 | Train Loss: 0.27382 | Valid Loss: 0.27449 | Time: 0.48 seconds\n",
            "Epoch: 665 | Train Loss: 0.27339 | Valid Loss: 0.27516 | Time: 0.45 seconds\n",
            "Epoch: 666 | Train Loss: 0.27296 | Valid Loss: 0.27440 | Time: 0.48 seconds\n",
            "Epoch: 667 | Train Loss: 0.27253 | Valid Loss: 0.27443 | Time: 0.45 seconds\n",
            "Epoch: 668 | Train Loss: 0.27213 | Valid Loss: 0.27380 | Time: 0.49 seconds\n",
            "Epoch: 669 | Train Loss: 0.27166 | Valid Loss: 0.27230 | Time: 0.48 seconds\n",
            "Epoch: 670 | Train Loss: 0.27122 | Valid Loss: 0.27299 | Time: 0.47 seconds\n",
            "Epoch: 671 | Train Loss: 0.27079 | Valid Loss: 0.27384 | Time: 0.46 seconds\n",
            "Epoch: 672 | Train Loss: 0.27031 | Valid Loss: 0.27124 | Time: 0.46 seconds\n",
            "Epoch: 673 | Train Loss: 0.26990 | Valid Loss: 0.27387 | Time: 0.47 seconds\n",
            "Epoch: 674 | Train Loss: 0.26947 | Valid Loss: 0.27072 | Time: 0.47 seconds\n",
            "Epoch: 675 | Train Loss: 0.26899 | Valid Loss: 0.27186 | Time: 0.47 seconds\n",
            "Epoch: 676 | Train Loss: 0.26858 | Valid Loss: 0.27093 | Time: 0.47 seconds\n",
            "Epoch: 677 | Train Loss: 0.26818 | Valid Loss: 0.27033 | Time: 0.47 seconds\n",
            "Epoch: 678 | Train Loss: 0.26774 | Valid Loss: 0.26770 | Time: 0.48 seconds\n",
            "Epoch: 679 | Train Loss: 0.26730 | Valid Loss: 0.26843 | Time: 0.48 seconds\n",
            "Epoch: 680 | Train Loss: 0.26686 | Valid Loss: 0.26764 | Time: 0.46 seconds\n",
            "Epoch: 681 | Train Loss: 0.26644 | Valid Loss: 0.26932 | Time: 0.47 seconds\n",
            "Epoch: 682 | Train Loss: 0.26605 | Valid Loss: 0.26982 | Time: 0.47 seconds\n",
            "Epoch: 683 | Train Loss: 0.26559 | Valid Loss: 0.26544 | Time: 0.47 seconds\n",
            "Epoch: 684 | Train Loss: 0.26517 | Valid Loss: 0.26678 | Time: 0.46 seconds\n",
            "Epoch: 685 | Train Loss: 0.26475 | Valid Loss: 0.26650 | Time: 0.46 seconds\n",
            "Epoch: 686 | Train Loss: 0.26435 | Valid Loss: 0.26477 | Time: 0.50 seconds\n",
            "Epoch: 687 | Train Loss: 0.26390 | Valid Loss: 0.26571 | Time: 0.47 seconds\n",
            "Epoch: 688 | Train Loss: 0.26348 | Valid Loss: 0.26626 | Time: 0.47 seconds\n",
            "Epoch: 689 | Train Loss: 0.26305 | Valid Loss: 0.26597 | Time: 0.48 seconds\n",
            "Epoch: 690 | Train Loss: 0.26262 | Valid Loss: 0.26441 | Time: 0.50 seconds\n",
            "Epoch: 691 | Train Loss: 0.26220 | Valid Loss: 0.26481 | Time: 0.47 seconds\n",
            "Epoch: 692 | Train Loss: 0.26178 | Valid Loss: 0.26324 | Time: 0.48 seconds\n",
            "Epoch: 693 | Train Loss: 0.26138 | Valid Loss: 0.26417 | Time: 0.46 seconds\n",
            "Epoch: 694 | Train Loss: 0.26096 | Valid Loss: 0.26404 | Time: 0.47 seconds\n",
            "Epoch: 695 | Train Loss: 0.26054 | Valid Loss: 0.26230 | Time: 0.47 seconds\n",
            "Epoch: 696 | Train Loss: 0.26011 | Valid Loss: 0.26116 | Time: 0.48 seconds\n",
            "Epoch: 697 | Train Loss: 0.25975 | Valid Loss: 0.25982 | Time: 0.48 seconds\n",
            "Epoch: 698 | Train Loss: 0.25928 | Valid Loss: 0.26016 | Time: 0.47 seconds\n",
            "Epoch: 699 | Train Loss: 0.25888 | Valid Loss: 0.25775 | Time: 0.47 seconds\n",
            "Epoch: 700 | Train Loss: 0.25843 | Valid Loss: 0.25861 | Time: 0.46 seconds\n",
            "Epoch: 701 | Train Loss: 0.25803 | Valid Loss: 0.25982 | Time: 0.47 seconds\n",
            "Epoch: 702 | Train Loss: 0.25761 | Valid Loss: 0.25998 | Time: 0.46 seconds\n",
            "Epoch: 703 | Train Loss: 0.25722 | Valid Loss: 0.25930 | Time: 0.49 seconds\n",
            "Epoch: 704 | Train Loss: 0.25676 | Valid Loss: 0.25762 | Time: 0.48 seconds\n",
            "Epoch: 705 | Train Loss: 0.25636 | Valid Loss: 0.25754 | Time: 0.47 seconds\n",
            "Epoch: 706 | Train Loss: 0.25601 | Valid Loss: 0.25630 | Time: 0.48 seconds\n",
            "Epoch: 707 | Train Loss: 0.25560 | Valid Loss: 0.25754 | Time: 0.48 seconds\n",
            "Epoch: 708 | Train Loss: 0.25517 | Valid Loss: 0.25720 | Time: 0.48 seconds\n",
            "Epoch: 709 | Train Loss: 0.25474 | Valid Loss: 0.25482 | Time: 0.48 seconds\n",
            "Epoch: 710 | Train Loss: 0.25432 | Valid Loss: 0.25534 | Time: 0.47 seconds\n",
            "Epoch: 711 | Train Loss: 0.25395 | Valid Loss: 0.25627 | Time: 0.48 seconds\n",
            "Epoch: 712 | Train Loss: 0.25355 | Valid Loss: 0.25471 | Time: 0.47 seconds\n",
            "Epoch: 713 | Train Loss: 0.25309 | Valid Loss: 0.25619 | Time: 0.48 seconds\n",
            "Epoch: 714 | Train Loss: 0.25274 | Valid Loss: 0.25390 | Time: 0.47 seconds\n",
            "Epoch: 715 | Train Loss: 0.25231 | Valid Loss: 0.25563 | Time: 0.46 seconds\n",
            "Epoch: 716 | Train Loss: 0.25190 | Valid Loss: 0.25249 | Time: 0.48 seconds\n",
            "Epoch: 717 | Train Loss: 0.25150 | Valid Loss: 0.25350 | Time: 0.47 seconds\n",
            "Epoch: 718 | Train Loss: 0.25108 | Valid Loss: 0.25382 | Time: 0.47 seconds\n",
            "Epoch: 719 | Train Loss: 0.25073 | Valid Loss: 0.25196 | Time: 0.47 seconds\n",
            "Epoch: 720 | Train Loss: 0.25035 | Valid Loss: 0.25138 | Time: 0.51 seconds\n",
            "Epoch: 721 | Train Loss: 0.24992 | Valid Loss: 0.25236 | Time: 0.48 seconds\n",
            "Epoch: 722 | Train Loss: 0.24952 | Valid Loss: 0.25195 | Time: 0.48 seconds\n",
            "Epoch: 723 | Train Loss: 0.24912 | Valid Loss: 0.25198 | Time: 0.46 seconds\n",
            "Epoch: 724 | Train Loss: 0.24871 | Valid Loss: 0.24912 | Time: 0.48 seconds\n",
            "Epoch: 725 | Train Loss: 0.24835 | Valid Loss: 0.25015 | Time: 0.46 seconds\n",
            "Epoch: 726 | Train Loss: 0.24794 | Valid Loss: 0.25093 | Time: 0.47 seconds\n",
            "Epoch: 727 | Train Loss: 0.24752 | Valid Loss: 0.25014 | Time: 0.46 seconds\n",
            "Epoch: 728 | Train Loss: 0.24712 | Valid Loss: 0.24871 | Time: 0.48 seconds\n",
            "Epoch: 729 | Train Loss: 0.24675 | Valid Loss: 0.24908 | Time: 0.47 seconds\n",
            "Epoch: 730 | Train Loss: 0.24638 | Valid Loss: 0.24570 | Time: 0.46 seconds\n",
            "Epoch: 731 | Train Loss: 0.24592 | Valid Loss: 0.24661 | Time: 0.47 seconds\n",
            "Epoch: 732 | Train Loss: 0.24558 | Valid Loss: 0.24686 | Time: 0.46 seconds\n",
            "Epoch: 733 | Train Loss: 0.24516 | Valid Loss: 0.24544 | Time: 0.48 seconds\n",
            "Epoch: 734 | Train Loss: 0.24482 | Valid Loss: 0.24616 | Time: 0.47 seconds\n",
            "Epoch: 735 | Train Loss: 0.24440 | Valid Loss: 0.24581 | Time: 0.47 seconds\n",
            "Epoch: 736 | Train Loss: 0.24403 | Valid Loss: 0.24643 | Time: 0.45 seconds\n",
            "Epoch: 737 | Train Loss: 0.24359 | Valid Loss: 0.24506 | Time: 0.51 seconds\n",
            "Epoch: 738 | Train Loss: 0.24321 | Valid Loss: 0.24532 | Time: 0.46 seconds\n",
            "Epoch: 739 | Train Loss: 0.24281 | Valid Loss: 0.24600 | Time: 0.47 seconds\n",
            "Epoch: 740 | Train Loss: 0.24243 | Valid Loss: 0.24389 | Time: 0.49 seconds\n",
            "Epoch: 741 | Train Loss: 0.24207 | Valid Loss: 0.24299 | Time: 0.49 seconds\n",
            "Epoch: 742 | Train Loss: 0.24169 | Valid Loss: 0.24421 | Time: 0.46 seconds\n",
            "Epoch: 743 | Train Loss: 0.24128 | Valid Loss: 0.24418 | Time: 0.46 seconds\n",
            "Epoch: 744 | Train Loss: 0.24093 | Valid Loss: 0.24095 | Time: 0.47 seconds\n",
            "Epoch: 745 | Train Loss: 0.24049 | Valid Loss: 0.24256 | Time: 0.46 seconds\n",
            "Epoch: 746 | Train Loss: 0.24013 | Valid Loss: 0.24223 | Time: 0.47 seconds\n",
            "Epoch: 747 | Train Loss: 0.23976 | Valid Loss: 0.24268 | Time: 0.46 seconds\n",
            "Epoch: 748 | Train Loss: 0.23940 | Valid Loss: 0.24317 | Time: 0.46 seconds\n",
            "Epoch: 749 | Train Loss: 0.23901 | Valid Loss: 0.24178 | Time: 0.46 seconds\n",
            "Epoch: 750 | Train Loss: 0.23861 | Valid Loss: 0.24070 | Time: 0.48 seconds\n",
            "Epoch: 751 | Train Loss: 0.23826 | Valid Loss: 0.23994 | Time: 0.48 seconds\n",
            "Epoch: 752 | Train Loss: 0.23787 | Valid Loss: 0.24036 | Time: 0.47 seconds\n",
            "Epoch: 753 | Train Loss: 0.23745 | Valid Loss: 0.23873 | Time: 0.47 seconds\n",
            "Epoch: 754 | Train Loss: 0.23708 | Valid Loss: 0.23814 | Time: 0.47 seconds\n",
            "Epoch: 755 | Train Loss: 0.23672 | Valid Loss: 0.23761 | Time: 0.48 seconds\n",
            "Epoch: 756 | Train Loss: 0.23632 | Valid Loss: 0.23684 | Time: 0.48 seconds\n",
            "Epoch: 757 | Train Loss: 0.23598 | Valid Loss: 0.23725 | Time: 0.47 seconds\n",
            "Epoch: 758 | Train Loss: 0.23560 | Valid Loss: 0.23704 | Time: 0.48 seconds\n",
            "Epoch: 759 | Train Loss: 0.23520 | Valid Loss: 0.23751 | Time: 0.48 seconds\n",
            "Epoch: 760 | Train Loss: 0.23484 | Valid Loss: 0.23669 | Time: 0.46 seconds\n",
            "Epoch: 761 | Train Loss: 0.23448 | Valid Loss: 0.23590 | Time: 0.47 seconds\n",
            "Epoch: 762 | Train Loss: 0.23410 | Valid Loss: 0.23602 | Time: 0.48 seconds\n",
            "Epoch: 763 | Train Loss: 0.23369 | Valid Loss: 0.23490 | Time: 0.48 seconds\n",
            "Epoch: 764 | Train Loss: 0.23337 | Valid Loss: 0.23404 | Time: 0.47 seconds\n",
            "Epoch: 765 | Train Loss: 0.23300 | Valid Loss: 0.23534 | Time: 0.47 seconds\n",
            "Epoch: 766 | Train Loss: 0.23261 | Valid Loss: 0.23472 | Time: 0.45 seconds\n",
            "Epoch: 767 | Train Loss: 0.23228 | Valid Loss: 0.23559 | Time: 0.48 seconds\n",
            "Epoch: 768 | Train Loss: 0.23184 | Valid Loss: 0.23121 | Time: 0.48 seconds\n",
            "Epoch: 769 | Train Loss: 0.23150 | Valid Loss: 0.23224 | Time: 0.45 seconds\n",
            "Epoch: 770 | Train Loss: 0.23113 | Valid Loss: 0.23400 | Time: 0.47 seconds\n",
            "Epoch: 771 | Train Loss: 0.23078 | Valid Loss: 0.23369 | Time: 0.46 seconds\n",
            "Epoch: 772 | Train Loss: 0.23039 | Valid Loss: 0.23311 | Time: 0.46 seconds\n",
            "Epoch: 773 | Train Loss: 0.23007 | Valid Loss: 0.23269 | Time: 0.46 seconds\n",
            "Epoch: 774 | Train Loss: 0.22970 | Valid Loss: 0.23308 | Time: 0.47 seconds\n",
            "Epoch: 775 | Train Loss: 0.22931 | Valid Loss: 0.23146 | Time: 0.46 seconds\n",
            "Epoch: 776 | Train Loss: 0.22899 | Valid Loss: 0.23035 | Time: 0.47 seconds\n",
            "Epoch: 777 | Train Loss: 0.22857 | Valid Loss: 0.23058 | Time: 0.47 seconds\n",
            "Epoch: 778 | Train Loss: 0.22823 | Valid Loss: 0.23124 | Time: 0.48 seconds\n",
            "Epoch: 779 | Train Loss: 0.22786 | Valid Loss: 0.22990 | Time: 0.47 seconds\n",
            "Epoch: 780 | Train Loss: 0.22747 | Valid Loss: 0.22976 | Time: 0.47 seconds\n",
            "Epoch: 781 | Train Loss: 0.22714 | Valid Loss: 0.22930 | Time: 0.48 seconds\n",
            "Epoch: 782 | Train Loss: 0.22677 | Valid Loss: 0.22789 | Time: 0.49 seconds\n",
            "Epoch: 783 | Train Loss: 0.22640 | Valid Loss: 0.22987 | Time: 0.47 seconds\n",
            "Epoch: 784 | Train Loss: 0.22605 | Valid Loss: 0.22875 | Time: 0.47 seconds\n",
            "Epoch: 785 | Train Loss: 0.22571 | Valid Loss: 0.22737 | Time: 0.47 seconds\n",
            "Epoch: 786 | Train Loss: 0.22535 | Valid Loss: 0.22774 | Time: 0.49 seconds\n",
            "Epoch: 787 | Train Loss: 0.22499 | Valid Loss: 0.22759 | Time: 0.49 seconds\n",
            "Epoch: 788 | Train Loss: 0.22467 | Valid Loss: 0.22665 | Time: 0.46 seconds\n",
            "Epoch: 789 | Train Loss: 0.22424 | Valid Loss: 0.22533 | Time: 0.48 seconds\n",
            "Epoch: 790 | Train Loss: 0.22395 | Valid Loss: 0.22578 | Time: 0.45 seconds\n",
            "Epoch: 791 | Train Loss: 0.22352 | Valid Loss: 0.22615 | Time: 0.48 seconds\n",
            "Epoch: 792 | Train Loss: 0.22321 | Valid Loss: 0.22551 | Time: 0.46 seconds\n",
            "Epoch: 793 | Train Loss: 0.22284 | Valid Loss: 0.22396 | Time: 0.47 seconds\n",
            "Epoch: 794 | Train Loss: 0.22247 | Valid Loss: 0.22405 | Time: 0.47 seconds\n",
            "Epoch: 795 | Train Loss: 0.22213 | Valid Loss: 0.22192 | Time: 0.46 seconds\n",
            "Epoch: 796 | Train Loss: 0.22181 | Valid Loss: 0.22418 | Time: 0.47 seconds\n",
            "Epoch: 797 | Train Loss: 0.22146 | Valid Loss: 0.22183 | Time: 0.47 seconds\n",
            "Epoch: 798 | Train Loss: 0.22108 | Valid Loss: 0.22229 | Time: 0.46 seconds\n",
            "Epoch: 799 | Train Loss: 0.22070 | Valid Loss: 0.22262 | Time: 0.48 seconds\n",
            "Epoch: 800 | Train Loss: 0.22038 | Valid Loss: 0.22121 | Time: 0.48 seconds\n",
            "Epoch: 801 | Train Loss: 0.22003 | Valid Loss: 0.22128 | Time: 0.46 seconds\n",
            "Epoch: 802 | Train Loss: 0.21969 | Valid Loss: 0.22264 | Time: 0.48 seconds\n",
            "Epoch: 803 | Train Loss: 0.21932 | Valid Loss: 0.22018 | Time: 0.49 seconds\n",
            "Epoch: 804 | Train Loss: 0.21900 | Valid Loss: 0.22057 | Time: 0.48 seconds\n",
            "Epoch: 805 | Train Loss: 0.21865 | Valid Loss: 0.22034 | Time: 0.47 seconds\n",
            "Epoch: 806 | Train Loss: 0.21828 | Valid Loss: 0.22172 | Time: 0.48 seconds\n",
            "Epoch: 807 | Train Loss: 0.21793 | Valid Loss: 0.22069 | Time: 0.46 seconds\n",
            "Epoch: 808 | Train Loss: 0.21761 | Valid Loss: 0.21861 | Time: 0.47 seconds\n",
            "Epoch: 809 | Train Loss: 0.21726 | Valid Loss: 0.21845 | Time: 0.49 seconds\n",
            "Epoch: 810 | Train Loss: 0.21693 | Valid Loss: 0.21801 | Time: 0.46 seconds\n",
            "Epoch: 811 | Train Loss: 0.21656 | Valid Loss: 0.21730 | Time: 0.48 seconds\n",
            "Epoch: 812 | Train Loss: 0.21624 | Valid Loss: 0.21733 | Time: 0.46 seconds\n",
            "Epoch: 813 | Train Loss: 0.21589 | Valid Loss: 0.21669 | Time: 0.47 seconds\n",
            "Epoch: 814 | Train Loss: 0.21556 | Valid Loss: 0.21792 | Time: 0.47 seconds\n",
            "Epoch: 815 | Train Loss: 0.21521 | Valid Loss: 0.21772 | Time: 0.47 seconds\n",
            "Epoch: 816 | Train Loss: 0.21491 | Valid Loss: 0.21583 | Time: 0.48 seconds\n",
            "Epoch: 817 | Train Loss: 0.21452 | Valid Loss: 0.21711 | Time: 0.47 seconds\n",
            "Epoch: 818 | Train Loss: 0.21418 | Valid Loss: 0.21654 | Time: 0.46 seconds\n",
            "Epoch: 819 | Train Loss: 0.21385 | Valid Loss: 0.21566 | Time: 0.48 seconds\n",
            "Epoch: 820 | Train Loss: 0.21350 | Valid Loss: 0.21343 | Time: 0.49 seconds\n",
            "Epoch: 821 | Train Loss: 0.21320 | Valid Loss: 0.21473 | Time: 0.47 seconds\n",
            "Epoch: 822 | Train Loss: 0.21284 | Valid Loss: 0.21382 | Time: 0.46 seconds\n",
            "Epoch: 823 | Train Loss: 0.21252 | Valid Loss: 0.21370 | Time: 0.49 seconds\n",
            "Epoch: 824 | Train Loss: 0.21217 | Valid Loss: 0.21416 | Time: 0.47 seconds\n",
            "Epoch: 825 | Train Loss: 0.21181 | Valid Loss: 0.21311 | Time: 0.46 seconds\n",
            "Epoch: 826 | Train Loss: 0.21148 | Valid Loss: 0.21464 | Time: 0.47 seconds\n",
            "Epoch: 827 | Train Loss: 0.21114 | Valid Loss: 0.21290 | Time: 0.48 seconds\n",
            "Epoch: 828 | Train Loss: 0.21084 | Valid Loss: 0.21212 | Time: 0.47 seconds\n",
            "Epoch: 829 | Train Loss: 0.21046 | Valid Loss: 0.21332 | Time: 0.46 seconds\n",
            "Epoch: 830 | Train Loss: 0.21013 | Valid Loss: 0.21073 | Time: 0.47 seconds\n",
            "Epoch: 831 | Train Loss: 0.20979 | Valid Loss: 0.21083 | Time: 0.46 seconds\n",
            "Epoch: 832 | Train Loss: 0.20945 | Valid Loss: 0.21082 | Time: 0.48 seconds\n",
            "Epoch: 833 | Train Loss: 0.20915 | Valid Loss: 0.20947 | Time: 0.48 seconds\n",
            "Epoch: 834 | Train Loss: 0.20882 | Valid Loss: 0.21163 | Time: 0.47 seconds\n",
            "Epoch: 835 | Train Loss: 0.20848 | Valid Loss: 0.20938 | Time: 0.46 seconds\n",
            "Epoch: 836 | Train Loss: 0.20815 | Valid Loss: 0.20853 | Time: 0.48 seconds\n",
            "Epoch: 837 | Train Loss: 0.20782 | Valid Loss: 0.20868 | Time: 0.46 seconds\n",
            "Epoch: 838 | Train Loss: 0.20753 | Valid Loss: 0.20895 | Time: 0.45 seconds\n",
            "Epoch: 839 | Train Loss: 0.20719 | Valid Loss: 0.20775 | Time: 0.49 seconds\n",
            "Epoch: 840 | Train Loss: 0.20685 | Valid Loss: 0.20867 | Time: 0.45 seconds\n",
            "Epoch: 841 | Train Loss: 0.20654 | Valid Loss: 0.20893 | Time: 0.47 seconds\n",
            "Epoch: 842 | Train Loss: 0.20620 | Valid Loss: 0.20836 | Time: 0.48 seconds\n",
            "Epoch: 843 | Train Loss: 0.20585 | Valid Loss: 0.20727 | Time: 0.47 seconds\n",
            "Epoch: 844 | Train Loss: 0.20554 | Valid Loss: 0.20635 | Time: 0.46 seconds\n",
            "Epoch: 845 | Train Loss: 0.20523 | Valid Loss: 0.20729 | Time: 0.50 seconds\n",
            "Epoch: 846 | Train Loss: 0.20489 | Valid Loss: 0.20754 | Time: 0.46 seconds\n",
            "Epoch: 847 | Train Loss: 0.20458 | Valid Loss: 0.20545 | Time: 0.47 seconds\n",
            "Epoch: 848 | Train Loss: 0.20424 | Valid Loss: 0.20477 | Time: 0.46 seconds\n",
            "Epoch: 849 | Train Loss: 0.20392 | Valid Loss: 0.20542 | Time: 0.46 seconds\n",
            "Epoch: 850 | Train Loss: 0.20361 | Valid Loss: 0.20532 | Time: 0.46 seconds\n",
            "Epoch: 851 | Train Loss: 0.20328 | Valid Loss: 0.20528 | Time: 0.46 seconds\n",
            "Epoch: 852 | Train Loss: 0.20293 | Valid Loss: 0.20464 | Time: 0.48 seconds\n",
            "Epoch: 853 | Train Loss: 0.20266 | Valid Loss: 0.20455 | Time: 0.46 seconds\n",
            "Epoch: 854 | Train Loss: 0.20233 | Valid Loss: 0.20337 | Time: 0.47 seconds\n",
            "Epoch: 855 | Train Loss: 0.20198 | Valid Loss: 0.20198 | Time: 0.47 seconds\n",
            "Epoch: 856 | Train Loss: 0.20166 | Valid Loss: 0.20125 | Time: 0.48 seconds\n",
            "Epoch: 857 | Train Loss: 0.20137 | Valid Loss: 0.20273 | Time: 0.47 seconds\n",
            "Epoch: 858 | Train Loss: 0.20104 | Valid Loss: 0.20170 | Time: 0.46 seconds\n",
            "Epoch: 859 | Train Loss: 0.20071 | Valid Loss: 0.20286 | Time: 0.46 seconds\n",
            "Epoch: 860 | Train Loss: 0.20039 | Valid Loss: 0.20031 | Time: 0.47 seconds\n",
            "Epoch: 861 | Train Loss: 0.20009 | Valid Loss: 0.20044 | Time: 0.46 seconds\n",
            "Epoch: 862 | Train Loss: 0.19978 | Valid Loss: 0.20250 | Time: 0.47 seconds\n",
            "Epoch: 863 | Train Loss: 0.19946 | Valid Loss: 0.20125 | Time: 0.46 seconds\n",
            "Epoch: 864 | Train Loss: 0.19916 | Valid Loss: 0.20039 | Time: 0.45 seconds\n",
            "Epoch: 865 | Train Loss: 0.19879 | Valid Loss: 0.20134 | Time: 0.47 seconds\n",
            "Epoch: 866 | Train Loss: 0.19854 | Valid Loss: 0.20024 | Time: 0.48 seconds\n",
            "Epoch: 867 | Train Loss: 0.19820 | Valid Loss: 0.20003 | Time: 0.48 seconds\n",
            "Epoch: 868 | Train Loss: 0.19786 | Valid Loss: 0.19976 | Time: 0.47 seconds\n",
            "Epoch: 869 | Train Loss: 0.19758 | Valid Loss: 0.19869 | Time: 0.48 seconds\n",
            "Epoch: 870 | Train Loss: 0.19725 | Valid Loss: 0.19836 | Time: 0.47 seconds\n",
            "Epoch: 871 | Train Loss: 0.19695 | Valid Loss: 0.19909 | Time: 0.46 seconds\n",
            "Epoch: 872 | Train Loss: 0.19663 | Valid Loss: 0.19769 | Time: 0.46 seconds\n",
            "Epoch: 873 | Train Loss: 0.19631 | Valid Loss: 0.19807 | Time: 0.47 seconds\n",
            "Epoch: 874 | Train Loss: 0.19599 | Valid Loss: 0.19857 | Time: 0.47 seconds\n",
            "Epoch: 875 | Train Loss: 0.19575 | Valid Loss: 0.19755 | Time: 0.49 seconds\n",
            "Epoch: 876 | Train Loss: 0.19541 | Valid Loss: 0.19684 | Time: 0.47 seconds\n",
            "Epoch: 877 | Train Loss: 0.19511 | Valid Loss: 0.19702 | Time: 0.46 seconds\n",
            "Epoch: 878 | Train Loss: 0.19477 | Valid Loss: 0.19638 | Time: 0.47 seconds\n",
            "Epoch: 879 | Train Loss: 0.19448 | Valid Loss: 0.19648 | Time: 0.48 seconds\n",
            "Epoch: 880 | Train Loss: 0.19418 | Valid Loss: 0.19626 | Time: 0.47 seconds\n",
            "Epoch: 881 | Train Loss: 0.19388 | Valid Loss: 0.19494 | Time: 0.47 seconds\n",
            "Epoch: 882 | Train Loss: 0.19355 | Valid Loss: 0.19580 | Time: 0.47 seconds\n",
            "Epoch: 883 | Train Loss: 0.19327 | Valid Loss: 0.19524 | Time: 0.48 seconds\n",
            "Epoch: 884 | Train Loss: 0.19295 | Valid Loss: 0.19472 | Time: 0.49 seconds\n",
            "Epoch: 885 | Train Loss: 0.19262 | Valid Loss: 0.19414 | Time: 0.46 seconds\n",
            "Epoch: 886 | Train Loss: 0.19236 | Valid Loss: 0.19505 | Time: 0.48 seconds\n",
            "Epoch: 887 | Train Loss: 0.19201 | Valid Loss: 0.19245 | Time: 0.46 seconds\n",
            "Epoch: 888 | Train Loss: 0.19176 | Valid Loss: 0.19404 | Time: 0.46 seconds\n",
            "Epoch: 889 | Train Loss: 0.19144 | Valid Loss: 0.19518 | Time: 0.46 seconds\n",
            "Epoch: 890 | Train Loss: 0.19115 | Valid Loss: 0.19247 | Time: 0.47 seconds\n",
            "Epoch: 891 | Train Loss: 0.19081 | Valid Loss: 0.19291 | Time: 0.48 seconds\n",
            "Epoch: 892 | Train Loss: 0.19053 | Valid Loss: 0.19262 | Time: 0.46 seconds\n",
            "Epoch: 893 | Train Loss: 0.19019 | Valid Loss: 0.19155 | Time: 0.49 seconds\n",
            "Epoch: 894 | Train Loss: 0.18993 | Valid Loss: 0.19075 | Time: 0.47 seconds\n",
            "Epoch: 895 | Train Loss: 0.18964 | Valid Loss: 0.19094 | Time: 0.49 seconds\n",
            "Epoch: 896 | Train Loss: 0.18934 | Valid Loss: 0.19043 | Time: 0.47 seconds\n",
            "Epoch: 897 | Train Loss: 0.18903 | Valid Loss: 0.19130 | Time: 0.48 seconds\n",
            "Epoch: 898 | Train Loss: 0.18873 | Valid Loss: 0.19032 | Time: 0.48 seconds\n",
            "Epoch: 899 | Train Loss: 0.18846 | Valid Loss: 0.18958 | Time: 0.49 seconds\n",
            "Epoch: 900 | Train Loss: 0.18814 | Valid Loss: 0.19093 | Time: 0.46 seconds\n",
            "Epoch: 901 | Train Loss: 0.18786 | Valid Loss: 0.18884 | Time: 0.48 seconds\n",
            "Epoch: 902 | Train Loss: 0.18757 | Valid Loss: 0.18981 | Time: 0.46 seconds\n",
            "Epoch: 903 | Train Loss: 0.18723 | Valid Loss: 0.18833 | Time: 0.47 seconds\n",
            "Epoch: 904 | Train Loss: 0.18695 | Valid Loss: 0.18731 | Time: 0.49 seconds\n",
            "Epoch: 905 | Train Loss: 0.18670 | Valid Loss: 0.18747 | Time: 0.48 seconds\n",
            "Epoch: 906 | Train Loss: 0.18640 | Valid Loss: 0.18781 | Time: 0.47 seconds\n",
            "Epoch: 907 | Train Loss: 0.18608 | Valid Loss: 0.18889 | Time: 0.46 seconds\n",
            "Epoch: 908 | Train Loss: 0.18581 | Valid Loss: 0.18845 | Time: 0.49 seconds\n",
            "Epoch: 909 | Train Loss: 0.18551 | Valid Loss: 0.18796 | Time: 0.46 seconds\n",
            "Epoch: 910 | Train Loss: 0.18520 | Valid Loss: 0.18691 | Time: 0.47 seconds\n",
            "Epoch: 911 | Train Loss: 0.18490 | Valid Loss: 0.18603 | Time: 0.46 seconds\n",
            "Epoch: 912 | Train Loss: 0.18464 | Valid Loss: 0.18561 | Time: 0.49 seconds\n",
            "Epoch: 913 | Train Loss: 0.18433 | Valid Loss: 0.18482 | Time: 0.47 seconds\n",
            "Epoch: 914 | Train Loss: 0.18403 | Valid Loss: 0.18551 | Time: 0.46 seconds\n",
            "Epoch: 915 | Train Loss: 0.18376 | Valid Loss: 0.18542 | Time: 0.45 seconds\n",
            "Epoch: 916 | Train Loss: 0.18345 | Valid Loss: 0.18508 | Time: 0.46 seconds\n",
            "Epoch: 917 | Train Loss: 0.18318 | Valid Loss: 0.18599 | Time: 0.49 seconds\n",
            "Epoch: 918 | Train Loss: 0.18289 | Valid Loss: 0.18404 | Time: 0.47 seconds\n",
            "Epoch: 919 | Train Loss: 0.18262 | Valid Loss: 0.18505 | Time: 0.47 seconds\n",
            "Epoch: 920 | Train Loss: 0.18232 | Valid Loss: 0.18397 | Time: 0.47 seconds\n",
            "Epoch: 921 | Train Loss: 0.18201 | Valid Loss: 0.18407 | Time: 0.47 seconds\n",
            "Epoch: 922 | Train Loss: 0.18176 | Valid Loss: 0.18180 | Time: 0.46 seconds\n",
            "Epoch: 923 | Train Loss: 0.18149 | Valid Loss: 0.18290 | Time: 0.48 seconds\n",
            "Epoch: 924 | Train Loss: 0.18119 | Valid Loss: 0.18292 | Time: 0.46 seconds\n",
            "Epoch: 925 | Train Loss: 0.18089 | Valid Loss: 0.18220 | Time: 0.47 seconds\n",
            "Epoch: 926 | Train Loss: 0.18061 | Valid Loss: 0.18212 | Time: 0.46 seconds\n",
            "Epoch: 927 | Train Loss: 0.18033 | Valid Loss: 0.18282 | Time: 0.47 seconds\n",
            "Epoch: 928 | Train Loss: 0.18003 | Valid Loss: 0.18204 | Time: 0.47 seconds\n",
            "Epoch: 929 | Train Loss: 0.17976 | Valid Loss: 0.18130 | Time: 0.47 seconds\n",
            "Epoch: 930 | Train Loss: 0.17949 | Valid Loss: 0.18089 | Time: 0.48 seconds\n",
            "Epoch: 931 | Train Loss: 0.17920 | Valid Loss: 0.18292 | Time: 0.45 seconds\n",
            "Epoch: 932 | Train Loss: 0.17894 | Valid Loss: 0.18042 | Time: 0.47 seconds\n",
            "Epoch: 933 | Train Loss: 0.17864 | Valid Loss: 0.18079 | Time: 0.46 seconds\n",
            "Epoch: 934 | Train Loss: 0.17834 | Valid Loss: 0.18030 | Time: 0.48 seconds\n",
            "Epoch: 935 | Train Loss: 0.17808 | Valid Loss: 0.17944 | Time: 0.46 seconds\n",
            "Epoch: 936 | Train Loss: 0.17779 | Valid Loss: 0.17796 | Time: 0.48 seconds\n",
            "Epoch: 937 | Train Loss: 0.17753 | Valid Loss: 0.17940 | Time: 0.46 seconds\n",
            "Epoch: 938 | Train Loss: 0.17726 | Valid Loss: 0.17957 | Time: 0.47 seconds\n",
            "Epoch: 939 | Train Loss: 0.17694 | Valid Loss: 0.17897 | Time: 0.46 seconds\n",
            "Epoch: 940 | Train Loss: 0.17670 | Valid Loss: 0.17718 | Time: 0.48 seconds\n",
            "Epoch: 941 | Train Loss: 0.17640 | Valid Loss: 0.17818 | Time: 0.47 seconds\n",
            "Epoch: 942 | Train Loss: 0.17613 | Valid Loss: 0.17711 | Time: 0.47 seconds\n",
            "Epoch: 943 | Train Loss: 0.17586 | Valid Loss: 0.17758 | Time: 0.47 seconds\n",
            "Epoch: 944 | Train Loss: 0.17557 | Valid Loss: 0.17676 | Time: 0.48 seconds\n",
            "Epoch: 945 | Train Loss: 0.17529 | Valid Loss: 0.17927 | Time: 0.47 seconds\n",
            "Epoch: 946 | Train Loss: 0.17500 | Valid Loss: 0.17636 | Time: 0.47 seconds\n",
            "Epoch: 947 | Train Loss: 0.17474 | Valid Loss: 0.17656 | Time: 0.47 seconds\n",
            "Epoch: 948 | Train Loss: 0.17448 | Valid Loss: 0.17613 | Time: 0.47 seconds\n",
            "Epoch: 949 | Train Loss: 0.17421 | Valid Loss: 0.17559 | Time: 0.50 seconds\n",
            "Epoch: 950 | Train Loss: 0.17392 | Valid Loss: 0.17491 | Time: 0.48 seconds\n",
            "Epoch: 951 | Train Loss: 0.17366 | Valid Loss: 0.17515 | Time: 0.48 seconds\n",
            "Epoch: 952 | Train Loss: 0.17342 | Valid Loss: 0.17641 | Time: 0.47 seconds\n",
            "Epoch: 953 | Train Loss: 0.17309 | Valid Loss: 0.17373 | Time: 0.48 seconds\n",
            "Epoch: 954 | Train Loss: 0.17285 | Valid Loss: 0.17419 | Time: 0.46 seconds\n",
            "Epoch: 955 | Train Loss: 0.17256 | Valid Loss: 0.17600 | Time: 0.47 seconds\n",
            "Epoch: 956 | Train Loss: 0.17233 | Valid Loss: 0.17215 | Time: 0.47 seconds\n",
            "Epoch: 957 | Train Loss: 0.17203 | Valid Loss: 0.17384 | Time: 0.46 seconds\n",
            "Epoch: 958 | Train Loss: 0.17176 | Valid Loss: 0.17296 | Time: 0.47 seconds\n",
            "Epoch: 959 | Train Loss: 0.17149 | Valid Loss: 0.17412 | Time: 0.46 seconds\n",
            "Epoch: 960 | Train Loss: 0.17120 | Valid Loss: 0.17259 | Time: 0.48 seconds\n",
            "Epoch: 961 | Train Loss: 0.17098 | Valid Loss: 0.17328 | Time: 0.45 seconds\n",
            "Epoch: 962 | Train Loss: 0.17068 | Valid Loss: 0.17307 | Time: 0.46 seconds\n",
            "Epoch: 963 | Train Loss: 0.17043 | Valid Loss: 0.17244 | Time: 0.46 seconds\n",
            "Epoch: 964 | Train Loss: 0.17016 | Valid Loss: 0.17194 | Time: 0.47 seconds\n",
            "Epoch: 965 | Train Loss: 0.16990 | Valid Loss: 0.17226 | Time: 0.47 seconds\n",
            "Epoch: 966 | Train Loss: 0.16965 | Valid Loss: 0.17131 | Time: 0.48 seconds\n",
            "Epoch: 967 | Train Loss: 0.16935 | Valid Loss: 0.17045 | Time: 0.47 seconds\n",
            "Epoch: 968 | Train Loss: 0.16911 | Valid Loss: 0.17022 | Time: 0.48 seconds\n",
            "Epoch: 969 | Train Loss: 0.16884 | Valid Loss: 0.17018 | Time: 0.47 seconds\n",
            "Epoch: 970 | Train Loss: 0.16855 | Valid Loss: 0.16971 | Time: 0.46 seconds\n",
            "Epoch: 971 | Train Loss: 0.16830 | Valid Loss: 0.17013 | Time: 0.48 seconds\n",
            "Epoch: 972 | Train Loss: 0.16806 | Valid Loss: 0.16902 | Time: 0.48 seconds\n",
            "Epoch: 973 | Train Loss: 0.16777 | Valid Loss: 0.16942 | Time: 0.48 seconds\n",
            "Epoch: 974 | Train Loss: 0.16751 | Valid Loss: 0.16983 | Time: 0.46 seconds\n",
            "Epoch: 975 | Train Loss: 0.16727 | Valid Loss: 0.16882 | Time: 0.49 seconds\n",
            "Epoch: 976 | Train Loss: 0.16701 | Valid Loss: 0.16924 | Time: 0.46 seconds\n",
            "Epoch: 977 | Train Loss: 0.16676 | Valid Loss: 0.16747 | Time: 0.48 seconds\n",
            "Epoch: 978 | Train Loss: 0.16644 | Valid Loss: 0.16834 | Time: 0.47 seconds\n",
            "Epoch: 979 | Train Loss: 0.16618 | Valid Loss: 0.16709 | Time: 0.48 seconds\n",
            "Epoch: 980 | Train Loss: 0.16594 | Valid Loss: 0.16718 | Time: 0.48 seconds\n",
            "Epoch: 981 | Train Loss: 0.16571 | Valid Loss: 0.16846 | Time: 0.48 seconds\n",
            "Epoch: 982 | Train Loss: 0.16547 | Valid Loss: 0.16747 | Time: 0.46 seconds\n",
            "Epoch: 983 | Train Loss: 0.16518 | Valid Loss: 0.16643 | Time: 0.48 seconds\n",
            "Epoch: 984 | Train Loss: 0.16494 | Valid Loss: 0.16612 | Time: 0.47 seconds\n",
            "Epoch: 985 | Train Loss: 0.16470 | Valid Loss: 0.16627 | Time: 0.46 seconds\n",
            "Epoch: 986 | Train Loss: 0.16441 | Valid Loss: 0.16564 | Time: 0.50 seconds\n",
            "Epoch: 987 | Train Loss: 0.16414 | Valid Loss: 0.16652 | Time: 0.46 seconds\n",
            "Epoch: 988 | Train Loss: 0.16392 | Valid Loss: 0.16583 | Time: 0.47 seconds\n",
            "Epoch: 989 | Train Loss: 0.16366 | Valid Loss: 0.16480 | Time: 0.47 seconds\n",
            "Epoch: 990 | Train Loss: 0.16336 | Valid Loss: 0.16488 | Time: 0.47 seconds\n",
            "Epoch: 991 | Train Loss: 0.16316 | Valid Loss: 0.16464 | Time: 0.46 seconds\n",
            "Epoch: 992 | Train Loss: 0.16285 | Valid Loss: 0.16531 | Time: 0.47 seconds\n",
            "Epoch: 993 | Train Loss: 0.16264 | Valid Loss: 0.16463 | Time: 0.46 seconds\n",
            "Epoch: 994 | Train Loss: 0.16238 | Valid Loss: 0.16331 | Time: 0.48 seconds\n",
            "Epoch: 995 | Train Loss: 0.16213 | Valid Loss: 0.16369 | Time: 0.47 seconds\n",
            "Epoch: 996 | Train Loss: 0.16188 | Valid Loss: 0.16267 | Time: 0.47 seconds\n",
            "Epoch: 997 | Train Loss: 0.16163 | Valid Loss: 0.16341 | Time: 0.47 seconds\n",
            "Epoch: 998 | Train Loss: 0.16136 | Valid Loss: 0.16232 | Time: 0.47 seconds\n",
            "Epoch: 999 | Train Loss: 0.16112 | Valid Loss: 0.16395 | Time: 0.48 seconds\n",
            "Epoch: 1000 | Train Loss: 0.16091 | Valid Loss: 0.16280 | Time: 0.46 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 998\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [1000 Epochs] : 7.90 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation RMSE [Fold 10]: 30.55930\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Total Time to 10 Fold CV : 78.39 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Fold 1, RMSE 32.77649\n",
            "Fold 2, RMSE 33.05209\n",
            "Fold 3, RMSE 33.37374\n",
            "Fold 4, RMSE 32.20404\n",
            "Fold 5, RMSE 34.59102\n",
            "Fold 6, RMSE 31.66981\n",
            "Fold 7, RMSE 32.94501\n",
            "Fold 8, RMSE 31.94207\n",
            "Fold 9, RMSE 30.99997\n",
            "Fold 10, RMSE 30.55930\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best RMSE : 30.55930\n",
            "Avg RMSE  : 32.41135\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J67n6rXMLvte"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}