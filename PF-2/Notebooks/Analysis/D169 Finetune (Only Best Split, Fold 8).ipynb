{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PF - Finetune D169 (Only Best Split Data, Fold 8).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBRdxRO7e3S"
      },
      "source": [
        "1. **Combines a pretrained Densenet169 Model with the Final Layer trained seperately.**\n",
        "\n",
        "2. **Final Layer weights are loaded into the model and then entire model is trained.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxBVKIs7zbAU"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdCKIRnFzJAk"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d jackstapleton/petfinder-pretrained-images-nocrop\n",
        "\n",
        "!mkdir ~/.data\n",
        "!unzip -q petfinder-pretrained-images-nocrop.zip -d /.data\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAcY29SW3mRO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRO1nmX73yxE"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujg_cbzw30XF"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import gc\n",
        "import pickle\n",
        "import random as r\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.nn.utils import weight_norm as WN\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from time import time\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7f3Fu1q31oH"
      },
      "source": [
        "## Constants and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CO2Y8R135S_"
      },
      "source": [
        "SEED = 49\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_FEATURES = 1664\n",
        "TRANSFORM = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                     [0.229, 0.224, 0.225]),\n",
        "                                ])\n",
        "\n",
        "IMAGE_PATH = \"/.data\"\n",
        "STATE_PATH = \"/content/gdrive/My Drive/Temp\"\n",
        "\n",
        "verbose = True\n",
        "DEBUG = False\n",
        "\n",
        "sc_y = StandardScaler()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrpUJpuR4EHC"
      },
      "source": [
        "def breaker(num=50, char=\"*\") -> None:\n",
        "    print(\"\\n\" + num*char + \"\\n\")\n",
        "\n",
        "\n",
        "def get_targets() -> np.ndarray:\n",
        "    df = pd.read_csv(\"/content/gdrive/My Drive/train.csv\", engine=\"python\")\n",
        "    targets = df[\"Pawpularity\"].copy().values\n",
        "    return targets.reshape(-1, 1)\n",
        "\n",
        "\n",
        "def show_graphs(L: list, title=None) -> None:\n",
        "    TL, VL = [], []\n",
        "    for i in range(len(L)):\n",
        "        TL.append(L[i][\"train\"])\n",
        "        VL.append(L[i][\"valid\"])\n",
        "    x_Axis = np.arange(1, len(L) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(x_Axis, TL, \"r\", label=\"train\")\n",
        "    plt.plot(x_Axis, VL, \"b\", label=\"valid\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    if title:\n",
        "        plt.title(\"{} Loss\".format(title))\n",
        "    else:\n",
        "        plt.title(\"Loss\")\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KA-btTd4Iob"
      },
      "source": [
        "## Dataset Template and Build Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raIbkq-_4KY6"
      },
      "source": [
        "class DS(Dataset):\n",
        "    def __init__(self, images=None, targets=None, transform=None):\n",
        "        self.images = images\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.images[idx]), torch.FloatTensor(self.targets[idx])\n",
        "\n",
        "\n",
        "def build_dataloaders(tr_images: np.ndarray, va_images: np.ndarray,\n",
        "                              tr_targets: np.ndarray, va_targets: np.ndarray,\n",
        "                              batch_size: int, seed: int, transform=None):\n",
        "\n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Building Train and Validation DataLoaders ...\")\n",
        "    \n",
        "    tr_data_setup = DS(images=tr_images, targets=tr_targets, transform=transform)\n",
        "    va_data_setup = DS(images=va_images, targets=va_targets, transform=transform)\n",
        "    \n",
        "    dataloaders = {\n",
        "        \"train\" : DL(tr_data_setup, batch_size=batch_size, shuffle=True, generator=torch.manual_seed(seed)),\n",
        "        \"valid\" : DL(va_data_setup, batch_size=batch_size, shuffle=False)\n",
        "    }\n",
        "    \n",
        "    return dataloaders"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-E8pae4zfA"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJbYa-Fq41wt"
      },
      "source": [
        "def build_model(IL: int, seed: int, path: str):\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self, IL=None):\n",
        "            super(Model, self).__init__()\n",
        "\n",
        "            self.features = models.densenet169(pretrained=True, progress=False)\n",
        "            self.features = nn.Sequential(*[*self.features.children()][:-1])\n",
        "            self.features.add_module(\"Adaptive Average Pool\", nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
        "            self.features.add_module(\"Flatten\", nn.Flatten())\n",
        "\n",
        "            self.predictor = nn.Sequential()\n",
        "            self.predictor.add_module(\"BN\", nn.BatchNorm1d(num_features=IL, eps=1e-5))\n",
        "            self.predictor.add_module(\"FC\", WN(nn.Linear(in_features=IL, out_features=1)))\n",
        "        \n",
        "        def get_optimizer(self, lr=1e-3, wd=0.0):\n",
        "            params = [p for p in self.parameters() if p.requires_grad]\n",
        "            return optim.SGD(params, lr=lr, momentum=0.9, weight_decay=wd)\n",
        "        \n",
        "        def forward(self, x1, x2=None):\n",
        "            if x2 is not None:\n",
        "                x1 = self.features(x1)\n",
        "                x2 = self.features(x2)\n",
        "                return self.predictor(x1), self.predictor(x2)\n",
        "            else:\n",
        "                x1 = self.features(x1)\n",
        "                return self.predictor(x1)\n",
        "\n",
        "    \n",
        "    model = Model(IL=IL)\n",
        "    \n",
        "    pretrained_state_dict = torch.load(path, map_location=DEVICE)[\"model_state_dict\"]\n",
        "    model.predictor.BN.weight = nn.Parameter(pretrained_state_dict[\"predictor.BN.weight\"])\n",
        "    model.predictor.BN.bias = nn.Parameter(pretrained_state_dict[\"predictor.BN.bias\"]) \n",
        "    model.predictor.FC.bias = nn.Parameter(pretrained_state_dict[\"predictor.FC.bias\"])\n",
        "    model.predictor.FC.weight_g = nn.Parameter(pretrained_state_dict[\"predictor.FC.weight_g\"]) \n",
        "    model.predictor.FC.weight_v = nn.Parameter(pretrained_state_dict[\"predictor.FC.weight_v\"]) \n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0niMi7JJONc"
      },
      "source": [
        "## Fit and Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_CBK6ytJQCm"
      },
      "source": [
        "def fit(model=None, optimizer=None, scheduler=None, \n",
        "        epochs=None, early_stopping_patience=None,\n",
        "        dataloaders=None, verbose=False) -> tuple:\n",
        "    \n",
        "    name = \"./state.pt\"\n",
        "\n",
        "    breaker()\n",
        "    print(\"Training ...\")\n",
        "    breaker()\n",
        "\n",
        "    Losses = []\n",
        "    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
        "\n",
        "    start_time = time()\n",
        "    for e in range(epochs):\n",
        "        e_st = time()\n",
        "        epochLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
        "\n",
        "        for phase in [\"train\", \"valid\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            \n",
        "            lossPerPass = []\n",
        "\n",
        "            for X, y in dataloaders[phase]:\n",
        "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    output = model(X)\n",
        "                    loss = torch.nn.MSELoss()(output, y)\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                lossPerPass.append(loss.item())\n",
        "            epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
        "        Losses.append(epochLoss)\n",
        "\n",
        "        if early_stopping_patience:\n",
        "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "                bestLoss = epochLoss\n",
        "                BLE = e + 1\n",
        "                torch.save({\"model_state_dict\": model.state_dict(),\n",
        "                            \"optim_state_dict\": optimizer.state_dict()},\n",
        "                           name)\n",
        "                early_stopping_step = 0\n",
        "            else:\n",
        "                early_stopping_step += 1\n",
        "                if early_stopping_step > early_stopping_patience:\n",
        "                    if verbose:\n",
        "                        print(\"\\nEarly Stopping at Epoch {}\".format(e))\n",
        "                    break\n",
        "        \n",
        "        if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "            bestLoss = epochLoss\n",
        "            BLE = e + 1\n",
        "            torch.save({\"model_state_dict\": model.state_dict(),\n",
        "                        \"optim_state_dict\": optimizer.state_dict()},\n",
        "                       name)\n",
        "        \n",
        "        if scheduler:\n",
        "            scheduler.step(epochLoss[\"valid\"])\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Time: {:.2f} seconds\".format(e+1, epochLoss[\"train\"], epochLoss[\"valid\"], time()-e_st))\n",
        "    \n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Best Validation Loss at Epoch {}\".format(BLE))\n",
        "        breaker()\n",
        "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(len(Losses), (time()-start_time)/60))\n",
        "        breaker()\n",
        "        print(\"Training Completed\")\n",
        "        breaker()\n",
        "\n",
        "    return Losses, BLE, name\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "def predict_batch(model=None, dataloader=None, mode=\"test\", path=None) -> np.ndarray:    \n",
        "    model.load_state_dict(torch.load(path, map_location=DEVICE)[\"model_state_dict\"])\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    y_pred = torch.zeros(1, 1).to(DEVICE)\n",
        "    if re.match(r\"valid\", mode, re.IGNORECASE):\n",
        "        for X, _ in dataloader:\n",
        "            X = X.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                output = model(X)\n",
        "            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n",
        "    elif re.match(r\"test\", mode, re.IGNORECASE):\n",
        "        for X in dataloader:\n",
        "            X = X.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                output = model(X)\n",
        "            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n",
        "    \n",
        "    return y_pred[1:].detach().cpu().numpy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdxevwnmJWKa"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVPG30fTJXhv"
      },
      "source": [
        "def train(images: np.ndarray, targets: np.ndarray, n_splits: int, \n",
        "          batch_size: int, lr: float, wd: float, \n",
        "          epochs: int, early_stopping: int, path: str,\n",
        "          patience=None, eps=None) -> list:        \n",
        "        \n",
        "    fold = 1\n",
        "    for tr_idx, va_idx in KFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(images):\n",
        "        fold += 1\n",
        "        if fold == 8:\n",
        "            break\n",
        "        \n",
        "    tr_images, va_images   = images[tr_idx], images[va_idx]\n",
        "    tr_targets, va_targets = targets[tr_idx], targets[va_idx]\n",
        "\n",
        "    tr_targets = sc_y.fit_transform(tr_targets)\n",
        "    va_targets = sc_y.transform(va_targets)\n",
        "\n",
        "    dataloaders = build_dataloaders(tr_images, va_images, \n",
        "                                    tr_targets, va_targets, \n",
        "                                    batch_size, SEED, \n",
        "                                    transform=TRANSFORM)\n",
        "    model = build_model(IL=NUM_FEATURES, seed=SEED, path=path).to(DEVICE)\n",
        "    optimizer = model.get_optimizer(lr=lr, wd=wd)\n",
        "    scheduler = None\n",
        "    if isinstance(patience, int) and isinstance(eps, float):\n",
        "        scheduler = model.get_plateau_scheduler(optimizer, patience, eps)\n",
        "\n",
        "    L, _, name = fit(model=model, optimizer=optimizer, scheduler=scheduler, \n",
        "                     epochs=epochs, early_stopping_patience=early_stopping,\n",
        "                     dataloaders=dataloaders, verbose=verbose)\n",
        "    y_pred = predict_batch(model=model, dataloader=dataloaders[\"valid\"], mode=\"valid\", path=name)\n",
        "    RMSE = np.sqrt(mean_squared_error(sc_y.inverse_transform(y_pred), sc_y.inverse_transform(va_targets)))\n",
        "    if verbose:\n",
        "        print(\"Validation RMSE : {:.5f}\".format(RMSE))\n",
        "        breaker()\n",
        "        show_graphs(L)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBUy00LcKG_I"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQYu9Db6KITD"
      },
      "source": [
        "def main():\n",
        "    breaker()\n",
        "    print(\"Clean Memory , {} Objects Collected ...\".format(gc.collect()))\n",
        "\n",
        "    ########### Params ###########\n",
        "    \n",
        "    if DEBUG:\n",
        "        n_splits = 3\n",
        "        patience, eps = 5, 1e-8\n",
        "        epochs, early_stopping = 5, 5\n",
        "\n",
        "        batch_size = 64\n",
        "        lr = 1e-5\n",
        "        wd = 1e-5\n",
        "    else:\n",
        "        n_splits = 10\n",
        "        patience, eps = 5, 1e-8\n",
        "        epochs, early_stopping = 25, 8\n",
        "\n",
        "        batch_size = 64\n",
        "        lr = 1e-5\n",
        "        wd = 1e-5\n",
        "    \n",
        "    ##############################\n",
        "\n",
        "    if verbose:\n",
        "        breaker()\n",
        "        print(\"Loading Data ...\")\n",
        "    \n",
        "    images = np.load(os.path.join(IMAGE_PATH, \"Images_224x224.npy\"))\n",
        "    targets  = get_targets()\n",
        "    pretrained_ann_path = os.path.join(STATE_PATH, \"Fold_8_state.pt\")\n",
        "\n",
        "    # Without Scheduler\n",
        "    train(images, targets, n_splits, batch_size, lr, wd, epochs, early_stopping, pretrained_ann_path, patience=None, eps=None)\n",
        "\n",
        "    # With Scheduler\n",
        "    # train(images, targets, n_splits, batch_size, lr, wd, epochs, early_stopping, pretrained_ann_path, patience=patience, eps=eps)\n",
        "    breaker()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FZ_PwKpxMZSs",
        "outputId": "2d325d55-4ca3-4fb4-f05a-89a618bd57ab"
      },
      "source": [
        "main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Clean Memory , 584 Objects Collected ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Loading Data ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Building Train and Validation DataLoaders ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Training ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Epoch: 1 | Train Loss: 0.78886 | Valid Loss: 0.84806 | Time: 243.94 seconds\n",
            "Epoch: 2 | Train Loss: 0.78808 | Valid Loss: 0.84557 | Time: 243.31 seconds\n",
            "Epoch: 3 | Train Loss: 0.78363 | Valid Loss: 0.84388 | Time: 243.33 seconds\n",
            "Epoch: 4 | Train Loss: 0.77724 | Valid Loss: 0.84045 | Time: 243.12 seconds\n",
            "Epoch: 5 | Train Loss: 0.77442 | Valid Loss: 0.84198 | Time: 242.76 seconds\n",
            "Epoch: 6 | Train Loss: 0.76768 | Valid Loss: 0.83971 | Time: 243.03 seconds\n",
            "Epoch: 7 | Train Loss: 0.76894 | Valid Loss: 0.84271 | Time: 242.62 seconds\n",
            "Epoch: 8 | Train Loss: 0.76223 | Valid Loss: 0.84084 | Time: 242.63 seconds\n",
            "Epoch: 9 | Train Loss: 0.76335 | Valid Loss: 0.84085 | Time: 242.65 seconds\n",
            "Epoch: 10 | Train Loss: 0.75770 | Valid Loss: 0.83964 | Time: 243.04 seconds\n",
            "Epoch: 11 | Train Loss: 0.75382 | Valid Loss: 0.83749 | Time: 243.33 seconds\n",
            "Epoch: 12 | Train Loss: 0.75295 | Valid Loss: 0.84064 | Time: 242.75 seconds\n",
            "Epoch: 13 | Train Loss: 0.75129 | Valid Loss: 0.83918 | Time: 242.80 seconds\n",
            "Epoch: 14 | Train Loss: 0.74563 | Valid Loss: 0.83872 | Time: 243.35 seconds\n",
            "Epoch: 15 | Train Loss: 0.74333 | Valid Loss: 0.84062 | Time: 242.84 seconds\n",
            "Epoch: 16 | Train Loss: 0.74482 | Valid Loss: 0.83844 | Time: 242.77 seconds\n",
            "Epoch: 17 | Train Loss: 0.73982 | Valid Loss: 0.83658 | Time: 243.05 seconds\n",
            "Epoch: 18 | Train Loss: 0.73657 | Valid Loss: 0.83830 | Time: 242.77 seconds\n",
            "Epoch: 19 | Train Loss: 0.73494 | Valid Loss: 0.84117 | Time: 242.67 seconds\n",
            "Epoch: 20 | Train Loss: 0.73185 | Valid Loss: 0.84126 | Time: 242.95 seconds\n",
            "Epoch: 21 | Train Loss: 0.72864 | Valid Loss: 0.83931 | Time: 241.99 seconds\n",
            "Epoch: 22 | Train Loss: 0.72925 | Valid Loss: 0.83855 | Time: 242.07 seconds\n",
            "Epoch: 23 | Train Loss: 0.71985 | Valid Loss: 0.83883 | Time: 242.97 seconds\n",
            "Epoch: 24 | Train Loss: 0.72091 | Valid Loss: 0.83834 | Time: 241.77 seconds\n",
            "Epoch: 25 | Train Loss: 0.72380 | Valid Loss: 0.84029 | Time: 242.73 seconds\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Best Validation Loss at Epoch 17\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Time Taken [25 Epochs] : 101.19 minutes\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Training Completed\n",
            "\n",
            "**************************************************\n",
            "\n",
            "\n",
            "Validation RMSE : 18.80892\n",
            "\n",
            "**************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8dcnEAgkbLIEZAdBQUAgAURQCaKCK1VU0Lq1io8qLohV1H4pUq3WfceqxaUVIz/cqMWi0uCKCkHZVxEhoGyyGCRs+fz++EzMEBMyZJvkzuf5eNxH5i4zc84MvO+dc889V1QV55xzwRUX7QI455wrXx70zjkXcB70zjkXcB70zjkXcB70zjkXcB70zjkXcB70zjkXcB70LqaJyBoRGRTtcjhXnjzonXMu4DzonStARGqKyKMisiE0PSoiNUPrGonIOyKyXUR+FJGPRSQutO42EVkvIj+JyHIROSW6NXHOVI92AZyrhO4Ejge6Awq8DfwJ+D9gDJAFNA5tezygInI0MAropaobRKQNUK1ii+1c4fyI3rlfuwSYoKqbVHUzcBdwaWjdPqAZ0FpV96nqx2oDRh0AagKdRSReVdeo6jdRKb1zBXjQO/drRwLfhc1/F1oG8ACwCnhPRFaLyFgAVV0F3ASMBzaJSLqIHIlzlYAHvXO/tgFoHTbfKrQMVf1JVceoajvgHODmvLZ4VZ2sqv1Dz1XgbxVbbOcK50HvHMSLSELeBLwK/ElEGotII2Ac8C8AETlLRI4SEQF2YE02uSJytIgMDJ20zQF2A7nRqY5zB/Ogdw6mY8GcNyUAc4EFwEJgHnB3aNsOwAdANjAbeFpVM7D2+fuALcAPQBPg9oqrgnNFE7/xiHPOBZsf0TvnXMB50DvnXMB50DvnXMB50DvnXMBVuiEQGjVqpG3atAFg165dJCYmRrdAURLLdYfYrn8s1x1iu/6lqXtmZuYWVW1c2LpKF/Rt2rRh7ty5AMyaNYsBAwZEt0BREst1h9iufyzXHWK7/qWpu4h8V9Q6b7pxzrmA86B3zrmA86B3zrmA86B3zrmA86B3zrmA86B3zrmA86B3zrmAC0zQq8If/wjTp0NOTrRL45xzlUdggn7NGpg4Ec48Exo2hN/8BiZNgo0bo10y55yLrkp3ZWxJtW0LW7bArFnw73/DtGnw1lsgAn36wDnnwNlnw7HH2jLnnIsVgTmiB0hIgMGD4amnYO1a+OorGD8e9u+HO+6Arl2hfXu48UaYORP27o12iZ1zrvwFKujDiUD37jBuHMyZA+vXw9//Dp07w7PPwqBB0LgxXHABPPQQfPQRZGdHu9TOOVf2AtN0U5wjj4SRI23atcuO6KdNg/ffh6lTbZu4OOjUCVJToVcvm447DmrWjG7ZnXOuNGIm6MMlJlqb/Tnn2PymTXbUnzdNnw4vvWTr4uOhW7eDw79zZ6gek5+cc64q8rgCmjSx3jpnnmnzqrBu3cHh/+qr1vQD0LRp/q+D5s2jV27nnItEYNvoS0MEWrWC88+H++6zZp5t22DZMnj5ZejRA/7yF2jdGoYNg4wM2zlUJaqweDFs2BDtkjjnypsHfYTi4uDoo+HSS61pZ+VKGD3aQn7gQOu2+eSTsHNn6d9r/37YsSO+9C9UiO++g7/+1ZqfunSxXyRt2sDFF1v5582z93fOBYc33ZRQ+/bwwAMwYQK89ho8/TRcfz2MHWs7g2uvte6cxdm5ExYsgPnz4euv7e/ChZCT048OHeD00+G00yAtDZKSSlbWHTvshPM//wkffmjLTjzRupnm5MBnn9nyV1+1dYmJdu3BCSfYdPzx0KBByd7buUipVr1fxlVFREEvIoOBx4BqwPOqel+B9a2Al4D6oW3Gqur0AuuXAONV9cEyKnulUKsWXHGFTXPmWOC/8AI884yF6bXXwnnn2UndtWsPDvSvv4bVq/Nf64gjrEvoH/4Au3Z9Q1ZWeyZNsiPt+HgL3dNOs/Dv0cN+ZRRl3z6YMcPCfdo0C/SOHa3J6ZJL7AKzPDfdlH9e4tNPLfg/+wzuvRcOHLBtOne2909JsesV4OD/lEU9BttBdehgU506JfmUy56qfUY1akS7JAdThdzcaJeidDZuhClT7ABozRr7N5Sba3/DHxdclvfvpk2bXpx+uv3/OfFEa0Z1pSNazC5URKoBK4BTgSxgDjBCVZeEbfMs8JWqThSRzsB0VW0Ttn4qoMAXxQV9amqqVvV7xm7damE/caIFeaNG1hyyfbutF4GjjrKum9275/9t3jz/qt28uu/ZY+H73nsW3F9/besbNYJTT7XgP+006z6qCnPnWrinp8Pmzbbd8OH2K6NXr8O7Kjg723Zen31mZZg9O78OJdWsme1wOnSwv3lTu3YHd2Mtr+8+K8t6VE2aZCHUoYP1quraNf9vmzaH3omWpf37baf/ySf2GX/6KWzdeoCTT67GoEF2vcdxx1VceUpqxw54802YPNnOaeXm5vdWq1bNpri4Xz8uuGz/fnj//a0sW9bwl2bQli0t8Pv3t7+dO1f+z+Nw5ObCokXw8cewatUKHnmkY4leR0QyVTW1sHWRHNH3Blap6urQi6UD52JH6HkUqBt6XA/45RSfiAwFvgV2HX7Rq6aGDeGWW+Dmm/OPquvWzQ/1rl0jb4apWdPOAQwcaCeGN260vv/vvWdTXnNLly72n2TZMnvO2WfDZZfZlcLxJWzuT0qyJqO0NJvPzbWgDD/iDN9xFPV42zY7p7FyJaxYYdPbb9uOKE9cnJ3czgv+pKRkOna0HVhp7dljv2omTbLPLDfXPs/hw2HpUjsvMXVq/hFlUpJ9R+Hh37Vr2TRf7dxpO8y8UP/iC7uuAyzQTjoJcnJ+YMWK5tx6qy1v2NDKmxf87dqVvhxlYfdu+M9/7N/gf/5jn3O7dnD77TBihJ23KolBgxZy4okDWLjQdoAff2znwiZPtvUNGkC/fvnhn5pa+X6ZHcqePXYA9fHH+Tv4HTtsXZcuyeXynpEc0Q8DBqvqVaH5S4E+qjoqbJtmwHtAAyARGKSqmSKSBLyP/Rq4Bcgu7IheREYCIwGSk5NT0tPTAcjOziappA3TVVwkdc/NhdWrE5kz5wjmzj0CVRg4cBMDBmwmKanyn1HNzq5OVlYt1q2rRVZWbbKy7O+6dbXYvduOQVq12kXPntvp2XMb3btvp06dyOu1alUi777bjA8+SGbnzniaNMnh9NN/YMiQH2jW7OAhTnfvrsa339Zm9eokVq9O/OXvTz/l7yUbN86hceM9JCYeoHbt/Qf9TUzcX+iyuDhlxYo6LFpUj0WL6rF6dSKqQlyc0r59Nl267KBLl5106bKDJk32hD4X++63bKnBV181IDPTpi1b7CdPs2a76dlzGykp2+jZczv16u0r7VcRsQMHhMzM+sycmcwnnzTi55+rc8QRe0hL28zAgRvp1OmnUo8lVdi/fVX4/vsEFiywz3HBgvqsW1cbgLg4pV69fRxxxF4aNNjLEUfsLfJx3br7Cy2fNeXFsXdvHHv22JT3eO/eauzdKyQk5JKYuJ/ExP0kJR0gIeFARHXNzq7OokV1WbiwHgsX1mPZsrrs22c/SVq33kWXLjvo1s2mxMQt1KlTssxLS0sr8oi+rIL+5tBrPSQifYF/AF2A+4EvVXWKiIyniKAPF4Smm7IQy3XPzYV//GMuO3akMnOmDU/x88/2K6FnTzjlFJv694fatQ9+7rZtdoQ5aRJkZtqR3tCh8Pvf23OqVYu8HKrW/XTBAjtBvnCh/aLauTN/2rEjsqEzkpLspHa/fjYdf3zR5ysK++5VYfly+OADmzIy8nt4de8OAwbknzwv62s7NmywI9D337e2982boV4961o8YoS99+F8rsWJ9N/+5s12NDxvHvzwg303P/yQPxU2llV8vF03k5Bgv0h277bzVzk5h38iuFo1+xyKmvbvt19vCxbYa1evbue48pqg+vWzptWS1L0wpW26WQ+0DJtvEVoW7vfAYABVnS0iCUAjoA8wTETux07U5opIjqo+eZh1cDEkLg46dMhmwABrAtu715o4Zs606eGH4f77LcT79rUA79wZXn8d3njDfhofdxw8/rh1G23YsGTlELHQbN4chgwpersDByzs84I/fCeQk5Pf/FOaq6lF4JhjbBo1ykIkMzM/+J95Bh591LZt1So/9E84wd4/0ua7bdvsPE/ehYJffpl/rUWtWtYkePHF1iQY7aFBGje2nfjQob9ep2qff3jwh+8I9u61+tSqZaGf97jgfN7jmjXtYGPHjoOn7dsPnv/uu/xlubnQu7cNrNi/v/VkS0ys8I8JiCzo5wAdRKQtFvDDgYsLbLMWOAV4UUQ6AQnAZlU9MW+DsCN6D3l3WGrUyO+BMX68herHH+cH/7hxtl39+nDVVfC739mRf0UJP7Jr2bL47ctC9eoWHH36wJ13WnDNn5/fY+qTT+yEPFhQ9e6dH/x9+9rOb/duG+E1L9DnzLHzKHk6drTzM7162fO7d7fXqgpE7N9D/fq2c4x1xQa9qu4XkVHADKzr5CRVXSwiE4C5qjoNGAM8JyKjsROzV2hxbULOlVBSkh1h5x1lb9kCS5ZYGOV1/Yw1NWrkj8V04422bN06azrIC/8HHsi/GK5lSztSz+s+27y5fX5XXmmvkZpqIemCIaIfk6E+8dMLLBsX9ngJ0K+Y1xhfgvI5V6xGjay3ijtYy5Y2XXihzf/8szXLfPaZHf23b2/h3quXdXt1weVXxjoXI2rXth2i7xRjT4AuO3DOOVcYD3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAs4D3rnnAu4iIJeRAaLyHIRWSUiYwtZ30pEMkTkKxFZICJnhJafKiKZIrIw9HdgWVfAOefcoVUvbgMRqQY8BZwKZAFzRGSaqi4J2+xPwBRVnSginYHpQBtgC3C2qm4QkS7ADKB5GdfBOefcIURyRN8bWKWqq1V1L5AOnFtgGwXqhh7XAzYAqOpXqrohtHwxUEtEapa+2M455yJV7BE9dgS+Lmw+C+hTYJvxwHsicj2QCAwq5HXOB+ap6p4SlNM551wJiaoeegORYcBgVb0qNH8p0EdVR4Vtc3PotR4Skb7AP4AuqpobWn8sMA04TVW/KeQ9RgIjAZKTk1PS09MByM7OJikpqfS1rIJiue4Q2/WP5bpDbNe/NHVPS0vLVNXUQleq6iEnoC8wI2z+duD2AtssBlqGza8GmoQetwBWAP2Key9VJSUlRfNkZGRorIrluqvGdv1jue6qsV3/0tQdmKtF5GokbfRzgA4i0lZEagDDsaPzcGuBUwBEpBOQAGwWkfrAf4CxqvppZPsl55xzZanYoFfV/cAorMfMUqx3zWIRmSAi54Q2GwNcLSLzgVeBK0J7mFHAUcA4Efk6NDUpl5o455wrVCQnY1HV6ViXyfBl48IeLwH6FfK8u4G7S1lG55xzpeBXxjrnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMB50DvnXMBFFPQiMlhElovIKhEZW8j6ViKSISJficgCETkjbN3toectF5HTy7Lwzjnnile9uA1EpBrwFHAqkAXMEZFpqrokbLM/AVNUdaKIdAamA21Cj4cDxwJHAh+ISEdVPVDWFXHOOVe4SI7oewOrVHW1qu4F0oFzC2yjQN3Q43rAhtDjc4F0Vd2jqt8Cq0Kv55xzroIUe0QPNAfWhc1nAX0KbDMeeE9ErgcSgUFhz/28wHObF3wDERkJjARITk5m1qxZAGRnZ//yONbEct0htusfy3WH2K5/edU9kqCPxAjgRVV9SET6Av8UkS6RPllVnwWeBUhNTdUBAwYAMGvWLPIex5pYrjvEdv1jue4Q2/Uvr7pHEvTrgZZh8y1Cy8L9HhgMoKqzRSQBaBThc51zzpWjSNro5wAdRKStiNTATq5OK7DNWuAUABHpBCQAm0PbDReRmiLSFugAfFlWhXfOOVe8Yo/oVXW/iIwCZgDVgEmqulhEJgBzVXUaMAZ4TkRGYydmr1BVBRaLyBRgCbAfuM573DjnXMWKqI1eVadjXSbDl40Le7wE6FfEc+8B7ilFGZ1zzpWCXxnrnHMB50HvnHMB50HvnHMB50HvnHMB50HvnHMB50HvnHMB50HvnHMB50HvnHMB50HvnHMB50HvnHMBF5ygz82FjAxYuhS2bwfVaJfIOecqhbIajz76tmyBgQPz5xMSoGlTm5o1K/pvkyYQHx+9cjvnXDkLTtDXrQv/+x/88AN8//3Bf1esgA8/hB9//PXzkpJgzBib6tSp+HI751w5C07QJyRAWtqht9mzBzZuPHgn8P77cNddMHEijBsHV18NNWpUTJmdc64CBKeNPhI1a0KrVtC7N5x7LlxzDUydCl98AZ06wahR0LkzvPaatfk751wAxFbQF6V3bzuRO3061K4Nw4dDnz7WFOScc1WcB30eERgyBL76Cl56CTZtglNOsWXz50e7dM45V2Ie9AVVqwaXXQbLl8ODD1qzTo8ecOmlsGZNtEvnnHOHzYO+KAkJ1hNn9Wq47TZryz/6aLj5Zti6Ndqlc865iHnQF6d+fbj3Xli50o7qH3sMjj0WPvoo2iVzzrmIeNBHqkULeP55mDcP6tWzi7MeesivwHXOVXoe9IfruONgzhzrnnnLLXDBBbBzZ7RL5ZxzRYoo6EVksIgsF5FVIjK2kPWPiMjXoWmFiGwPW3e/iCwWkaUi8riISFlWICrq1rU2+wcfhLfesu6ZixdHu1TOOVeoYoNeRKoBTwFDgM7ACBHpHL6Nqo5W1e6q2h14Angj9NwTgH5AN6AL0As4uUxrEC0idrJ25kwbRK13b3j11WiXyjnnfiWSI/rewCpVXa2qe4F04NxDbD8CyEs8BRKAGkBNIB7YWPLiVkInn2zt9j16wMUXww03wN690S6Vc879QrSYk4kiMgwYrKpXheYvBfqo6qhCtm0NfA60UNUDoWUPAlcBAjypqncW8ryRwEiA5OTklPT0dACys7NJSkoqee0qkOzfT7u//52WU6ey49hjWfznP7O3ceMSv15Vqnt5iOX6x3LdIbbrX5q6p6WlZapqaqErVfWQEzAMeD5s/lIssAvb9jbgibD5o4D/AEmhaTZw4qHeLyUlRfNkZGRolfPaa6qJiapNmqj+738lfpkqWfcyFMv1j+W6q8Z2/UtTd2CuFpGrkTTdrAdahs23CC0rzHDym20AfgN8rqrZqpoNvAv0jeA9q64LL7ReOUccAYMGwf33exdM51xURRL0c4AOItJWRGpgYT6t4EYicgzQADtqz7MWOFlEqotIPHYidmnpi13JdeoEX34J559vV9Wedx6sL2rf6Jxz5avYoFfV/cAoYAYW0lNUdbGITBCRc8I2HQ6kh35C5JkKfAMsBOYD81X132VW+sqsTh0b7viRR+Cdd6BlSxgwAJ55BjZvjnbpnHMxJKIbj6jqdGB6gWXjCsyPL+R5B4BrSlG+qk0EbroJzjoLJk+27pd/+IONez9okA2HPHSoDbPgnHPlxK+MrQhHHWV3r1qyxIY8vvVWu73hlVdCcrKFfXo67NoV7ZI65wLIg74iiUC3bvDXv8I339gQyNddZydvR4yAxo3hoovgzTeJ8774zrky4kEfLSJ2Ne3DD8O6dXbz8iuusLtanXcefS+4wO545ZxzpeRBXxnExcFJJ8HTT9tNy2fMIKdJE2vb9+6ZzrlS8qCvbKpXh9NO46vHH4dhw6x75qWXwu7d0S6Zc66K8qCvpHJr1bLumXffDa+8YmPqeF9851wJeNBXZiJw5502FPLSpdCrl53Adc65w+BBXxWcey7Mnm33sT35ZHj55WiXyDlXhXjQVxVdulg3zBNOgMsvhz/+EQ4ciHapnHNVgAd9VdKwIcyYYX3vH3zQeuVs317885xzMS2iIRBcJRIfD08+aRdeXXcd9OkD06bB0UdH9vyff7arcpcvhzVrbGdx7LHlWmTnXHR50FdVI0faKJnnnWdhn54OgwfbOlXIyrIwX74cli3Lf7x27cGvM2GCtfmff37F18E5VyE86KuyE0+EuXPtZO2ZZ9rR+bp1Fug//5y/XVISHHOMbX/00flTnTpwySXWX3/cOPjzn+3iLedcoHjQV3WtW8Onn8K119rfDh2sZ054oDdrZl01C5ORYSNqTpgACxfCSy/ZDsA5Fxge9EGQmGgBXRIJCTBpEhx3HIwZY7163n4b2rUr2zI656LGf6e7/HHz//tfu/q2Vy8bXM05Fwge9C7fqafaLRCTk+G006x3jw+o5lyV50HvDnbUUfD553DGGXD99da7x8fGd65K86B3v1a3ro2vc8cd8PzzMHAgbNwY7VI550rIT8a6wsXFwT332IVZV14JqakW/ikphW+/bx98953dOavglJwMTz0V+UVdzrky5UHvDu2ii6zL5tCh0L8/PPaYDcVQMMzXroXc3Pzn1aplPXfatbNunz16wN/+Zlfzel995yqUB70rXs+eNqDa+efDNdfkL2/YENq3h7594be/tcd5U3jf/e+/h6uughtusK6bL7wALVtGpy7OxaCIgl5EBgOPAdWA51X1vgLrHwHSQrO1gSaqWj+0rhXwPNASUOAMVV1TJqV3FSc52bpcfvhhfsDXqxfZc5s1g3fesfb+0aOha1d44gnbORR1IZdzrswU+xtaRKoBTwFDgM7ACBHpHL6Nqo5W1e6q2h14AngjbPXLwAOq2gnoDWwqq8K7ClajhnXB7Nkz8pDPIwJXXw0LFljQX3aZDb2weXP5lNU594tIGkt7A6tUdbWq7gXSgXMPsf0I4FWA0A6huqq+D6Cq2ar68yGe64KuXTuYNctuev7OOzbO/rRp0S6Vc4EmWswFMSIyDBisqleF5i8F+qjqqEK2bQ18DrRQ1QMiMhS4CtgLtAU+AMaq6oECzxsJjARITk5OSU9PByA7O5ukpKTS1bCKioW6J65ezTH33kudVav4fsgQVl13HQcSE4HYqH9RYrnuENv1L03d09LSMlU1tdCVqnrICRiGtcvnzV8KPFnEtrcBTxR47g6gHXY+4HXg94d6v5SUFM2TkZGhsSpm6r5nj+qdd6rGxam2bq0aqnfM1L8QsVx31diuf2nqDszVInI1kqab9diJ1DwtQssKM5xQs01IFvC1WrPPfuAtoGcE7+liRY0acPfd8Mkn9jgtDW6+mbg9e6JdMucCI5KgnwN0EJG2IlIDC/NfNaqKyDFAA2B2gefWF5HGofmBwJLSFdkFUt++8NVX1s/+kUc4fsQI63e/c2e0S+ZclVds0IeOxEcBM4ClwBRVXSwiE0TknLBNhwPpoZ8Qec89ANwCzBSRhYAAz5VlBVyAJCbaQGoffUR2+/Ywdiy0agV33gmbvLOWcyUVUT96VZ0OTC+wbFyB+fFFPPd9oFsJy+di0YknsuCBBxhQpw7cdx/cey88/DD8/vdwyy3Qpk20S+hcleLXorvKKyUF/t//s3veXnIJPPusja552WWweHG0S+dcleFB7yq/jh3tqtrVq20Yhddft/73Q4fakMrOuUPyoHdVR4sW1oSzdq3dyPyjj+wkbloaTJ9uY+ocOFD86zgXY3xQM1f1NGwI48dbe/1zz8FDD8GZZ9q6atVsbJ0jj4TmzX895S33G6C7GOJB76qupCQbJO3aa2HmTBsPf/36/Gn5chuIbceOXz+3Th0bjiElxcbaT021sfdr1qz4ejhXzjzoXdVXs6bd+rAou3ZZ8G/Y8OsdwbRpMGmSbRcfb23/ecGfmmrzNWpUTD2cKyce9C74EhPthG7Hjr9ep2pt/pmZMHeuTVOnWpMQWMgfd1x+8J99NjRu/OvXca4S86B3sU0EWre26bzzbJkqfPttfvBnZsIrr8DEiXZ+4O9/t5uwOFdFeK8b5woSsfb7Cy+04ZRnzoRt2yzw27SxcfQvuwy2b492SZ2LiAe9c5GIi7MbrsyebV07J0+2G6h88EG0S+ZcsTzonTsc8fHWtXP2bGv7P/VUu4jrZ7+fjqu8POidK4levWy0zRtvtPvf9ugBX34Z7VI5VygPeudKqlYtePRRa8PfvRtOOAHGjYN9+6JdMucO4kHvXGkNHAgLF9rAa3/5Cxx/PCzx2y64ysOD3rmyUK8evPSSDbi2dq2duH34YcjNjXbJnPOgd65MnXceLFoEp50GY8bYgGtTpsCPP0a7ZC6GedA7V9aSk+Htt21ohUWL4KKL7Gravn3hrrtsaOWyGmVz40Y7R7BuXdm8ngskD3rnyoMIXHmlBfGnn9rtEHNzLej79oUmTWwH8MILNgZPcfbsga+/hpdftlE7Tz3VdihNm8KgQTa8wz332HbOFeBDIDhXnqpXt944J5wAEybAli12kdWMGTZNmWLbde0Kp58OgwdTc+tW+O9/YcECm+bPt7ts7d9v29asaYOtnXmmjcNz9NH26+FPf7IdwZNP2o7AuRAPeucqUqNGMHy4TarWW2fGDAv2xx+HBx+kb/j2LVtamJ9zjg2j3K0bdOhgO5Bwgwfb64waZecHLrzQTgY3b16RtXOVlAe9c9Eikh/ef/yjDac8axYr3n+fjuedZ0f5DRpE/nqnn247jvvvh7/+1e66ddddcP31dkWvi1neRu9cZZGYCGeeyYahQ+Gkkw4v5PMkJNhFW4sX22uMGWM3V/nkk7Ivr6syIgp6ERksIstFZJWIjC1k/SMi8nVoWiEi2wusrysiWSLyZFkV3Dl3CO3bwzvvwJtv2iibJ55oJ4c3bYp2yVwUFBv0IlINeAoYAnQGRohI5/BtVHW0qnZX1e7AE8AbBV7mL8BHZVNk51xERGDoUFi6FMaOhX/9y07cTpzoN1GPMZEc0fcGVqnqalXdC6QD53P8LwwAAA6zSURBVB5i+xHAq3kzIpICJAPvlaagzrkSSkyEe++13jvdu9s9do8/Ht54w8fliRGiqofeQGQYMFhVrwrNXwr0UdVRhWzbGvgcaKGqB0QkDvgf8FtgEJBaxPNGAiMBkpOTU9LT0wHIzs4mKSmpFNWrumK57hDb9S/XuqvSZOZM2j37LAmbN7O3QQO+HzKE7884g5xK0kPHv/uS1T0tLS1TVVMLXamqh5yAYcDzYfOXAk8Wse1twBNh86OAW0OPryjqeeFTSkqK5snIyNBYFct1V43t+ldI3fftU502TfXss1Xj4lRBdeBA1fR01Zyc8n//Q/DvvmSAuVpErkbSdLMeaBk23yK0rDDDCWu2AfoCo0RkDfAgcJmI3BfBezrnylP16naj82nTbBC2v/wFvvnG+vc3b269dZYti3YpXRmJpB/9HKCDiLTFAn44cHHBjUTkGKABMDtvmapeErb+Cqzp5le9doqzb98+srKyyMnJOdynVkkJCQmISLSL4WJF8+Z2Ve0dd9hVu889ZxdvPfww9O8PI0fafXJr1Yp2SV0JFRv0qrpfREYBM4BqwCRVXSwiE7CfCtNCmw4H0kM/IcpUVlYWderUoU2bNoEPQFVl69atJCYmRrsoLtbExdlVtaedZmP0vPQSPP+83Qj9hhvgggvsJG5KCnTu7BdhVSERXRmrqtOB6QWWjSswP76Y13gRePGwSheSk5MTEyEPICI0bNiQdT4aoYum5GS49Va7YvfDD+0oPz3d/oKNt9Otm4V+SoqNv9+lC9SoEd1yu0JVmSEQYiHk88RSXV0lJwIDBtiUmwurVkFmpk3z5sGrr8Izz9i2NWrYsA09e+bvALp18/CvBKpM0DvnoiwuzoZD7tgRRoywZbm5sHp1fvBnZsLUqflH/g0b2i0Wr7jCbqDuosLHuonQ9u3befrppw/7eWeccQbbt28vfkPnqqK4ODjqKBtb/29/s5O5W7da+L/2Gpxyih3x9+xpF2s9+qgPwxAFHvQRKiro9+eNEV6E6dOnU79+/fIqlnOVjwi0bWtDJb/2Gnz/PTz1lDXhjB5tvXyGDoW33oK9e6Nd2phQ9ZpubrrJ7rRTlvKONA5h7NixfPPNN3Tv3p34+HgSEhJo0KABy5YtY8WKFQwdOpR169aRk5PDjTfeyMiRIwFo06YNc+fOJTs7myFDhtC/f38+++wzmjdvzttvv00t77Lmgu6II2zYhWuvtVE1X3oJ/vlPu91io0bw299a085xx0W7pIHlR/QRuu+++2jfvj1ff/01DzzwAPPmzeOxxx5jxYoVAEyaNInMzEzmzp3L448/ztatW3/1GitXruS6665j8eLF1K9fn9dff72iq+FcdB17rI2Xv26dja45YAA8/bQdbPXoAY89RvyOHdEuZeBUvSP6Yo68K0rv3r1p27btL/OPP/44b775JgDr1q1j5cqVNGzY8KDntG3blu7duwOQkpLCmjVrKqy8zlUq1avbrRDPPNPa9NPT4cUX4aab6BsfD+edB1ddBQMH2nkAVyr+CZZQ+AVNs2bN4oMPPmD27NnMnz+fHj16FHoVb82aNX95XK1atWLb952LCQ0bwnXXwZw5sGABG845B95/3+5727493H03ZGVFu5RVmgd9hOrUqcNPP/1U6LodO3bQoEEDateuzbJly/j8888ruHTOBUTXrqwaNQrWr7c++u3bw//9H7RuDWedZSdwfWjlw1b1mm6ipGHDhvTr148uXbpQq1YtkpOTf1k3ePBgnnnmGTp16sTRRx/N8ccfH8WSOhcACQn5N1FfvRomTYIXXoDf/AaaNrWTt7/7nd0ovTi5ubBjB2zZYs1EP/5o5wSOPLLcq1FZeNAfhsmTJxe6vGbNmrz77ruFrstrh2/UqBGLFi36Zfktt9xS5uVzLpDatbPmm/Hj4d13bfydBx6A++6zk7nnngu7d1uIFzb9+KOFfbjGjeHzz+21Y4AHvXOuasgbWvnss2HDBuum+Y9/WN98sNE1GzbMn7p1y3/cqFH+YxHr0jlkCHz2mS0LOA9651zVc+SRcPvtcNttNtJm/fqHN4zy22/DoEFwzjl2NW/Ar2fxk7HOuaorLg6aNTv8oO7f3y7a+uwzG4a5YNNOwHjQO+di0wUXwIMP2iBst94a7dKUK2+6cc7FrptvhjVr4KGHrAvn9ddHu0TlwoPeORe7ROxq+3Xr4MYboVUr68UTMN50U06SkpIA2LBhA8OGDSt0mwEDBjB37tyKLJZzrqBq1WDyZOjVy8bZ/+KLqBVFymk0Tw/6cnbkkUcyderUaBfDOXcotWvDv/9tJ3bPPhu++abi3nvjRrsZ+/HH02XcuOK3L4Eq13QTpVGKGTt2LC1btuS6664DYPz48VSvXp2MjAy2bdvGvn37uPvuuzm3wM++NWvWcNZZZ7Fo0SJ2797NlVdeyfz58znmmGPYvXt32VbEOVdyTZrYBVl9++b3sW/UqHzea+dOePNN+yXxwQfW66d7d7adcALl0avfj+gjdNFFFzFlypRf5qdMmcLll1/Om2++ybx588jIyGDMmDGoapGvMXHiRGrXrs3SpUu56667yMzMrIiiO+ci1bEjTJsGa9fmX3FbVnJy4I03YNgw26lccYXdg/eOO2yc/q++IuuCC8ru/cJUuSP6aI1S3KNHDzZt2sSGDRvYvHkzDRo0oGnTpowePZqPPvqIuLg41q9fz8aNG2natGmhr/HRRx9xww03ANCtWze6detWkVVwzkWiXz/417/sDlmXXWZ3ySrpUMkHDkBGhh25v/66Hck3aQLXXAMXXwy9e9sJ4XIWUdCLyGDgMaAa8Lyq3ldg/SNAWmi2NtBEVeuLSHdgIlAXOADco6qvlVXhK9oFF1zA1KlT+eGHH7jooot45ZVX2Lx5M5mZmcTHx9OmTZtChyd2zlUxw4ZZH/sxY6yP/YMPFv+c3Fy7beK339o0dy5MmQI//AB16sD551u4p6XZcA4VqNh3E5FqwFPAqUAWMEdEpqnqkrxtVHV02PbXA3m3e/8ZuExVV4rIkUCmiMxQ1Sp5t+yLLrqIq6++mi1btvDhhx8yZcoUmjRpQnx8PBkZGXz33XeHfP5JJ53E5MmTGThwIIsWLWLBggUVVHLn3GEbPfrgPvajRtkgaXlBHj6tWQPffQd79uQ/v0YNG1r54ovhjDOiOsxCJLuV3sAqVV0NICLpwLnAkiK2HwH8GUBVV+QtVNUNIrIJaAxUyaA/9thj+emnn2jevDnNmjXjkksu4eyzz6Zr166kpqZyzDHHHPL5f/jDH7jyyivp1KkTnTp1IiUlpYJK7pw7bCLwyCP5fezvuAOysw/epmFDuxF6t27Wpt+2bf7UurUNt1wJyKFOHgKIyDBgsKpeFZq/FOijqqMK2bY18DnQQlUPFFjXG3gJOFZVcwusGwmMBEhOTk5JT08HIDs7m6SkJOrVq8dRRx1VwipWTStXrmTnzp3RLkbU5H33sSiW6w6Vr/5xOTm0efFF4vbtI6dZM3Y3bUpOs2bkNG3KgbA7zZWF0tQ9LS0tU1VTC1tX1g1Fw4GphYR8M+CfwOUFQx5AVZ8FngVITU3VAQMGAHaLvgEDBrB06VLq1KlTxkWt3ESEvM8hFuV997EolusOlbT+gwdXyNuUV90jOZW8HmgZNt8itKwww4FXwxeISF3gP8Cdqur32HPOuQoWSdDPATqISFsRqYGF+bSCG4nIMUADYHbYshrAm8DLqlqqy0OLa2IKkliqq3Ou/BUb9Kq6HxgFzACWAlNUdbGITBCRc8I2HQ6k68EpdSFwEnCFiHwdmrofbiETEhLYunVrTASgqrJ161YOHDhQ/MbOOReBiNroVXU6ML3AsnEF5scX8rx/Af8qRfkAaNGiBVlZWWzevLm0L1UlJCQksGvXrmgXwzkXEFXiytj4+Hjatm0b7WJUqOL65DvnXKR8rBvnnAs4D3rnnAs4D3rnnAu4Yq+MrWgishnIa6BuBGyJYnGiKZbrDrFd/1iuO8R2/UtT99aq2riwFZUu6MOJyNyiLukNuliuO8R2/WO57hDb9S+vunvTjXPOBZwHvXPOBVxlD/pno12AKIrlukNs1z+W6w6xXf9yqXulbqN3zjlXepX9iN4551wpedA751zAVcqgF5HBIrJcRFaJyNhol6eiicgaEVkYGu1zbrTLU95EZJKIbBKRRWHLjhCR90VkZehvg2iWsbwUUffxIrI+bMTXM6JZxvIiIi1FJENElojIYhG5MbQ88N/9IepeLt99pWujD92MfAVhNyMHRoTfjDzoRGQNkKqqMXHRiIicBGRj9y3oElp2P/Cjqt4X2tk3UNXbolnO8lBE3ccD2ar6YDTLVt5Cd55rpqrzRKQOkAkMBa4g4N/9Iep+IeXw3VfGI/pfbkauqnuBvJuRu4BS1Y+AHwssPhe7xzChv0MrtFAVpIi6xwRV/V5V54Ue/4Td76I5MfDdH6Lu5aIyBn1zYF3YfBbl+AFUUgq8JyKZoRunx6JkVf0+9PgHIDmahYmCUSKyINS0E7imi4JEpA3QA/iCGPvuC9QdyuG7r4xB76C/qvYEhgDXhX7ex6zQXcsqVxtj+ZoItAe6A98DD0W3OOVLRJKA14GbVHVn+Lqgf/eF1L1cvvvKGPSHczPyQFLV9aG/m7B77vaObomiYmOoHTOvPXNTlMtTYVR1o6oeUNVc4DkC/P2LSDwWdK+o6huhxTHx3RdW9/L67itj0Ed0M/KgEpHE0MkZRCQROA1YdOhnBdI04PLQ48uBt6NYlgqVF3IhvyGg37+ICPAPYKmqPhy2KvDffVF1L6/vvtL1ugEIdSl6FKgGTFLVe6JcpAojIu2wo3iwWz1ODnr9ReRVYAA2ROtG4M/AW8AUoBU2bPWFqhq4k5ZF1H0A9tNdgTXANWFt1oEhIv2Bj4GFQG5o8R1YW3Wgv/tD1H0E5fDdV8qgd845V3YqY9ONc865MuRB75xzAedB75xzAedB75xzAedB75xzAedB75xzAedB75xzAff/AX71LpwcCZSKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************************************************\n",
            "\n"
          ]
        }
      ]
    }
  ]
}