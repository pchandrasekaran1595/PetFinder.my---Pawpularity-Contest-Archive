{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d682fe2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.013122,
     "end_time": "2021-10-08T21:19:34.710105",
     "exception": false,
     "start_time": "2021-10-08T21:19:34.696983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13781ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:34.815271Z",
     "iopub.status.busy": "2021-10-08T21:19:34.813853Z",
     "iopub.status.idle": "2021-10-08T21:19:34.816696Z",
     "shell.execute_reply": "2021-10-08T21:19:34.817176Z",
     "shell.execute_reply.started": "2021-10-08T21:11:58.494935Z"
    },
    "papermill": {
     "duration": 0.094909,
     "end_time": "2021-10-08T21:19:34.817476",
     "exception": false,
     "start_time": "2021-10-08T21:19:34.722567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "notebook_start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd230674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:34.848041Z",
     "iopub.status.busy": "2021-10-08T21:19:34.847457Z",
     "iopub.status.idle": "2021-10-08T21:19:40.169158Z",
     "shell.execute_reply": "2021-10-08T21:19:40.168222Z",
     "shell.execute_reply.started": "2021-10-08T21:12:17.268484Z"
    },
    "papermill": {
     "duration": 5.339471,
     "end_time": "2021-10-08T21:19:40.169330",
     "exception": false,
     "start_time": "2021-10-08T21:19:34.829859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import random as r\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from torch.nn.utils import weight_norm as WN\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b207b",
   "metadata": {
    "papermill": {
     "duration": 0.012659,
     "end_time": "2021-10-08T21:19:40.194774",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.182115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Constants and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4bb5c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.266896Z",
     "iopub.status.busy": "2021-10-08T21:19:40.265976Z",
     "iopub.status.idle": "2021-10-08T21:19:40.269129Z",
     "shell.execute_reply": "2021-10-08T21:19:40.268699Z",
     "shell.execute_reply.started": "2021-10-08T21:14:45.479313Z"
    },
    "papermill": {
     "duration": 0.062257,
     "end_time": "2021-10-08T21:19:40.269265",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.207008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATH = \"../input/petfinder-pawpularity-score\"\n",
    "FEATURES_PATH = \"../input/petfinder-pretrained-features-ua-all\"\n",
    "MODEL_NAME = \"densenet169\"\n",
    "\n",
    "sc_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2359e23b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.304396Z",
     "iopub.status.busy": "2021-10-08T21:19:40.303630Z",
     "iopub.status.idle": "2021-10-08T21:19:40.306055Z",
     "shell.execute_reply": "2021-10-08T21:19:40.305637Z",
     "shell.execute_reply.started": "2021-10-08T21:14:45.629648Z"
    },
    "papermill": {
     "duration": 0.024594,
     "end_time": "2021-10-08T21:19:40.306158",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.281564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def breaker(num=50, char=\"*\") -> None:\n",
    "    print(\"\\n\" + num*char + \"\\n\")\n",
    "\n",
    "\n",
    "def head(x, no_of_ele=5) -> None:\n",
    "    print(x[:no_of_ele])\n",
    "\n",
    "\n",
    "def get_targets(path: str) -> np.ndarray:\n",
    "    df = pd.read_csv(os.path.join(path, \"train.csv\"), engine=\"python\")\n",
    "    targets  = df.iloc[:, -1].copy().values\n",
    "    return targets\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i] = (x[i] - torch.min(x[i])) / (torch.max(x[i]) - torch.min(x[i]))\n",
    "    return x\n",
    "\n",
    "\n",
    "def show_graphs(L: list) -> None:\n",
    "    TL, VL = [], []\n",
    "    for i in range(len(L)):\n",
    "        TL.append(L[i][\"train\"])\n",
    "        VL.append(L[i][\"valid\"])    \n",
    "    \n",
    "    x_Axis = np.arange(1, len(L) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(x_Axis, TL, \"r\", label=\"train\")\n",
    "    plt.plot(x_Axis, VL, \"b\", label=\"valid\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title(\"MSE Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d37a35",
   "metadata": {
    "papermill": {
     "duration": 0.011623,
     "end_time": "2021-10-08T21:19:40.329950",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.318327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7d3189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.360927Z",
     "iopub.status.busy": "2021-10-08T21:19:40.360155Z",
     "iopub.status.idle": "2021-10-08T21:19:40.362491Z",
     "shell.execute_reply": "2021-10-08T21:19:40.362059Z",
     "shell.execute_reply.started": "2021-10-08T21:14:45.913701Z"
    },
    "papermill": {
     "duration": 0.019386,
     "end_time": "2021-10-08T21:19:40.362591",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.343205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, features=None, targets=None):\n",
    "        self.features = features\n",
    "        self.targets  = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.features[idx]), torch.FloatTensor(self.targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f857da",
   "metadata": {
    "papermill": {
     "duration": 0.011731,
     "end_time": "2021-10-08T21:19:40.386026",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.374295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6781c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.416107Z",
     "iopub.status.busy": "2021-10-08T21:19:40.413043Z",
     "iopub.status.idle": "2021-10-08T21:19:40.418620Z",
     "shell.execute_reply": "2021-10-08T21:19:40.419015Z",
     "shell.execute_reply.started": "2021-10-08T21:16:41.409116Z"
    },
    "papermill": {
     "duration": 0.020776,
     "end_time": "2021-10-08T21:19:40.419140",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.398364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataloaders(tr_features: np.ndarray, va_features: np.ndarray,\n",
    "                      tr_targets: np.ndarray, va_targets: np.ndarray,\n",
    "                      batch_size: int, seed: int):\n",
    "\n",
    "    # breaker()\n",
    "    # print(\"Building Train and Validation DataLoaders ...\")\n",
    "    \n",
    "    tr_data_setup = DS(features=tr_features, targets=tr_targets)\n",
    "    va_data_setup = DS(features=va_features, targets=va_targets)\n",
    "    \n",
    "    dataloaders = {\n",
    "        \"train\" : DL(tr_data_setup, batch_size=batch_size, shuffle=True, generator=torch.manual_seed(seed)),\n",
    "        \"valid\" : DL(va_data_setup, batch_size=batch_size, shuffle=False)\n",
    "    }\n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0b796",
   "metadata": {
    "papermill": {
     "duration": 0.012136,
     "end_time": "2021-10-08T21:19:40.444098",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.431962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df0303b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.478184Z",
     "iopub.status.busy": "2021-10-08T21:19:40.472047Z",
     "iopub.status.idle": "2021-10-08T21:19:40.480130Z",
     "shell.execute_reply": "2021-10-08T21:19:40.480551Z",
     "shell.execute_reply.started": "2021-10-08T21:16:41.863148Z"
    },
    "papermill": {
     "duration": 0.023518,
     "end_time": "2021-10-08T21:19:40.480665",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.457147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(IL: int, seed: int):\n",
    "    class ANN(nn.Module):\n",
    "        def __init__(self, IL=None):\n",
    "            super(ANN, self).__init__()\n",
    "\n",
    "            self.predictor = nn.Sequential()\n",
    "            self.predictor.add_module(\"BN\", nn.BatchNorm1d(num_features=IL, eps=1e-5))\n",
    "            self.predictor.add_module(\"FC\", WN(nn.Linear(in_features=IL, out_features=1)))\n",
    "\n",
    "        def get_optimizer(self, lr=1e-3, wd=0):\n",
    "            params = [p for p in self.parameters() if p.requires_grad]\n",
    "            return optim.Adam(params, lr=lr, weight_decay=wd)\n",
    "\n",
    "        def get_plateau_scheduler(self, optimizer=None, patience=5, eps=1e-8):\n",
    "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=patience, eps=eps, verbose=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.predictor(x)\n",
    "    \n",
    "    # breaker()\n",
    "    # print(\"Building Model ...\")\n",
    "    # print(\"\\n{} -> 1\".format(IL))\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    model = ANN(IL=IL)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f85e3",
   "metadata": {
    "papermill": {
     "duration": 0.011839,
     "end_time": "2021-10-08T21:19:40.504315",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.492476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fit and Predict Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ebb582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.550482Z",
     "iopub.status.busy": "2021-10-08T21:19:40.535825Z",
     "iopub.status.idle": "2021-10-08T21:19:40.552570Z",
     "shell.execute_reply": "2021-10-08T21:19:40.553011Z",
     "shell.execute_reply.started": "2021-10-08T21:16:42.542049Z"
    },
    "papermill": {
     "duration": 0.036884,
     "end_time": "2021-10-08T21:19:40.553141",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.516257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model=None, optimizer=None, scheduler=None, \n",
    "        epochs=None, early_stopping_patience=None,\n",
    "        dataloaders=None, fold=None, seed=None, \n",
    "        verbose=False) -> tuple:\n",
    "    \n",
    "    name = \"./Seed_{}_Fold_{}_state.pt\".format(seed, fold)\n",
    "    \n",
    "    if verbose:\n",
    "        breaker()\n",
    "        print(\"Training Seed {}, Fold {}...\".format(seed, fold))\n",
    "        breaker()\n",
    "    else:\n",
    "        print(\"Training Seed {}, Fold {}...\".format(seed, fold))\n",
    "\n",
    "    Losses = []\n",
    "    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    start_time = time()\n",
    "    for e in range(epochs):\n",
    "        e_st = time()\n",
    "        epochLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            lossPerPass = []\n",
    "\n",
    "            for X, y in dataloaders[phase]:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    output = model(X)\n",
    "                    loss = torch.nn.MSELoss()(output, y)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                lossPerPass.append(loss.item())\n",
    "            epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
    "        Losses.append(epochLoss)\n",
    "        \n",
    "        if early_stopping_patience:\n",
    "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
    "                bestLoss = epochLoss\n",
    "                BLE = e + 1\n",
    "                torch.save({\"model_state_dict\": model.state_dict(),\n",
    "                            \"optim_state_dict\": optimizer.state_dict()},\n",
    "                           name)\n",
    "                early_stopping_step = 0\n",
    "            else:\n",
    "                early_stopping_step += 1\n",
    "                if early_stopping_step > early_stopping_patience:\n",
    "                    if verbose:\n",
    "                        print(\"\\nEarly Stopping at Epoch {}\".format(e))\n",
    "                    break\n",
    "        \n",
    "        if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
    "            bestLoss = epochLoss\n",
    "            BLE = e + 1\n",
    "            torch.save({\"model_state_dict\": model.state_dict(),\n",
    "                        \"optim_state_dict\": optimizer.state_dict()},\n",
    "                       name)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(epochLoss[\"valid\"])\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Time: {:.2f} seconds\".format(e+1, epochLoss[\"train\"], epochLoss[\"valid\"], time()-e_st))\n",
    "    \n",
    "    if verbose:\n",
    "        breaker()\n",
    "        print(\"Best Validation Loss at Epoch {}\".format(BLE))\n",
    "        breaker()\n",
    "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(len(Losses), (time()-start_time)/60))\n",
    "        breaker()\n",
    "        print(\"Training Completed\")\n",
    "        breaker()\n",
    "\n",
    "    return Losses, BLE, name\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "def predict_batch(model=None, dataloader=None, mode=\"test\", path=None) -> np.ndarray:\n",
    "    model.load_state_dict(torch.load(path, map_location=DEVICE)[\"model_state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = torch.zeros(1, 1).to(DEVICE)\n",
    "    if re.match(r\"valid\", mode, re.IGNORECASE):\n",
    "        for X, _ in dataloader:\n",
    "            X = X.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                output = model(X)\n",
    "            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n",
    "    elif re.match(r\"test\", mode, re.IGNORECASE):\n",
    "        for X in dataloader:\n",
    "            X = X.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                output = model(X)\n",
    "            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n",
    "    \n",
    "    return y_pred[1:].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5786698",
   "metadata": {
    "papermill": {
     "duration": 0.012696,
     "end_time": "2021-10-08T21:19:40.579390",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.566694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4248ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.618690Z",
     "iopub.status.busy": "2021-10-08T21:19:40.617646Z",
     "iopub.status.idle": "2021-10-08T21:19:40.619540Z",
     "shell.execute_reply": "2021-10-08T21:19:40.620021Z",
     "shell.execute_reply.started": "2021-10-08T21:17:44.957748Z"
    },
    "papermill": {
     "duration": 0.028022,
     "end_time": "2021-10-08T21:19:40.620163",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.592141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(features: np.ndarray, targets: np.ndarray,\n",
    "          n_splits: int, batch_size: int, lr: float, wd: float, \n",
    "          epochs: int, early_stopping: int, seed: int,\n",
    "          patience=None, eps=None) -> list:        \n",
    "    \n",
    "    metrics = []\n",
    "        \n",
    "    KFold_start_time = time()\n",
    "    # breaker()\n",
    "    # print(\"Performing {} Fold CV ...\".format(n_splits))\n",
    "    \n",
    "    fold = 1\n",
    "    for tr_idx, va_idx in KFold(n_splits=n_splits, shuffle=True, random_state=seed).split(features):\n",
    "\n",
    "        tr_features, va_features = features[tr_idx], features[va_idx]\n",
    "        tr_targets, va_targets   = targets[tr_idx], targets[va_idx]\n",
    "\n",
    "        tr_targets, va_targets   = tr_targets.reshape(-1, 1), va_targets.reshape(-1, 1)\n",
    "\n",
    "        tr_targets = sc_y.fit_transform(tr_targets)\n",
    "        va_targets = sc_y.transform(va_targets)\n",
    "\n",
    "        dataloaders = build_dataloaders(tr_features, va_features, \n",
    "                                         tr_targets, va_targets, \n",
    "                                         batch_size, seed)\n",
    "        model = build_model(IL=tr_features.shape[1], seed=seed)\n",
    "        \n",
    "        optimizer = model.get_optimizer(lr=lr, wd=wd)\n",
    "        scheduler = None\n",
    "        if isinstance(patience, int) and isinstance(eps, float):\n",
    "            scheduler = model.get_plateau_scheduler(optimizer, patience, eps)\n",
    "\n",
    "        L, _, name = fit(model=model, optimizer=optimizer, scheduler=scheduler, \n",
    "                         epochs=epochs, early_stopping_patience=early_stopping,\n",
    "                         dataloaders=dataloaders, fold=fold, seed=seed, verbose=False)\n",
    "        y_pred = predict_batch(model=model, dataloader=dataloaders[\"valid\"], mode=\"valid\", path=name)\n",
    "        RMSE = np.sqrt(mean_squared_error(sc_y.inverse_transform(y_pred), sc_y.inverse_transform(va_targets)))\n",
    "        # print(\"Validation RMSE [Fold {}]: {:.5f}\".format(fold, RMSE))\n",
    "        # breaker()\n",
    "        # show_graphs(L)\n",
    "        \n",
    "        metrics_dict = {\"Seed\" : seed, \"Fold\" : fold, \"RMSE\" : RMSE}\n",
    "        metrics.append(metrics_dict)\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    # breaker()\n",
    "    # print(\"Total Time to {} Fold CV : {:.2f} minutes\".format(n_splits, (time() - KFold_start_time)/60))\n",
    "    # breaker()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa180867",
   "metadata": {
    "papermill": {
     "duration": 0.012579,
     "end_time": "2021-10-08T21:19:40.645210",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.632631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdeefe39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:19:40.684499Z",
     "iopub.status.busy": "2021-10-08T21:19:40.680594Z",
     "iopub.status.idle": "2021-10-08T21:38:51.305581Z",
     "shell.execute_reply": "2021-10-08T21:38:51.306222Z",
     "shell.execute_reply.started": "2021-10-08T21:18:30.485939Z"
    },
    "papermill": {
     "duration": 1150.647858,
     "end_time": "2021-10-08T21:38:51.306455",
     "exception": false,
     "start_time": "2021-10-08T21:19:40.658597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 49, Fold 1...\n",
      "Training Seed 49, Fold 2...\n",
      "Training Seed 49, Fold 3...\n",
      "Training Seed 49, Fold 4...\n",
      "Training Seed 49, Fold 5...\n",
      "Training Seed 49, Fold 6...\n",
      "Training Seed 49, Fold 7...\n",
      "Training Seed 49, Fold 8...\n",
      "Training Seed 49, Fold 9...\n",
      "Training Seed 49, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 97, Fold 1...\n",
      "Training Seed 97, Fold 2...\n",
      "Training Seed 97, Fold 3...\n",
      "Training Seed 97, Fold 4...\n",
      "Training Seed 97, Fold 5...\n",
      "Training Seed 97, Fold 6...\n",
      "Training Seed 97, Fold 7...\n",
      "Training Seed 97, Fold 8...\n",
      "Training Seed 97, Fold 9...\n",
      "Training Seed 97, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 53, Fold 1...\n",
      "Training Seed 53, Fold 2...\n",
      "Training Seed 53, Fold 3...\n",
      "Training Seed 53, Fold 4...\n",
      "Training Seed 53, Fold 5...\n",
      "Training Seed 53, Fold 6...\n",
      "Training Seed 53, Fold 7...\n",
      "Training Seed 53, Fold 8...\n",
      "Training Seed 53, Fold 9...\n",
      "Training Seed 53, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 5, Fold 1...\n",
      "Training Seed 5, Fold 2...\n",
      "Training Seed 5, Fold 3...\n",
      "Training Seed 5, Fold 4...\n",
      "Training Seed 5, Fold 5...\n",
      "Training Seed 5, Fold 6...\n",
      "Training Seed 5, Fold 7...\n",
      "Training Seed 5, Fold 8...\n",
      "Training Seed 5, Fold 9...\n",
      "Training Seed 5, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 33, Fold 1...\n",
      "Training Seed 33, Fold 2...\n",
      "Training Seed 33, Fold 3...\n",
      "Training Seed 33, Fold 4...\n",
      "Training Seed 33, Fold 5...\n",
      "Training Seed 33, Fold 6...\n",
      "Training Seed 33, Fold 7...\n",
      "Training Seed 33, Fold 8...\n",
      "Training Seed 33, Fold 9...\n",
      "Training Seed 33, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 65, Fold 1...\n",
      "Training Seed 65, Fold 2...\n",
      "Training Seed 65, Fold 3...\n",
      "Training Seed 65, Fold 4...\n",
      "Training Seed 65, Fold 5...\n",
      "Training Seed 65, Fold 6...\n",
      "Training Seed 65, Fold 7...\n",
      "Training Seed 65, Fold 8...\n",
      "Training Seed 65, Fold 9...\n",
      "Training Seed 65, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 62, Fold 1...\n",
      "Training Seed 62, Fold 2...\n",
      "Training Seed 62, Fold 3...\n",
      "Training Seed 62, Fold 4...\n",
      "Training Seed 62, Fold 5...\n",
      "Training Seed 62, Fold 6...\n",
      "Training Seed 62, Fold 7...\n",
      "Training Seed 62, Fold 8...\n",
      "Training Seed 62, Fold 9...\n",
      "Training Seed 62, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 51, Fold 1...\n",
      "Training Seed 51, Fold 2...\n",
      "Training Seed 51, Fold 3...\n",
      "Training Seed 51, Fold 4...\n",
      "Training Seed 51, Fold 5...\n",
      "Training Seed 51, Fold 6...\n",
      "Training Seed 51, Fold 7...\n",
      "Training Seed 51, Fold 8...\n",
      "Training Seed 51, Fold 9...\n",
      "Training Seed 51, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 38, Fold 1...\n",
      "Training Seed 38, Fold 2...\n",
      "Training Seed 38, Fold 3...\n",
      "Training Seed 38, Fold 4...\n",
      "Training Seed 38, Fold 5...\n",
      "Training Seed 38, Fold 6...\n",
      "Training Seed 38, Fold 7...\n",
      "Training Seed 38, Fold 8...\n",
      "Training Seed 38, Fold 9...\n",
      "Training Seed 38, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Training Seed 61, Fold 1...\n",
      "Training Seed 61, Fold 2...\n",
      "Training Seed 61, Fold 3...\n",
      "Training Seed 61, Fold 4...\n",
      "Training Seed 61, Fold 5...\n",
      "Training Seed 61, Fold 6...\n",
      "Training Seed 61, Fold 7...\n",
      "Training Seed 61, Fold 8...\n",
      "Training Seed 61, Fold 9...\n",
      "Training Seed 61, Fold 10...\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    DEBUG = False\n",
    "    \n",
    "    r.seed(SEED)\n",
    "    \n",
    "    ########### Params ###########\n",
    "    \n",
    "    if DEBUG:\n",
    "        n_splits = 3\n",
    "        batch_size = 512\n",
    "        lr, wd = 1e-3, 0\n",
    "        patience, eps = 5, 1e-8\n",
    "        epochs, early_stopping = 5, 5\n",
    "        seeds = [r.randint(0, 99) for _ in range(2)]\n",
    "    else:\n",
    "        n_splits = 10\n",
    "        batch_size = 32\n",
    "        lr, wd = 1e-2, 0\n",
    "        patience, eps = 5, 1e-8\n",
    "        epochs, early_stopping = 100, 8\n",
    "        seeds = [r.randint(0, 99) for _ in range(10)]\n",
    "\n",
    "    complete_metrics = []\n",
    "    \n",
    "    ##############################\n",
    "\n",
    "    # breaker()\n",
    "    # print(\"Loading Data ...\")\n",
    "    \n",
    "    features = np.load(os.path.join(FEATURES_PATH, \"{}_features.npy\".format(MODEL_NAME)))\n",
    "    targets = get_targets(PATH)\n",
    "\n",
    "    for seed in seeds:\n",
    "        breaker()\n",
    "        \n",
    "        # Without Scheduler\n",
    "        metrics = train(features, targets, n_splits, batch_size, lr, wd, epochs, early_stopping, seed=seed, patience=None, eps=None)\n",
    "\n",
    "        # # With Plateau Scheduler\n",
    "        # metrics = train(features, targets, n_splits, batch_size, lr, wd, epochs, early_stopping, seed=seed, patience=patience, eps=eps)    \n",
    "        \n",
    "        complete_metrics.append(metrics)\n",
    "    \n",
    "    if DEBUG:\n",
    "        breaker()\n",
    "        for i in range(len(complete_metrics)):\n",
    "            for j in range(len(complete_metrics[i])):\n",
    "                print(complete_metrics[i][j])\n",
    "\n",
    "    with open(\"metrics.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(complete_metrics, fp)\n",
    "    \n",
    "    breaker()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c218933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T21:38:51.390908Z",
     "iopub.status.busy": "2021-10-08T21:38:51.389300Z",
     "iopub.status.idle": "2021-10-08T21:38:51.393279Z",
     "shell.execute_reply": "2021-10-08T21:38:51.392806Z",
     "shell.execute_reply.started": "2021-10-06T14:55:46.659053Z"
    },
    "papermill": {
     "duration": 0.047536,
     "end_time": "2021-10-08T21:38:51.393391",
     "exception": false,
     "start_time": "2021-10-08T21:38:51.345855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "\n",
      "Notebook Run Time : 19.28 minutes\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "breaker()\n",
    "print(\"Notebook Run Time : {:.2f} minutes\".format((time()-notebook_start_time)/60))\n",
    "breaker()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1164.915913,
   "end_time": "2021-10-08T21:38:52.977246",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-08T21:19:28.061333",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
